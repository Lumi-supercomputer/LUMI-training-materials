{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview of LUMI trainings","text":"<p>Most recently completed main training events:</p> <ul> <li> <p>4-day comprehensive LUMI training aimed at developers and advanced users:     Comprehensive general LUMI course (May 30 - June 2, 2023)</p> </li> <li> <p>1-day LUMI training aimed at regular users:     LUMI 1-day training (September, 2023)</p> </li> </ul>"},{"location":"#lumi-user-coffee-break-talks","title":"LUMI User Coffee Break Talks","text":"<p>In reverse chronological order:</p> <ul> <li>Current state of running AI workloads on LUMI (June 28, 2023)</li> </ul>"},{"location":"#archive-of-the-regular-trainings","title":"Archive of the regular trainings","text":"<p>In reverse chronological order:</p> <ul> <li>Comprehensive general LUMI course (October 3-6, 2023)</li> <li>LUMI 1-day training (September, 2023)</li> <li>Comprehensive general LUMI course (May 30 - June 2, 2023)</li> <li>LUMI 1-day training (May 9 and 16, 2023)</li> <li>LUMI-G hackathon (April 17-21, 2023)</li> <li>HPE and AMD profiling tools (April 13, 2023)</li> <li>Comprehensive general LUMI course (February 14-17, 2023)</li> <li>LUMI-G Training (January 11, 2023)</li> <li>Detailed introduction to the LUMI-C environment and architecture (November 23/24, 2022)</li> <li>LUMI-G Pilot Training (August 23, 2022)</li> <li>EasyBuild course for CSC and local organisations (May 9/11, 2022)</li> <li>Detailed introduction to the LUMI-C environment and architecture (April 27/28, 2022)</li> </ul>"},{"location":"#information-for-local-organisations","title":"Information for local organisations","text":"<p>The materials in the GitHub repository Lumi-supercomputer/LUMI-training-materials and all materials linked in this web site and served from 462000265.lumidata.eu that are presented by a member of LUST are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) license. This includes all of the material of the LUMI 1-day trainings series.</p> <p>Presentations given by AMD of which some material can be downloaded from this web site and from 462000265.lumidata.eu are copyrighted by AMD, or in cases where AMD is using material available in the public domain (e.g., for exercises), licensed under  the source license for that material. Using AMD copyrighted materials should be discussed with AMD.</p> <p>All presentation material presented by HPE is copyrighted by HPE and can only be shared with people who have an account on LUMI. Therefore that material is not available via this web site and can only be accessed on LUMI itself.</p>"},{"location":"1day-20230509/","title":"LUMI 1-day training May 2023","text":""},{"location":"1day-20230509/#organisation","title":"Organisation","text":"<ul> <li> <p>Schedule</p> </li> <li> <p>Questions from the Hedgedoc document of the 9 May 2020 session</p> <ul> <li>Original document on Hedgedoc (may disappear over time)</li> </ul> </li> <li> <p>Questions from the Hedgedoc document of the 16 May 2020 session</p> <ul> <li>Original document on Hedgedoc (may disappear over time)</li> </ul> </li> </ul>"},{"location":"1day-20230509/#setting-up-for-the-exercises","title":"Setting up for the exercises","text":"<ul> <li> <p>Create a directory in the scratch of the training project, or if you want to     keep the exercises around for a while after the session and have already     another project on LUMI, in a subdirectory or your project directory      or in your home directory (though we don't recommend the latter).     Then go into that directory.</p> <p>E.g., in the scratch directory of the project:</p> <pre><code>mkdir -p /scratch/project_465000523/$USER/exercises\ncd /scratch/project_465000523/$USER/exercises\n</code></pre> </li> <li> <p>Now download the exercises and un-tar:</p> <pre><code>wget https://462000265.lumidata.eu/1day-20230509/files/exercises-20230509.tar.gz\ntar -xf exercises-20230509.tar.gz\n</code></pre> <p>Link to the tar-file with the exercises</p> </li> <li> <p>You're all set to go!</p> </li> </ul>"},{"location":"1day-20230509/#downloads","title":"Downloads","text":"Presentation Slides Notes recording Introduction / / recording LUMI Architecture slides notes recording HPE Cray Programming Environment slides notes recording Modules on LUMI slides notes recording LUMI Software Stacks slides notes recording Exercises 1 / notes / Running Jobs on LUMI slides / recording Exercises 2 / notes / Introduction to Lustre and Best Practices slides / recording LUMI User Support slides / recording"},{"location":"1day-20230509/01_Architecture/","title":"The LUMI Architecture","text":"<p>In this presentation, we will build up LUMI part by part, stressing those aspects that are important to know to run on LUMI efficiently and define jobs that can scale.</p>"},{"location":"1day-20230509/01_Architecture/#lumi-is","title":"LUMI is ...","text":"<p>LUMI is a pre-exascale supercomputer, and not a superfast PC nor a compute cloud architecture.</p> <p>Each of these architectures have their own strengths and weaknesses and offer different  compromises and it is key to chose the right infrastructure for the job and use the right  tools for each infrastructure.</p> <p>Just some examples of using the wrong tools or infrastructure:</p> <ul> <li> <p>We've had users who were disappointed about the speed of a single core and were expecting     that this would be much faster than their PCs. Supercomputers however are optimised for      performance per Watt and get their performance from using lots of cores through well-designed     software. If you want the fastest core possible, you'll need a gaming PC.</p> </li> <li> <p>Even the GPU may not be that much faster for some tasks than GPUs in gaming PCs, especially since     an MI250x should be treated as two GPUs for most practical purposes. The better double precision     floating point operations and matrix operations, also at full precision, requires transistors also      that on some other GPUs are used for rendering hardware or for single precision compute units.</p> </li> <li> <p>A user complained that they did not succeed in getting their nice remote development environment to     work on LUMI. The original author of these notes took a test license and downloaded a trial version.     It was a very nice environment but really made for local development and remote development in a      cloud environment with virtual machines individually protected by personal firewalls and was      not only hard to get working on a supercomputer but also insecure.</p> </li> <li> <p>CERN came telling on a EuroHPC Summit Week before the COVID pandemic that they would start using more     HPC and less cloud and that they expected a 40% cost reduction that way. A few years later they     published a paper with their experiences and it was mostly disappointment. The HPC infrastructure     didn't fit their model for software distribution and performance was poor. Basically their solution     was designed around the strengths of a typical cloud infrastructure and relied precisely on those things     that did make their cloud infrastructure more expensive than the HPC infrastructure they tested. It relied     on fast local disks that require a proper management layer in the software, (ab)using the file system as     a database for unstructured data, a software distribution mechanism that requires an additional daemon     running permanently on the compute nodes (and local storage on those nodes), ...</p> </li> </ul> <p>True supercomputers, and LUMI in particular, are built for scalable parallel applications and features that are found on smaller clusters or on workstations that pose a threat to scalability are removed from the system. It is also a shred infrastructure but with a much more lightweight management layer than a cloud infrastructure and far less isolation between users, meaning that abuse by one user can have more of a negative impact on  other users than in a cloud infrastructure. Supercomputers since the mid to late '80s are also build according to the principle of trying to reduce the hardware cost by using cleverly designed software both at the system and application level. They perform best when streaming data through the machine at all levels of the  memory hierarchy and are not built at all for random access to small bits of data (where the definition of \"small\" depends on the level in the memory hierarchy).</p> <p>At several points in this course you will see how this impacts what you can do with a supercomputer and how you work with a supercomputer.</p>"},{"location":"1day-20230509/01_Architecture/#lumi-spec-sheet-a-modular-system","title":"LUMI spec sheet: A modular system","text":"<p>So we've already seen that LUMI is in the first place a EuroHPC pre-exascale machine. LUMI is built to prepare for the exascale era and to fit in the EuroHPC ecosystem.  But it does not even mean that it has to cater to all pre-exascale compute needs. The EuroHPC JU tries to build systems that have some flexibility, but also does not try to cover  all needs with a single machine. They are building 3 pre-exascale systems with different architecture to explore multiple architectures and to cater to a more diverse audience.</p> <p>LUMI is also a very modular machine designed according to the principles explored in a series of European projects, and in particular DEEP and its successors) that explored the cluster-booster concept.</p> <p>LUMI is in the first place a huge GPGPU supercomputer. The GPU partition of LUMI, called LUMI-G, contains 2560 nodes with a single 64-core AMD EPYC 7A53 CPU and 4 AMD MI250x GPUs. Each node has 512 GB of RAM attached to the CPU (the maximum the CPU can handle without compromising bandwidth) and 128 GB of HBM2e memory per GPU. Each GPU node has a theoretical peak performance of 200 TFlops in single (FP32) or double (FP64) precision vector arithmetic (and twice that with the packed FP32 format, but that  is not well supported so this number is not often quoted). The matrix units are capable of about 400 TFlops in FP32 or FP64. However, compared to the NVIDIA GPUs, the performance for lower precision formats used in some AI applications is not that stellar.</p> <p>LUMI also has a large CPU-only partition, called LUMI-C, for jobs that do not run well on GPUs, but also integrated enough with the GPU partition that it is possible to have applications that combine both node types. LUMI-C consists of 1536 nodes with 2 64-core AMD EPYC 7763 CPUs. 32 of those nodes have 1TB of RAM (with some of these nodes actually reserved for special purposes such as connecting to a Quantum computer), 128 have 512 GB and 1376 have 256 GB of RAM.</p> <p>LUMI also has a 7 PB flash based file system running the Lustre parallel file system. This system is often denoted as LUMI-F. The bandwidth of that system is 1740 GB/s.  Note however that this is still a remote file system with a parallel file system on it, so do not expect that it will behave as the local SSD in your laptop. But that is  also the topic of another session in this course.</p> <p>The main work storage is provided by 4 20 PB hard disk based Lustre file systems with a bandwidth of 240 GB/s each. That section of the machine is often denoted  as LUMI-P. </p> <p>Big parallel file systems need to be used in the proper way to be able to offer the performance that one would expect from their specifications. This is important enough that  we have a separate session about that in this course.</p> <p>Currently LUMI has 4 login nodes, called user access nodes in the HPE Cray world. They each have 2 64-core AMD EPYC 7742 processors and 1 TB of RAM. Note that  whereas the GPU and CPU compute nodes have the Zen3 architecture code-named \"Milan\", the processors on the login nodes are Zen2 processors, code-named \"Rome\". Zen3 adds some new instructions so if a compiler generates them, that code would not run on the login nodes. These instructions are basically used in cryptography though. However, many instructions have very different latency, so a compiler that optimises specifically for Zen3 may chose another ordering of instructions then when optimising for Zen2 so it may still make sense to compile specifically for the compute nodes on LuMI.</p> <p>All compute nodes, login nodes and storage are linked together through a  high-performance interconnect. LUMI uses the Slingshot 11 interconnect which is developed by HPE Cray, so not the Mellanox/NVIDIA InfiniBand that you may be familiar with from many smaller clusters, and as we shall discuss later this also influences how you work on LUMI.</p> <p>Some services for LUMI are still in the planning.</p> <p>LUMI also has nodes for interactive data analytics. 8 of those have two  64-core Zen2/Rome CPUs with 4 TB of RAM per node, while 8 others have dual 64-core Zen2/Rome CPUs and 8 NVIDIA A40 GPUs for visualisation. Currently we are working on an Open OnDemand based service to make some fo those facilities available. Note though that these nodes are meant for a very specific use, so it is not that we will also be offering, e.g., GPU compute facilities on NVIDIA hardware, and that these are shared resources that should not be monopolised by a single user (so no hope to run an MPI job on 8 4TB nodes).</p> <p>An object based file system similar to the Allas service of CSC that some of the Finnish users may be familiar with is also being worked on.</p> <p>Early on a small partition for containerised micro-services managed with Kubernetes was also planned, but that may never materialize due to lack of  people to set it up and manage it.</p> <p>In this section of the course we will now build up LUMI step by step.</p>"},{"location":"1day-20230509/01_Architecture/#building-lumi-the-cpu-amd-7xx3-milanzen3-cpu","title":"Building LUMI: The CPU AMD 7xx3 (Milan/Zen3) CPU","text":"<p>The LUMI-C and LUMI-G compute nodes use third generation AMD EPYC CPUs. Whereas Intel CPUs launched in the same period were built out of a single large monolithic piece of silicon (that only changed recently with some variants of the Sapphire Rapids CPU launched in early 2023), AMD CPUs are build out of multiple so-called chiplets. </p> <p>The basic building block of Zen3 CPUs is the Core Complex Die (CCD). Each CCD contains 8 cores, and each core has 32 kB of L1 instruction  and 32 kB of L1 data cache, and 512 kB of L2 cache. The L3 cache is shared across all cores on a chiplet and has a total size of 32 MB on LUMI (there are some variants of the processor where this is 96MB). At the user level, the instruction set is basically equivalent to that of the Intel Broadwell generation. AVX2 vector instructions and the FMA instruction are fully supported, but there is no support for any of the AVX-512 versions that can be found on Intel Skylake server processors and later generations. Hence the number of floating point operations that a core can in theory do each clock cycle is 16 (in  double precision) rather than the 32 some Intel processors are capable of. </p> <p></p> <p>The full processor package for the AMD EPYC processors used in LUMI have 8 such Core Complex Dies for a total of 64 cores. The caches are not shared between different CCDs, so it also implies that the processor has 8 so-called L3 cache regions. (Some cheaper variants have only 4 CCDs, and some have CCDs with only 6 or fewer cores enabled but the same 32 MB of L3 cache per CCD).</p> <p>Each CCD connects to the memory/IO die through an Infinity Fabric link.  The memory/IO die contains the memory controllers, connections to connect two CPU packages together, PCIe lanes to connect to external hardware, and some additional hardware, e.g., for managing the processor.  The memory/IO die supports 4 dual channel DDR4 memory controllers providing  a total of 8 64-bit wide memory channels. From a logical point of view the memory/IO-die is split in 4 quadrants, with each quadrant having a dual channel memory controller and 2 CCDs. They basically act as 4 NUMA domains. For a core it is slightly faster to access memory in its own quadrant than memory attached to another quadrant, though for the 4 quadrants within the same socket the difference is small. (In fact, the BIOS can be set to show only two or one NUMA domain which is advantageous in some cases, like the typical load pattern of login nodes where it is impossible to nicely spread processes and their memory across the 4 NUMA domains).</p> <p>The theoretical memory bandwidth of a complete package is around 200 GB/s. However, that bandwidth is not available to a single core but can only be used if enough  cores spread over all CCDs are used.</p>"},{"location":"1day-20230509/01_Architecture/#building-lumi-a-lumi-c-node","title":"Building LUMI: a LUMI-C node","text":"<p>A compute node is then built out of two such processor packages, connected  though 4 16-bit wide Infinity Fabric connections with a total theoretical bandwidth of 144 GB/s in each direction. So note that the bandwidth in each direction is less than the memory bandwidth of a socket. Again, it is not really possible to use the full memory bandwidth of a node using just cores on a single socket. Only one of the two sockets has a direct connection to the high performance Slingshot interconnect though.</p>"},{"location":"1day-20230509/01_Architecture/#a-strong-hierarchy-in-the-node","title":"A strong hierarchy in the node","text":"<p>As can be seen from the node architecture in the previous slide, the CPU compute nodes have a very hierarchical architecture. When mapping an application onto  one or more compute nodes, it is key for performance to take that hierarchy into account. This is also the reason why we will pay so much attention to thread and process pinning in this tutorial course.</p> <p>At the coarsest level, each core supports two hardware threads (what Intel calls hyperthreads). Those hardware threads share all the resources of a core, including the  L1 data and instruction caches and the L2 cache.  At the next level, a Core Complex Die contains (up to) 8 cores. These cores share the L3 cache and the link to the memory/IO die.  Next, as configured on the LUMI compute nodes, there are 2 Core Complex Dies in a NUMA node. These two CCDs share the DRAM channels of that NUMA node. At the fourth level in our hierarchy 4 NUMA nodes are grouped in a socket. Those 4  nodes share an inter-socket link. At the fifth and last level in our shared memory hierarchy there are two sockets in a node. On LUMI, they share a single Slingshot inter-node link.</p> <p>The finer the level (the lower the number), the shorter the distance and hence the data delay is between threads that need to communicate with each other through the memory hierarchy, and the higher the bandwidth.</p> <p>This table tells us a lot about how one should map jobs, processes and threads onto a node. E.g., if a process has fewer then 8 processing threads running concurrently, these should be mapped to cores on a single CCD so that they can share  the L3 cache, unless they are sufficiently independent of one another, but even in the latter case the additional cores on those CCDs should not be used by other processes as they may push your data out of the cache or saturate the link to the memory/IO die and hence slow down some threads of your process. Similarly, on a 256 GB compute node each NUMA node has 32 GB of RAM (or actually a bit less as the OS also needs memory, etc.), so if you have a job that uses 50 GB of memory but only, say, 12 threads, you should really have two NuMA nodes reserved for that job as otherwise other threads or processes running on cores in those NUMA nodes could saturate some resources needed by your job. It might also be preferential to spread those 12 threads over the 4  CCDs in those 2 NUMA domains unless communication through the L3 threads would be the bottleneck in your application.</p>"},{"location":"1day-20230509/01_Architecture/#hierarchy-delays-in-numbers","title":"Hierarchy: delays in numbers","text":"<p>This slide shows the ACPI System Locality distance Information Table (SLIT) as returned by, e.g., <code>numactl -H</code> which gives relative distances to memory from a core. E.g., a value of 32 means that access takes 3.2x times the  time it would take to access memory attached to the same NUMA node.  We can see from this table that the penalty for accessing memory in  another NUMA domain in the same socket is still relatively minor (20%  extra time), but accessing memory attached to the other socket is a lot  more expensive. If a process running on one socket would only access memory attached to the other socket, it would run a lot slower which is why Linux has mechanisms to try to avoid that, but this cannot be done in all scenarios which is why on some clusters you will be allocated cores in proportion to the amount of memory you require, even if that is more cores than you really need (and you will be billed for them).</p>"},{"location":"1day-20230509/01_Architecture/#building-lumi-concept-lumi-g-node","title":"Building LUMI: Concept LUMI-G node","text":"<p>This slide shows a conceptual view of a LUMI-G compute node. This node is unlike any Intel-architecture-CPU-with-NVIDIA-GPU compute node you may have  seen before, and rather mimics the architecture of the USA pre-exascale machines Summit and Sierra which have IBM POWER9 CPUs paired with  NVIDIA V100 GPUs.</p> <p>Each GPU node consists of one 64-core AMD EPYC CPU and 4 AMD MI250x GPUs.  So far nothing special. However, two elements make this compute node very special. The GPUs are not connected to the CPU though a PCIe bus. Instead they are connected through the same links that AMD uses to link the GPUs together, or to link the two sockets in the LUMI-C compute nodes, known as xGMI or Infinity Fabric. This enables CPU and GPU to access each others memory  rather seamlessly and to implement coherent caches across the whole system. The second remarkable element is that the Slingshot interface cards connect directly to the GPUs (through a PCIe interface on the GPU) rather than two the CPU. The CPUs have a shorter path to the communication  network than the CPU in this design. </p> <p>This makes the LUMI-G compute node really a \"GPU first\" system. The architecture looks more like a GPU system with a CPU as the accelerator for tasks that a GPU is not good at such as some scalar processing or running an OS, rather than a CPU node with GPU accelerator.</p> <p>It is also a good fit with the cluster-booster design explored in the DEEP project series. In that design, parts of your application that cannot be properly accelerated would run on CPU nodes, while booster GPU nodes would be used for those parts  that can (at least if those two could execute concurrently with each other). Different node types are mixed and matched as needed for each specific application,  rather than building clusters with massive and expensive nodes that few applications can fully exploit. As the cost per transistor does not decrease anymore, one has to look for ways to use each transistor as efficiently as possible...</p> <p>It is also important to realise that even though we call the partition \"LUMI-G\", the MI250x is not a GPU in the true sense of the word. It is not a rendering GPU, which for AMD is  currently the RDNA architecture with version 3 just out, but a compute accelerator with an architecture that evolved from a GPU architecture, in this case the VEGA architecture from AMD. The architecture of the MI200 series is also known as CDNA2, with the MI100 series being just CDNA, the first version. Much of the hardware that does not serve compute purposes has been removed from the design to have more transistors available for compute.  Rendering is possible, but it will be software-based  rendering with some GPU acceleration for certain parts of the pipeline, but not full hardware rendering. </p> <p>This is not an evolution at AMD only. The same is happening with NVIDIA GPUs and there is a reason why the latest generation is called \"Hopper\" for compute and \"Ada Lovelace\" for rendering GPUs.  Several of the functional blocks in the Ada Lovelace architecture are missing in the Hopper  architecture to make room for more compute power and double precision compute units. E.g., Hopper does not contain the ray tracing units of Ada Lovelace.</p> <p>Graphics on one hand and HPC and AI on the other hand are becoming separate workloads for which manufacturers make different, specialised cards, and if you have applications that need both, you'll have to rework them to work in two phases, or to use two types of nodes and communicate between them over the interconnect, and look for supercomputers that support both workloads.</p> <p>But so far for the sales presentation, let's get back to reality...</p>"},{"location":"1day-20230509/01_Architecture/#building-lumi-what-a-lumi-g-node-really-looks-like","title":"Building LUMI: What a LUMI-G node really looks like","text":"<p>Or the full picture with the bandwidths added to it:</p> <p>The LUMI-G node uses the 64-core AMD 7A53 EPYC processor, known under the code name \"Trento\". This is basically a Zen3 processor but with a customised memory/IO die, designed specifically  for HPE Cray (and in fact Cray itself, before the merger) for the USA Coral-project to build the Frontier supercomputer, the fastest system in the world at the end of 2022 according to at least the Top500 list. Just as the CPUs in the LUMI-C nodes, it is a design with 8 CCDs and a memory/IO die.</p> <p>The MI250x GPU is also not a single massive die, but contains two compute dies besides the 8 stacks of HBM2e memory, 4 stacks or 64 GB per compute die. The two compute dies in a package are linked together  through 4 16-bit Infinity Fabric links. These links run at a higher speed than the links between two CPU sockets in a LUMI-C node, but per link the bandwidth is still only 50 GB/s per direction, creating a total bandwidth of 200 GB/s per direction between the two compute dies in an MI250x GPU. That amount of bandwidth is very low compared to even the memory bandwidth, which is roughly 1.6 TB/s peak per die, let alone compared to whatever bandwidth caches on the compute dies would have or the bandwidth of the internal structures that  connect all compute engines on the compute die. Hence the two dies in a single package cannot function efficiently as as single GPU which is one reason why each MI250x GPU on LUMI is actually seen as two GPUs. </p> <p>Each compute die uses a further 2 or 3 of those Infinity Fabric (or xGNI) links to connect to some compute dies in other MI250x packages. In total, each MI250x package is connected through 5 such links to other MI250x packages. These links run at the same 25 GT/s speed as the  links between two compute dies in a package, but even then the bandwidth is only a meager  250 GB/s per direction, less than an NVIDIA A100 GPU which offers 300 GB/s per direction or the NVIDIA H100 GPU which offers 450 GB/s per direction. Each Infinity Fabric link may be twice as fast as each NVLINK 3 or 4 link (NVIDIA Ampere and Hopper respectively), offering 50 GB/s per direction rather than 25 GB/s per direction for NVLINK,  but each Ampere GPU has 12 such links and each Hopper GPU 18 (and in fact a further 18 similar ones to link to a Grace CPU), while each MI250x package has only 5 such links available to link to other GPUs (and the three that we still need to discuss).</p> <p>Note also that even though the connection between MI250x packages is all-to-all, the connection between GPU dies is all but all-to-all. as each GPU die connects to only 3 other GPU dies. There are basically two rings that don't need to share links in the topology, and then some extra connections. The rings are:</p> <ul> <li>1 - 0 - 6 - 7 - 5 - 4 - 2 - 3 - 1</li> <li>1 - 5 - 4 - 2 - 3 - 7 - 6 - 0 - 1</li> </ul> <p>Each compute die is also connected to one CPU Core Complex Die (or as documentation of the node sometimes says, L3 cache region). This connection only runs at the same speed as the links between CPUs on the LUMI-C CPU nodes, i.e., 36 GB/s per direction (which is still enough for  all 8 GPU compute dies together to saturate the memory bandwidth of the CPU).  This implies that each of the 8 GPU dies has a preferred CPU die to work with, and this should definitely be taken into account when mapping processes and threads on a LUMI-G node. </p> <p>The figure also shows another problem with the LUMI-G node: The mapping between CPU cores/dies and GPU dies is all but logical:</p> GPU die CCD hardware threads NUMA node 0 6 48-55, 112-119 3 1 7 56-63, 120-127 3 2 2 16-23, 80-87 1 3 3 24-31, 88-95 1 4 0 0-7, 64-71 0 5 1 8-15, 72-79 0 6 4 32-39, 96-103 2 7 5 40-47, 104, 11 2 <p>and as we shall see later in the course, exploiting this is a bit tricky at the moment.</p>"},{"location":"1day-20230509/01_Architecture/#what-the-future-looks-like","title":"What the future looks like...","text":"<p>Some users may be annoyed by the \"small\" amount of memory on each node. Others may be annoyed by the limited CPU capacity on a node compared to some systems  with NVIDIA GPUs. It is however very much in line with the cluster-booster philosophy already mentioned a few times, and it does seem to be the future according to both AMD and Intel. In fact, it looks like with respect to memory  capacity things may even get worse.</p> <p>We saw the first little steps of bringing GPU and CPU closer together and  integrating both memory spaces in the USA pre-exascale systems Summit and Sierra. The LUMI-G node which was really designed for the first USA exascale systems continues on this philosophy, albeit with a CPU and GPU from a different manufacturer. Given that manufacturing large dies becomes prohibitively expensive in newer semiconductor processes and that the transistor density on a die is also not increasing at the same rate anymore with process shrinks, manufacturers are starting to look at other ways of increasing the number of transistors per \"chip\" or should we say package. So multi-die designs are here to stay, and as is already the case in the AMD CPUs, different dies may be manufactured with different processes for economical reasons.</p> <p>Moreover, a closer integration of CPU and GPU would not only make programming easier as memory management becomes easier, it would also enable some code to run on GPU  accelerators that is currently bottlenecked by memory transfers between GPU and CPU.</p> <p>AMD at its 2022 Investor day and at CES 2023 in early January, and Intel at an Investor day in 2022 gave a glimpse of how they see the future. The future is one where one or more CPU dies, GPU dies and memory controllers are combined in a single package and - contrary to the Grace Hopper design of NVIDIA - where CPU and GPU share  memory controllers. At CES 2023, AMD already showed a MI300 package that will be used in El Capitan, one of the next USA exascale systems (the third one if Aurora gets built in time). It employs 13 chiplets in two layers, linked to (still only) 8  memory stacks (albeit of a slightly faster type than on the MI250x). The 4 dies on the bottom layer are likely the controllers for memory and inter-GPU links as they produce the least heat, while it was announced that the GPU would feature 24 Zen4 cores, so the top  layer consists likely of 3 CPU and 6 GPU chiplets. It looks like the AMD design may  have no further memory beyond the 8 HBM stacks, likely providing 128 GB of RAM.</p> <p>Intel has shown only very conceptual drawings of its Falcon Shores chip which it calls an XPU, but those drawings suggest that that chip will also support some low-bandwidth but higher capacity external memory, similar to the approach taken in some Sapphire  Rapids Xeon processors that combine HBM memory on-package with DDR5 memory outside  the package. Falcon Shores will be the next generation of Intel GPUs for HPC, after  Ponte Vecchio which will be used in the Aurora supercomputer. It is currently not clear though if Intel will already use the integrated CPU+GPU model for the Falcon Shores generation or if this is getting postponed.</p> <p>However, a CPU closely integrated with accelerators is nothing new as Apple Silicon is  rumoured to do exactly that in its latest generations, including the M-family chips.</p>"},{"location":"1day-20230509/01_Architecture/#building-lumi-the-slingshot-interconnect","title":"Building LUMI: The Slingshot interconnect","text":"<p>All nodes of LUMI, including the login, management and storage nodes, are linked together using the Slingshot interconnect (and almost all use Slingshot 11, the full implementation with 200 Gb/s bandwidth per direction).</p> <p>Slingshot is an interconnect developed by HPE Cray and based on Ethernet, but with proprietary extensions for better HPC performance. It adapts to the regular Ethernet protocols when talking to a node that only supports Ethernet, so one of the attractive features is that regular servers with Ethernet can be directly connected to the  Slingshot network switches. HPE Cray has a tradition of developing their own interconnect for very large systems. As in previous generations, a lot of attention went to adaptive routing and congestion control. There are basically two versions of it. The early version was named Slingshot 10, ran at 100 Gb/s per direction and did not yet have all features. It was used on the initial deployment of LUMI-C compute nodes but has since been upgraded to the full version. The full version with all features is called Slingshot 11. It supports a bandwidth of 200 Gb/s per direction, comparable to HDR InfiniBand with 4x links. </p> <p>Slingshot is a different interconnect from your typical Mellanox/NVIDIA InfiniBand implementation and hence also has a different software stack. This implies that there are no UCX libraries on the system as the Slingshot 11 adapters do not support that. Instead, the software stack is  based on libfabric (as is the stack for many other Ethernet-derived solutions and even Omni-Path has switched to libfabric under its new owner).</p> <p>LUMI uses the dragonfly topology. This topology is designed to scale to a very large number of  connections while still minimizing the amount of long cables that have to be used. However, with its complicated set of connections it does rely on adaptive routing and congestion control for optimal performance more than the fat tree topology used in many smaller clusters. It also needs so-called high-radix switches. The Slingshot switch, code-named Rosetta, has 64 ports. 16 of those ports connect directly to compute nodes (and the next slide will show you how). Switches are then combined in groups. Within a group there is an all-to-all connection between  switches: Each switch is connected to each other switch. So traffic between two nodes of a  group passes only via two switches if it takes the shortest route. However, as there is typically only one 200 Gb/s direct connection between two switches in a group, if all 16 nodes on two  switches in a group would be communicating heavily with each other, it is clear that some traffic will have to take a different route. In fact, it may be statistically better if the 32 involved nodes would be spread  more evenly over the group, so topology based scheduling of jobs and getting the processes of a job on as few switches as possible may not be that important on a dragonfly Slingshot network.  The groups in a slingshot network are then also connected in an all-to-all fashion, but the number of direct links between two groups is again limited so traffic again may not always want to take  the shortest path. The shortest path between two nodes in a dragonfly topology never involves  more than 3 hops between switches (so 4 switches): One from the switch the node is connected to  the switch in its group that connects to the other group, a second hop to the other group, and then a third hop in the destination group to the switch the destination node is attached to.</p>"},{"location":"1day-20230509/01_Architecture/#assembling-lumi","title":"Assembling LUMI","text":"<p>Let's now have a look at how everything connects together to the supercomputer LUMI. LUMI does use a custom rack design for the compute nodes that is also fully water cooled. It is build out of units that can contain up to 4 custom cabinets, and a cooling distribution unit (CDU). The size of the complex as depicted in the slide is approximately 12 m2. Each cabinet contains 8 compute chassis in 2 columns of 4 rows. In between the two columns is all the power circuitry. Each compute chassis can contain 8 compute blades that are mounted vertically. Each compute blade can contain multiple nodes, depending on the type of compute blades. HPE Cray have multiple types of compute nodes, also with  different types of GPUs. In fact, the Aurora supercomputer which uses Intel CPUs and GPUs and El Capitan, which uses the MI300 series of APU (integrated CPU and GPU) will use the same design with a different compute blade. Each LUMI-C compute blade contains 4 compute nodes and two network interface cards, with each network interface card implementing two Slingshot interfaces and connecting to two nodes. A LUMI-G compute blade contains two nodes and 4 network interface cards, where each interface card now connects to two GPUs in the same  node. All connections for power, management network and high performance interconnect of the compute node are at the back of the compute blade. At the front of the compute blades one can find the connections to the cooling manifolds that distribute cooling water to the blades. One compute blade of LUMI-G can consume up to 5kW, so the power density of this setup is incredible, with 40 kW for a single compute chassis.</p> <p>The back of each cabinet is equally genius. At the back each cabinet has 8 switch chassis, each matching the position of a compute chassis. The switch chassis contains the connection to the power delivery system and a switch for the management network and has 8 positions for  switch blades. These are mounted horizontally and connect directly to the compute blades. Each slingshot switch has 8x2 ports on the inner side for that purpose, two for each compute blade. Hence for LUMI-C two switch blades are needed in each switch chassis as each blade has 4 network interfaces, and for LUMI-G 4 switch blades are needed for each compute chassis as those nodes have 8 network interfaces. Note that this also implies that the nodes on the same  compute blade of LUMI-C will be on two different switches even though in the node numbering they are numbered consecutively. For LUMI-G both nodes on a blade will be on a different pair of switches  and each node is connected to two switches. Thw switch blades are also water cooled (each one can  consume up to 250W). No currently possible configuration of the Cray EX system needs that  all switch positions in the switch chassis.</p> <p>This does not mean that the extra positions cannot be useful in the future. If not for an interconnect, one could, e.g., export PCIe ports to the back and attach, e.g., PCIe-based storage via blades as the  switch blade environment is certainly less hostile to such storage than the very dense and very hot compute blades.</p>"},{"location":"1day-20230509/01_Architecture/#lumi-assembled","title":"LUMI assembled","text":"<p>This slide shows LUMI fully assembled (as least as it was at the end of 2022).</p> <p>At the front there are 5 rows of cabinets similar to the ones in the exploded Cray EX picture  on the previous slide. Each row has 2 CDUs and 6 cabinets with compute nodes.  The first row, the one with the wolf, contains all nodes of LUMI-C, while the other four  rows, with the letters of LUMI, contain the GPU accelerator nodes. At the back of the room there are more  regular server racks that house the storage, management nodes, some special compute nodes , etc. The total size is roughly the size of a tennis court. </p> <p>Remark</p> <p>The water temperature that a system like the Cray EX can handle is so high that in fact the water can be cooled again with so-called \"free cooling\", by just radiating the heat to the environment rather  than using systems with compressors similar to air conditioning systems, especially in regions with a colder climate. The LUMI supercomputer is housed in Kajaani in Finland, with moderate temperature almost  year round, and the heat produced by the supercomputer is fed into the central heating system of the city, making it one of the greenest supercomputers in the world as it is also fed with renewable energy.</p>"},{"location":"1day-20230509/02_CPE/","title":"The HPE Cray Programming Environment","text":"<p>Every user needs to know the basics about the programming environment as after all most software is installed through the programming environment, and to some extent it also determines how programs should be run.</p>"},{"location":"1day-20230509/02_CPE/#why-do-i-need-to-know-this","title":"Why do I need to know this?","text":"<p>The typical reaction of someone who only wants to run software on an HPC system when confronted with a talk about development tools is \"I only want to run some programs, why do I need to know about programming environments?\"</p> <p>The answer is that development environments are an intrinsic part of an HPC system.  No HPC system is as polished as a personal computer and the software users want to use is typically very unpolished. </p> <p>Programs on an HPC cluster are preferably installed from sources to generate binaries optimised for the system. CPUs have gotten new instructions over time that can sometimes speed-up execution of a program a lot, and compiler optimisations that take specific strengths and weaknesses of particular CPUs into account can also gain some performance. Even just a 10% performance gain on an investment of 160 million EURO such as LUMI means a lot of money. When running, the build environment on most systems needs to be at least partially recreated. This is somewhat less relevant on Cray systems as we will see at the end of this part of the course, but if you want reproducibility it becomes important again.</p> <p>Even when installing software from prebuild binaries some modules might still be needed, e.g., as you may want to inject an optimised MPI library as we shall see in the container section of this course.</p>"},{"location":"1day-20230509/02_CPE/#the-operating-system-on-lumi","title":"The operating system on LUMI","text":"<p>The login nodes of LUMI run a regular SUSE Linux Enterprise Server 15 SP4 distribution. The compute nodes however run Cray OS, a restricted version of the SUSE Linux that runs on the login nodes. Some daemons are inactive or configured differently and Cray also  does not support all regular file systems. The goal of this is to minimize OS jitter, interrupts that the OS handles and slow down random cores at random moments, that can  limit scalability of programs. Yet on the GPU nodes there was still the need to reserve one core for the OS and driver processes.</p> <p>This also implies that some software that works perfectly fine on the login nodes may not work on the compute nodes. E.g., there is no <code>/run/user/$UID</code> directory and we have experienced that D-Bus (which stands for Desktop-Bus) also does not work as one should expect.</p> <p>Large HPC clusters also have a small system image, so don't expect all the bells-and-whistles  from a Linux workstation to be present on a large supercomputer. Since LUMI compute nodes are diskless, the system image actually occupies RAM which is another reason to keep it small.</p>"},{"location":"1day-20230509/02_CPE/#programming-models","title":"Programming models","text":"<p>On LUMI we have several C/C++ and Fortran compilers. These will be discussed more in this session.</p> <p>There is also support for MPI and SHMEM for distributed applications. And we also support RCCL, the ROCm-equivalent of the  CUDA NCCL library that is popular in machine learning packages.</p> <p>All compilers have some level of OpenMP support,  and two compilers support OpenMP offload to  the AMD GPUs, but again more about that later.</p> <p>OpenACC, the other directive-based model for GPU offloading,  is only supported in the Cray Fortran compiler. There is no commitment of neither HPE Cray or AMD to extend that support to C/C++ or other compilers, even though there is work going on in the LLVM community and several compilers on the system are based on LLVM.</p> <p>The other important programming model for AMD GPUs is HIP,  which is their alternative for the proprietary CUDA model. It does not support all CUDA features though (basically it is more CUDA 7 or 8 level)  and there is also no equivalent to CUDA Fortran.</p> <p>The commitment to OpenCL is very unclear, and this actually holds for other GPU vendors also.</p> <p>We also try to provide SYCL as it is a programming language/model that works on all three GPU families currently used in HPC. </p> <p>Python is of course pre-installed on the system but we do ask to use big Python installations in a special way as Python puts a tremendous load on the file system. More about that later in this course.</p> <p>Some users also report some success in running Julia. We don't have full support though and have to depend on binaries as provided by julialang.org. The AMD GPUs are not yet fully supported by Julia.</p> <p>It is important to realise that there is no CUDA on AMD GPUs and there will never be as this is a  proprietary technology that other vendors cannot implement. LUMI will in the future have some nodes with NVIDIA GPUs but these nodes are meant for visualisation and not for compute.</p>"},{"location":"1day-20230509/02_CPE/#the-development-environment-on-lumi","title":"The development environment on LUMI","text":"<p>Long ago, Cray designed its own processors and hence had to develop their own compilers. They kept doing so, also when they moved to using more standard components, and had a lot of expertise in that field, especially when it comes to the needs of  scientific codes, programming models that are almost only used in scientific computing or stem from such projects, and as they develop their own interconnects, it does make sense to also develop an MPI implementation that can use the interconnect in an optimal way. They also have a long tradition in developing performance measurement and analysis tools  and debugging tools that work in the context of HPC.</p> <p>The first important component of the HPE Cray Programming Environment is the compilers. Cray still builds its own compilers for C/C++ and Fortran, called the Cray Compiling Environment (CCE). Furthermore, the GNU compilers are also supported on every Cray system, though at the moment AMD GPU support is not enabled. Depending on the hardware of the  system other compilers will also be provided and integrated in the environment. On LUMI two other compilers are available: the AMD AOCC compiler for CPU-only code and the  AMD ROCm compilers for GPU programming. Both contain a C/C++ compiler based on Clang and LLVM and a Fortran compiler which is currently based on the former PGI frontend with LLVM backend. The ROCm compilers also contain the support for HIP, AMD's CUDA clone.</p> <p>The second component is the Cray Scientific and Math libraries, containing the usual suspects as BLAS, LAPACK and ScaLAPACK, and FFTW, but also some data libraries and Cray-only libraries.</p> <p>The third component is the Cray Message Passing Toolkit. It provides an MPI implementation optimized for Cray systems, but also the Cray SHMEM libraries, an implementation of OpenSHMEM 1.5.</p> <p>The fourth component is some Cray-unique sauce to integrate all these components, and  support for hugepages to make memory access more efficient for some programs that  allocate huge chunks of memory at once.</p> <p>Other components include the Cray Performance Measurement and Analysis Tools and the  Cray Debugging Support Tools that will not be discussed in this one-day course, and Python and R modules that both also provide some packages compiled with support for the Cray Scientific Libraries.</p> <p>Besides the tools provided by HPE Cray, several of the development tools from the ROCm stack are also available on the system while some others can be user-installed (and one of those, Omniperf, is not available due to security concerns). Furthermore there are some third party tools available on LUMI, including Linaro Forge (previously ARM Forge) and Vampir and some open source profiling tools.</p> <p>We will now discuss some of these components in a little bit more detail, but refer to the 4-day trainings that we organise three times a year with HPE for more material.</p>"},{"location":"1day-20230509/02_CPE/#the-cray-compiling-environment","title":"The Cray Compiling Environment","text":"<p>The Cray Compiling Environment are the default compilers on many Cray systems and on LUMI. These compilers are designed specifically for scientific software in an HPC environment. The current versions use are LLVM-based with extensions by HPE Cray for automatic vectorization and shared memory parallelization, technology that they have experience with since the late '70s or '80s.</p> <p>The compiler offers extensive standards support. The C and C++ compiler is essentially their own build of Clang with LLVM with some of their optimisation plugins and OpenMP run-time. The version numbering of the CCE currently follows the major versions of the Clang compiler used. The support for C and C++ language standards corresponds to that of Clang. The Fortran compiler uses a frontend developed by HPE Cray, but an LLVM-based backend.  The compiler supports most of Fortran 2018 (ISO/IEC 1539:2018). The CCE Fortran compiler is known to be very strict with language standards. Programs that use GNU or Intel extensions will usually fail to compile, and unfortunately since many developers only test with these compilers, much Fortran code is not fully standards compliant and will fail.</p> <p>All CCE compilers support OpenMP, with offload for AMD and NVIDIA GPUs. They claim full OpenMP 4.5 support with partial (and growing) support for OpenMP 5.0 and 5.1. More  information about the OpenMP support is found by checking a manual page: <pre><code>man intro_openmp\n</code></pre> which does require that the <code>cce</code> module is loaded. The Fortran compiler also supports OpenACC for AMD and NVIDIA GPUs. That implementation claims to be fully OpenACC 2.0 compliant, and offers partial support for OpenACC 2.x/3.x.  Information is available via <pre><code>man intro_openacc\n</code></pre> AMD and HPE Cray still recommend moving to OpenMP which is a much broader supported standard. There are no plans to also support OpenACC in the C/C++ compiler.</p> <p>The CCE compilers also offer support for some PGAS (Partitioned Global Address Space) languages. UPC 1.2 is supported, as is Fortran 2008 coarray support. These implementations do not require a preprocessor that first translates the code to regular C or Fortran. There is also support for debugging with Linaro Forge.</p> <p>Lastly, there are also bindings for MPI.</p>"},{"location":"1day-20230509/02_CPE/#scientific-and-math-libraries","title":"Scientific and math libraries","text":"<p>Some mathematical libraries have become so popular that they basically define an API for which several implementations exist, and CPU manufacturers and some open source groups spend a significant amount of resources to make optimal implementations for each CPU architecture.</p> <p>The most notorious library of that type is BLAS, a set of basic linear algebra subroutines for vector-vector, matrix-vector and matrix-matrix implementations. It is the basis for many other libraries that need those linear algebra operations, including Lapack, a library with solvers for linear systems and eigenvalue problems.</p> <p>The HPE Cray LibSci library contains BLAS and its C-interface CBLAS, and LAPACK and its C interface LAPACKE. It also adds ScaLAPACK, a distributed memory version of LAPACK, and BLACS, the  Basic Linear Algebra Communication Subprograms, which is the communication layer used by ScaLAPACK. The BLAS library combines implementations from different sources, to try to offer the most optimal one for several architectures and a range of matrix and vector sizes.</p> <p>LibSci also contains one component which is HPE Cray-only: IRT, the Iterative Refinement Toolkit,  which allows to do mixed precision computations for LAPACK operations that can speed up the generation of a double precision result with nearly a factor of two for those problems that are suited for iterative refinement. If you are familiar with numerical analysis, you probably know that the matrix should not be too ill-conditioned for that.</p> <p>There is also a GPU-optimized version of LibSci, called LibSCi_ACC, which contains a subset of the routines of LibSci. We don't have much experience in the support team with this library though. It can be compared with what Intel is doing with oneAPI MKL which also offers GPU versions of some of the traditional MKL routines.</p> <p>Another separate component of the scientific and mathematical libraries is FFTW3,  Fastest Fourier Transforms in the West, which comes with optimized versions for all CPU architectures supported by recent HPE Cray machines.</p> <p>Finally, the scientific and math libraries also contain HDF5 and netCDF libraries in sequential and parallel versions.</p>"},{"location":"1day-20230509/02_CPE/#cray-mpi","title":"Cray MPI","text":"<p>HPE Cray build their own MPI library with optimisations for their own interconnects. The Cray MPI library is derived from the ANL MPICH 3.4 code base and fully support the  ABI (Application Binary Interface) of that application which implies that in principle it should be possible to swap the MPI library of applications build with that ABI with the Cray MPICH library. Or in other words, if you can only get a binary distribution of an application and that application was build against an MPI library compatible with  the MPICH 3.4 ABI (which includes Intel MPI) it should be possible to exchange that library for the Cray one to have optimised communication on the Cray Slingshot interconnect.</p> <p>Cray MPI contains many tweaks specifically for Cray systems. HPE Cray claim improved algorithms for many collectives, an asynchronous progress engine to improve overlap of communications and computations,  customizable collective buffering when using MPI-IO, and optimized remote memory access (MPI one-sided communication) which also supports passive remote memory access.</p> <p>When used in the correct way (some attention is needed when linking applications) it is allo fully GPU aware with currently support for AMD and NVIDIA GPUs.</p> <p>The MPI library also supports bindings for Fortran 2008.</p> <p>MPI 3.1 is almost completely supported, with two exceptions. Dynamic process management is not supported (and a problem anyway on systems with batch schedulers), and when using CCE MPI_LONG_DOUBLE and MPI_C_LONG_DOUBLE_COMPLEX are also not supported.</p> <p>The Cray MPI library does not support the <code>mpirun</code> or <code>mpiexec</code> commands, which is in fact allowed by the standard which only requires a process starter and suggest <code>mpirun</code> or <code>mpiexec</code>  depending on the version of the standard. Instead the Slurm <code>srun</code> command is used as the  process starter. This actually makes a lot of sense as the MPI application should be mapped correctly on the allocated resources, and the resource manager is better suited to do so.</p> <p>Cray MPI on LUMI is layered on top of libfabric, which in turn uses the so-called Cassini provider to interface with the hardware. UCX is not supported on LUMI (but Cray MPI can support it when used on InfiniBand clusters). It also uses a GPU Transfer Library (GTL) for GPU-aware MPI.</p>"},{"location":"1day-20230509/02_CPE/#lmod","title":"Lmod","text":"<p>Virtually all clusters use modules to enable the users to configure the environment and select the versions of software they want. There are three different module systems around. One is an old implementation that is hardly evolving anymore but that can still be found on\\ a number of clusters. HPE Cray still offers it as an option. Modulefiles are written in TCL, but the tool itself is in C. The more popular tool at the moment is probably Lmod. It is largely compatible with modulefiles for the old tool, but prefers modulefiles written in LUA. It is also supported by the HPE Cray PE and is our choice on LUMI. The final implementation is a full TCL implementation developed  in France and also in use on some large systems in Europe.</p> <p>Fortunately the basic commands are largely similar in those implementations, but what differs is the way to search for modules. We will now only discuss the basic commands, the more advanced ones will be discussed in the next session of this tutorial course.</p> <p>Modules also play an important role in configuring the HPE Cray PE, but before touching that  topic we present the basic commands:</p> <ul> <li><code>module avail</code>: Lists all modules that can currently be loaded. </li> <li><code>module list</code>: Lists all modules that are currently loaded</li> <li><code>module load</code>: Command used to load a module. Add the name and version of the module.</li> <li><code>module unload</code>: Unload a module. Using the name is enough as there can only one version be      loaded of a module.</li> <li><code>module swap</code>:  Unload the first module given and then load the second one. In Lmod this is      really equivalent to a <code>module unload</code> followed by a <code>module load</code>.</li> </ul> <p>Lmod supports a hierarchical module system. Such a module setup distinguishes between installed modules and available modules. The installed modules are all modules that can be loaded in one way or another by the module systems, but loading some of those may require loading other modules first. The available modules are the modules that can be loaded directly without loading any other module. The list of available modules changes all the time based on modules that are already loaded, and if you unload a module that makes other loaded modules unavailable, those will also be deactivated by Lmod. The advantage of a hierarchical module system is that one can support multiple configurations of a module while all configurations can have the same name and version. This is not fully exploited on LUMI, but it  is used a lot in the HPE Cray PE. E.g., the MPI libraries for the various compilers on the system all have the same name and version yet make different binaries available depending on the compiler that is being used.</p>"},{"location":"1day-20230509/02_CPE/#compiler-wrappers","title":"Compiler wrappers","text":"<p>The HPE Cray PE compilers are usually used through compiler wrappers. The wrapper for C is <code>cc</code>, the one for C++ is <code>CC</code> and the one for Fortran is <code>ftn</code>. The wrapper then calls the selected compiler. Which compiler will be called is determined by which compiler module is loaded. As shown on the slide  \"Development environment on LUMI\", on LUMI the Cray Compiling Environment (module <code>cce</code>), GNU Compiler Collection (module <code>gcc</code>),  the AMD Optimizing Compiler for CPUs (module <code>aocc</code>) and the ROCm LLVM-based compilers (module <code>amd</code>) are available. On other HPE Cray systems, you may also find the Intel compilers or on systems with NVIDIA GPUS, the NVIDIA HPC compilers.</p> <p>The target architectures for CPU and GPU are also selected through modules, so it is better to not use compiler options such as <code>-march=native</code>. This makes cross compiling also easier.</p> <p>The wrappers will also automatically link in certain libraries, and make the include files available, depending on which other modules are loaded. In some cases it tries to do so cleverly, like selecting an MPI, OpenMP, hybrid or sequential option depending on whether the MPI module is loaded and/or OpenMP compiler flag is used. This is the case for:</p> <ul> <li>The MPI libraries. There is no <code>mpicc</code>, <code>mpiCC</code>, <code>mpif90</code>, etc. on LUMI. The regular compiler     wrappers do the job as soon as the <code>cray-mpich</code> module is loaded.</li> <li>LibSci and FFTW are linked automatically if the corresponding modules are loaded. So no need     to look, e.g., for the BLAS or LAPACK libraries: They will be offered to the linker if the     <code>cray-libsci</code> module is loaded (and it is an example of where the wrappers try to take the     right version based not only on compiler, but also on whether MPI is loaded or not and the     OpenMP compiler flag).</li> <li>netCDF and HDF5</li> </ul> <p>It is possible to see which compiler and linker flags the wrappers add through the <code>--craype-verbose</code> flag.</p> <p>The wrappers do have some flags of their own, but also accept all flags of the selected compiler and  simply pass those to those compilers.</p>"},{"location":"1day-20230509/02_CPE/#selecting-the-version-of-the-cpe","title":"Selecting the version of the CPE","text":"<p>The version numbers of the HPE Cray PE are of the form <code>yy.dd</code>, e.g., <code>22.08</code> for the version released in August 2022. There are usually 10 releases per year (basically every month except July and January), though not all versions are ever offered on LUMI. </p> <p>There is always a default version assigned by the sysadmins when installing the programming environment. It is possible to change the default version for loading further modules by loading one of the versions of the <code>cpe</code> module. E.g., assuming the 22.08 version would be present on the system, it can be loaded through <pre><code>module load cpe/22.08\n</code></pre> Loading this module will also try to switch the already loaded PE modules to the versions from that release. This does not always work correctly, due to some bugs in most versions of this module and a limitation of Lmod. Executing the <code>module load</code> twice will fix this: <pre><code>module load cpe/22.08\nmodule load cpe/22.08\n</code></pre> The module will also produce a warning when it is unloaded (which is also the case when you do a <code>module load</code> of <code>cpe</code> when one is already loaded, as it then first unloads the already loaded <code>cpe</code> module). The warning can be ignored, but keep in mind that what it says is true, it cannot restore the environment you found on LUMI at login.</p> <p>The <code>cpe</code> module is also not needed when using the LUMI software stacks, but more about that later.</p>"},{"location":"1day-20230509/02_CPE/#the-target-modules","title":"The target modules","text":"<p>The target modules are used to select the CPU and GPU optimization targets and to  select the network communication layer. </p> <p>On LUMI there are three CPU target modules that are relevant:</p> <ul> <li><code>craype-x86-rome</code> selects the Zen2 CPU family code named Rome. These CPUs are     used on the login nodes and the nodes of the data analytics and visualisation      partition of LUMI. However, as Zen3 is a superset of Zen2, software compiled     to this target should run everywhere, but may not exploit the full potential     of the LUMI-C and LUMI-G nodes (though the performance loss is likely minor).</li> <li><code>craype-x86-milan</code> is the target module for the Zen3 CPUs code named Milan that     are used on the CPU-only compute nodes of LUMI (the LUMI-C partition).</li> <li><code>craype-x86-trento</code> is the target module for the Zen3 CPUs code named Trento that     are used on the GPU compute nodes of LUMI (the LUMI-G partition).</li> </ul> <p>Two GPU target modules are relevant for LUMI:</p> <ul> <li><code>craype-accel-host</code>: Will tell some compilers to compile offload code for the host     instead.</li> <li><code>craype-accel-gfx90a</code>: Compile offload code for the MI200 series GPUs that are used on LUMI-G.</li> </ul> <p>Two network target modules are relevant for LUMI:</p> <ul> <li><code>craype-network-ofi</code> selects the libfabric communication layer which is needed for     Slingshot 11.</li> <li><code>craype-network-none</code> omits all network specific libraries.</li> </ul> <p>The compiler wrappers also have corresponding compiler flags that can be used to overwrite these settings: <code>-target-cpu</code>, <code>-target-accel</code> and <code>-target-network</code>.</p>"},{"location":"1day-20230509/02_CPE/#prgenv-and-compiler-modules","title":"PrgEnv and compiler modules","text":"<p>In the HPE Cray PE, the <code>PrgEnv-*</code> modules are usually used to load a specific variant of the programming environment. These modules will load the compiler wrapper (<code>craype</code>), compiler, MPI and LibSci module and may load some other modules also.</p> <p>The following table gives an overview of the available <code>PrgEnv-*</code> modules and the compilers they activate:</p> PrgEnv Description Compiler module Compilers PrgEnv-cray Cray Compiling Environment <code>cce</code> <code>craycc</code>, <code>crayCC</code>, <code>crayftn</code> PrgEnv-gnu GNU Compiler Collection <code>gcc</code> <code>gcc</code>, <code>g++</code>, <code>gfortran</code> PrgEnv-aocc AMD Optimizing Compilers(CPU only) <code>aocc</code> <code>clang</code>, <code>clang++</code>, <code>flang</code> PrgEnv-amd AMD ROCm LLVM compilers (GPU support) <code>amd</code> <code>amdclang</code>, <code>amdclang++</code>, <code>amdflang</code> <p>There is also a second module that offers the AMD ROCm environment, <code>rocm</code>. That module has to be used with <code>PrgEnv-cray</code> and <code>PrgEnv-gnu</code> to enable MPI-aware GPU, hipcc with the GNU compilers or GPU support with the Cray compilers.</p>"},{"location":"1day-20230509/02_CPE/#getting-help","title":"Getting help","text":"<p>Help on the HPE Cray Programming Environment is offered mostly through manual pages and compiler flags. Online help is limited and difficult to locate.</p> <p>For the compilers and compiler wrappers, the following man pages are relevant:</p> PrgEnv C C++ Fortran PrgEnv-cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> PrgEnv-gnu <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> PrgEnv-aocc/PrgEnv-amd - - - Compiler wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> <p>Recently, HPE Cray have also created  a web version of some of the CPE documentation.</p> <p>Some compilers also support the <code>--help</code> flag, e.g., <code>amdclang --help</code>. For the wrappers, the switch <code>-help</code> should be used instead as the double dash version is passed to the  compiler.</p> <p>The wrappers also support the <code>-dumpversion</code> flag to show the version of the underlying compiler. Many other commands, including the actual compilers, use <code>--version</code> to show the version.</p> <p>For Cray Fortran compiler error messages, the <code>explain</code> command is also helpful. E.g.,</p> <pre><code>$ ftn\nftn-2107 ftn: ERROR in command line\n  No valid filenames are specified on the command line.\n$ explain ftn-2107\n\nError : No valid filenames are specified on the command line.\n\nAt least one file name must appear on the command line, with any command-line\noptions.  Verify that a file name was specified, and also check for an\nerroneous command-line option which may cause the file name to appear to be\nan argument to that option.\n</code></pre> <p>On older Cray systems this used to be a very useful command with more compilers but as  HPE Cray is using more and more open source components instead there are fewer commands that give additional documentation via the <code>explain</code> command.</p> <p>Lastly, there is also a lot of information in the \"Developing\" section of the LUMI documentation.</p>"},{"location":"1day-20230509/02_CPE/#google-chatgpt-and-lumi","title":"Google, ChatGPT and LUMI","text":"<p>When looking for information on the HPE Cray Programming Environment using search engines such as Google, you'll be disappointed how few results show up. HPE doesn't put much information on the  internet, and the environment so far was mostly used on Cray systems of which there are not that many. </p> <p>The same holds for ChatGPT. In fact, much of the training of the current version of ChatGPT was done with data of two or so years ago and there is not that much suitable training data available on the internet either.</p> <p>The HPE Cray environment has a command line alternative to search engines though: the <code>man -K</code> command that searches for a term in the manual pages. It is often useful to better understand some error messages. E.g., sometimes Cray MPICH will suggest you to set some environment variable to work around some problem. You may remember that <code>man intro_mpi</code> gives a lot of information about Cray MPICH, but if you don't and, e.g., the error message suggests you to set <code>FI_CXI_RX_MATCH_MODE</code> to either <code>software</code> or <code>hybrid</code>, one way to find out where you can get more information about this environment variable is</p> <pre><code>man -K FI_CXI_RX_MATCH_MODE\n</code></pre>"},{"location":"1day-20230509/02_CPE/#other-modules","title":"Other modules","text":"<p>Other modules that are relevant even to users who do not do development:</p> <ul> <li>MPI: <code>cray-mpich</code>. </li> <li>LibSci: <code>cray-libsci</code></li> <li>Cray FFTW3 library: <code>cray-fftw</code></li> <li>HDF5:<ul> <li><code>cray-hdf5</code>: Serial HDF5 I/O library</li> <li><code>cray-hdf5-parallel</code>: Parallel HDF5 I/O library</li> </ul> </li> <li>NetCDF:<ul> <li><code>cray-netcdf</code></li> <li><code>cray-netcdf-hdf5parallel</code></li> <li><code>cray-parallel-netcdf</code></li> </ul> </li> <li>Python: <code>cray-python</code>, already contains a selection of packages that interface with     other libraries of the HPE Cray PE, including mpi4py, NumPy, SciPy and pandas.</li> <li>R: <code>cray-R</code></li> </ul> <p>The HPE Cray PE also offers other modules for debugging, profiling, performance analysis, etc. that are not covered in this short version of the LUMI course. Many more are covered in the 4-day courses for developers that we organise several times per year with the help of HPE and AMD.</p>"},{"location":"1day-20230509/02_CPE/#warning-1-you-do-not-always-get-what-you-expect","title":"Warning 1: You do not always get what you expect...","text":"<p>The HPE Cray PE packs a surprise in terms of the libraries it uses, certainly for users who come from an environment where the software is managed through EasyBuild, but also for most other users.</p> <p>The PE does not use the versions of many libraries determined by the loaded modules at runtime but instead uses default versions of libraries (which are actually in <code>/opt/cray/pe/lib64</code> on the system) which correspond to the version of the programming environment that is set as the default when installed. This is very much the behaviour of Linux applications also that pick standard libraries in a few standard directories and it enables many programs build with the HPE Cray PE to run without reconstructing the environment and in some cases to mix programs compiled with different compilers with ease (with the emphasis on some as there may still be library conflicts between other libraries when not using the  so-called rpath linking). This does have an annoying side effect though: If the default PE on the system  changes, all applications will use different libraries and hence the behaviour of your application may  change. </p> <p>Luckily there are some solutions to this problem.</p> <p>By default the Cray PE uses dynamic linking, and does not use rpath linking, which is a form of dynamic linking where the search path for the libraries is stored in each executable separately. On Linux, the search path for libraries is set through the environment variable <code>LD_LIBRARY_PATH</code>. Those Cray PE modules that have their libraries also in the default location, add the directories that contain the actual version of the libraries corresponding to the version of the module to the PATH-style environment variable <code>CRAY_LD_LIBRARY_PATH</code>. Hence all one needs to do is to ensure that those directories are put in <code>LD_LIBRARY_PATH</code> which is searched before the default location: <pre><code>export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n</code></pre></p> Small demo of adapting <code>LD_LIBRARY_PATH</code>: <p>An example that can only be fully understood after the section on the LUMI software stacks: <pre><code>$ module load LUMI/22.08\n$ module load lumi-CPEtools/1.0-cpeGNU-22.08\n$ ldd $EBROOTLUMIMINCPETOOLS/bin/mpi_check\n      linux-vdso.so.1 (0x00007f420cd55000)\n      libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f420c929000)\n      libmpi_gnu_91.so.12 =&gt; /opt/cray/pe/lib64/libmpi_gnu_91.so.12 (0x00007f4209da4000)\n      ...\n$ export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n$ ldd $EBROOTLUMIMINCPETOOLS/bin/mpi_check\n        linux-vdso.so.1 (0x00007fb38c1e0000)\n      libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fb38bdb4000)\n      libmpi_gnu_91.so.12 =&gt; /opt/cray/pe/mpich/8.1.18/ofi/gnu/9.1/lib/libmpi_gnu_91.so.12 (0x00007fb389198000)\n      ...\n</code></pre> The <code>ldd</code> command shows which libraries are used by an executable. Only a part of the very long output is shown in the above example. But we can already see that in the first case, the library <code>libmpi_gnu_91.so.12</code> is taken from <code>opt/cray/pe/lib64</code> which is the directory with the default versions, while in the second case it is taken from <code>/opt/cray/pe/mpich/8.1.18/ofi/gnu/9.1/lib/</code> which clearly is for a specific version of <code>cray-mpich</code>.</p> <p>We do provide an experimental module <code>lumi-CrayPath</code>  that tries to fix <code>LD_LIBRARY_PATH</code> in a way that unloading the module fixes <code>LD_LIBRARY_PATH</code> again to the state before adding <code>CRAY_LD_LIBRARY_PATH</code> and that reloading the module adapts <code>LD_LIBRARY_PATH</code> to the current value of <code>CRAY_LD_LIBRARY_PATH</code>. Loading that module after loading all other modules should fix this issue for most if not all software.</p> <p>The second solution would be to use rpath-linking for the Cray PE libraries, which can be done by setting the <code>CRAY_ADD_RPATH</code>environment variable: <pre><code>export CRAY_ADD_RPATH=yes\n</code></pre></p>"},{"location":"1day-20230509/02_CPE/#warning-2-order-matters","title":"Warning 2: Order matters","text":"<p>Lmod is a hierarchical module scheme and this is exploited by the HPE Cray PE. Not all modules are available right away and some only become available after loading other modules. E.g.,</p> <ul> <li><code>cray-fftw</code> only becomes available when a processor target module is loaded</li> <li><code>cray-mpich</code> requires both the network target module <code>craype-network-ofi</code> and a compiler module to be loaded</li> <li><code>cray-hdf5</code> requires a compiler module to be loaded and <code>cray-netcdf</code> in turn requires <code>cray-hdf5</code></li> </ul> <p>but there are many more examples in the programming environment.</p> <p>In the next section of the course we will see how unavailable modules can still be found with <code>module spider</code>. That command can also tell which other modules should be loaded  before a module can be loaded, but unfortunately due to the sometimes non-standard way  the HPE Cray PE uses Lmod that information is not always complete for the PE, which is also why we didn't demonstrate it here.</p>"},{"location":"1day-20230509/03_Modules/","title":"Modules on LUMI","text":"<p>Intended audience</p> <p>As this course is designed for people already familiar with HPC systems and as virtually any cluster nowadays uses some form of module environment, this section assumes that the reader is already familiar with a module environment but not necessarily the one used on LUMI.</p>"},{"location":"1day-20230509/03_Modules/#module-environments","title":"Module environments","text":"<p>Modules are commonly used on HPC systems to enable users to create  custom environments and select between multiple versions of applications. Note that this also implies that applications on HPC systems are often not installed in the regular directories one would expect from the documentation of some packages, as that location may not even always support proper multi-version installations and as one prefers to have a software stack which is as isolated as possible from the system installation to keep the image that has to be loaded on the compute nodes small.</p> <p>Another use of modules not mentioned on the slide is to configure the programs that is being activated. E.g., some packages expect certain additional environment variables to be set and modules can often take care of that also.</p> <p>There are 3 systems in use for module management. The oldest is a C implementation of the commands using module files written in Tcl. The development of that system stopped around 2012, with version 3.2.10.  This system is supported by the HPE Cray Programming Environment. A second system builds upon the C implementation but now uses Tcl also for the module command and not only for the module files. It is developed in France at the C\u00c9A compute centre. The version numbering was continued from the C implementation, starting with version 4.0.0.  The third system and currently probably the most popular one is Lmod, a version written in Lua with module files also written in Lua. Lmod also supports most Tcl module files. It is also supported by HPE Cray, though they tend to be a bit slow in following versions.</p> <p>On LUMI we have chosen to use Lmod. As it is very popular, many users may already be familiar with it, though it does make sense to revisit some of the commands that are specific for Lmod and differ from those in the two other implementations.</p> <p>It is important to realise that each module that you see in the overview corresponds to a module file that contains the actual instructions that should be executed when loading  or unloading a module, but also other information such as some properties of the module, information for search and help information.</p> Links <ul> <li>Old-style environment modules on SourceForge</li> <li>TCL Environment Modules home page on SourceForge and the     development on GitHub</li> <li>Lmod documentation and      Lmod development on GitHub</li> </ul> <p>I know Lmod, should I continue?</p> <p>Lmod is a very flexible tool. Not all sides using Lmod use all features, and Lmod can be configured in different ways to the extent that it may even look like a very different module system for people coming from another cluster. So yes, it makes sense to continue reading as Lmod on LUMI may have some tricks that are not available on your home cluster.</p>"},{"location":"1day-20230509/03_Modules/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the few modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"1day-20230509/03_Modules/#benefits-of-a-hierarchy","title":"Benefits of a hierarchy","text":"<p>When the hierarchy is well designed, you get some protection from loading modules that do not work together well. E.g., in the HPE Cray PE it is not possible to load the MPI library built for another compiler than your current main compiler. This is currently not exploited as much as we could on LUMI, mainly because we realised at the start that too many users are not familiar enough with hierarchies and would get confused more than the hierarchy helps them.</p> <p>Another benefit is that when \"swapping\" a module that makes other modules available with a different one, Lmod will try to look for equivalent modules in the list of modules made available by the newly loaded module.</p> <p>An easy example (though a tricky one as there are other mechanisms at play also) it to load a different programming environment in the default login environment right after login:</p> <pre><code>$ module load PrgEnv-aocc\n</code></pre> <p>which results in</p> <p></p> <p>The first two lines of output are due to to other mechanisms that are at work here,  and the order of the lines may seem strange but that has to do with the way Lmod works internally. Each of the PrgEnv modules hard loads a compiler module which is why Lmod tells you that it is loading <code>aocc/3.2.0</code>. However, there is also another mechanism at work that causes <code>cce/15.0.0</code> and <code>PrgEnv-cray/8.3.3</code> to be unloaded, but more about that in the next subsection (next slide).</p> <p>The important line for the hierarchy in the output are the lines starting with  \"Due to MODULEPATH changes...\". Remember that we said that each module has a corresponding module file. Just as binaries on a system, these are organised in a directory structure, and there is a path, in this case MODULEPATH, that determines where Lmod will look for module files. The hierarchy is implemented with a directory structure and the environment variable MODULEPATH, and when the <code>cce/15.0.0</code> module was unloaded and <code>aocc/3.2.0</code> module was loaded, that  MODULEPATH was changed. As a result, the version of the cray-mpich module for the  <code>cce/15.0.0</code> compiler became unavailable, but one with the same module name for the <code>aocc/3.2.0</code> compiler became available and hence Lmod unloaded the version for the <code>cce/15.0.0</code> compiler as it is no longer available but loaded the matching one for the <code>aocc/3.2.0</code> compiler. </p>"},{"location":"1day-20230509/03_Modules/#about-module-names-and-families","title":"About module names and families","text":"<p>In Lmod you cannot have two modules with the same name loaded at the same time. On LUMI, when you load a module with the same name as an already loaded module, that other module will be unloaded automatically before loading the new one. There is  even no need to use the <code>module swap</code> command for that (which in Lmod corresponds to a <code>module unload</code> of the first module and a <code>module load</code> of the second). This gives you an automatic protection against some conflicts if the names of the modules are properly chosen. </p> <p>Note</p> <p>Some clusters do not allow the automatic unloading of a module with the same name as the one you're trying to load, but on LUMI we felt that this is a  necessary feature to fully exploit a hierarchy.</p> <p>Lmod goes further also. It also has a family concept: A module can belong to a family (and at most 1) and no two modules of the same family can be loaded together.  The family property is something that is defined in the module file. It is commonly  used on systems with multiple compilers and multiple MPI implementations to ensure  that each compiler and each MPI implementation can have a logical name without  encoding that name in the version string (like needing to have <code>compiler/gcc-11.2.0</code> rather than <code>gcc/11.2.0</code>), while still having an easy way to avoid having two  compilers or MPI implementations loaded at the same time.  On LUMI, the conflicting module of the same family will be unloaded automatically when loading another module of that particular family.</p> <p>This is shown in the example in the previous subsection (the <code>module load PrgEnv-gnu</code> in  a fresh long shell) in two places. It is the mechanism that unloaded <code>PrgEnv-cray</code> when loading <code>PrgEnv-gnu</code> and that then unloaded <code>cce/14.0.1</code> when the  <code>PrgEnv-gnu</code> module loaded the <code>gcc/11.2.0</code> module.</p> <p>Note</p> <p>Some clusters do not allow the automatic unloading of a module of the same family as the one you're trying to load and produce an error message instead. On LUMI, we felt that this is a necessary feature to fully exploit the  hierarchy and the HPE Cray Programming Environment also relies very much on this feature being enabled to make live easier for users.</p>"},{"location":"1day-20230509/03_Modules/#extensions","title":"Extensions","text":"<p>It would not make sense to have a separate module for each of the hundreds of R packages or tens of Python packages that a software stack may contain. In fact, as the software for each module is installed in a separate directory it would also create a performance problem due to excess directory accesses simply to find out where a command is located, and very long search path environment variables such as PATH or the various variables packages such as Python, R or Julia use to find extension packages. On LUMI related packages are often bundled in a single module. </p> <p>Now you may wonder: If a module cannot be simply named after the package it contains as it contains several ones, how can I then find the appropriate module to load? Lmod has a solution for that through the so-called extension mechanism. An Lmod module can define extensions, and some of the search commands for modules will also search in the extensions of a module. Unfortunately, the HP{E Cray PE cray-python and cray-R modules do not provide that  information at the moment as they too contain several packages that may benefit from linking to optimised math libraries.</p>"},{"location":"1day-20230509/03_Modules/#searching-for-modules-the-module-spider-command","title":"Searching for modules: the module spider command","text":"<p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive.      The spider command will not only search in module names for the package, but also in extensions     of the modules and so will be able to tell you that a package is delivered by another module. See      Example 4 below where we will search for the CMake tools.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module.      This shows two kinds of information. First it shows which combinations of other modules one     might have to load to get access to the package. That works for both modules and extensions     of modules. In the latter case it will show both the module, and other modules that you might     have to load first to make the module available.     Second it will also show help information for the module if the module file provides      such information. </p> </li> </ol>"},{"location":"1day-20230509/03_Modules/#example-1-running-module-spider-on-lumi","title":"Example 1: Running <code>module spider</code> on LUMI","text":"<p>Let's first run the <code>module spider</code> command. The output varies over time, but at the time of writing, and leaving out a lot of the output, one would have gotten:</p> <p></p> <p></p> <p></p> <p>On the second screen we see, e.g., the ARMForge module which was available in just a single version at that time, and then Autoconf where the version is in blue and followed by <code>(E)</code>. This denotes that the Autoconf package is actually provided as an extension of another module, and one of the next examples will tell us how to figure out which one.</p> <p>The third screen shows the last few lines of the output, which actually also shows some help information for the command.</p>"},{"location":"1day-20230509/03_Modules/#example-2-searching-for-the-fftw-module-which-happens-to-be-provided-by-the-pe","title":"Example 2: Searching for the FFTW module which happens to be provided by the PE","text":"<p>Next let us search for the popular FFTW library on LUMI:</p> <pre><code>$ module spider FFTW\n</code></pre> <p>produces</p> <p></p> <p>This shows that the FFTW library is actually provided by the <code>cray-fftw</code> module and was at the time that this was tested available in 3 versions.  Note that (a) it is not case sensitive as FFTW is not in capitals in the module name and (b) it also finds modules where the argument of module spider is only part of the name.</p> <p>The output also suggests us to dig a bit deeper and  check for a specific version, so let's run</p> <pre><code>$ module spider cray-fftw/3.3.10.3\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>We now get a long list of possible combinations of modules that would enable us to load this module. What these modules are will be explained in the next session of this course. However, it does show a weakness when module spider is used with the HPE Cray PE. In some cases, not all possible combinations are shown (and this is the case here as the module is actually available directly after login and also via some other combinations of modules that are not shown). This is because the HPE Cray Programming Environment is system-installed and sits next to the application software stacks that are managed differently, but in some cases also because the HPE Cray PE sometimes fails to give the complete combination of modules that is needed. The command does work well with the software managed by the LUMI User Support Team as the next two examples will show.</p>"},{"location":"1day-20230509/03_Modules/#example-3-searching-for-gnuplot","title":"Example 3: Searching for GNUplot","text":"<p>To see if GNUplot is available, we'd first search for the name of the package:</p> <pre><code>$ module spider GNUplot\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>The output again shows that the search is not case sensitive which is fortunate as uppercase and lowercase letters are not always used in the same way on different clusters. Some management tools for scientific software stacks will only use lowercase letters, while the package we use on LUMI often uses both.</p> <p>We see that there are a lot of versions installed on the system and that the version actually contains more  information (e.g., <code>-cpeGNU-22.12</code>) that we will explain in the next part of this course. But you might of course guess that it has to do with the compilers that were used. It may look strange to you to have the same software built with different compilers. However, mixing compilers is sometimes risky as a library compiled with one compiler may not work in an executable compiled with another one, so to enable workflows that use multiple tools we try  to offer many tools compiled with multiple compilers (as for most software we don't use rpath linking which could help to solve that problem). So you want to chose the appropriate line in terms of the other software that you will be using.</p> <p>The output again suggests to dig a bit further for more information, so let's try</p> <pre><code>$ module spider gnuplot/5.4.6-cpeGNU-22.12\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>In this case, this module is provided by 3 different combinations of modules that also will be explained in the next part of this course. Furthermore, the output of the command now also shows some help information about the module, with some links to further documentation available on the system or on the web. The format of the output is generated automatically by the software installation tool that we use and we sometimes have to do some effort to fit all information in there.</p> <p>For some packages we also have additional information in our LUMI Software Library web site so it is often worth looking there also.</p>"},{"location":"1day-20230509/03_Modules/#example-4-searching-for-an-extension-of-a-module-cmake","title":"Example 4: Searching for an extension of a module: CMake.","text":"<p>The <code>cmake</code> command on LUMI is available in the operating system image, but as is often the case with such tools distributed with the OS, it is a rather old version and you may want to use a newer one.</p> <p>If you would just look through the list of available modules, even after loading some other modules to activate a larger software stack, you will not find any module called <code>CMake</code> though. But let's use the powers of <code>module spider</code> and try</p> <pre><code>$ module spider cmake\n</code></pre> <p>which produces</p> <p></p> <p>The output above shows us that there are actually four other versions of CMake on the system, but their version is followed by <code>(E)</code> which says that they are extensions of other modules. There is no module called <code>CMake</code> on the system.  But Lmod already tells us how to find out which module actually provides the CMake tools. So let's try</p> <pre><code>$ module spider CMake/3.25.2\n</code></pre> <p>which produces</p> <p></p> <p></p> <p>This shows us that the version is provided by a number of <code>buildtools</code> modules, and for each of those modules also shows us which other modules should be loaded to get access to the commands. E.g., the first line tells us that there is a module <code>buildtools/22.08</code> that provides that version of CMake, but that we first need to load some other modules, with <code>LUMI/22.08</code> and <code>partition/L</code> (in that order)  one such combination.</p> <p>So in this case, after</p> <pre><code>$ module load LUMI/22.12 partition/L buildtools/22.12\n</code></pre> <p>the <code>cmake</code> command would be available.</p> <p>And you could of course also use</p> <pre><code>$ module spider buildtools/22.12\n</code></pre> <p>to get even more information about the buildtools module, including any help included in the module.</p>"},{"location":"1day-20230509/03_Modules/#alternative-search-the-module-keyword-command","title":"Alternative search: the module keyword command","text":"<p>Lmod has a second way of searching for modules: <code>module keyword</code>, but unfortunately it does not yet work very well on LUMI as the version of Lmod is rather old and still has some bugs in the processing of the command. </p> <p>The <code>module keyword</code> command searches in some of the information included in module files for the given keyword, and shows in which modules the keyword was found.</p> <p>We do an effort to put enough information in the modules to make this a suitable additional way to discover software that is installed on the system.</p> <p>Let us look for packages that allow us to download software via the <code>https</code> protocol. One could try</p> <pre><code>$ module keyword https\n</code></pre> <p>which produces a lot of output:</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>The bug in the Lmod 8.3 version on LUMI is that all extensions are shown in the output while they are irrelevant. On the second screen though we see <code>cURL</code> and on the fourth screen <code>wget</code> which are two tools that can be used to fetch files from the internet.</p> <p>LUMI Software Library</p> <p>The LUMI Software Library also has a search box in the upper right. We will see in the next section of this course that much of the software of LUMI is managed through a tool called EasyBuild, and each module file corresponds to an EasyBuild recipe which is a file with the <code>.eb</code> extension. Hence the keywords can also be found in the EasyBuild recipes which are included in this web site, and from a page with an EasyBuild recipe (which may not mean much for you) it is easy to go back to the software package page itself for more information. Hence you can use the search box to search for packages that may not be installed on the system.</p> <p>The example given above though, searching for `https, would not work via that box as most EasyBuild recipes include https web links to refer to, e.g., documentation and would be  shown in the result.</p> <p>The LUMI Software Library site includes both software installed in our central software stack and software for which we make customisable build recipes available for user installation, but more about that in the tutorial section on LUMI software stacks.</p>"},{"location":"1day-20230509/03_Modules/#sticky-modules-and-the-module-purge-command","title":"Sticky modules and the module purge command","text":"<p>On some systems you will be taught to avoid <code>module purge</code> as many HPC systems do their default user configuration also through modules. This advice is often given on Cray systems as it is a common practice to preload a suitable set of target modules and a programming environment. On LUMI both are used. A default programming environment and set of target modules suitable for the login nodes is preloaded when you log in to the system, and next the <code>init-lumi</code> module is loaded which in turn makes the LUMI software stacks available that we will discuss in the next session.</p> <p>Lmod however has a trick that help to avoid removing necessary modules and it is called sticky modules. When issuing the <code>module purge</code> command these modules are automatically reloaded. It is very important to realise that those modules will not just be kept \"as is\" but are in fact unloaded and loaded again as we shall see later that this may have consequences. It is still possible to force unload all these modules using <code>module --force purge</code> or selectively unload those using <code>module --force unload</code>.</p> <p>The sticky property is something that is defined in the module file and not used by the module files ot the HPE Cray Programming Environment, but we shall see that there is a partial workaround for this in some of the LUMI software stacks. The <code>init-lumi</code> module mentioned above though is a sticky module, as are the modules that activate a software stack so that you don't have to start from scratch if you have already chosen a software stack but want to clean up your environment.</p> <p>Let us look at the output of the <code>module avail</code> command, taken just after login on the system at the time of writing of these notes (the exact list of modules shown is a bit fluid):</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Next to the names of modules you sometimes see one or more letters. The <code>(D)</code> means that that is currently the default version of the module, the one that will be loaded if you do not specify a version. Note that the default version may depend on other modules that are already loaded as we have seen in the discussion of the programming environment.</p> <p>The <code>(L)</code> means that a module is currently loaded.</p> <p>The <code>(S)</code> means that the module is a sticky module.</p> <p>Next to the <code>rocm</code> module you see <code>(D:5.0.2:5.2.0)</code>.  The <code>D</code> means that this version of the module, <code>5.2.3</code>, is currently the default on the system. The two version numbers next to this module show that the module can also  be loaded as <code>rocm/5.0.2</code> and <code>rocm/5.2.0</code>. These are two modules that were removed from the system during the last update of the system, but version 5.2.3 can be loaded as a replacement of these modules so that software that used the removed modules may still work without recompiling.</p> <p>At the end of the overview the extensions are also shown. If this would be fully implemented on LUMI, the list might become very long. There is a way in Lmod to hide that output but unfortunately it does not work on LUMI yet due to another bug in the already old version of Lmod.</p>"},{"location":"1day-20230509/03_Modules/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed in the above example that we don't show directories of module files in the overview (as is the case on most clusters) but descriptive texts about the module group. This is just one view on the module tree though, and it can be changed easily by loading a  version of the <code>ModuleLabel</code> module.</p> <ul> <li><code>ModuleLabel/label</code> produces the default view of the previous example</li> <li><code>ModuleLabel/PEhierarchy</code> still uses descriptive texts but will show the whole      module hierarchy of the HPE Cray Programming Environment.</li> <li><code>ModuleLabel/system</code> does not use the descriptive texts but shows module directories instead.</li> </ul> <p>When using any kind of descriptive labels, Lmod can actually bundle module files from different  directories in a single category and this is used heavily when <code>ModuleLabel/label</code> is loaded  and to some extent also when <code>ModuleLabel/PEhierarchy</code> is loaded.</p> <p>It is rather hard to provide multiple colour schemes in Lmod, and as we do not know how your  terminal is configured it is also impossible to find a colour scheme that works for all users. Hence we made it possible to turn on and off the use of colours by Lmod through the <code>ModuleColour/on</code> and <code>ModuleColour/off</code> modules.</p> <p>In the future, as soon as we have a version of Lmod where module extensions function properly, we will also provide a module to turn on and off the display of extension in the output of <code>module avail</code> .</p> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment.  You can still load them if you know they exist and specify the full version but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work if you use modules that are hidden in the context you're in or if you try to use any module that was designed for us to maintain the system and is therefore hidden  from regular users.</p> <p>Example</p> <p>An example that will only become clear in the next session: When working with the software stack called <code>LUMI/22.08</code>, which is built upon the HPE Cray Programming Environment version 22.08, all (well, most) of the modules corresponding to other version of the Cray PE are hidden.</p>"},{"location":"1day-20230509/03_Modules/#getting-help-with-the-module-help-command","title":"Getting help with the module help command","text":"<p>Lmod has the <code>module help</code> command to get help on modules</p> <pre><code>$ module help\n</code></pre> <p>without further arguments will show some help on the <code>module</code> command. </p> <p>With the name of a module specified, it will show the help information for the default version of that module, and with a full name and version specified it will show this information specifically for that version of the module. But note that <code>module help</code> can only show help for currently available modules.</p> <p>Try, e.g., the following commands:</p> <pre><code>$ module help cray-mpich\n$ module help cray-python/3.9.13.1\n$ module help buildtools/22.12\n</code></pre> <p>Lmod also has another command that produces more limited information (and is currently not fully exploited on LUMI): <code>module whatis</code>. It is more a way to tag a module with different kinds of information, some of  which has a special meaning for Lmod and is used at some places, e.g., in the output of <code>module spider</code> without arguments.</p> <p>Try, e.g.,:</p> <pre><code>$ module whatis Subversion\n$ module whatis Subversion/1.14.2\n</code></pre>"},{"location":"1day-20230509/03_Modules/#a-note-on-caching","title":"A note on caching","text":"<p>Modules are stored as (small) files in the file system. Having a large module system with much software preinstalled for everybody means a lot of small files which will make our Lustre file system very unhappy. Fortunately Lmod does use caches by default. On LUMI we currently have no  system cache and only a user cache. That cache can be found in <code>$HOME/.lmod.d</code>. </p> <p>That cache is also refreshed automatically every 24 hours. You'll notice when this happens as, e.g., the <code>module spider</code> and <code>module available</code> commands will be slow during the rebuild. you may need to clean the cache after installing new software as on LUMI Lmod does not always detect changes to the installed software,</p> <p>Sometimes you may have to clear the cache also if you get very strange answers from  <code>module spider</code>. It looks like the non-standard way in which the HPE Cray Programming Environment does certain things in Lmod can cause inconsistencies in the cache. This is also one of the reasons whey we do not yet have a central cache for that  software that is installed in the central stacks as we are not sure when that cache is in good shape.</p>"},{"location":"1day-20230509/03_Modules/#a-note-on-other-commands","title":"A note on other commands","text":"<p>As this tutorial assumes some experience with using modules on other clusters, we haven't paid much attention to some of the basic commands that are mostly the same across all three module environments implementations.  The <code>module load</code>, <code>module unload</code> and <code>module list</code> commands work largely as you would expect, though the output style of <code>module list</code> may be a little different from what you expect. The latter may show some inactive modules. These are modules that were loaded at some point, got unloaded when a module closer to the root of the hierarchy of the module system got unloaded, and they will be reloaded automatically when that module or an equivalent (family or name) module is loaded that makes this one or an equivalent module available again.</p> <p>Example</p> <p>To demonstrate this, try in a fresh login shell (with the lines starting with a <code>$</code> the commands that you should enter at the command prompt):</p> <pre><code>$ module unload craype-network-ofi\n\nInactive Modules:\n  1) cray-mpich\n\n$ module load craype-network-ofi\n\nActivating Modules:\n  1) cray-mpich/8.1.23\n</code></pre> <p>The <code>cray-mpich</code> module needs both a valid network architecture target module to be loaded (not <code>craype-network-none</code>) and a compiler module. Here we remove the network target module which inactivates the <code>cray-mpich</code> module, but the module gets reactivated again as soon as the network target module is reloaded.</p> <p>The <code>module swap</code> command is basically equivalent to a <code>module unload</code> followed by a <code>module load</code>.  With one argument it will look for a module with the same name that is loaded and unload that one  before loading the given module. With two modules, it will unload the first one and then load the second one. The <code>module swap</code> command is not really needed on LUMI as loading a conflicting module (name or family) will automatically unload the previously loaded one. However, in case of replacing  a module of the same family with a different name, <code>module swap</code> can be a little faster than just a <code>module load</code> as that command will need additional operations as in the first step it will  discover the family conflict and then try to resolve that in the following steps (but explaining that in detail would take us too far in the internals of Lmod).</p>"},{"location":"1day-20230509/03_Modules/#links","title":"Links","text":"<p>These links were OK at the time of the course. This tutorial will age over time though and is not maintained but may be replaced with evolved versions when the course is organised again, so links may break over time.</p> <ul> <li>Lmod documentation and more specifically     the User Guide for Lmod which is the part specifically for regular users who do not     want to design their own modules.</li> <li>Information on the module environment in the LUMI documentation</li> </ul>"},{"location":"1day-20230509/04_Software_stacks/","title":"LUMI Software Stacks","text":"<p>In this section we discuss</p> <ul> <li>Several of the ways in which we offer software on LUMI</li> <li>Managing software in our primary software stack which is based on EasyBuild</li> </ul>"},{"location":"1day-20230509/04_Software_stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"1day-20230509/04_Software_stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: the option to use a coherent unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in Apple Silicon M-series but then without the NUMA character     (except maybe for the Ultra version that consists of two dies).</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a a talk in the     EasyBuild user meeting in 2022.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"1day-20230509/04_Software_stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparent way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be accustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. We do offer some help so set up Spack also but it is mostly offered \"as is\" an we will not do bug-fixing or development in Spack package files.</p>"},{"location":"1day-20230509/04_Software_stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionnaire send out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, the so-called Cassini provider,      so any software compiled with an MPI library that     requires UCX, or any other distributed memory model build on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intra-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-bus comes to mind.</li> </ul> <p>Also, the LUMI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that I did not yet mention is that software that accesses tens of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. On LUMI the tool is called lumi-container-wrapper but it may by some from CSC also be known as Tykky.</p>"},{"location":"1day-20230509/04_Software_stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 3 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes and zen3 + MI250X for the LUMI-G partition. We were also planning to have a fourth version for the visualisation nodes with  zen2 CPUs combined with NVIDIA GPUs, but that may never materialise and we may manage those differently.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p> <p>We also have an extensible software stack based on Spack which has been pre-configured to use the compilers from the Cray PE. This stack is offered as-is for users who know how to use Spack, but we don't offer much support nor do we do any bugfixing in Spack.</p>"},{"location":"1day-20230509/04_Software_stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"1day-20230509/04_Software_stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"1day-20230509/04_Software_stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It ia also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. </p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"1day-20230509/04_Software_stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/22.08, LUMI/22.12 and LUMI/23.03 modules. Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules. There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes and partition/G for the AMD GPU nodes. We may have a separate partition for the visualisation nodes in the future but that is not clear yet.</p> <p>There is also a hidden partition/common module in which we install software that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"1day-20230509/04_Software_stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"1day-20230509/04_Software_stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system. We expect this to happen especially with packages that  require specific MPI versions. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And we need a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"1day-20230509/04_Software_stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is our primary software installation tool. We selected this as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the build-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain we would have problems with MPI. EasyBuild uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures with some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     or the Intel compiler will simply optimize for a two decades old CPU.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system. </p> <p>We also have the LUMI Software Library which documents all software for which we have EasyBuild recipes available.  This includes both the pre-installed software and the software for which we provide recipes in the LUMI-EasyBuild-contrib GitHub repository, and even instructions for some software that is not suitable for installation through EasyBuild or Spack, e.g., because it likes to write in its own directories while running.</p>"},{"location":"1day-20230509/04_Software_stacks/#easybuild-recipes-easyconfigs","title":"EasyBuild recipes - easyconfigs","text":"<p>EasyBuild uses a build recipe for each individual package, or better said, each individual module as it is possible to install more than one software package in the same module. That installation description relies on either a generic or a specific installation process provided by an easyblock. The build recipes are called easyconfig files or simply easyconfigs and are Python files with  the extension <code>.eb</code>. </p> <p>The typical steps in an installation process are:</p> <ol> <li>Downloading sources and patches. For licensed software you may have to provide the sources as     often they cannot be downloaded automatically.</li> <li>A typical configure - build - test - install process, where the test process is optional and     depends on the package providing useable pre-installation tests.</li> <li>An extension mechanism can be used to install perl/python/R extension packages</li> <li>Then EasyBuild will do some simple checks (some default ones or checks defined in the recipe)</li> <li>And finally it will generate the module file using lots of information specified in the      EasyBuild recipe.</li> </ol> <p>Most or all of these steps can be influenced by parameters in the easyconfig.</p>"},{"location":"1day-20230509/04_Software_stacks/#the-toolchain-concept","title":"The toolchain concept","text":"<p>EasyBuild uses the toolchain concept. A toolchain consists of compilers, an MPI implementation and some basic mathematics libraries. The latter two are optional in a toolchain. All these  components have a level of exchangeability as there are language standards, as MPI is standardised, and the math libraries that are typically included are those that provide a standard API for which several implementations exist. All these components also have in common that it is risky to combine  pieces of code compiled with different sets of such libraries and compilers because there can be conflicts in names in the libraries.</p> <p>On LUMI we don't use the standard EasyBuild toolchains but our own toolchains specifically for Cray and these are precisely the <code>cpeCray</code>, <code>cpeGNU</code>, <code>cpeAOCC</code> and <code>cpeAMD</code> modules already mentioned  before.</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p></p> <p>There is also a special toolchain called the SYSTEM toolchain that uses the compiler provided by the operating system. This toolchain does not fully function in the same way as the other toolchains when it comes to handling dependencies of a package and is therefore a bit harder to use. The EasyBuild designers had in mind that this compiler would only be used to bootstrap an EasyBuild-managed software stack, but we do use it for a bit more on LUMI as it offers us a relatively easy way to compile some packages also for the CrayEnv stack and do this in a way that they interact as little as possible with other software.</p> <p>It is not possible to load packages from different cpe toolchains at the same time. This is an EasyBuild restriction, because mixing libraries compiled with different compilers does not always work. This could happen, e.g., if a package compiled with the Cray Compiling Environment and one compiled with the GNU compiler collection would both use a particular  library, as these would have the same name and hence the last loaded one would be used by both executables (we don't use rpath or runpath linking in EasyBuild for those familiar with that technique).</p> <p>However, as we did not implement a hierarchy in the Lmod implementation of our software stack at the toolchain level, the module system will not protect you from these mistakes.  When we set up the software stack, most people in the support team considered it too misleading and difficult to ask users to first select the toolchain they want to use and then see the  software for that toolchain.</p> <p>It is however possible to combine packages compiled with one CPE-based toolchain with packages compiled with teh system toolchain, but we do avoid mixing those when linking as that may cause problems. The reason is that we try to use as much as possible static linking in the SYSTEM toolchain so that these packages are as independent as possible.</p> <p>And with some tricks it might also be possible to combine packages from the LUMI software stack with packages compiled with Spack, but one should make sure that no Spack packages are available when building as mixing libraries could cause problems. Spack uses rpath linking which is why this may work.</p>"},{"location":"1day-20230509/04_Software_stacks/#easyconfig-names-and-module-names","title":"EasyConfig names and module names","text":"<p>There is a convention for the naming of an EasyConfig as shown on the slide. This is not mandatory, but EasyBuild will fail to automatically locate easyconfigs for dependencies  of a package that are not yet installed if the easyconfigs don't follow the naming convention. Each part of the name also corresponds to a parameter in the easyconfig  file.</p> <p>Consider, e.g., the easyconfig file <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.</p> <ol> <li>The first part of the name, <code>GROMACS</code>, is the name of the package, specified by the     <code>name</code> parameter in the easyconfig, and is after installation also the name of the     module.</li> <li>The second part, <code>2021.4</code>, is the version of GROMACS and specified by the     <code>version</code> parameter in the easyconfig.</li> <li> <p>The next part, <code>cpeCray-22.08</code> is the name and version of the toolchain,     specified by the <code>toolchain</code> parameter in the easyconfig. The version of the     toolchain must always correspond to the version of the LUMI stack. So this is     an easyconfig for installation in <code>LUMI/22.08</code>.</p> <p>This part is not present for the SYSTEM toolchain</p> </li> <li> <p>The final part, <code>-PLUMED-2.8.0-CPU</code>, is the version suffix and used to provide     additional information and distinguish different builds with different options     of the same package. It is specified in the <code>versionsuffix</code> parameter of the     easyconfig.</p> <p>This part is optional.</p> </li> </ol> <p>The version, toolchain + toolchain version and versionsuffix together also combine to the version of the module that will be generated during the installation process. Hence this easyconfig file will generate the module  <code>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.8.0-CPE</code>.</p>"},{"location":"1day-20230509/04_Software_stacks/#installing","title":"Installing","text":""},{"location":"1day-20230509/04_Software_stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"1day-20230509/04_Software_stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>The next step is to configure your environment. First load the proper version of the LUMI stack for which you want to install software, and you may want to change to the proper partition also if you are cross-compiling.</p> <p>Once you have selected the software stack and partition, all you need to do to activate EasyBuild to install additional software is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition. </p> <p>Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p> <p>Note that the <code>EasyBuild-user</code> module is only needed for the installation process. For using the software that is installed that way it is sufficient to ensure that <code>EBU_USER_PREFIX</code> has the proper value before loading the <code>LUMI</code> module.</p>"},{"location":"1day-20230509/04_Software_stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS we already have support. At the moment we have to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre> We now also have the LUMI Software Library which lists all software that we manage via EasyBuild and make available either pre-installed on the system or as an EasyBuild recipe for user installation.</p> <p>Output of the search commands:</p> <p><code>eb --search GROMACS</code> produces:</p> <p> </p> <p>while <code>eb -S GROMACS</code> produces:</p> <p> </p> <p>The information provided by both variants of the search command is the same, but <code>-S</code> presents the information in a more compact form.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS there already is a GPU version for AMD GPUs in active development so even before LUMI-G was active we chose to ensure that we could distinguish between GPU and CPU-only versions. To install it, we first run  <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The installation of dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>The output of this command looks like:</p> <p></p> <p></p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb\n</code></pre></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p>"},{"location":"1day-20230509/04_Software_stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>There is a little problem though that you may run into. Sometimes the module does not show up immediately. This is because Lmod keeps a cache when it feels that Lmod searches become too slow and often fails to detect that the cache is outdated. The easy solution is then to simply remove the cache which is in <code>$HOME/.lmod.d/.cache</code>,  which you can do with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> And we have seen some very rare cases where even that did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work.</p>"},{"location":"1day-20230509/04_Software_stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r . </code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.0-cpeGNU-22.08.eb \u2013r . </code></pre></p>"},{"location":"1day-20230509/04_Software_stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greatest before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/easybuild/easyconfigs</code>.</p>"},{"location":"1day-20230509/04_Software_stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory, and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software.</p> <p>Moreover, EasyBuild also keeps copies of all installed easyconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"1day-20230509/04_Software_stacks/#easybuild-tips-and-tricks","title":"EasyBuild tips and tricks","text":"<p>Updating the version of a package often requires only trivial changes in the easyconfig file. However, we do tend to use checksums for the sources so that we can detect if the available sources have changed. This may point to files being tampered with, or other changes that might need us to be a bit more careful when installing software and check a bit more again.  Should the checksum sit in the way, you can always disable it by using  <code>--ignore-checksums</code> with the <code>eb</code> command.</p> <p>Updating an existing recipe to a new toolchain might be a bit more involving as you also have to make build recipes for all dependencies. When we update a toolchain on the system, we often bump the versions of all installed libraries to one of the latest versions to have most bug fixes and security patches in the software stack, so you need to check for those versions also to avoid installing yet another unneeded version of a library.</p> <p>We provide documentation on the available software that is either pre-installed or can be user-installed with EasyBuild in the  LUMI Software Library. For most packages this documentation does also contain information about the license. The user documentation for some packages gives more information about how to use the package on LUMI, or sometimes also about things that do not work. The documentation also shows all EasyBuild recipes, and for many packages there is  also some technical documentation that is more geared towards users who want to build or modify recipes. It sometimes also tells why we did things in a particular way.</p>"},{"location":"1day-20230509/04_Software_stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>There is also a later course developed by LUST for developers of EasyConfigs for LUMI that can be found on  lumi-supercomputer.github.io/easybuild-tutorial.</p>"},{"location":"1day-20230509/05_Exercises_1/","title":"Exercises 1: Modules, the HPE Cray PE and EasyBuild","text":"<p>See the instructions to set up for the exercises.</p>"},{"location":"1day-20230509/05_Exercises_1/#exercises-on-the-use-of-modules","title":"Exercises on the use of modules","text":"<ol> <li> <p>The <code>Bison</code> program installed in the OS image is pretty old (version 3.0.4) and     we want to use a newer one. Is there one available on LUMI?</p> Click to see the solution. <pre><code>module spider Bison\n</code></pre> <p>tells us that there are indeed newer versions available on the system. </p> <p>The versions that have a compiler name (usually <code>gcc</code>) in their name followed by some seemingly random characters are installed with Spack and not in the CrayEnv or LUMI environments.</p> <p>To get more information about <code>Bison/3.8.2</code>: </p> <pre><code>module spider Bison/3.8.2\n</code></pre> <p>tells us that Bison 3.8.2 is provided by a couple of <code>buildtools</code> modules and available in all partitions in several versions of the <code>LUMI</code> software stack and in <code>CrayEnv</code>.</p> <p>Alternatively, in this case</p> <pre><code>module keyword Bison\n</code></pre> <p>would also have shown that Bison is part of several versions of the <code>buildtools</code> module.</p> <p>The <code>module spider</code> command is often the better command if you use names that with a high  likelihood could be the name of a package, while <code>module keyword</code> is often the better choice for words that are more a keyword. But if one does not return the solution it is a good idea  to try the other one also.</p> </li> <li> <p>The <code>htop</code> command is a nice alternative for the <code>top</code> command with a more powerful user interface.     However, typing <code>htop</code> on the command line produces an error message. Can you find and run <code>htop</code>?</p> Click to see the solution. <p>We can use either <code>module spider htop</code> or <code>module keyword htop</code> to find out that <code>htop</code> is indeed available on the system. With <code>module keyword htop</code> we'll find out immediately that it is in the  <code>systools</code> modules and some of those seem to be numbered after editions of the LUMI stack suggesting that they may be linked to a stack, with <code>module spider</code> you'll first see that it is an extension of a module and see the versions. You may again see some versions installed with Spack.</p> <p>Let's check further for <code>htop/3.2.1</code> that should exist according to <code>module spider htop</code>:</p> <pre><code>module spider htop/3.2.1\n</code></pre> <p>tells us that this version of <code>htop</code> is available in all partitions of <code>LUMI/22.08</code> and <code>LUMI/22.06</code>, and in <code>CrayEnv</code>. Let us just run it in the <code>CrayEnv</code> environment:</p> <pre><code>module load CrayEnv\nmodule load systools/22.08\nhtop\n</code></pre> <p>(You can quit <code>htop</code> by pressing <code>q</code> on the keyboard.)</p> </li> <li> <p>In the future LUMI will offer Open OnDemand as a browser-based interface to LUMI that will also enable     running some graphical programs. At the moment the way to do this is through a so-called VNC server.     Do we have such a tool on LUMI, and if so, how can we use it?</p> Click to see the solution. <p><code>module spider VNC</code> and <code>module keyword VNC</code> can again both be used to check if there is software available to use VNC. Both will show that there is a module <code>lumi-vnc</code> in several versions. If you  try loading the older ones of these (the version number points at the date of some scripts) you will notice that some produce a warning as they are deprecated. However, when installing a new version we  cannot remove older ones in one sweep, and users may have hardcoded full module names in scripts they use to set their environment, so we chose to not immediate delete these older versions.</p> <p>One thing you can always try to get more information about how to run a program, is to ask for the help information of the module. For this to work the module must first be available, or you have to use  <code>module spider</code> with the full name of the module. We see that version <code>20230110</code> is the newest version of the module, so let's try that one:</p> <pre><code>module spider lumi-vnc/20230110\n</code></pre> <p>The output may look a little strange as it mentions <code>init-lumi</code> as one of the modules that you can load. That is because this tool is available even outside <code>CrayEnv</code> or the LUMI stacks. But this command also shows a long help test telling you how to use this module (though it does assume some familiarity with how X11 graphics work on Linux).</p> <p>Note that if there is only a single version on the system, as is the case for the course in May 2023, the <code>module spider VNC</code> command without specific version or correct module name will already display the help information.</p> </li> <li> <p>Search for the <code>bzip2</code> tool (and not just the <code>bunzip2</code> command as we also need the <code>bzip2</code> command) and make      sure that you can use software compiled with the Cray compilers in the LUMI stacks in the same session.</p> Click to see the solution. <pre><code>module spider bzip2\n</code></pre> <p>shows that there are versions of <code>bzip2</code> for several of the <code>cpe*</code> toolchains and in several versions of the LUMI software stack.</p> <p>Of course we prefer to use a recent software stack, the <code>22.08</code> or <code>22.12</code> (but as of early May 2023,  there is a lot more software ready-to-install for <code>22.08</code>).  And since we want to use other software compiled with the Cray compilers also, we really want a <code>cpeCray</code> version to avoid conflicts between  different toolchains. So the module we want to load is <code>bzip2/1.0.8-cpeCray-22.08</code>.</p> <p>To figure out how to load it, use</p> <pre><code>module spider bzip2/1.0.8-cpeCray-22.08\n</code></pre> <p>and see that (as expected from the name) we need to load <code>LUMI/22.08</code> and can then use it in any of the partitions.</p> </li> </ol>"},{"location":"1day-20230509/05_Exercises_1/#exercises-on-compiling-software-by-hand","title":"Exercises on compiling software by hand","text":"<p>These exercises are optional during the session, but useful if you expect  to be compiling software yourself. The source files mentioned can be found in the subdirectory CPE of the download.</p>"},{"location":"1day-20230509/05_Exercises_1/#compilation-of-a-program-1-a-simple-hello-world-program","title":"Compilation of a program 1: A simple \"Hello, world\" program","text":"<p>Four different implementations of a simple \"Hello, World!\" program are provided in the <code>CPE</code> subdirectory:</p> <ul> <li><code>hello_world.c</code> is an implementation in C,</li> <li><code>hello_world.cc</code> is an implementation in C++,</li> <li><code>hello_world.f</code> is an implementation in Fortran using the fixed format source form,</li> <li><code>hello_world.f90</code> is an implementation in Fortran using the more modern free format source form.</li> </ul> <p>Try to compile these programs using the programming environment of your choice.</p> Click to see the solution. <p>We'll use the default version of the programming environment (22.12 at the moment of the course in May 2023), but in case you want to use a particular version, e.g., the 22.08 version, and want to be very sure that all modules are loaded correctly from the start you could consider using</p> <pre><code>module load cpe/22.08\nmodule load cpe/22.08\n</code></pre> <p>So note that we do twice the same command as the first iteration does not always succeed to reload all modules in the correct version. Do not combine both lines into a single <code>module load</code> statement as that would again trigger the bug that prevents all modules to be reloaded in the first iteration.</p> <p>The sample programs that we asked you to compile do not use the GPU. So there are three programming environments that we can use: <code>PrgEnv-gnu</code>, <code>PrgEnv-cray</code> and <code>PrgEnv-aocc</code>. All three will work, and they work almost the same.</p> <p>Let's start with an easy case, compiling the C version of the program with the GNU C compiler. For this all we need to do is</p> <pre><code>module load PrgEnv-gnu\ncc hello_world.c\n</code></pre> <p>which will generate an executable named <code>a.out</code>.  If you are not comfortable using the default version of <code>gcc</code> (which produces the warning message when loading the <code>PrgEnv-gnu</code> module) you can always load the <code>gcc/11.2.0</code> module instead after loading <code>PrgEnv-gnu</code>.</p> <p>Of course it is better to give the executable a proper name which can be done with the <code>-o</code> compiler option:</p> <pre><code>module load PrgEnv-gnu\ncc hello_world.c -o hello_world.x\n</code></pre> <p>Try running this program:</p> <pre><code>./hello_world.x\n</code></pre> <p>to see that it indeed works. We did forget another important compiler option, but we'll discover that in the next exercise.</p> <p>The other programs are equally easy to compile using the compiler wrappers:</p> <pre><code>CC hello_world.cc -o hello_world.x\nftn hello_world.f -o hello_world.x\nftn hello_world.f90 -o hello_world.x\n</code></pre>"},{"location":"1day-20230509/05_Exercises_1/#compilation-of-a-program-2-a-program-with-blas","title":"Compilation of a program 2: A program with BLAS","text":"<p>In the <code>CPE</code> subdirectory you'll find the C program <code>matrix_mult_C.c</code> and the Fortran program <code>matrix_mult_F.f90</code>. Both do the same thing: a matrix-matrix multiplication using the 6 different orders of the three nested loops involved in doing a matrix-matrix multiplication, and a call to the BLAS routine DGEMM that does the same for comparison.</p> <p>Compile either of these programs using the Cray LibSci library for the BLAS routine. Do not use OpenMP shared memory parallelisation. The code does not use MPI.</p> <p>The resulting executable takes one command line argument, the size of the square matrix. Run the script using <code>1000</code> for the matrix size and see what happens.</p> <p>Note that the time results may be very unreliable as we are currently doing this on the login nodes. In the session of Slurm you'll learn how to request compute nodes and it might be interesting to redo this on a compute node with a larger matrix size as the with a matrix size of 1000 all data may stay in the third level cache and you will not notice the differences that you should note. Also, because these nodes are shared with a lot of people any benchmarking is completely unreliable.</p> <p>If this program takes more than half a minute or so before the first result line in the table, starting with <code>ijk-variant</code>, is printed, you've very likely done something wrong (unless the load on the system is extreme). In fact, if you've done things well the time reported for the <code>ijk</code>-variant should be well under 3 seconds for both the C and Fortran versions...</p> Click to see the solution. <p>Just as in the previous exercise, this is a pure CPU program so we can chose between the same three programming environments.</p> <p>The one additional \"difficulty\" is that we need to link with the BLAS library. This is very easy however in  the HPE Cray PE if you use the compiler wrappers rather than calling the compilers yourself: you only need to make sure that the <code>cray-libsci</code> module is loaded and the wrappers will take care of the rest. And on most systems (including LUMI) this module will be loaded automatically when you load the <code>PrgEnv-*</code> module.</p> <p>To compile with the GNU C compiler, all you need to do is</p> <pre><code>module load PrgEnv-gnu\ncc -O3 matrix_mult_C.c -o matrix_mult_C_gnu.x\n</code></pre> <p>will generate the executable <code>matrix_mult_C_gnu.x</code>.</p> <p>Note that we add the <code>-O3</code> option and it is very important to add either <code>-O2</code> or <code>-O3</code> as by default the GNU compiler will generate code without any optimization for debugging purposes, and that code is in this case easily five times or more slower. So if you got much longer run times than indicated this is likely the mistake that you made.</p> <p>To use the Cray C compiler instead only one small change is needed: Loading a different programming  environment module:</p> <pre><code>module load PrgEnv-cray\ncc -O3 matrix_mult_C.c -o matrix_mult_C_cray.x\n</code></pre> <p>will generate the executable <code>matrix_mult_C_cray.x</code>.</p> <p>Likewise for the AMD AOCC compiler we can try with loading yet another <code>PrgEnv-*</code> module:</p> <pre><code>module load PrgEnv-aocc\ncc -O3 matrix_mult_C.c -o matrix_mult_C_aocc.x\n</code></pre> <p>but it turns out that this fails with linker error messages about not being able to find the <code>sin</code> and <code>cos</code> functions. When using the AOCC compiler the <code>libm</code> library with basic math functions is not linked automatically, but this is easily done by adding the <code>-lm</code> flag:</p> <pre><code>module load PrgEnv-aocc\ncc -O3 matrix_mult_C.c -lm -o matrix_mult_C_aocc.x\n</code></pre> <p>For the Fortran version of the program we have to use the <code>ftn</code> compiler wrapper instead, and the issue with the math libraries in the AOCC compiler does not occur. So we get</p> <pre><code>module load PrgEnv-gnu\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_gnu.x\n</code></pre> <p>for the GNU Fortran compiler,</p> <pre><code>module load PrgEnv-cray\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_cray.x\n</code></pre> <p>for the Cray Fortran compiler and</p> <pre><code>module load PrgEnv-aocc\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_aocc.x\n</code></pre> <p>for the AMD Fortran compiler.</p> <p>When running the program you will see that even though the 6 different loop orderings  produce the same result, the time needed to compile the matrix-matrix product is very different and those differences would be even more pronounced with bigger matrices (which you can do after the session on using Slurm).</p> <p>The exercise also shows that not all codes are equal even if they produce a result of the same quality. The six different loop orderings run at very different speed, and none of our simple implementations can beat a good library, in this case the BLAS library included in LibSci.</p> <p>The results with the Cray Fortran compiler are particularly interesting. The result for the BLAS library is slower which we do not yet understand, but it also turns out that  for four of the six loop orderings we get the same result as with the BLAS library DGEMM routine. It looks like the compiler simply recognized that this was code for a matrix-matrix multiplication and replaced it with a call to the BLAS library. The Fortran 90 matrix multiplication is also replaced by a call of the DGEMM routine. To confirm all this, unload the <code>cray-libsci</code> module and try to compile again and you will see five error messages about not being able to find DGEMM.</p>"},{"location":"1day-20230509/05_Exercises_1/#compilation-of-a-program-3-a-hybrid-mpiopenmp-program","title":"Compilation of a program 3: A hybrid MPI/OpenMP program","text":"<p>The file <code>mpi_omp_hello.c</code> is a hybrid MPI and OpenMP C program that sends a message from each thread in each MPI rank. It is basically a simplified version of the programs found in the <code>lumi-CPEtools</code> modules that can be used to quickly check  the core assignment in a hybrid MPI and OpenMP job (see later in this tutorial). It is again just a CPU-based program.</p> <p>Compile the program with your favourite C compiler on LUMI.</p> <p>We have not yet seen how to start an MPI program. However, you can run the executable on the login nodes and it will then contain just a single MPI rank. </p> Click to see the solution. <p>In the HPE Cray PE environment, you don't use <code>mpicc</code> to compile a C MPI program, but you just use the <code>cc</code> wrapper as for any other C program. To enable MPI you  have to make sure that the <code>cray-mpich</code> module is loaded. This module will usually be loaded by loading one of the <code>PrgEnv-*</code> modules, but only if the right network target module, which is <code>craype-network-ofi</code>, is also already loaded. </p> <p>Compiling the program is very simple:</p> <pre><code>module load PrgEnv-gnu\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_gnu.x\n</code></pre> <p>to compile with the GNU C compiler, </p> <pre><code>module load PrgEnv-cray\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_cray.x\n</code></pre> <p>to compile with the Cray C compiler, and</p> <pre><code>module load PrgEnv-aocc\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_aocc.x\n</code></pre> <p>to compile with the AMD AOCC compiler.</p> <p>To run the executables it is not even needed to have the respective <code>PrgEnv-*</code> module loaded since the binaries will use a copy of the libraries stored in a default directory, though there have been bugs in the past preventing this to work with <code>PrgEnv-aocc</code>.</p>"},{"location":"1day-20230509/05_Exercises_1/#information-in-the-lumi-software-library","title":"Information in the LUMI Software Library","text":"<p>Explore the LUMI Software Library.</p> <ul> <li>Search for information for the package ParaView and quickly read through the page</li> </ul> Click to see the solution. <p>Link to the ParaView documentation</p> <p>It is an example of a package for which we have both user-level and some technical information. The page will first show some license information, then the actual user information which in case of this package is very detailed and long. But it is also a somewhat complicated package to use. It will become easier when LUMI evolves a bit further, but there will always be some pain. Next comes the more technical part: Links to the EasyBuild recipe and some information about how we build the package.</p> <p>We currently only provide ParaView in the cpeGNU toolchain. This is because it has a lot of dependencies that are not trivial to compile and to port to the other compilers on the system, and EasyBuild is  strict about mixing compilers basically because it can cause a lot of problems, e.g., due to conflicts between OpenMP runtimes.</p>"},{"location":"1day-20230509/05_Exercises_1/#installing-software-with-easybuild","title":"Installing software with EasyBuild","text":"<p>These exercises are based on material from the EasyBuild tutorials (and we have a special version for LUMI also).</p> <p>Note: If you want to be able to uninstall all software installed through the exercises easily, we suggest you make a separate EasyBuild installation for the course, e.g., in <code>/scratch/project_465000523/$USER/eb-course</code> if you make the exercises during the course:</p> <ul> <li>Start from a clean login shell with only the standard modules loaded.</li> <li> <p>Set <code>EBU_USER_PREFIX</code>: </p> <pre><code>export EBU_USER_PREFIX=/scratch/project_465000523/$USER/eb-course\n</code></pre> <p>You'll need to do that in every shell session where you want to install or use that software.</p> </li> <li> <p>From now on you can again safely load the necessary <code>LUMI</code> and <code>partition</code> modules for the exercise.</p> </li> <li> <p>At the end, when you don't need the software installation anymore, you can simply remove the directory     that you just created.</p> <pre><code>rm -rf /scratch/project_465000523/$USER/eb-course\n</code></pre> </li> </ul>"},{"location":"1day-20230509/05_Exercises_1/#installing-a-simple-program-without-dependencies-with-easybuild","title":"Installing a simple program without dependencies with EasyBuild","text":"<p>The LUMI Software Library contains the package <code>eb-tutorial</code>. Install the version of the package for the <code>cpeCray</code> toolchain in the 22.08 version of the software stack.</p> <p>At the time of this course, in early May 2023, we're still working on EasyBuild build recipes for the 22.12 version of the software stack.</p> Click to see the solution. <ul> <li> <p>We can check the      eb-tutorial page     in the      LUMI Software Library     if we want to see more information about the package.</p> <p>You'll notice that there are versions of the EasyConfigs for <code>cpeGNU</code> and <code>cpeCray</code>. As we want to install software with the <code>cpeCray</code> toolchain for <code>LUMI/22.08</code>, we'll need the <code>cpeCray-22.08</code> version which is the EasyConfig <code>eb-tutorial-1.0.1-cpeCray-22.08.eb</code>.</p> </li> <li> <p>Obviously we need to load the <code>LUMI/22.08</code> module. If we would like to install software     for the CPU compute nodes, you need to also load <code>partition/C</code>.     To be able to use EasyBuild, we also need the <code>EasyBuild-user</code> module.</p> <pre><code>module load LUMI/22.08 partition/C\nmodule load EasyBuild-user\n</code></pre> </li> <li> <p>Now all we need to do is run the <code>eb</code> command from EasyBuild to install the software.</p> <p>Let's however take the slow approach and first check if what dependencies the package needs:</p> <pre><code>eb eb-tutorial-1.0.1-cpeCray-22.08.eb -D\n</code></pre> <p>We can do this from any directory as the EasyConfig file is already in the LUMI Software Library and will be located automatically by EasyBuild. You'll see that all dependencies are already on  the system so we can proceed with the installation:</p> <pre><code>eb eb-tutorial-1.0.1-cpeCray-22.08.eb \n</code></pre> </li> <li> <p>After this you should have a module <code>eb-tutorial/1.0.1-cpeCray-22.08</code> but it may not show up      yet due to the caching of Lmod. Try</p> <pre><code>module av eb-tutorial/1.0.1-cpeCray-22.08\n</code></pre> <p>If this produces an error message complaining that the module cannot be found, it is time to clear the Lmod cache:</p> <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> </li> <li> <p>Now that we have the module, we can check what it actually does:</p> <pre><code>module help eb-tutorial/1.0.1-cpeCray-22.08\n</code></pre> <p>and we see that it provides the <code>eb-tutorial</code> command.</p> </li> <li> <p>So let's now try to run this command:</p> <pre><code>module load eb-tutorial/1.0.1-cpeCray-22.08\neb-tutorial\n</code></pre> <p>Note that if you now want to install one of the other versions of this module, EasyBuild will complain that some modules are loaded that it doesn't like to see, including the <code>eb-tutorial</code> module and the <code>cpeCray</code> modules so it is better to unload those first:</p> <pre><code>module unload cpeCray eb-tutorial\n</code></pre> </li> </ul>"},{"location":"1day-20230509/05_Exercises_1/#installing-an-easyconfig-given-to-you-by-lumi-user-support","title":"Installing an EasyConfig given to you by LUMI User Support","text":"<p>Sometimes we have no solution ready in the LUMI Software Library, but we prepare one or more custom EasyBuild recipes for you. Let's mimic this case. In practice we would likely send  those as attachments to a mail from the ticketing system and you would be asked to put them in a separate directory (basically since putting them at the top of your home directory would in some cases let EasyBuild search your whole home directory for dependencies which would be a very slow process).</p> <p>You've been given two EasyConfig files to install a tool called <code>py-eb-tutorial</code> which is in fact a Python package that uses the <code>eb-tutorial</code> package installed in the previous exercise. These EasyConfig files are in the <code>EasyBuild</code> subdirectory of the exercises for this course. In the first exercise you are asked to install the version of <code>py-eb-tutorial</code> for the <code>cpeCray/22.08</code> toolchain.</p> Click to see the solution. <ul> <li> <p>Go to the <code>EasyBuild</code> subdirectory of the exercises and check that it indeed contains the     <code>py-eb-tutorial-1.0.0-cpeCray-22.08-cray-python-3.9.12.1.eb</code> and     <code>py-eb-tutorial-1.0.0-cpeGNU-22.08-cray-python-3.9.12.1.eb</code> files.     It is the first one that we need for this exercise.</p> <p>You can see that we have used a very long name as we are also using a version suffix to make clear which version of Python we'll be using.</p> </li> <li> <p>Let's first check for the dependencies (out of curiosity):</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeCray-22.08-cray-python-3.9.12.1.eb -D\n</code></pre> <p>and you'll see that all dependencies are found (at least if you made the previous exercise  successfully). You may find it strange that it shows no Python module but that is because we are using the <code>cray-python</code> module which is not installed through EasyBuild and only known to EasyBuild as an external module.</p> </li> <li> <p>And now we can install the package:</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeCray-22.08-cray-python-3.9.12.1.eb\n</code></pre> </li> <li> <p>To use the package all we need to do is to load the module and to run the command that it     defines:</p> <pre><code>module load py-eb-tutorial/1.0.0-cpeCray-22.08-cray-python-3.9.12.1\npy-eb-tutorial\n</code></pre> <p>with the same remark as in the previous exercise if Lmod fails to find the module.</p> <p>You may want to do this step in a separate terminal session set up the same way, or you will get an error message in the next exercise with EasyBuild complaining that there are some modules loaded that should not be loaded.</p> </li> </ul>"},{"location":"1day-20230509/05_Exercises_1/#installing-software-with-uninstalled-dependencies","title":"Installing software with uninstalled dependencies","text":"<p>Now you're asked to also install the version of <code>py-eb-tutorial</code> for the <code>cpeGNU</code> toolchain in <code>LUMI/22.08</code> (and the solution given below assumes you haven'ty accidentally installed the wrong EasyBuild recipe in one of the previous two exercises).</p> Click to see the solution. <ul> <li> <p>We again work in the same environment as in the previous two exercises. Nothing has changed here.     Hence if not done yet we need</p> <pre><code>module load LUMI/22.08 partition/C\nmodule load EasyBuild-user\n</code></pre> </li> <li> <p>Now go to the <code>EasyBuild</code> subdirectory of the exercises (if not there yet from the previous     exercise) and check what the <code>py-eb-tutorial-1.0.0-cpeGNU-22.08-cray-python-3.9.12.1.eb</code> needs:</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeGNU-22.08-cray-python-3.9.12.1.eb -D\n</code></pre> <p>We'll now see that there are two missing modules. Not only is the  <code>py-eb-tutorial/1.0.0-cpeGNU-22.08-cray-python-3.9.12.1</code> that we try to install missing, but also the <code>eb-tutorial/1.0.1-cpeGNU-22.08</code>. EasyBuild does however manage to find a recipe from which this module can be built in the pre-installed build recipes.</p> </li> <li> <p>We can install both packages separately, but it is perfectly possible to install both packages in a single     <code>eb</code> command by using the <code>-r</code> option to tell EasyBuild to also install all dependencies.</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeGNU-22.08-cray-python-3.9.12.1.eb -r\n</code></pre> </li> <li> <p>At the end you'll now notice (with <code>module avail</code>) that both the module      <code>eb-tutorial/1.0.1-cpeGNU-22.08</code> and <code>py-eb-tutorial/1.0.0-cpeGNU-22.08-cray-python-3.9.12.1</code>     are now present.</p> <p>To run you can use</p> <pre><code>module load py-eb-tutorial/1.0.0-cpeGNU-22.08-cray-python-3.9.12.1\npy-eb-tutorial\n</code></pre> </li> </ul>"},{"location":"1day-20230509/06_Running_jobs/","title":"Running jobs","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230509/07_Exercises_2/","title":"Exercises 2: Running jobs with Slurm","text":""},{"location":"1day-20230509/07_Exercises_2/#exercises-on-the-slurm-allocation-modes","title":"Exercises on the Slurm allocation modes","text":"<ol> <li> <p>Run single task on the CPU partition with <code>srun</code> using multiple cpu cores. Inspect default task allocation with <code>taskset</code> command (<code>taskset -cp $$</code> will show you cpu numbers allocated to a current process). </p> Click to see the solution. <pre><code>srun --partition=small --nodes=1 --tasks=1 --cpus-per-task=16 --time=5 --partition=small --account=&lt;project_id&gt; bash -c 'taskset -cp $$' \n</code></pre> <p>Note you need to replace <code>&lt;project_id&gt;</code> with actual project account ID in a form of <code>project_</code> plus 9 digits number.</p> <p>The command runs single process (<code>bash</code> shell with a native Linux <code>taskset</code> tool showing process's CPU affinity) on a compute node. You can use <code>man taskset</code> command to see how the tool works.</p> </li> <li> <p>Try Slurm allocations with <code>hybrid_check</code> tool program from the LUMI Software Stack. The program is preinstalled on the system. </p> <p>Use the simple job script to run parallel program with multiple tasks (MPI ranks) and threads (OpenMP). Test task/threads affinity with <code>sbatch</code> submission on the CPU partition.</p> <pre><code>#!/bin/bash -l\n#SBATCH --partition=small           # Partition (queue) name\n#SBATCH --nodes=1                   # Total number of nodes\n#SBATCH --ntasks-per-node=8         # 8 MPI ranks per node\n#SBATCH --cpus-per-task=16          # 16 threads per task\n#SBATCH --time=5                    # Run time (minutes)\n#SBATCH --account=&lt;project_id&gt;      # Project for billing\n\nmodule load LUMI/22.12\nmodule load lumi-CPEtools\n\nsrun hybrid_check -n -r\n</code></pre> <p>Be careful with copy/paste of script body while it may brake some specific characters.</p> Click to see the solution. <p>Save script contents into <code>job.sh</code> file (you can use <code>nano</code> console text editor for instance), remember to use valid project account name.</p> <p>Submit job script using <code>sbatch</code> command. </p> <pre><code>sbatch job.sh\n</code></pre> <p>The job output is saved in the <code>slurm-&lt;job_id&gt;.out</code> file. You can view it's contents with either <code>less</code> or <code>more</code> shell commands.</p> <p>Actual task/threads affinity may depend on the specific OpenMP runtime but you should see \"block\" thread affinity as a default behaviour.</p> </li> <li> <p>Improve threads affinity with OpenMP runtime variables. Alter your script and add MPI runtime variable to see another cpu mask summary. </p> Click to see the solution. <p>Export <code>SRUN_CPUS_PER_TASK</code> environment variable to follow convention from recent Slurm's versions in your script. Add this line before the <code>hybrid_check</code> call:</p> <pre><code>export SRUN_CPUS_PER_TASK=16 \n</code></pre> <p>Add OpenMP environment variables definition to your script:</p> <pre><code>export OMP_NUM_THREADS=${SRUN_CPUS_PER_TASK}\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n</code></pre> <p>You can also add MPI runtime variable to see another cpu mask summary:</p> <pre><code>export MPICH_CPUMASK_DISPLAY=1\n</code></pre> <p>Note <code>hybrid_check</code> and MPICH cpu mask may not be consistent. It is found to be confusing.</p> </li> <li> <p>Build <code>hello_jobstep</code> program tool using interactive shell on a GPU node. You can pull the source code for the program from git repository <code>https://code.ornl.gov/olcf/hello_jobstep.git</code>. It uses <code>Makefile</code> for building. Try to run the program interactively. </p> Click to see the solution. <p>Clone the code using <code>git</code> command:</p> <pre><code>git clone https://code.ornl.gov/olcf/hello_jobstep.git\n</code></pre> <p>It will create <code>hello_jobstep</code> directory consisting source code and <code>Makefile</code>.</p> <p>Allocate resources for a single task with a single GPU with <code>salloc</code>:</p> <pre><code>salloc --partition=small-g --nodes=1 --tasks=1 --cpus-per-task=1 --gpus-per-node=1 --time=10 --account=&lt;project_id&gt;\n</code></pre> <p>Note that, after allocation being granted, you receive new shell but still on the compute node. You need to use <code>srun</code> to execute on the allocated node. </p> <p>Start interactive session on a GPU node:</p> <pre><code>srun --pty bash -i\n</code></pre> <p>Note now you are on the compute node. <code>--pty</code> option for srun is required to interact with the remote shell.</p> <p>Enter the <code>hello_jobstep</code> directory and issue <code>make</code> command. It will fail without additional options and modules.</p> <pre><code>module load rocm\n</code></pre> <p>Note compiler (and entire programming environment) is the one you have set (or not) in the origin shell on the login node.  </p> <p>Nevertheless <code>rocm</code> module is required to build code for GPU.</p> <pre><code>make LMOD_SYSTEM_NAME=\"frontier\"\n</code></pre> <p>You need to add <code>LMOD_SYSTEM_NAME=\"frontier\"</code> variable for make while the code originates from the Frontier system.</p> <p>You can exercise to fix <code>Makefile</code> and enable it for LUMI :)</p> <p>Eventually you can just execute <code>./hello_jobstep</code> binary program to see how it behaves:</p> <pre><code>./hello_jobstep\n</code></pre> <p>Note executing the program with <code>srun</code> in the srun interactive session will result in a hang. You need to work with <code>--overlap</code> option for srun to mitigate it.</p> <p>Still remember to terminate your interactive session with <code>exit</code> command.</p> <pre><code>exit\n</code></pre> </li> </ol>"},{"location":"1day-20230509/07_Exercises_2/#slurm-custom-binding-on-gpu-nodes","title":"Slurm custom binding on GPU nodes","text":"<ol> <li> <p>Allocate one GPU node with one task per GPU and bind tasks to each CCD (8-core group sharing L3 cache) leaving first (#0) and last (#7) cores unused. Run a program with 6 threads per task and inspect actual task/threads affinity.</p> Click to see the solution. <p>Begin with the example from the slides with 7 cores per task:</p> <pre><code>#!/bin/bash -l\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=1               # Total number of nodes\n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=5                # Run time (minutes)\n#SBATCH --account=&lt;project_id&gt;  # Project for billing\n#SBATCH --hint=nomultithread\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\n\nchmod +x ./select_gpu\n\nCPU_BIND=\"mask_cpu:0xfe000000000000,0xfe00000000000000,\"\nCPU_BIND=\"${CPU_BIND}0xfe0000,0xfe000000,\"\nCPU_BIND=\"${CPU_BIND}0xfe,0xfe00,\"\nCPU_BIND=\"${CPU_BIND}0xfe00000000,0xfe0000000000\"\n\nexport OMP_NUM_THREADS=7\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n\nexport MPICH_CPUMASK_DISPLAY=1\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu ./hello_jobstep/hello_jobstep\n</code></pre> <p>If you save the script in the <code>job_step.sh</code> then simply submit it with sbatch. Inspect the job output.</p> <p>Now you would need to alter masks to disable 7th core of each of the group (CCD). Base mask is then <code>01111110</code> which is <code>0x7e</code> in hexadecimal notation.</p> <p>Try to apply new bitmask, change the corresponding variable to spawn 6 threads per task and check how new binding works.</p> </li> </ol>"},{"location":"1day-20230509/08_Lustre_intro/","title":"I/O and file systems","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230509/09_LUMI_support/","title":"How to get support and documentation","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230509/notes_20230509/","title":"Questions session 9 May 2023","text":""},{"location":"1day-20230509/notes_20230509/#lumi-hardware","title":"LUMI Hardware","text":"<ol> <li> <p>\"Real LUMI-G node\" slide presented the CPU with two threads per core. I assume it is just to give full insight, what the CPU allows, but you are not using hyper-threading, right?</p> <p>Answer: SMT is activated but not used by default excepted if you ask for it in your job script with <code>--hint=multithread</code>. The same applies to LUMI-C nodes.</p> </li> </ol>"},{"location":"1day-20230509/notes_20230509/#programming-environment-module-system","title":"Programming Environment &amp; Module System","text":"<ol> <li> <p>Is there a way to reload all sticky modules (with one command), if you first have unloaded all sticky modules.</p> <p>Answer: If you have \"force purged\" all modules, you can get the default environment with <code>module restore</code> but it will not reload non-default sticky modules you may have loaded previously.</p> </li> </ol>"},{"location":"1day-20230509/notes_20230509/#using-and-installing-software","title":"Using and Installing Software","text":"<ol> <li> <p>Is \"lumi-container-wrapper\" related to https://cotainr.readthedocs.io/en/latest/ by DeiC from Denmark?</p> <p>Answer:</p> <ul> <li> <p>No. It is a different tool. It's the LUMI version of the tykky tool available on the CSC Puhti and Mahti clusters.</p> </li> <li> <p>The cotainr tool from DeiC is also available though (see the LUMI Software Library page) but we're waiting for them to test it on newer versions of the Cray PE.</p> </li> </ul> </li> <li> <p>What does RPM stand for?</p> <p>Answer: RPM stands for Redhat Package Manager. It is a popular tool for distributing Linux software as binaries for direct installation in the OS image.</p> </li> <li> <p>If I installed a software and prepared a module file by myself, is there a place I can contribute my module to the LUMI user community? Maybe it can save time when a new LUMI user is struggling installing the same exact software.</p> <p>Answer: Yes, of course. We have a GitHub repository for that. https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib/     Just create a pull request there and we will have a look and merge it</p> </li> <li> <p>What options --try-toolchain-version=22.08 --robot help us with?</p> <p>Answer: These options should work as in the regular EasyBuild. (and the <code>-r</code> I used is the abbreviation of <code>--robot</code>)</p> <p>In fact, because I want a reproducible build environment most EasyConfigs that we offer also use the buildtools module, but as the version I use the <code>toolchain_version</code> variable so that that dependency is automatically adapted also. We bundle several build tools not only to have less modules, but also to have to adapt fewer dependency versions...</p> </li> <li> <p>Which changes were made in <code>lumi-container-wrapper</code> compared to <code>tykky</code>?</p> <p>Answer: It uses a different base container better suited for LUMI and for Python it is configure to build upon cray-python.</p> </li> <li> <p>For how long will this project (project_465000522) be available?</p> <p>Answer: It will stay active for the  next two days (terminates on May, 11th).   </p> </li> <li> <p>I have installed cp2k with easybuil, but I'm not able to run any programs, because it stops running in between and error file shows Segmentation fault - invalid memory reference? This is a problem I am not figuring out how to solve. Any help regarding this.</p> <p>Answer: Too few details to say a lot. You may have made errors during installation though most of those errors would lead to different errors. However, you may have hit a bug in CP2K also, or a bug in the PRogramming Environment. We have several users who have successfully used our recipes, but they may have been trying different things with CP2K. Our configuration for CP2K (at least the CPU version) is also based on the configuration used on a similar Cray system at CSCS which is one of the machines used by the CP2K developers...</p> <p>This is also more the type of problem that is better handled through a ticket though it is unclear from the description if we can do a lot about it.</p> </li> </ol>"},{"location":"1day-20230509/notes_20230509/#exercise-session-1","title":"Exercise session 1","text":"<ol> <li> <p>Lmod shows \"LUMI/23.03  partition/D\" as the only available pre-requisite with LUMI/23.03 for the VNC module. Yet, despite this I am able to:</p> <pre><code>module load LUMI/23.03  partition/L\nmodule load lumi-vnc\n</code></pre> <p>Does this mean that Lmod is just not able to show all of the possible pre-requisite combinations? Or will <code>lumi-vnc</code> turn out not to work correctly with <code>partition/L</code>?</p> <p>Answer: <code>partition/D</code> should not even be shown, that is a bug in the software installation that I need to correct. </p> <p>But a nice find. The output is confusing because LMOD gets confused by some hidden software stacks and partitions. It actually also shows a line <code>init-lumi/0.2</code> which is a module that you have loaded automatically at login. And this in turns means that having this module is enough to use <code>lumi-vnc</code>, i.e., it works everywhere even without any <code>LUMI</code> stack or <code>CrayEnv</code>.</p> </li> <li> <p>In general, if I set export EBU_USER_PREFIX for project directory, do I also need to set another one for the scratch?</p> <p>Answer: No, it points to the root of the software installation which is one clear place. The reason to install in <code>.project</code> and not in <code>/scratch</code> is that you want the software installation to be available for your whole project. If you check the disk use policies in the storage section of the docs you'd see that data on <code>/scratch</code> is not meant to be there for the whole project but can be erased after 90 days which is not what you want with your software installation.</p> </li> </ol>"},{"location":"1day-20230509/notes_20230509/#running-jobs","title":"Running jobs","text":"<ol> <li> <p>Is it possible to get an exemption from the the maximum 2 day allocation?</p> <p>Answer: No. No exceptions are made at all. We don't want nodes to be monopolized by a user and it makes maintenance more difficult. Moreover, given the intrinsic instability of large clusters it is essential that jobs use codes that store intermediate states from which can be restarted.</p> <pre><code>Users have been using dependent jobs with success to automatically start the follow-on job after the previous one ends.\n</code></pre> </li> <li> <p>Is it not possible to use the <code>singularity build</code> command?</p> <p>Answer: Not all options of <code>singularity build</code> work. Any build requiring fakeroot will fail as that is disabled due to security concerns.</p> </li> <li> <p>Does this (binding tasks to resrouces) mean that it will be necessary to use custom bindings to align tasks with specific NUMA domains on each CPU? (Since NUMA domains seem to be a level in-between cores and sockets)</p> <p>Answer: If you are using all cores on an exclusive node the standard ways in which Slurm distributes processes and threads may do just what you want.</p> <p>Even if, e.g., it would turn out that it is better to use only 75% of the cores and you would be using 16 MPI processes with 6 threads per process, then a creative solution is to ask Slurm for 8 cores per task and then set <code>OMP_NUM_THREADS=6</code> to only start 6 threads. There are often creative solutions.</p> <p>Some clusters will redefine the socket to coincide with the NUMA domain but it looks like this is not done on LUMI.</p> </li> <li> <p>Where do we look up the specific NUMA domain / GPU correspondence? In the LUMI documentation? Or perhaps by a command in LUMI?</p> <p>Answer:</p> <ul> <li> <p>See this image from the LUMI-G hardware documentation page. It presents the numbering from the point of view of the GPUs and CPU.</p> </li> <li> <p>See also <code>rocm-smi --showtoponuma</code> (on a LUMI-G node)</p> </li> </ul> </li> <li> <p>If we enable hardware threads for a job/allocation, does \"--cpus-per-task\" become HW threads?</p> <p>Answer: Yes: <pre><code># 2 HWT per core, all cores allocated \n$ srun -pstandard --cpus-per-task=256 --hint=multithread --pty bash -c 'taskset -c -p $$'\npid 161159's current affinity list: 0-255\n\n# 2 HWT per core but only the first 64 cores allocated \n$ srun -pstandard --cpus-per-task=128 --hint=multithread --pty bash -c 'taskset -c -p $$'\npid 161411's current affinity list: 0-63,128-191\n</code></pre></p> </li> <li> <p>Is it possible to make sure a job requesting 16 cores is allocated all cores in one NUMA domain?</p> <p>Answer:</p> <ul> <li> <p>Is your question for sub-node allocations (small and small-g partitions)?</p> <ul> <li>Yes, the question is not relevant for production runs, it was only out of interest. It is something to be aware of during scaling tests for example.<ul> <li>Our advise to users in our local compute centre who have to do scaling tests to submit a proposal for time on LUMI (or our Tier-1 systems) is to use exclusive nodes to avoid surprises and reduce randomness. The most objective way is probably if you want to do a test on 16 nodes to run 8 such tests next to one another to fill up the node. Because there is another issue also. I haven't tried if the options to fix the clock speed from Slurm work on LUMI, but depending on the other work that is going on in a socket the clock speed of the cores may vary. </li> </ul> </li> </ul> </li> <li> <p>I doubt there is a way to do that for the sub-node allocation partitions. I can't find one that works at the moment. Binding really only works well on job-exclusive nodes. For me this is a shortcomming of Slurm as it doesn't have enough levels in its hierarchy for modern clusters.</p> </li> <li> <p>For a sub-node allocation, you will get random cores depending on which cores are available: <pre><code>$ srun -psmall --cpus-per-task=16 --pty bash -c 'taskset -c -p $$'\npid 46818's current affinity list: 44-46,50,52-63\n\n$ srun -pstandard --cpus-per-task=16 --pty bash -c 'taskset -c -p $$'\npid 220496's current affinity list: 0-15\n</code></pre></p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230509/#storage","title":"Storage","text":"<ol> <li> <p>To access /scratch/ from a container, we have to mount it. However, we need the full path and not just the symlink. Where do we find the full path? </p> <p>Answer: You can use <code>file /scratch/project_465000522</code> for example. Don't try to mount the whole scratch. That will not work. The <code>project_*</code> subdirectories in <code>/scratch</code> are distributed across the 4 file systems of LUMI-P. <code>ls -l /scratch/project_465000522</code> will actually show you which file system is serving that project's scratch directory.</p> </li> <li> <p>The documentation page states that \"Automatic cleaning of project scratch and fast storage is not active at the moment\". Is this still true, and will the users be informed if this changes?</p> <p>Answer:</p> <ul> <li> <p>This is still true today and usually users are informed about changes but with short notice. Quota were also disabled for a while due to problems after an upgrade last July but solving those problems became a higher priority when abuse was noticed, and there was only 14 days notice. So abusing scratch and flash for long-term storage is asking for increasing the priority of that part of the LUMI setup working... I'd say, don't count on it as the message may arrive as well when you are on a holiday.</p> </li> <li> <p>For slightly longer time storage but still limited to the lifetime of your project there is also the object storage. However, at the moment only rather basic tools to use that storage are already available.</p> </li> </ul> </li> <li> <p>What is the preferred way for transferring data between LUMI and some external server or other supercomputer e.g. CSC Mahti?</p> <p>Answer:</p> <ul> <li> <p>Mahti is so close to LUMI (as far as I know even in the same data centre but a different hall) that connection latency should not limit bandwidth so that you can just use sftp.</p> <p>I believe the CSC documentation also contains information on how to access the allas object storage from LUMI. Using allas as intermediate system is also an option. Or the LUMI-O storage but at the moment allas is both more developed and better documented. (For readers: allas is a CSC object system only available to users that are CSC clients and not to other users of LUMI.)</p> </li> <li> <p>For supercomputers that are \"farther away\" from LUMI where bandwidth is a problem when using sftp, it looks like the LUMI-O object storage is a solution as the tools that read from the object storage use so-called \"multi-stream transport\" so that they can better deal with connections with a high latency. The documentation on how to access the LUMI object storage from elsewhere needs work though.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/","title":"Questions session 16 May 2023","text":""},{"location":"1day-20230509/notes_20230516/#lumi-architecture","title":"LUMI Architecture","text":"<ol> <li> <p>The slides say the GPUs have 128 GB mem, but when I queried the information with the HIP-framework it only returned 64 GB mem. Does it differ on different partitions or something? </p> <ul> <li>Kurt will go into more detail soon. But each GPU has 128GB but each GPU conists of 2 dies (basically independent GPUs). Each of those has 64GB. Basically each LUMI-G node has in practise 8 GPUs on 4 cards.</li> </ul> </li> <li> <p>This is maybe a better question for when you will discuss software, but seeing the AMD hardware, my question is how compatible the GPU partitions/software are with DL frameworks such as Tensorflow and PyTorch. Are the systems fully ROCm compatible? Are there downsides compared to CUDA implementations?</p> <ul> <li>Let's discuss that later in detail. But short answer: ROCm is not as mature as CUDA yet but most DL frameworks work already quite well.</li> </ul> </li> <li> <p>I believe the GPU nodes have 64 cores. But from the slides I understood that the nodes have 1 CPU with 8 cores.     Just as a note: this is output from hip:     <pre><code>  Device 0:\n  Total Global Memory: 63.9844 GB\n  Compute Capability: 9.0\n  Max Threads per Block: 1024\n  Multiprocessor Count: 110\n  Max Threads per Multiprocessor: 2048\n  Clock Rate: 1700 MHz\n  Memory Clock Rate: 1600 MHz\n  Memory Bus Width: 4096 bits\n  L2 Cache Size: 8 MB\n  Total Constant Memory: 2048 MB\n  Warp Size: 64\n  Concurrent Kernels: Yes\n  ECC Enabled: No\n  Unified Memory: No\n</code></pre></p> <ul> <li>The slide was about the CPUs in the node. The basic element of the GPU is the \"Compute Unit\" (CU)     (the \"multiprocessor count\" in the above output).     And one CU has 4 16-wide SIMD units and 4 matrix core units.     AMD doesn't use the word core very often in the context of GPU as what NVIDIA calls a core is     actually called an Arithmetic and Logical Unit in a CPU and is only a part of a core.</li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#cray-programming-environment","title":"Cray Programming Environment","text":"<ol> <li> <p>what is called underneath with compiling with <code>hipcc</code>? rocm compiler I assume? - @bcsj</p> <ul> <li> <p>Actually it is AMD's branch of Clang.</p> </li> <li> <p>@bcsj: sidenote, I've had trouble with compiling GPU code with the <code>CC</code> compiler, which I assume calls something else underneath. The code would run, but in a profiler it showed that a lot of memory was being allocated when it shouldn't. <code>hipcc</code> compiling fixed this issue.</p> <ul> <li> <p>I believe <code>CC</code> is using different Clang frontend being Cray's branch of Clang with a slightly different codebase. At the end it should use the same ROCm backend. It may require more debugging to understand the problem.</p> </li> <li> <p>@bcsj: possibly ... it was some very simple kernels though, so I'm pretty confident it was not a kernel-issue. The profiling was done using APEX and rocmprofiler. Kevin Huck helped me, during the TAU/APEX course.</p> </li> <li> <p>The frontend that <code>CC</code> is using depends on which modules you have loaded. IF the <code>cce</code> compiler module is loaded, it will use the Cray clang frontend while if the <code>amd</code> compiler module is loaded it will use the AMD ROCm C++ compiler.</p> </li> </ul> </li> <li> <p>@mszpindler Could you please post a support ticket than we can investigate memory issues, thanks.</p> </li> <li> <p>@bcsj: It's been a while and I restructured my environment to avoid the issue, but I'll see if I can find the setup I used before.</p> </li> </ul> </li> <li> <p>What is the policy on changes to these centrally installed and supported modules? Are versions guaranteed to be available for a certain period of time?</p> <ul> <li>Unfortunately not at the moment. WE hope to be able to provide LTS (Long term support) versions in the future but they are not yet vendor supported. But we will always inform you about changes to the SW stack.</li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#module-system","title":"Module System","text":"<ol> <li> <p>Are open source simulation software such as quantum espresso centrally installed on LUMI?</p> <ul> <li> <p>Please use the Software Library https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/q/QuantumESPRESSO/ to understand what the policy is.</p> </li> <li> <p>Short answer: No, almost no softare (except debugger, profilers) is installed globally. But you will see soon, that it is very easy to install SW yourself with Easybuild using our easyconfigs (basically building recipes).</p> </li> </ul> </li> <li> <p>The program I am using and developing requires certain dependencies such as paralution, PETSc, Boost... Is it possible to manually install these dependencies if not available among the modules listed?</p> <ul> <li> <p>Yes, it is actually very easy and will be the topic of the next session (and we have some configurations on Boost on the system, try <code>module spider Boost</code>...)</p> </li> <li> <p>We have an installation recipe for one configuration of PETSc also. And PETSc is one of those libraries that does strange things behind the scenes that can cause it to stop working after a system update... We have not tried paralution. But basically there are an estimated 40,000 scientific software packages not counting the 300,000+ packages on PyPi, R packages, etc., so there is no way any system can support them all.</p> </li> <li> <p>@mszpindler Please try PETSc with recipes from https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/p/PETSc/ If you see wrong behaviour then please open support ticket.</p> </li> </ul> </li> <li> <p>Can I use modules that are available on CSC supercomputers?</p> <ul> <li>Basically we use different set of modules and even a different primary system to manage the modules. The machines are different, the team managing the machine is different, and the licenses for software on puhti or mahti do not always allow use on LUMI, and certainly not for all users on LUMI, while we have no way to control who has access and who has not.</li> </ul> </li> <li> <p>If i find out that my application is able to work in different programming environments (different compilers), which should I prefer? Cray? </p> <ul> <li> <p>No answer that is always right, you have to benchmark to know.</p> <p>And even for packages for which we offer build recipes we cannot do that benchmarking as it requires domain knowledge to develop proper benchmarks. And the answer may even differe on the test case.</p> <ul> <li>Ok, test with Cray first.. </li> </ul> </li> <li> <p>Again, if you look at the Software Library https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/q/QuantumESPRESSO/ then you can see recipe (easyconfigs) versions for specific programmming environments. Those listed there, are supported.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#using-and-installing-software","title":"Using and installing software","text":"<ol> <li> <p>In our own tier-1 I've always used virtual envs successfully. The reason that I do not rely on containers is that I often work on editable installs that I pull from git. Looking at the documentation (https://docs.lumi-supercomputer.eu/software/installing/container-wrapper/#plain-pip-installations) it seems that this is not supported. In other words: I would like to be able to create an environment, install an editable Python git repo, and when an updated comes to the remote repo, just pull it and keep using the env. If I understand correctly I would need to rebuild the container after every <code>git pull</code> on LUMI?</p> <ul> <li> <p>I  t is actually CSC's development called Tykky https://docs.csc.fi/computing/containers/tykky/ and I believe you can try with <code>pip-containerize update ...</code> to update existing image but you need to try if it works with your specific environment.</p> </li> <li> <p>Something really difficult: You can spread a Python installation over multiple directories. So you could put all dependencies of your software in a container and mount a directory from outside in which you install the software you're developing. That would already reduce the load of small packages on the file system.</p> <p>The speed difference can be dramatic. On the installation side I've worked on 5 or 6 big clusters on Europe. On the slowest it took me 2 hours to install a bunch of Python packages that installed in under 30 seconds on the SSD of my laptop... Measuring the speed difference while running is more difficult as I couldn't run the benchmarks on my PC and as there are other factors in play also. But CSC reports that a 30% speedup is not that uncommon from using Tykky.</p> </li> <li> <p>I have successfully installed Python repos as editable, by setting PYTHONUSERBASE to point to the project directory and then using both --user and --editable flags with pip.</p> </li> <li> <p>There is some information on containers also in the \"Additional Softwre on LUMI\" talks in our 4-day course. The latest for which notes and a recording are available is the presentation during the February 2023 course.</p> </li> </ul> </li> <li> <p>Sorry, probably you are going to speak about containers later. I'm just interested in the opportunity to use one particular commercial software from within, say, Singularity container on LUMI. So, if I sort out the license server issues, is it possible for virtually any kind of software or there are limitations? If yes, is it, overall, a good idea? Does it make the performance of the software run deteriorate?</p> <ul> <li> <p>Unless there is MPI involved you can try to run any, say DockerHub, container image on LUMI. For the MPI parallel software packages it may still work on a single node but do not expect them to run on multiple computing nodes.  </p> </li> <li> <p>There is some information on containers also in the \"Additional Softwre on LUMI\" talks in our 4-day course. The latest for which notes and a recording are available is the presentation during the February 2023 course.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#exercises","title":"Exercises","text":"<ol> <li> <p>Looking at the Exercise 1.1 solution, I don't really see any difference between the outputs from <code>module spider Bison</code> and <code>module spider Bison/3.8.2</code>, but from how the solution reads, it seems like they shouldn't be the same?</p> <ul> <li> <p>That's because there were two different versions on the system when I prepared the exercise. It found a version generated with Spack also and it looks like the person managing that stack disabled that module again. If <code>module spider</code> finds only a single version it produces the output it would produce when called with the full version as the argument.</p> <p>I wanted to use it as an example to show you how you can quickly see from the <code>module spider</code> output if a program comes from the LUMI stacks or from Spack...</p> <ul> <li>ok, thanks</li> </ul> </li> <li> <p>You can see the different behaviours with for example <code>module spider buildtools</code></p> </li> </ul> </li> <li> <p>is there a module similar to <code>cray-libsci</code> for loading/linking <code>hipBlas</code>? So far I've been doing that manually. I tried to <code>module spider hipblas</code> but that returns nothing.</p> <ul> <li> <p>No, there is not. AMD doesn't polish its environment as much HPE Cray.</p> <p>Also, all of ROCm is in a single module and as several of those modules are provided by HPE and AMD they don't contain the necessary information to search for components with <code>module spider</code>.</p> </li> </ul> </li> <li> <p>Is there a similar tool to <code>csc-projects</code> for checking info on your projects?</p> <ul> <li>Yes, please try <code>lumi-allocations</code> command-line tool.</li> </ul> </li> <li> <p>Perhaps I missed this earlier, but what is LUMI-D?</p> <ul> <li>It is the name that was used for the \"Data Analytics and Visualisation partition\" which basically turns out to be two partitions that need a different setup.     It consists of 8 nodes with 4 TB of memory that really have the same architecture as the login nodes hence can use software of what we will later in the course call <code>partition/L</code>, and 8 nodes with 8 NVIDIA A30 GPUs for visualisation each.</li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#running-jobs-with-slurm","title":"Running jobs with Slurm","text":"<ol> <li> <p>Would it be possible to show an example of how to run R interactively on a compute node?</p> <ul> <li> <p>If you don't need X11, one way is</p> <pre><code>srun -n 1 -c 1 -t 1:00:00 -p small -A project_465000XXX --pty bash\nmodule load cray-R\nR\n</code></pre> <p>which would ask for 1 core for 1 hour. For some shared memory parallel processing you'd use a larger value for c but you may have to set environment variables to tell R to use more threads. </p> </li> </ul> </li> <li> <p>Is Rstudio server exist as a module on LUMI? Is it planned to be added at some point? Is it possible for normal user to install it?</p> <ul> <li>We expect to be able to offer Rstudio with Open OnDemand, but no time set for now. But as any batch system, LUMI is not that well suited for interactive work as there is no guarantee that your interactive session will start immediately. Some resources will be set aside for Open OnDemand and I assume it will be possible to oversubscribe some resources. But LUST is not currently involved with the setup so there is not much we can say.</li> </ul> </li> <li> <p>May be a beginner question.. When to work with GPU nodes and when it is less efficient to use it? Does it depend on the structure of the data or the software used? Is it possible to use GPU nodes with R scripts?</p> <ul> <li> <p>GPU comute requires software that explicitly supports compute on GPU. GPUs are never used automatically. Base R does not use GPU compute. Some R packages may as in principle some large linear algebra operations that are used in statistics may benefit from GPU acceleration. However, they will have to support AMD GPUs and not NVIDIA GPUs.  </p> <p>There is no simple answer when GPU compute offers benefits and when it does not as it depends a lot on the software that is being used also.</p> </li> </ul> </li> <li> <p>How to monitor the progress / resources use (e.g. how much RAM / # cores are actually used) of currently running and finished batch jobs?</p> <ul> <li> <p>Slurm <code>sstat</code> command can give information on running jobs. Once the job has finished, <code>sacct</code> can be used. Both commands have very customizable output but they will not tell you core per core how that core was used. Then you need to do active profiling.</p> </li> <li> <p>You can also attach an interactive job step to a running job (as shown on slide 9). I'm not sure <code>rocm-smi</code> works reliably in that case (it didn't always in the past), but commands like <code>top</code> and <code>htop</code> (the latter provided by the <code>systools</code> module) should work to monitor the CPU use.</p> </li> </ul> </li> <li> <p>Do job-arrays open program the number of processes which we specified with --ntasks=1? or it will open 16 independent jobs with 1 processes for each job? </p> <ul> <li>A job array with 16 elements in the job array is 16 jobs for the scheduler if that is what you mean. If you want multiple processes in one job you'd submit a single job for the combined resources of all 16 jobs and then use srun to start 16 processes in that job.</li> </ul> <p>What happens if we choose job-array=1-16 and --ntasks=2? It will use 16 jobs and each jobs has 2 tasks, right?</p> <ul> <li>Yes. After all some people may want to use a job array for management where each element of the job array is an MPI program.</li> </ul> </li> <li> <p>Is the limit \"total jobs in the queue\" or \"total concurrntly running\"?</p> <ul> <li> <p>There are two different limits that are both shown in the LUMI documentation. There is a limit on the number of jobs running concurrently and a limit on the number of jobs in the queue (which includes running jobs). That limit is also very low. LUMI is a very large cluster and the total number of jobs that a scheduler can handle of all users together is limited. Schedulers don't scale well. Which is why the limit on the number of jobs is considerably lower than it typically is on small clusters.</p> <p>The right way to deal with parallelism on big systems is using a hierarchy, and this holds for job management also: The scheduler to allocate bigger chunks of the machine and then run another tool to create parallelism in the job.</p> </li> </ul> </li> <li> <p>Out of curiousity, how did the GPU-id and NUMA-id misalignment occur? It somehow makes me surprised that/(if?) it is consistently wired in this same \"weird\" manner all over the nodes.</p> <ul> <li> <p>Luckily it is consistent. I'm pretty sure it is basically a result of the motherboard design. The connections between the GPUs determine which GPU considers itself GPU 0 during the boot procedure, while the connections between the GPU socket and CPU socket determine the mapping between CCDs and GPU dies.</p> <ul> <li>Interesting, thanks for the answer!</li> </ul> </li> </ul> </li> <li> <p>Regarding the containers and MPI... If I want to run my software on multiple nodes from within a Singularity container with decent scalability, should I use host (LUMI's) MPI, right? Then, which MPI should I make this software work with? Open MPI, Intel MPI - don't work on LUMI, right? What should I aim at then?</p> <ul> <li> <p>Open MPI doesn't work very well at the moment. Some people got enough performance from it though for CPU codes and I worked on a recent ticket where it worked well for a user within a node.</p> <p>HPE Cray is also working on a translation layer from Open MPI 4.1 to Cray MPICH.</p> </li> <li> <p>We know that Intel internally must have an MPI that is compatible with LUMI as they are building the software environment for the USA Aurora supercomputer that uses the same interconnect as LUMI. But so far experiments with the versions distributed with oneAPI etc. have been a disappointment. It might be possible to try to force the application compiled with Intel MPI to use Cray MPICH as they should have the same binary interface.</p> </li> <li> <p>But the MPI on LUMI is basically compatible with the ABI from MPICH 3.4.</p> </li> <li> <p>The main advise it though to avoid containers and software that comes as binaries when you want to use MPI. It is often a pain to get the software to work properly. Containers are good for some level of portability between sufficiently similar machines with a close enough OS kernel, same hardware and same kernel modules, and were never meant to be portable in all cases. They work very well in, e.g., a cluster management environment (And they are used on the LUMI management nodes) but then you know that the containers will be moving between identical hardware (or very similar hardware if the vendor provides them ready-to-run).</p> </li> </ul> </li> <li> <p>Is it possible to list all nodes with their resource occupation? I want to see how many GPUs / memory is available on different nodes.</p> <ul> <li> <p>All GPU nodes are identical. There is only one node type. And the majority of the GPU nodes is job exclusive so another job could not even start on them.</p> <ul> <li>So if my application utilizes only 1 GPU, it will still hold the whole node with all GPUs?</li> </ul> </li> <li> <p>It depends on what partition you use. If you use <code>standard-g</code>, yes and you will pay for the full node. On <code>small-g</code> you are billed based on a combination of memory use, core use and GPU use (as if, e.g., you ask for half the CPU memory of a node you basically make it impossible for others to efficiently use half of the GPUs and half of the CPU cores, so you would be billed for half a node).</p> <p>But it makes no sense to try to be cleverer than the scheduler and think that \"look, there are two GPUs free on that node so if I now submit a job that requires only 2 GPUs it will run immediately\" as the scheduler may already have reserved those resources for another job for which it is gathering enough GPUs or nodes to run.</p> </li> </ul> </li> <li> <p>Is it possible for us as users to see the current status of LUMI nodes (e.g. using dashboard or a command line)? I mean how many nodes are used or available to work? How many jobs are currently queuing (including other users). I just need to know what would be the expected waiting time for running my jobs.</p> <ul> <li><code>sinfo</code> gives some information but that tells nothing about the queueing time for a job. Any command that gives such information is basically a random number generator. Other jobs can end sooner making resources available earlier, or other users with higher priority jobs may enter the queue and push your job further back.</li> </ul> </li> <li> <p>Are nodes assigned exclusively for projects? I mean, If I am submitting a job for a particular project, would I have access to most of the resources or for specific nodes? Is there a quota per project and how to know how much of this quotaa is used?</p> <ul> <li> <p>Nodes are either shared among jobs or exclusively assigned to jobs depending on the partition.</p> </li> <li> <p>Each job is also attached to a project for billing purposes. Your resource allocator should have given information about that and billing is documented well in the LUMI documentation. Maciej showed the command to check how much you have consumed (<code>lumi-allocations</code>).</p> </li> <li> <p>And each job also runs as a user which determines what you can access on the system.</p> </li> </ul> </li> <li> <p>How priority is determined? Does submitting more jobs or jobs that consume time or memory results in lower priority? Does priority is determined per user or project?</p> <ul> <li>We don't have precise details and it would make no sense either as it is a complicated formula that can be adjusted if the need arises to ensure fair use of LUMI. Priority is a property of a job, not of a project or of a user, but it can be influenced by factors that are user- or project-dependent, like fair use which is actually difficult on LUMI due to the different size of allocations, some projects have a 100 times more compute time than some others so the scheduler should also make sure that those users with huge projects can run jobs often enough.</li> </ul> </li> <li> <p>Is it possible to submit a job that may take more than 3 days?</p> <ul> <li> <p>No, and we make no exceptions at all. This is on one hand to prevent monopolisation of a partition by a single user, and on the other hand because it creates a maintenance nightmare as a rolling update of the system can take as long as the longest running job.</p> <p>Moreover, it is also a protection against yourself as large systems are inherently less stable than smaller systems so there is a much higher chance that your long running job may fail an hour before it would have finished.</p> </li> </ul> </li> <li> <p>If I allocate only a single GPU, will I automatically get assigned a GPU and a CPU which are \"close\" in the setup? (Assuming such an allocation is available)</p> <ul> <li> <p>Not sure about that and I even doubt it at the moment. It was definitely not the case before the upgrade, but it looks like the scheduler is still not doing a proper job. The only way to properly control binding is on exclusive nodes.</p> <p>You could try to run 8 subjobs in a job each using their own GPU, but then at the moment you may be hit with another scheduler bug for which we are still waiting for a fix from HPE.</p> </li> </ul> </li> <li> <p>Maybe I'm missing a point, but re slide #32: why do we want to skip core 8, 16, 24, 32, ...?</p> <ul> <li>For reasons of symmetry as core 0 cannot be used as it is reserved. It's a bit strange to use 7 threads on CCD 0 and then 8 threads on each of the other one.</li> </ul> <p>Okay, so it is becuase you don't want other tasks to behave differently from the first which only got 7 cores. Am I understanding that right?</p> <ul> <li>If these would be 8 fully independent programs it makes sense to use a different set of resources for each. But in an MPI program it is often easier if each rank has the same amount of resources. And after all the speed of your parallel process is determined by the slowest of the processes anyway.</li> </ul> <p>Okay, I think that makes sense to me.</p> <ul> <li>On Frontier they actually block each 8th core by default and we have asked AMD if this may have an advantage as driver threads for each GPU could then run on a different core which may be advantageous if you cannot really use these cores for applications anyway.</li> </ul> </li> <li> <p>Follow-up in Question 31.: If I reserve 2 GPUs, can I expect them to be the two GCDs on 1 device?</p> <ul> <li>No unfortunately, just as Slurm can also not guarantee on the CPU partition that all your cores would be on a single CCD (or within a single cache domain). With machines as LUMI we really need new scheduling technology that is more aware of the hierarchy in resources for sub-node scheduling.</li> </ul> <p>Okay, so I'd need to reserve the whole node to gain that kind of control.</p> <ul> <li>Unfortunately yes.</li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#exercises_1","title":"Exercises","text":"<ol> <li> <p>Rather general question:     Does there exist a wiki or open document that would provide suggestions and hints for best practices when using different scientific software on LUMI? The guidelines provided in this course show that LUMI can support a wide range of programming environments and compilers, as well as specific optimization tools and methods. From my understanding, these considerations can vary greatly for each application or software. Therefore, any experience with specific programs could prove invaluable in saving a significant amount of resources.</p> <ul> <li> <p>No. There are basically too many different packages in use to even be feasible to put an effort in it, and for some packages it really depends a lot on the actual problem you are solving. Sometimes completely different settings are needed depending on which parts of the packages that are being used (some packages support different algorithms that may be parallelised completely differently) and what problem you are trying to solve.</p> <p>That experience should come from user communities of a package as the same experience may be useful on several systems. And much of it may even transfer to systems that are not identical. I have seen manuals of software packages that do try to provide those insights. But, e.g., if your application is not too much restricted by the communication network than there is really no difference between running on LUMI or any other cluster with 64-core Milan CPUs of which there are more and more out these days, and it may even carry over to the newer Genoa CPU.</p> <p>For the GPUs it may be a bit different as HPE Cray is the only company that can sell this particular version (the MI250X) and others can only sell the regular MI250 which connects through PCIe. But even then in most cases that experience will be the same. There aren't that many MI200-faily GPUs out in the field though, most companies seem to be waiting for its successor.</p> </li> </ul> <p>Thanks. Alright, I take that the best practice should be seeked from the community of specific software. </p> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#lustre-io","title":"Lustre I/O","text":"<ol> <li> <p>Just a note: I've been on the receiving end of file-system downtime. First my project was down, then it went up and my user folder went down. That felt rather annoying... D: Wish both was on the same partition.</p> <ul> <li> <p>We know but the maintenance was urgent. It was a bug that corrupts files. One system was hit with corruption issues and it turned out that there were more serious problems on a second one also. It would have been better though if they had taken the whole system down, and maybe they could have done the work in the time it took now to do two of the four file systems...</p> </li> <li> <p>It is impossible to get the home directory and project space guaranteed on the same partition. Users can have multiple projects and projects have multiple users so there is no way we can organise that. In fact, several users come in via the course project before they even have a \"real\" project on LUMI...</p> </li> </ul> <p>My colleague got lucky in this regard, since we only have one project :p  </p> <ul> <li>Most of us in user support have two userids, one with CSC for our LUST work and then we got another one, either from our local organisation or because we needed to have one in Puhuri also for other work (before it was possible to have a single ID for the two systems that are used for user management). One of us was blocked on both accounts simultaneously, then tried to get a third account via an appointment at another university and was unlucky to get that one also on the same file system...</li> </ul> <p>poor guy ...</p> <ul> <li>Moreover there is a simple formala that connects your userid and project id to the respective storage system it is on...</li> </ul> </li> <li> <p>What is the difference between these folders at higher hierarchy? For example, my user folder is located at <code>/pfs/lustrep4/users</code>. Each of these folders contain folders for users and projects. </p> <ul> <li>They are all on the same file systems but with different quota policies and different retention policies. </li> </ul> <p>Then may be my personal files and project files are located in different parent folder, isn't it?</p> <ul> <li>Project and scratch will always be on the same file system but is assigned independently from the user home directory, basically because what I explained above. There is a many-to-many mapping between users and projects.</li> </ul> </li> <li> <p>Are files removed from LUMI after certain days of no activity?</p> <ul> <li> <p>The policies are an evolving thing but accounts that are not used for too long are blocked even if they have an active project because an unattended account is a security risk. </p> </li> <li> <p>Files on scratch and flash will be cleaned in the future after 90 or 30 days respectively (likely access date though and not creation date). This is rather common on big clusters actually.</p> </li> <li> <p>All files of your project are removed 90 days after the end of the project and not recoverable. </p> </li> <li> <p>Not sure how long a userid can exist without a project attached to it, but we already have closed accounts on LUMI with all files removed.</p> </li> <li> <p>And note that LUMI is not meant for data archiving. There is no backup, not even of the home directory. You are responsible for transfering all data to an external storage service, likely your home institute.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/notes_20230516/#lumi-user-support","title":"LUMI User Support","text":"<ol> <li> <p>Re the Tallinn course: will it be recorded too, like this one? And where will this course recording be available?</p> <ul> <li> <p>The problem with the 4-day courses that there is lot of copyrighted material in there that we can only make available to users of LUMI. So far this has been done with a project that was only accessible to those who took the course but we are looking to put them in a place were all users can access the data on LUMI. The HPE lectures will never go on the web though. There is a chance that we will be allowed to put the AMD presentations on the web.</p> <p>There is actually material from previous courses already on the course archive web site that J\u00f8rn referred to in his introduction, on lumi-supercomputer.github.io/LUMI-training-materials.</p> </li> </ul> <p>I'm mostly interested in the GPU-profiling, but I can't attend due to other events.</p> <ul> <li>Part of that is HPE material for which we are looking for a better solution, part of it is AMD material and so far we have been allowed to put their slides on the web, but we have to ask for the recordings. We only got a access to a system capable of serving the recordings last week so we are still working on that.</li> </ul> </li> <li> <p>Can we cancel our tickets ourselves, if the problem \"magically\" solves meanwhile :)?</p> <ul> <li> <p>I am not aware of such an option.</p> </li> <li> <p>Simply mail that the issue is resolved and the owner of the ticket will be very happy to close it ;-)</p> </li> </ul> </li> </ol>"},{"location":"1day-20230509/schedule/","title":"Schedule (tentative)","text":"09:00 CEST\u00a0\u00a0             10:00 EEST              Welcome and introduction             Presenter: J\u00f8rn Dietze (LUST) Recording:              09:10 CEST             10:10 EEST              LUMI Architecture             Presenter: Kurt Lust Notes             and             slides (PDF) Recording:              09:40 CEST             10:40 EEST              HPE Cray Programming Environment             Presenter: Kurt Lust Notes             and             slides (PDF) Recording:              10:10 CEST             11:10 EEST              Modules on LUMI             Presenter: Kurt Lust Notes             and             slides (PDF) Recording:              10:45 CEST             11:45 EEST Break              11:00 CEST             12:00 EEST              LUMI Software Stacks             Presenter: Kurt Lust Notes             and             slides (PDF) Recording:              11:45 CEST             12:45 EEST              Hands-on             Exercise assignments and solutions              12:15 CEST             13:15 EEST Lunch break              13:15 CEST             14:15 EEST              Running jobs on LUMI             Presenter: Maciej Szpindler slides (PDF) Recording:              15:15 CEST             16:15 EEST              Hands-on             Exercise assignments and solutions              15:30 CEST             16:39 EEST Break              15:40 CEST             16:40 EEST              Introduction to Lustre and Best Practices             Presenter: J\u00f8rn Dietze slides (PDF) Recording:              15:50 CEST             16:50 EEST              LUMI User Support             Presenter: J\u00f8rn Dietze slides (PDF) Recording:              16:15 CEST             17:15 EEST General Q&amp;A              16:30 CEST             17:30 EEST Course end"},{"location":"1day-20230509/video_00_Introduction/","title":"Welcome and introduction","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p>"},{"location":"1day-20230509/video_01_LUMI_Architecture/","title":"LUMI Architecture","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230509/video_02_HPE_Cray_Programming_Environment/","title":"HPE Cray Programming Environment","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230509/video_03_Modules_on_LUMI/","title":"Modules on LUMI","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230509/video_04_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230509/video_06_Running_Jobs_on_LUMI/","title":"Running Jobs on LUMI","text":"<p>Presenter: Maciej Szpindler (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"1day-20230509/video_08_Introduction_to_Lustre_and_Best_Practices/","title":"Introduction to Lustre and Best Practices","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"1day-20230509/video_09_LUMI_User_Support/","title":"LUMI User Support","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"1day-20230921/","title":"LUMI 1-day training 21 September 2023","text":""},{"location":"1day-20230921/#organisation","title":"Organisation","text":"<ul> <li> <p>Schedule</p> </li> <li> <p>Questions from the Hedgedoc document of the 21 September 2023 session</p> <ul> <li>Original document on Hedgedoc (may disappear over time)</li> </ul> </li> </ul>"},{"location":"1day-20230921/#setting-up-for-the-exercises","title":"Setting up for the exercises","text":"<ul> <li> <p>Create a directory in the scratch of the training project, or if you want to     keep the exercises around for a while after the session and have already     another project on LUMI, in a subdirectory or your project directory      or in your home directory (though we don't recommend the latter).     Then go into that directory.</p> <p>E.g., in the scratch directory of the project:</p> <pre><code>mkdir -p /scratch/project_465000688/$USER/exercises\ncd /scratch/project_465000688/$USER/exercises\n</code></pre> </li> <li> <p>Now download the exercises and un-tar:</p> <pre><code>wget https://462000265.lumidata.eu/1day-20230921/files/exercises-20230921.tar.gz\ntar -xf exercises-20230921.tar.gz\n</code></pre> <p>Link to the tar-file with the exercises</p> </li> <li> <p>You're all set to go!</p> </li> </ul>"},{"location":"1day-20230921/#downloads","title":"Downloads","text":"<p>Note: Some links in the table below will remain invalid until after the course when all materials are uploaded.</p> Presentation Slides Notes recording Introduction / / recording LUMI Architecture slides notes recording HPE Cray Programming Environment slides notes recording Modules on LUMI slides notes recording LUMI Software Stacks slides notes recording Exercises 1 / notes / Running Jobs on LUMI slides / recording Exercises 2 / notes / Introduction to Lustre and Best Practices slides / recording LUMI User Support slides / recording Appendix: Additional documentation / documentation /"},{"location":"1day-20230921/01_Architecture/","title":"The LUMI Architecture","text":"<p>In this presentation, we will build up LUMI part by part, stressing those aspects that are important to know to run on LUMI efficiently and define jobs that can scale.</p>"},{"location":"1day-20230921/01_Architecture/#why-do-i-kneed-to-know-this","title":"Why do I kneed to know this?","text":"<p>You may wonder why you need to know about system architecture if all you want to do is to run  some programs.</p> <p>A supercomputer is not simply a scaled-ups smartphone or PC that will offer good performance automatically. But it is a very expensive infrastructure, with an investment of 160M EURO for LUMI and an estimated total cost (including operations) of 250M EURO. So it is important to use the computer efficiently.</p> <p>And that efficiency comes not for free. Instead in most cases it is important to properly map an  application on the available resources to run efficiently.  The way an application is developed is important for this, but it is not the only factor. Every application needs some user help  to run in the most efficient way, and that requires an understanding of</p> <ol> <li> <p>The hardware architecture of the supercomputer, which is something that we discuss in this     section.</p> </li> <li> <p>The middleware: the layers of software that sit between the application on one hand and the     hardware and operating system on the other hand. This is a topic of discussion in several sessions     of this course.</p> </li> <li> <p>The application. This is very domain-specific and application-specific and hence cannot be the     topic of a general course like this one. In fact, there are so many different applications and     often considerable domain knowledge is required so that a small support team like the one of      LUMI cannot provide that information. It is up to scientific communities to organise such trainings,     and then up to users to combine the knowledge of an application obtained from such a course with the     knowledge about the computer you want to use and its middleware obtained from courses such as this one     or our 4-day more advanced course.</p> </li> </ol>"},{"location":"1day-20230921/01_Architecture/#lumi-is","title":"LUMI is ...","text":"<p>LUMI is a pre-exascale supercomputer, and not a superfast PC nor a compute cloud architecture.</p> <p>Each of these architectures have their own strengths and weaknesses and offer different  compromises and it is key to chose the right infrastructure for the job and use the right  tools for each infrastructure.</p> <p>Just some examples of using the wrong tools or infrastructure:</p> <ul> <li> <p>The single thread performance of the CPU is lower than on a high-end PC.      We've had users who were disappointed about the speed of a single core and were expecting     that this would be much faster than their PCs. Supercomputers however are optimised for      performance per Watt and get their performance from using lots of cores through well-designed     software. If you want the fastest core possible, you'll need a gaming PC.</p> <p>E.g., the AMD 5800X is a popular CPU for high end gaming PCs using the same core architecture  as the CPUs in LUMI. It runs at a base clock of 3.8 GHz and a boost clock of 4.7 GHz if only one core is used and the system has proper cooling. The 7763 used in the compute nodes of LUMI-C runs at a base clock of 2.45 GHz and a boost clock of 3.5 GHz. If you have only one single core job to run on your PC, you'll be able to reach that boost clock while on LUMI you'd probably need to have a large part of the node for yourself, and even then the performance for jobs that are not memory bandwidth limited will be lower than that of the gaming PC.</p> </li> <li> <p>For some data formats the GPU performance may be slower also than on a high end gaming PC.     This is even more so because     an MI250x should be treated as two GPUs for most practical purposes. The better double precision     floating point operations and matrix operations, also at full precision, require transistors also      that on some other GPUs are used for rendering hardware or for single precision compute units.</p> <p>E.g., a single GPU die of the MI250X (half a GPU) has a peak FP32 performance at the boost clock of almost 24 TFlops or 48 TFlops in the packed format which is actually hard for a compiler to exploit, while the high-end AMD graphics GPU RX 7900 XTX claims 61 TFlops at the boost clock. But the FP64 performance of one MI250X  die is also close to 24 TFlops in vector math, while the RX 7900 XTX does less than 2 TFlops in that data format which is important for a lot of scientific computing applications.</p> </li> <li> <p>Compute GPUs and rendering GPUs are different beasts these days.     We had a user who wanted to use the ray tracing units to do rendering. The MI250X does not     have texture units or ray tracing units though. It is not a real graphics processor anymore.</p> </li> <li> <p>The environment is different also. It is not that because it runs some Linux it handles are your     Linux software.     A user complained that they did not succeed in getting their nice remote development environment to     work on LUMI. The original author of these notes took a test license and downloaded a trial version.     It was a very nice environment but really made for local development and remote development in a      cloud environment with virtual machines individually protected by personal firewalls and was      not only hard to get working on a supercomputer but also insecure.</p> </li> <li> <p>And supercomputer need proper software that exploits the strengths and works around the weaknesses     of their architecture.     CERN came telling on a EuroHPC Summit Week before the COVID pandemic that they would start using more     HPC and less cloud and that they expected a 40% cost reduction that way. A few years later they     published a paper with their experiences and it was mostly disappointment. The HPC infrastructure     didn't fit their model for software distribution and performance was poor. Basically their solution     was designed around the strengths of a typical cloud infrastructure and relied precisely on those things     that did make their cloud infrastructure more expensive than the HPC infrastructure they tested. It relied     on fast local disks that require a proper management layer in the software, (ab)using the file system as     a database for unstructured data, a software distribution mechanism that requires an additional daemon     running permanently on the compute nodes (and local storage on those nodes), ...</p> </li> </ul> <p>True supercomputers, and LUMI in particular, are built for scalable parallel applications and features that are found on smaller clusters or on workstations that pose a threat to scalability are removed from the system. It is also a shared infrastructure but with a much more lightweight management layer than a cloud infrastructure and far less isolation between users, meaning that abuse by one user can have more of a negative impact on  other users than in a cloud infrastructure. Supercomputers since the mid to late '80s are also built according to the principle of trying to reduce the hardware cost by using cleverly designed software both at the system and application level. They perform best when streaming data through the machine at all levels of the  memory hierarchy and are not built at all for random access to small bits of data (where the definition of \"small\" depends on the level in the memory hierarchy).</p> <p>At several points in this course you will see how this impacts what you can do with a supercomputer and how you work with a supercomputer.</p>"},{"location":"1day-20230921/01_Architecture/#lumi-spec-sheet-a-modular-system","title":"LUMI spec sheet: A modular system","text":"<p>So we've already seen that LUMI is in the first place a EuroHPC pre-exascale machine. LUMI is built to prepare for the exascale era and to fit in the EuroHPC ecosystem.  But it does not even mean that it has to cater to all pre-exascale compute needs. The EuroHPC JU tries to build systems that have some flexibility, but also does not try to cover  all needs with a single machine. They are building 3 pre-exascale systems with different architecture to explore multiple architectures and to cater to a more diverse audience.</p> <p>LUMI is also a very modular machine designed according to the principles explored in a series of European projects, and in particular DEEP and its successors) that explored the cluster-booster concept. E.g., in a complicated multiphysics simulation  you could be using regular CPU nodes for the physics that cannot be GPU-accelerated communicating with compute GPU nodes for the physics that can be GPU-accelerated, then add a number of CPU nodes to do the I/O and a specialised render GPU node for in-situ visualisation.</p> <p>LUMI is in the first place a huge GPGPU supercomputer. The GPU partition of LUMI, called LUMI-G, contains 2928 (2978?) nodes with a single 64-core AMD EPYC 7A53 CPU and 4 AMD MI250x GPUs. Each node has 512 GB of RAM attached to the CPU (the maximum the CPU can handle without compromising bandwidth) and 128 GB of HBM2e memory per GPU. Each GPU node has a theoretical peak performance of nearly 200 TFlops in single (FP32) or double (FP64) precision vector arithmetic (and twice that with the packed FP32 format, but that  is not well supported so this number is not often quoted). The matrix units are capable of about 400 TFlops in FP32 or FP64. However, compared to the NVIDIA GPUs, the performance for lower precision formats used in some AI applications is not that stellar.</p> <p>LUMI also has a large CPU-only partition, called LUMI-C, for jobs that do not run well on GPUs, but also integrated enough with the GPU partition that it is possible to have applications that combine both node types. LUMI-C consists of 1536 nodes with 2 64-core AMD EPYC 7763 CPUs. 32 of those nodes have 1TB of RAM (with some of these nodes actually reserved for special purposes such as connecting to a Quantum computer), 128 have 512 GB and 1376 have 256 GB of RAM.</p> <p>LUMI also has two smaller groups of nodes for interactive data analytics.  8 of those nodes have two  64-core Zen2/Rome CPUs with 4 TB of RAM per node, while 8 others have dual 64-core Zen2/Rome CPUs and 8 NVIDIA A40 GPUs for visualisation. Currently we are working on an Open OnDemand based service to make some fo those facilities available. Note though that these nodes are meant for a very specific use, so it is not that we will also be offering, e.g., GPU compute facilities on NVIDIA hardware, and that these are shared resources that should not be monopolised by a single user (so no hope to run an MPI job on 8 4TB nodes).</p> <p>LUMI also has a 8 PB flash based file system running the Lustre parallel file system. This system is often denoted as LUMI-F. The bandwidth of that system is 1740 GB/s.  Note however that this is still a remote file system with a parallel file system on it, so do not expect that it will behave as the local SSD in your laptop.  But that is  also the topic of another session in this course.</p> <p>The main work storage is provided by 4 20 PB hard disk based Lustre file systems with a bandwidth of 240 GB/s each. That section of the machine is often denoted  as LUMI-P. </p> <p>Big parallel file systems need to be used in the proper way to be able to offer the performance that one would expect from their specifications. This is important enough that  we have a separate session about that in this course.</p> <p>An object based file system similar to the Allas service of CSC that some of the Finnish users may be familiar with is also being worked on. At the  moment the interface to that system is still rather primitive.</p> <p>Currently LUMI has 4 login nodes, called user access nodes in the HPE Cray world. They each have 2 64-core AMD EPYC 7742 processors and 1 TB of RAM. Note that  whereas the GPU and CPU compute nodes have the Zen3 architecture code-named \"Milan\", the processors on the login nodes are Zen2 processors, code-named \"Rome\". Zen3 adds some new instructions so if a compiler generates them, that code would not run on the login nodes. These instructions are basically used in cryptography though. However, many instructions have very different latency, so a compiler that optimises specifically for Zen3 may chose another ordering of instructions then when optimising for Zen2 so it may still make sense to compile specifically for the compute nodes on LUMI.</p> <p>All compute nodes, login nodes and storage are linked together through a  high-performance interconnect. LUMI uses the Slingshot 11 interconnect which is developed by HPE Cray, so not the Mellanox/NVIDIA InfiniBand that you may be familiar with from many smaller clusters, and as we shall discuss later this also influences how you work on LUMI.</p> <p>Early on a small partition for containerised micro-services managed with Kubernetes was also planned, but that may never materialize due to lack of  people to set it up and manage it.</p> <p>In this section of the course we will now build up LUMI step by step.</p>"},{"location":"1day-20230921/01_Architecture/#building-lumi-the-cpu-amd-7xx3-milanzen3-cpu","title":"Building LUMI: The CPU AMD 7xx3 (Milan/Zen3) CPU","text":"<p>The LUMI-C and LUMI-G compute nodes use third generation AMD EPYC CPUs. Whereas Intel CPUs launched in the same period were built out of a single large monolithic piece of silicon (that only changed recently with some variants of the Sapphire Rapids CPU launched in early 2023), AMD CPUs are build out of multiple so-called chiplets. </p> <p>The basic building block of Zen3 CPUs is the Core Complex Die (CCD). Each CCD contains 8 cores, and each core has 32 kB of L1 instruction  and 32 kB of L1 data cache, and 512 kB of L2 cache. The L3 cache is shared across all cores on a chiplet and has a total size of 32 MB on LUMI (there are some variants of the processor where this is 96MB). At the user level, the instruction set is basically equivalent to that of the Intel Broadwell generation. AVX2 vector instructions and the FMA instruction are fully supported, but there is no support for any of the AVX-512 versions that can be found on Intel Skylake server processors and later generations. Hence the number of floating point operations that a core can in theory do each clock cycle is 16 (in  double precision) rather than the 32 some Intel processors are capable of. </p> <p></p> <p>The full processor package for the AMD EPYC processors used in LUMI have 8 such Core Complex Dies for a total of 64 cores. The caches are not shared between different CCDs, so it also implies that the processor has 8 so-called L3 cache regions. (Some cheaper variants have only 4 CCDs, and some have CCDs with only 6 or fewer cores enabled but the same 32 MB of L3 cache per CCD).</p> <p>Each CCD connects to the memory/IO die through an Infinity Fabric link.  The memory/IO die contains the memory controllers, connections to connect two CPU packages together, PCIe lanes to connect to external hardware, and some additional hardware, e.g., for managing the processor.  The memory/IO die supports 4 dual channel DDR4 memory controllers providing  a total of 8 64-bit wide memory channels. From a logical point of view the memory/IO-die is split in 4 quadrants, with each quadrant having a dual channel memory controller and 2 CCDs. They basically act as 4 NUMA domains. For a core it is slightly faster to access memory in its own quadrant than memory attached to another quadrant, though for the 4 quadrants within the same socket the difference is small. (In fact, the BIOS can be set to show only two or one NUMA domain which is advantageous in some cases, like the typical load pattern of login nodes where it is impossible to nicely spread processes and their memory across the 4 NUMA domains).</p> <p>The theoretical memory bandwidth of a complete package is around 200 GB/s. However, that bandwidth is not available to a single core but can only be used if enough  cores spread over all CCDs are used.</p>"},{"location":"1day-20230921/01_Architecture/#building-lumi-a-lumi-c-node","title":"Building LUMI: A LUMI-C node","text":"<p>A compute node is then built out of two such processor packages, connected  through 4 16-bit wide Infinity Fabric connections with a total theoretical bandwidth of 144 GB/s in each direction. So note that the bandwidth in each direction is less than the memory bandwidth of a socket. Again, it is not really possible to use the full memory bandwidth of a node using just cores on a single socket. Only one of the two sockets has a direct connection to the high performance Slingshot interconnect though.</p>"},{"location":"1day-20230921/01_Architecture/#a-strong-hierarchy-in-the-node","title":"A strong hierarchy in the node","text":"<p>As can be seen from the node architecture in the previous slide, the CPU compute nodes have a very hierarchical architecture. When mapping an application onto  one or more compute nodes, it is key for performance to take that hierarchy into account. This is also the reason why we will pay so much attention to thread and process pinning in this tutorial course.</p> <p>At the coarsest level, each core supports two hardware threads (what Intel calls hyperthreads). Those hardware threads share all the resources of a core, including the  L1 data and instruction caches and the L2 cache, execution units and space for register renaming.  At the next level, a Core Complex Die contains (up to) 8 cores. These cores share the L3 cache and the link to the memory/IO die.  Next, as configured on the LUMI compute nodes, there are 2 Core Complex Dies in a NUMA node. These two CCDs share the DRAM channels of that NUMA node. At the fourth level in our hierarchy 4 NUMA nodes are grouped in a socket. Those 4  NUMA nodes share an inter-socket link. At the fifth and last level in our shared memory hierarchy there are two sockets in a node. On LUMI, they share a single Slingshot inter-node link.</p> <p>The finer the level (the lower the number), the shorter the distance and hence the data delay is between threads that need to communicate with each other through the memory hierarchy, and the higher the bandwidth.</p> <p>This table tells us a lot about how one should map jobs, processes and threads onto a node. E.g., if a process has fewer then 8 processing threads running concurrently, these should be mapped to cores on a single CCD so that they can share  the L3 cache, unless they are sufficiently independent of one another, but even in the latter case the additional cores on those CCDs should not be used by other processes as they may push your data out of the cache or saturate the link to the memory/IO die and hence slow down some threads of your process. Similarly, on a 256 GB compute node each NUMA node has 32 GB of RAM (or actually a bit less as the OS also needs memory, etc.), so if you have a job that uses 50 GB of memory but only, say, 12 threads, you should really have two NUMA nodes reserved for that job as otherwise other threads or processes running on cores in those NUMA nodes could saturate some resources needed by your job. It might also be preferential to spread those 12 threads over the 4  CCDs in those 2 NUMA domains unless communication through the L3 threads would be the bottleneck in your application.</p>"},{"location":"1day-20230921/01_Architecture/#hierarchy-delays-in-numbers","title":"Hierarchy: delays in numbers","text":"<p>This slide shows the ACPI System Locality distance Information Table (SLIT) as returned by, e.g., <code>numactl -H</code> which gives relative distances to memory from a core. E.g., a value of 32 means that access takes 3.2x times the  time it would take to access memory attached to the same NUMA node.  We can see from this table that the penalty for accessing memory in  another NUMA domain in the same socket is still relatively minor (20%  extra time), but accessing memory attached to the other socket is a lot  more expensive. If a process running on one socket would only access memory attached to the other socket, it would run a lot slower which is why Linux has mechanisms to try to avoid that, but this cannot be done in all scenarios which is why on some clusters you will be allocated cores in proportion to the amount of memory you require, even if that is more cores than you really need (and you will be billed for them).</p>"},{"location":"1day-20230921/01_Architecture/#building-lumi-concept-lumi-g-node","title":"Building LUMI: Concept LUMI-G node","text":"<p>This slide shows a conceptual view of a LUMI-G compute node. This node is unlike any Intel-architecture-CPU-with-NVIDIA-GPU compute node you may have  seen before, and rather mimics the architecture of the USA pre-exascale machines Summit and Sierra which have IBM POWER9 CPUs paired with  NVIDIA V100 GPUs.</p> <p>Each GPU node consists of one 64-core AMD EPYC CPU and 4 AMD MI250x GPUs.  So far nothing special. However, two elements make this compute node very special. First, the GPUs are not connected to the CPU though a PCIe bus. Instead they are connected through the same links that AMD uses to link the GPUs together, or to link the two sockets in the LUMI-C compute nodes, known as xGMI or Infinity Fabric. This enables unified memory across CPU and GPUs and  provides partial cache coherency across the system. The CPUs coherently cache the CPU DDR and GPU HBM memory, but each GPU only coherently caches  its own local memory. The second remarkable element is that the Slingshot interface cards connect directly to the GPUs (through a PCIe interface on the GPU) rather than two the CPU. The GPUs have a shorter path to the communication  network than the CPU in this design. </p> <p>This makes the LUMI-G compute node really a \"GPU first\" system. The architecture looks more like a GPU system with a CPU as the accelerator for tasks that a GPU is not good at such as some scalar processing or running an OS, rather than a CPU node with GPU accelerator.</p> <p>It is also a good fit with the cluster-booster design explored in the DEEP project series. In that design, parts of your application that cannot be properly accelerated would run on CPU nodes, while booster GPU nodes would be used for those parts  that can (at least if those two could execute concurrently with each other). Different node types are mixed and matched as needed for each specific application,  rather than building clusters with massive and expensive nodes that few applications can fully exploit. As the cost per transistor does not decrease anymore, one has to look for ways to use each transistor as efficiently as possible...</p> <p>It is also important to realise that even though we call the partition \"LUMI-G\", the MI250x is not a GPU in the true sense of the word. It is not a rendering GPU, which for AMD is  currently the RDNA architecture with version 3 just out, but a compute accelerator with an architecture that evolved from a GPU architecture, in this case the VEGA architecture from AMD. The architecture of the MI200 series is also known as CDNA2, with the MI100 series being just CDNA, the first version. Much of the hardware that does not serve compute purposes has been removed from the design to have more transistors available for compute.  Rendering is possible, but it will be software-based  rendering with some GPU acceleration for certain parts of the pipeline, but not full hardware rendering. </p> <p>This is not an evolution at AMD only. The same is happening with NVIDIA GPUs and there is a reason why the latest generation is called \"Hopper\" for compute and \"Ada Lovelace\" for rendering GPUs.  Several of the functional blocks in the Ada Lovelace architecture are missing in the Hopper  architecture to make room for more compute power and double precision compute units. E.g., Hopper does not contain the ray tracing units of Ada Lovelace. The Intel Data Center GPU Max code named \"Ponte Vecchio\" is the only current GPU for  HPC that still offers full hardware rendering support (and even ray tracing).</p> <p>Graphics on one hand and HPC and AI on the other hand are becoming separate workloads for which manufacturers make different, specialised cards, and if you have applications that need both, you'll have to rework them to work in two phases, or to use two types of nodes and communicate between them over the interconnect, and look for supercomputers that support both workloads.</p> <p>But so far for the sales presentation, let's get back to reality...</p>"},{"location":"1day-20230921/01_Architecture/#building-lumi-what-a-lumi-g-node-really-looks-like","title":"Building LUMI: What a LUMI-G node really looks like","text":"<p>Or the full picture with the bandwidths added to it:</p> <p>The LUMI-G node uses the 64-core AMD 7A53 EPYC processor, known under the code name \"Trento\". This is basically a Zen3 processor but with a customised memory/IO die, designed specifically  for HPE Cray (and in fact Cray itself, before the merger) for the USA Coral-project to build the Frontier supercomputer, the fastest system in the world at the end of 2022 according to at least the Top500 list. Just as the CPUs in the LUMI-C nodes, it is a design with 8 CCDs and a memory/IO die.</p> <p>The MI250x GPU is also not a single massive die, but contains two compute dies besides the 8 stacks of HBM2e memory, 4 stacks or 64 GB per compute die. The two compute dies in a package are linked together  through 4 16-bit Infinity Fabric links. These links run at a higher speed than the links between two CPU sockets in a LUMI-C node, but per link the bandwidth is still only 50 GB/s per direction, creating a total bandwidth of 200 GB/s per direction between the two compute dies in an MI250x GPU. That amount of bandwidth is very low compared to even the memory bandwidth, which is roughly 1.6 TB/s peak per die, let alone compared to whatever bandwidth caches on the compute dies would have or the bandwidth of the internal structures that  connect all compute engines on the compute die. Hence the two dies in a single package cannot function efficiently as as single GPU which is one reason why each MI250x GPU on LUMI is actually seen as two GPUs. </p> <p>Each compute die uses a further 2 or 3 of those Infinity Fabric (or xGNI) links to connect to some compute dies in other MI250x packages. In total, each MI250x package is connected through 5 such links to other MI250x packages. These links run at the same 25 GT/s speed as the  links between two compute dies in a package, but even then the bandwidth is only a meager  250 GB/s per direction, less than an NVIDIA A100 GPU which offers 300 GB/s per direction or the NVIDIA H100 GPU which offers 450 GB/s per direction. Each Infinity Fabric link may be twice as fast as each NVLINK 3 or 4 link (NVIDIA Ampere and Hopper respectively), offering 50 GB/s per direction rather than 25 GB/s per direction for NVLINK,  but each Ampere GPU has 12 such links and each Hopper GPU 18 (and in fact a further 18 similar ones to link to a Grace CPU), while each MI250x package has only 5 such links available to link to other GPUs (and the three that we still need to discuss).</p> <p>Note also that even though the connection between MI250x packages is all-to-all, the connection between GPU dies is all but all-to-all. as each GPU die connects to only 3 other GPU dies. There are basically two bidirectional rings that don't need to share links in the topology, and then some extra connections. The rings are:</p> <ul> <li>Green ring: 1 - 0 - 6 - 7 - 5 - 4 - 2 - 3 - 1</li> <li>Red ring: 1 - 0 - 2 - 3 - 7 - 6 - 4 - 5 - 1</li> </ul> <p>These rings play a role in the inter-GPU communication in AI applications using RCCL.</p> <p>Each compute die is also connected to one CPU Core Complex Die (or as documentation of the node sometimes says, L3 cache region). This connection only runs at the same speed as the links between CPUs on the LUMI-C CPU nodes, i.e., 36 GB/s per direction (which is still enough for  all 8 GPU compute dies together to saturate the memory bandwidth of the CPU).  This implies that each of the 8 GPU dies has a preferred CPU die to work with, and this should definitely be taken into account when mapping processes and threads on a LUMI-G node. </p> <p>The figure also shows another problem with the LUMI-G node: The mapping between CPU cores/dies and GPU dies is all but logical:</p> GPU die CCD hardware threads NUMA node 0 6 48-55, 112-119 3 1 7 56-63, 120-127 3 2 2 16-23, 80-87 1 3 3 24-31, 88-95 1 4 0 0-7, 64-71 0 5 1 8-15, 72-79 0 6 4 32-39, 96-103 2 7 5 40-47, 104, 11 2 <p>and as we shall see later in the course, exploiting this is a bit tricky at the moment.</p>"},{"location":"1day-20230921/01_Architecture/#what-the-future-looks-like","title":"What the future looks like...","text":"<p>Some users may be annoyed by the \"small\" amount of memory on each node. Others may be annoyed by the limited CPU capacity on a node compared to some systems  with NVIDIA GPUs. It is however very much in line with the cluster-booster philosophy already mentioned a few times, and it does seem to be the future according to AMD (with Intel also working into that direction).  In fact, it looks like with respect to memory  capacity things may even get worse.</p> <p>We saw the first little steps of bringing GPU and CPU closer together and  integrating both memory spaces in the USA pre-exascale systems Summit and Sierra. The LUMI-G node which was really designed for one of the first USA exascale systems continues on this philosophy, albeit with a CPU and GPU from a different manufacturer. Given that manufacturing large dies becomes prohibitively expensive in newer semiconductor processes and that the transistor density on a die is also not increasing at the same rate anymore with process shrinks, manufacturers are starting to look at other ways of increasing the number of transistors per \"chip\" or should we say package. So multi-die designs are here to stay, and as is already the case in the AMD CPUs, different dies may be manufactured with different processes for economical reasons.</p> <p>Moreover, a closer integration of CPU and GPU would not only make programming easier as memory management becomes easier, it would also enable some codes to run on GPU  accelerators that are currently bottlenecked by memory transfers between GPU and CPU.</p> <p>AMD at its 2022 Investor day and at CES 2023 in early January, and Intel at an Investor day in 2022 gave a glimpse of how they see the future. The future is one where one or more CPU dies, GPU dies and memory controllers are combined in a single package and - contrary to the Grace Hopper design of NVIDIA - where CPU and GPU share  memory controllers. At CES 2023, AMD already showed a MI300A package that will be used in El Capitan, one of the next USA exascale systems (the third one if Aurora gets built in time). It employs 13 chiplets in two layers, linked to (still only) 8  memory stacks (albeit of a slightly faster type than on the MI250x).  The 4 chiplets on the bottom layer are the memory controllers and inter-GPU links (an they can be at the bottom as they produce less heat). Furthermore each package features 6 GPU dies and 3 Zen4 \"Genoa\" CPU dies. The MI300A still uses only 8 HBM stacks and is also limited to 16 GB stacks, providing a total of 128 GB of RAM.</p> <p>Intel at some point has shown only very conceptual drawings of its Falcon Shores chip  which it calls an XPU, but those drawings suggest that that chip will also support some low-bandwidth but higher capacity external memory, similar to the approach taken in some Sapphire  Rapids Xeon processors that combine HBM memory on-package with DDR5 memory outside  the package. Falcon Shores will be the next generation of Intel GPUs for HPC, after  Ponte Vecchio which will be used in the Aurora supercomputer. It is currently very likely though that Intel will revert to a traditional design for Falcon Shores and push out the integrated CPU+GPU model to a later generation.</p> <p>However, a CPU closely integrated with accelerators is nothing new as Apple Silicon is  rumoured to do exactly that in its latest generations, including the M-family chips.</p>"},{"location":"1day-20230921/01_Architecture/#building-lumi-the-slingshot-interconnect","title":"Building LUMI: The Slingshot interconnect","text":"<p>All nodes of LUMI, including the login, management and storage nodes, are linked together using the Slingshot interconnect (and almost all use Slingshot 11, the full implementation with 200 Gb/s bandwidth per direction).</p> <p>Slingshot is an interconnect developed by HPE Cray and based on Ethernet, but with proprietary extensions for better HPC performance. It adapts to the regular Ethernet protocols when talking to a node that only supports Ethernet, so one of the attractive features is that regular servers with Ethernet can be directly connected to the  Slingshot network switches. HPE Cray has a tradition of developing their own interconnect for very large systems. As in previous generations, a lot of attention went to adaptive routing and congestion control. There are basically two versions of it. The early version was named Slingshot 10, ran at 100 Gb/s per direction and did not yet have all features. It was used on the initial deployment of LUMI-C compute nodes but has since been upgraded to the full version. The full version with all features is called Slingshot 11. It supports a bandwidth of 200 Gb/s per direction, comparable to HDR InfiniBand with 4x links. </p> <p>Slingshot is a different interconnect from your typical Mellanox/NVIDIA InfiniBand implementation and hence also has a different software stack. This implies that there are no UCX libraries on the system as the Slingshot 11 adapters do not support that. Instead, the software stack is  based on libfabric (as is the stack for many other Ethernet-derived solutions and even Omni-Path has switched to libfabric under its new owner).</p> <p>LUMI uses the dragonfly topology. This topology is designed to scale to a very large number of  connections while still minimizing the amount of long cables that have to be used. However, with its complicated set of connections it does rely on adaptive routing and congestion control for optimal performance more than the fat tree topology used in many smaller clusters. It also needs so-called high-radix switches. The Slingshot switch, code-named Rosetta, has 64 ports. 16 of those ports connect directly to compute nodes (and the next slide will show you how). Switches are then combined in groups. Within a group there is an all-to-all connection between  switches: Each switch is connected to each other switch. So traffic between two nodes of a  group passes only via two switches if it takes the shortest route. However, as there is typically only one 200 Gb/s direct connection between two switches in a group, if all 16 nodes on two  switches in a group would be communicating heavily with each other, it is clear that some traffic will have to take a different route. In fact, it may be statistically better if the 32 involved nodes would be spread  more evenly over the group, so topology based scheduling of jobs and getting the processes of a job on as few switches as possible may not be that important on a dragonfly Slingshot network.  The groups in a slingshot network are then also connected in an all-to-all fashion, but the number of direct links between two groups is again limited so traffic again may not always want to take  the shortest path. The shortest path between two nodes in a dragonfly topology never involves  more than 3 hops between switches (so 4 switches): One from the switch the node is connected to  the switch in its group that connects to the other group, a second hop to the other group, and then a third hop in the destination group to the switch the destination node is attached to.</p>"},{"location":"1day-20230921/01_Architecture/#assembling-lumi","title":"Assembling LUMI","text":"<p>Let's now have a look at how everything connects together to the supercomputer LUMI. It does show that LUMI is not your standard cluster build out of standard servers.</p> <p>LUMI is built very compactly to minimise physical distance between nodes and to reduce the cabling mess typical for many clusters. LUMI does use a custom rack design for the compute nodes that is also fully water cooled. It is build out of units that can contain up to 4 custom cabinets, and a cooling distribution unit (CDU). The size of the complex as depicted in the slide is approximately 12 m2. Each cabinet contains 8 compute chassis in 2 columns of 4 rows. In between the two columns is all the power circuitry. Each compute chassis can contain 8 compute blades that are mounted vertically. Each compute blade can contain multiple nodes, depending on the type of compute blades. HPE Cray have multiple types of compute nodes, also with  different types of GPUs. In fact, the Aurora supercomputer which uses Intel CPUs and GPUs and El Capitan, which uses the MI300A APUs (integrated CPU and GPU) will use the same design with a different compute blade. Each LUMI-C compute blade contains 4 compute nodes and two network interface cards, with each network interface card implementing two Slingshot interfaces and connecting to two nodes. A LUMI-G compute blade contains two nodes and 4 network interface cards, where each interface card now connects to two GPUs in the same  node. All connections for power, management network and high performance interconnect of the compute node are at the back of the compute blade. At the front of the compute blades one can find the connections to the cooling manifolds that distribute cooling water to the blades. One compute blade of LUMI-G can consume up to 5kW, so the power density of this setup is incredible, with 40 kW for a single compute chassis.</p> <p>The back of each cabinet is equally genius. At the back each cabinet has 8 switch chassis, each matching the position of a compute chassis. The switch chassis contains the connection to the power delivery system and a switch for the management network and has 8 positions for  switch blades. These are mounted horizontally and connect directly to the compute blades. Each slingshot switch has 8x2 ports on the inner side for that purpose, two for each compute blade. Hence for LUMI-C two switch blades are needed in each switch chassis as each blade has 4 network interfaces, and for LUMI-G 4 switch blades are needed for each compute chassis as those nodes have 8 network interfaces. Note that this also implies that the nodes on the same  compute blade of LUMI-C will be on two different switches even though in the node numbering they are numbered consecutively. For LUMI-G both nodes on a blade will be on a different pair of switches  and each node is connected to two switches. So when you get a few sequentially numbered nodes, they will not be on a single switch (LUMI-C) or switch pair (LUMI-G). The switch blades are also water cooled (each one can  consume up to 250W). No currently possible configuration of the Cray EX system needs that  all switch positions in the switch chassis.</p> <p>This does not mean that the extra positions cannot be useful in the future. If not for an interconnect, one could, e.g., export PCIe ports to the back and attach, e.g., PCIe-based storage via blades as the  switch blade environment is certainly less hostile to such storage than the very dense and very hot compute blades.</p>"},{"location":"1day-20230921/01_Architecture/#lumi-assembled","title":"LUMI assembled","text":"<p>This slide shows LUMI fully assembled (as least as it was at the end of 2022).</p> <p>At the front there are 5 rows of cabinets similar to the ones in the exploded Cray EX picture  on the previous slide. Each row has 2 CDUs and 6 cabinets with compute nodes.  The first row, the one with the wolf, contains all nodes of LUMI-C, while the other four  rows, with the letters of LUMI, contain the GPU accelerator nodes. At the back of the room there are more  regular server racks that house the storage, management nodes, some special compute nodes , etc. The total size is roughly the size of a tennis court. </p> <p>Remark</p> <p>The water temperature that a system like the Cray EX can handle is so high that in fact the water can be cooled again with so-called \"free cooling\", by just radiating the heat to the environment rather  than using systems with compressors similar to air conditioning systems, especially in regions with a colder climate. The LUMI supercomputer is housed in Kajaani in Finland, with moderate temperature almost  year round, and the heat produced by the supercomputer is fed into the central heating system of the city, making it one of the greenest supercomputers in the world as it is also fed with renewable energy.</p>"},{"location":"1day-20230921/02_CPE/","title":"The HPE Cray Programming Environment","text":"<p>In this session we discuss some of the basics of the operating system and programming environment on LUMI. Whether you like it or not, every user of a supercomputer like LUMI gets confronted with these elements at some point.</p>"},{"location":"1day-20230921/02_CPE/#why-do-i-need-to-know-this","title":"Why do I need to know this?","text":"<p>The typical reaction of someone who only wants to run software on an HPC system when confronted with a talk about development tools is \"I only want to run some programs, why do I need to know about programming environments?\"</p> <p>The answer is that development environments are an intrinsic part of an HPC system.  No HPC system is as polished as a personal computer and the software users want to use is typically very unpolished. And some of the essential middleware that turns the hardware with some variant of Linux into a parallel supercomputers is part of the programming  environment. The binary interfaces to those libraries are also not as standardised  as for the more common Linux system libraries.</p> <p>Programs on an HPC cluster are preferably installed from sources to generate binaries optimised for the system. CPUs have gotten new instructions over time that can sometimes speed-up execution of a program a lot, and compiler optimisations that take specific strengths and weaknesses of particular CPUs into account can also gain some performance. Even just a 10% performance gain on an investment of 160 million EURO such as LUMI means a lot of money. When running, the build environment on most systems needs to be at least partially recreated. This is somewhat less relevant on Cray systems as we will see at the end of this part of the course, but if you want reproducibility it becomes important again.</p> <p>Compiling on the system is also the easiest way to guarantee compatibility of the binaries  with the system. </p> <p>Even when installing software from prebuilt binaries some modules might still be needed. Prebuilt binaries will typically include the essential runtime libraries for the parallel technologies they use, but these may not be compatible with LUMI.  In some cases this can be solved by injecting a library from LUMI, e.g., you may want to inject an optimised MPI library as we shall see in the container section of this course. But sometimes a binary is simply incompatible with LUMI and there is no other solution than to build the software from sources.</p>"},{"location":"1day-20230921/02_CPE/#the-operating-system-on-lumi","title":"The operating system on LUMI","text":"<p>The login nodes of LUMI run a regular SUSE Linux Enterprise Server 15 SP4 distribution. The compute nodes however run Cray OS, a restricted version of the SUSE Linux that runs on the login nodes. Some daemons are inactive or configured differently and Cray also  does not support all regular file systems. The goal of this is to minimize OS jitter, interrupts that the OS handles and slow down random cores at random moments, that can  limit scalability of programs. Yet on the GPU nodes there was still the need to reserve one core for the OS and driver processes. This in turn led to an asymmetry in the setup so now 8 cores are reserved, one per CCD, so that all CCDs are equal again.</p> <p>This also implies that some software that works perfectly fine on the login nodes may not work on the compute nodes. E.g., there is no <code>/run/user/$UID</code> directory and we have experienced that D-Bus (which stands for Desktop-Bus) also does not work as one should expect.</p> <p>Large HPC clusters also have a small system image, so don't expect all the bells-and-whistles  from a Linux workstation to be present on a large supercomputer. Since LUMI compute nodes are diskless, the system image actually occupies RAM which is another reason to keep it small.</p>"},{"location":"1day-20230921/02_CPE/#programming-models","title":"Programming models","text":"<p>On LUMI we have several C/C++ and Fortran compilers. These will be discussed more in this session.</p> <p>There is also support for MPI and SHMEM for distributed applications. And we also support RCCL, the ROCm-equivalent of the  CUDA NCCL library that is popular in machine learning packages.</p> <p>All compilers have some level of OpenMP support,  and two compilers support OpenMP offload to  the AMD GPUs, but again more about that later.</p> <p>OpenACC, the other directive-based model for GPU offloading,  is only supported in the Cray Fortran compiler. There is no commitment of neither HPE Cray or AMD to extend that support to C/C++ or other compilers, even though there is work going on in the LLVM community and several compilers on the system are based on LLVM.</p> <p>The other important programming model for AMD GPUs is HIP,  which is their alternative for the proprietary CUDA model. It does not support all CUDA features though (basically it is more CUDA 7 or 8 level)  and there is also no equivalent to CUDA Fortran.</p> <p>The commitment to OpenCL is very unclear, and this actually holds for other GPU vendors also.</p> <p>We also try to provide SYCL as it is a programming language/model that works on all three GPU families currently used in HPC. </p> <p>Python is of course pre-installed on the system but we do ask to use big Python installations in a special way as Python puts a tremendous load on the file system. More about that later in this course.</p> <p>Some users also report some success in running Julia. We don't have full support though and have to depend on binaries as provided by julialang.org.</p> <p>It is important to realise that there is no CUDA on AMD GPUs and there will never be as this is a  proprietary technology that other vendors cannot implement. The visualisation nodes in LUMI have NVIDIA rendering GPUs but these nodes are meant for visualisation and not for compute.</p>"},{"location":"1day-20230921/02_CPE/#the-development-environment-on-lumi","title":"The development environment on LUMI","text":"<p>Long ago, Cray designed its own processors and hence had to develop their own compilers. They kept doing so, also when they moved to using more standard components, and had a lot of expertise in that field, especially when it comes to the needs of  scientific codes, programming models that are almost only used in scientific computing or stem from such projects. As they develop their own interconnects, it does make sense to also develop an MPI implementation that can use the interconnect in an optimal way. They also have a long tradition in developing performance measurement and analysis tools  and debugging tools that work in the context of HPC.</p> <p>The first important component of the HPE Cray Programming Environment is the compilers. Cray still builds its own compilers for C/C++ and Fortran, called the Cray Compiling Environment (CCE). Furthermore, the GNU compilers are also supported on every Cray system, though at the moment AMD GPU support is not enabled. Depending on the hardware of the  system other compilers will also be provided and integrated in the environment. On LUMI two other compilers are available: the AMD AOCC compiler for CPU-only code and the  AMD ROCm compilers for GPU programming. Both contain a C/C++ compiler based on Clang and LLVM and a Fortran compiler which is currently based on the former PGI frontend with LLVM backend. The ROCm compilers also contain the support for HIP, AMD's CUDA clone.</p> <p>The second component is the Cray Scientific and Math libraries, containing the usual suspects as BLAS, LAPACK and ScaLAPACK, and FFTW, but also some data libraries and Cray-only libraries.</p> <p>The third component is the Cray Message Passing Toolkit. It provides an MPI implementation optimized for Cray systems, but also the Cray SHMEM libraries, an implementation of OpenSHMEM 1.5.</p> <p>The fourth component is some Cray-unique sauce to integrate all these components, and  support for hugepages to make memory access more efficient for some programs that  allocate huge chunks of memory at once.</p> <p>Other components include the Cray Performance Measurement and Analysis Tools and the  Cray Debugging Support Tools that will not be discussed in this one-day course, and Python and R modules that both also provide some packages compiled with support for the Cray Scientific Libraries.</p> <p>Besides the tools provided by HPE Cray, several of the development tools from the ROCm stack are also available on the system while some others can be user-installed (and one of those, Omniperf, is not available due to security concerns). Furthermore there are some third party tools available on LUMI, including Linaro Forge (previously ARM Forge) and Vampir and some open source profiling tools.</p> <p>Specifically not on LUMI are the Intel and NVIDIA programming environments, nor is the regular Intel oneAPI HPC Toolkit. The classic Intel compilers pose problems on AMD CPUs as <code>-xHost</code> cannot be relied on, but it appears that the new compilers that are based on Clang and an LLVM backend behave better. Various MKL versions are also troublesome, with different workarounds for different versions, though here also it seems that Intel now has  code that works well on AMD for many MKL routines. We have experienced problems with Intel  MPI when testing it on LUMI though in principle it should be possible to use Cray MPICH as they are derived from the same version of MPICH. The NVIDIA programming environment doesn't make sense on an AMD GPU system, but it could have been usefull for some visualisation software on the  visualisation nodes.</p> <p>We will now discuss some of these components in a little bit more detail, but refer to the 4-day trainings that we organise three times a year with HPE for more material.</p> <p>Python and R</p> <p>Big Python and R installations can consist of lots of small files. Parallel file systems such as Lustre used on LUMI cannot work efficiently with such files. Therefore such installations should be containerised.</p> <p>We offer two tools for that on LUMI with different strengths and weaknesses:</p> <ul> <li> <p><code>lumi-container-wrapper</code>     can build upon Cray Python when installing packages with <code>pip</code> or can     do independent Conda installations from an environments file.     The tool also create wrapper scripts for all commands in the <code>bin</code> subdirectory of the     container installation so that the user does not always need to be aware that they are     working in a container.</p> <p>It is the LUMI-equivalent of the <code>tykky</code> module on the Finnish national systems operated by CSC.</p> </li> <li> <p><code>cotainr</code>     is a tool developed by the Danish LUMI-partner DeIC to build some types of containers     in user space and is also a good tool to containerise a Conda installation.</p> </li> </ul>"},{"location":"1day-20230921/02_CPE/#the-cray-compiling-environment","title":"The Cray Compiling Environment","text":"<p>The Cray Compiling Environment are the default compilers on many Cray systems and on LUMI. These compilers are designed specifically for scientific software in an HPC environment. The current versions are LLVM-based with extensions by HPE Cray for automatic vectorization and shared memory parallelization, technology that they have experience with since the late '70s or '80s.</p> <p>The compiler offers extensive standards support. The C and C++ compiler is essentially their own build of Clang with LLVM with some of their optimisation plugins and OpenMP run-time. The version numbering of the CCE currently follows the major versions of the Clang compiler used. The support for C and C++ language standards corresponds to that of Clang. The Fortran compiler uses a frontend and optimiser developed by HPE Cray, but an LLVM-based code generator.  The compiler supports most of Fortran 2018 (ISO/IEC 1539:2018). The CCE Fortran compiler is known to be very strict with language standards. Programs that use GNU or Intel extensions will usually fail to compile, and unfortunately since many developers only test with these compilers, much Fortran code is not fully standards compliant and will fail.</p> <p>All CCE compilers support OpenMP, with offload for AMD and NVIDIA GPUs. They claim full OpenMP 4.5 support with partial (and growing) support for OpenMP 5.0 and 5.1. More  information about the OpenMP support is found by checking a manual page: <pre><code>man intro_openmp\n</code></pre> which does require that the <code>cce</code> module is loaded. The Fortran compiler also supports OpenACC for AMD and NVIDIA GPUs. That implementation claims to be fully OpenACC 2.0 compliant, and offers partial support for OpenACC 2.x/3.x.  Information is available via <pre><code>man intro_openacc\n</code></pre> AMD and HPE Cray still recommend moving to OpenMP which is a much broader supported standard. There are no plans to also support OpenACC in the Cray C/C++ compiler, nor are there any  plans for support by AMD in the ROCm stack.</p> <p>The CCE compilers also offer support for some PGAS (Partitioned Global Address Space) languages. UPC 1.2 is supported, as is Fortran 2008 coarray support. These implementations do not require a preprocessor that first translates the code to regular C or Fortran. There is also support for debugging with Linaro Forge.</p> <p>Lastly, there are also bindings for MPI.</p>"},{"location":"1day-20230921/02_CPE/#scientific-and-math-libraries","title":"Scientific and math libraries","text":"<p>Some mathematical libraries have become so popular that they basically define an API for which several implementations exist, and CPU manufacturers and some open source groups spend a significant amount of resources to make optimal implementations for each CPU architecture.</p> <p>The most notorious library of that type is BLAS, a set of basic linear algebra subroutines for vector-vector, matrix-vector and matrix-matrix implementations. It is the basis for many other libraries that need those linear algebra operations, including Lapack, a library with solvers for linear systems and eigenvalue problems.</p> <p>The HPE Cray LibSci library contains BLAS and its C-interface CBLAS, and LAPACK and its C interface LAPACKE. It also adds ScaLAPACK, a distributed memory version of LAPACK, and BLACS, the  Basic Linear Algebra Communication Subprograms, which is the communication layer used by ScaLAPACK. The BLAS library combines implementations from different sources, to try to offer the most optimal one for several architectures and a range of matrix and vector sizes.</p> <p>LibSci also contains one component which is HPE Cray-only: IRT, the Iterative Refinement Toolkit,  which allows to do mixed precision computations for LAPACK operations that can speed up the generation of a double precision result with nearly a factor of two for those problems that are suited for iterative refinement. If you are familiar with numerical analysis, you probably know that the matrix should not be too ill-conditioned for that.</p> <p>There is also a GPU-optimized version of LibSci, called LibSci_ACC, which contains a subset of the routines of LibSci. We don't have much experience in the support team with this library though. It can be compared with what Intel is doing with oneAPI MKL which also offers GPU versions of some of the traditional MKL routines.</p> <p>Another separate component of the scientific and mathematical libraries is FFTW3,  Fastest Fourier Transforms in the West, which comes with optimized versions for all CPU architectures supported by recent HPE Cray machines.</p> <p>Finally, the scientific and math libraries also contain HDF5 and netCDF libraries in sequential and parallel versions. These are included because it is essential that  they interface properly with MPI parallel I/O and the Lustre file system to offer the best bandwidth to and from storage. </p> <p>Cray used to offer more pre-installed third party libraries for which the only added value was that they compiled the binaries. Instead they now offer build scripts in a GitHub repository.</p>"},{"location":"1day-20230921/02_CPE/#cray-mpi","title":"Cray MPI","text":"<p>HPE Cray build their own MPI library with optimisations for their own interconnects. The Cray MPI library is derived from the ANL MPICH 3.4 code base and fully supports the  ABI (Application Binary Interface) of that application which implies that in principle it should be possible to swap the MPI library of applications build with that ABI with the Cray MPICH library. Or in other words, if you can only get a binary distribution of an application and that application was build against an MPI library compatible with  the MPICH 3.4 ABI (which includes Intel MPI) it should be possible to exchange that library for the Cray one to have optimised communication on the Cray Slingshot interconnect.</p> <p>Cray MPI contains many tweaks specifically for Cray systems. HPE Cray claim improved algorithms for many collectives, an asynchronous progress engine to improve overlap of communications and computations,  customizable collective buffering when using MPI-IO, and optimized remote memory access (MPI one-sided communication) which also supports passive remote memory access.</p> <p>When used in the correct way (some attention is needed when linking applications) it is allo fully GPU aware with currently support for AMD and NVIDIA GPUs.</p> <p>The MPI library also supports bindings for Fortran 2008.</p> <p>MPI 3.1 is almost completely supported, with two exceptions. Dynamic process management is not supported (and a problem anyway on systems with batch schedulers), and when using CCE MPI_LONG_DOUBLE and MPI_C_LONG_DOUBLE_COMPLEX are also not supported.</p> <p>The Cray MPI library does not support the <code>mpirun</code> or <code>mpiexec</code> commands, which is in fact allowed by the standard which only requires a process starter and suggest <code>mpirun</code> or <code>mpiexec</code>  depending on the version of the standard. Instead the Slurm <code>srun</code> command is used as the  process starter. This actually makes a lot of sense as the MPI application should be mapped correctly on the allocated resources, and the resource manager is better suited to do so.</p> <p>Cray MPI on LUMI is layered on top of libfabric, which in turn uses the so-called Cassini provider to interface with the hardware. UCX is not supported on LUMI (but Cray MPI can support it when used on InfiniBand clusters). It also uses a GPU Transfer Library (GTL) for GPU-aware MPI.</p>"},{"location":"1day-20230921/02_CPE/#lmod","title":"Lmod","text":"<p>Virtually all clusters use modules to enable the users to configure the environment and select the versions of software they want. There are three different module systems around. One is an old implementation that is hardly evolving anymore but that can still be found on a number of clusters. HPE Cray still offers it as an option. Modulefiles are written in TCL, but the tool itself is in C. The more popular tool at the moment is probably Lmod. It is largely compatible with modulefiles for the old tool, but prefers modulefiles written in LUA. It is also supported by the HPE Cray PE and is our choice on LUMI. The final implementation is a full TCL implementation developed  in France and also in use on some large systems in Europe.</p> <p>Fortunately the basic commands are largely similar in those implementations, but what differs is the way to search for modules. We will now only discuss the basic commands, the more advanced ones will be discussed in the next session of this tutorial course.</p> <p>Modules also play an important role in configuring the HPE Cray PE, but before touching that  topic we present the basic commands:</p> <ul> <li><code>module avail</code>: Lists all modules that can currently be loaded. </li> <li><code>module list</code>: Lists all modules that are currently loaded</li> <li><code>module load</code>: Command used to load a module. Add the name and version of the module.</li> <li><code>module unload</code>: Unload a module. Using the name is enough as there can only one version be      loaded of a module.</li> <li><code>module swap</code>:  Unload the first module given and then load the second one. In Lmod this is      really equivalent to a <code>module unload</code> followed by a <code>module load</code>.</li> </ul> <p>Lmod supports a hierarchical module system. Such a module setup distinguishes between installed modules and available modules. The installed modules are all modules that can be loaded in one way or another by the module systems, but loading some of those may require loading other modules first. The available modules are the modules that can be loaded directly without loading any other module. The list of available modules changes all the time based on modules that are already loaded, and if you unload a module that makes other loaded modules unavailable, those will also be deactivated by Lmod. The advantage of a hierarchical module system is that one can support multiple configurations of a module while all configurations can have the same name and version. This is not fully exploited on LUMI, but it  is used a lot in the HPE Cray PE. E.g., the MPI libraries for the various compilers on the system all have the same name and version yet make different binaries available depending on the compiler that is being used.</p>"},{"location":"1day-20230921/02_CPE/#compiler-wrappers","title":"Compiler wrappers","text":"<p>The HPE Cray PE compilers are usually used through compiler wrappers. The wrapper for C is <code>cc</code>, the one for C++ is <code>CC</code> and the one for Fortran is <code>ftn</code>. The wrapper then calls the selected compiler. Which compiler will be called is determined by which compiler module is loaded. As shown on the slide  \"Development environment on LUMI\", on LUMI the Cray Compiling Environment (module <code>cce</code>), GNU Compiler Collection (module <code>gcc</code>),  the AMD Optimizing Compiler for CPUs (module <code>aocc</code>) and the ROCm LLVM-based compilers (module <code>amd</code>) are available. On other HPE Cray systems, you may also find the Intel compilers or on systems with NVIDIA GPUs, the NVIDIA HPC compilers.</p> <p>The target architectures for CPU and GPU are also selected through modules, so it is better to not use compiler options such as <code>-march=native</code>. This makes cross compiling also easier.</p> <p>The wrappers will also automatically link in certain libraries, and make the include files available, depending on which other modules are loaded. In some cases it tries to do so cleverly, like selecting an MPI, OpenMP, hybrid or sequential option depending on whether the MPI module is loaded and/or OpenMP compiler flag is used. This is the case for:</p> <ul> <li>The MPI libraries. There is no <code>mpicc</code>, <code>mpiCC</code>, <code>mpif90</code>, etc. on LUMI. The regular compiler     wrappers do the job as soon as the <code>cray-mpich</code> module is loaded.</li> <li>LibSci and FFTW are linked automatically if the corresponding modules are loaded. So no need     to look, e.g., for the BLAS or LAPACK libraries: They will be offered to the linker if the     <code>cray-libsci</code> module is loaded (and it is an example of where the wrappers try to take the     right version based not only on compiler, but also on whether MPI is loaded or not and the     OpenMP compiler flag).</li> <li>netCDF and HDF5</li> </ul> <p>It is possible to see which compiler and linker flags the wrappers add through the <code>--craype-verbose</code> flag.</p> <p>The wrappers do have some flags of their own, but also accept all flags of the selected compiler and  simply pass those to those compilers.</p> <p>The compiler wrappers are provided by the <code>craype</code> module (but you don't have to load that module by hand).</p>"},{"location":"1day-20230921/02_CPE/#selecting-the-version-of-the-cpe","title":"Selecting the version of the CPE","text":"<p>The version numbers of the HPE Cray PE are of the form <code>yy.dd</code>, e.g., <code>22.08</code> for the version released in August 2022. There are usually 10 releases per year (basically every month except July and January), though not all versions are ever offered on LUMI. </p> <p>There is always a default version assigned by the sysadmins when installing the programming environment. It is possible to change the default version for loading further modules by loading one of the versions of the <code>cpe</code> module. E.g., assuming the 22.08 version would be present on the system, it can be loaded through <pre><code>module load cpe/22.08\n</code></pre> Loading this module will also try to switch the already loaded PE modules to the versions from that release. This does not always work correctly, due to some bugs in most versions of this module and a limitation of Lmod. Executing the <code>module load</code> twice will fix this: <pre><code>module load cpe/22.08\nmodule load cpe/22.08\n</code></pre> The module will also produce a warning when it is unloaded (which is also the case when you do a <code>module load</code> of <code>cpe</code> when one is already loaded, as it then first unloads the already loaded <code>cpe</code> module). The warning can be ignored, but keep in mind that what it says is true, it cannot restore the environment you found on LUMI at login.</p> <p>The <code>cpe</code> module is also not needed when using the LUMI software stacks, but more about that later.</p>"},{"location":"1day-20230921/02_CPE/#the-target-modules","title":"The target modules","text":"<p>The target modules are used to select the CPU and GPU optimization targets and to  select the network communication layer. </p> <p>On LUMI there are three CPU target modules that are relevant:</p> <ul> <li><code>craype-x86-rome</code> selects the Zen2 CPU family code named Rome. These CPUs are     used on the login nodes and the nodes of the data analytics and visualisation      partition of LUMI. However, as Zen3 is a superset of Zen2, software compiled     to this target should run everywhere, but may not exploit the full potential     of the LUMI-C and LUMI-G nodes (though the performance loss is likely minor).</li> <li><code>craype-x86-milan</code> is the target module for the Zen3 CPUs code named Milan that     are used on the CPU-only compute nodes of LUMI (the LUMI-C partition).</li> <li><code>craype-x86-trento</code> is the target module for the Zen3 CPUs code named Trento that     are used on the GPU compute nodes of LUMI (the LUMI-G partition).</li> </ul> <p>Two GPU target modules are relevant for LUMI:</p> <ul> <li><code>craype-accel-host</code>: Will tell some compilers to compile offload code for the host     instead.</li> <li><code>craype-accel-gfx90a</code>: Compile offload code for the MI200 series GPUs that are used on LUMI-G.</li> </ul> <p>Two network target modules are relevant for LUMI:</p> <ul> <li><code>craype-network-ofi</code> selects the libfabric communication layer which is needed for     Slingshot 11.</li> <li><code>craype-network-none</code> omits all network specific libraries.</li> </ul> <p>The compiler wrappers also have corresponding compiler flags that can be used to overwrite these settings: <code>-target-cpu</code>, <code>-target-accel</code> and <code>-target-network</code>.</p>"},{"location":"1day-20230921/02_CPE/#prgenv-and-compiler-modules","title":"PrgEnv and compiler modules","text":"<p>In the HPE Cray PE, the <code>PrgEnv-*</code> modules are usually used to load a specific variant of the programming environment. These modules will load the compiler wrapper (<code>craype</code>), compiler, MPI and LibSci module and may load some other modules also.</p> <p>The following table gives an overview of the available <code>PrgEnv-*</code> modules and the compilers they activate:</p> PrgEnv Description Compiler module Compilers PrgEnv-cray Cray Compiling Environment <code>cce</code> <code>craycc</code>, <code>crayCC</code>, <code>crayftn</code> PrgEnv-gnu GNU Compiler Collection <code>gcc</code> <code>gcc</code>, <code>g++</code>, <code>gfortran</code> PrgEnv-aocc AMD Optimizing Compilers(CPU only) <code>aocc</code> <code>clang</code>, <code>clang++</code>, <code>flang</code> PrgEnv-amd AMD ROCm LLVM compilers (GPU support) <code>amd</code> <code>amdclang</code>, <code>amdclang++</code>, <code>amdflang</code> <p>There is also a second module that offers the AMD ROCm environment, <code>rocm</code>. That module has to be used with <code>PrgEnv-cray</code> and <code>PrgEnv-gnu</code> to enable MPI-aware GPU, hipcc with the GNU compilers or GPU support with the Cray compilers.</p> <p>The HPE Cray PE now also contains some mixed programming environments that combine the C/C++ compiler from one environment with the Fortran compiler from another. Currently on LUMI there is <code>PrgEnv-cray-amd</code> using the Cray Fortran compiler with the AMD ROCm C/C++ compiler and <code>PrgEnv-gnu-amd</code> using the GNU Fortran compiler with the AMD ROCm C/C++ compiler.</p>"},{"location":"1day-20230921/02_CPE/#getting-help","title":"Getting help","text":"<p>Help on the HPE Cray Programming Environment is offered mostly through manual pages and compiler flags. Online help is limited and difficult to locate.</p> <p>For the compilers and compiler wrappers, the following man pages are relevant:</p> PrgEnv C C++ Fortran PrgEnv-cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> PrgEnv-gnu <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> PrgEnv-aocc/PrgEnv-amd - - - Compiler wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> <p>Recently, HPE Cray have also created  a web version of some of the CPE documentation.</p> <p>Some compilers also support the <code>--help</code> flag, e.g., <code>amdclang --help</code>. For the wrappers, the switch <code>-help</code> should be used instead as the double dash version is passed to the  compiler.</p> <p>The wrappers also support the <code>-dumpversion</code> flag to show the version of the underlying compiler. Many other commands, including the actual compilers, use <code>--version</code> to show the version.</p> <p>For Cray Fortran compiler error messages, the <code>explain</code> command is also helpful. E.g.,</p> <pre><code>$ ftn\nftn-2107 ftn: ERROR in command line\n  No valid filenames are specified on the command line.\n$ explain ftn-2107\n\nError : No valid filenames are specified on the command line.\n\nAt least one file name must appear on the command line, with any command-line\noptions.  Verify that a file name was specified, and also check for an\nerroneous command-line option which may cause the file name to appear to be\nan argument to that option.\n</code></pre> <p>On older Cray systems this used to be a very useful command with more compilers but as  HPE Cray is using more and more open source components instead there are fewer commands that give additional documentation via the <code>explain</code> command.</p> <p>Lastly, there is also a lot of information in the \"Developing\" section of the LUMI documentation.</p>"},{"location":"1day-20230921/02_CPE/#google-chatgpt-and-lumi","title":"Google, ChatGPT and LUMI","text":"<p>When looking for information on the HPE Cray Programming Environment using search engines such as Google, you'll be disappointed how few results show up. HPE doesn't put much information on the  internet, and the environment so far was mostly used on Cray systems of which there are not that many. </p> <p>The same holds for ChatGPT. In fact, much of the training of the current version of ChatGPT was done with data of two or so years ago and there is not that much suitable training data available on the internet either.</p> <p>The HPE Cray environment has a command line alternative to search engines though: the <code>man -K</code> command that searches for a term in the manual pages. It is often useful to better understand some error messages. E.g., sometimes Cray MPICH will suggest you to set some environment variable to work around some problem. You may remember that <code>man intro_mpi</code> gives a lot of information about Cray MPICH, but if you don't and, e.g., the error message suggests you to set <code>FI_CXI_RX_MATCH_MODE</code> to either <code>software</code> or <code>hybrid</code>, one way to find out where you can get more information about this environment variable is</p> <pre><code>man -K FI_CXI_RX_MATCH_MODE\n</code></pre> <p>The new online documentation is now also complete enough that it makes sense trying the search box on that page instead.</p>"},{"location":"1day-20230921/02_CPE/#other-modules","title":"Other modules","text":"<p>Other modules that are relevant even to users who do not do development:</p> <ul> <li>MPI: <code>cray-mpich</code>. </li> <li>LibSci: <code>cray-libsci</code></li> <li>Cray FFTW3 library: <code>cray-fftw</code></li> <li>HDF5:<ul> <li><code>cray-hdf5</code>: Serial HDF5 I/O library</li> <li><code>cray-hdf5-parallel</code>: Parallel HDF5 I/O library</li> </ul> </li> <li>NetCDF:<ul> <li><code>cray-netcdf</code></li> <li><code>cray-netcdf-hdf5parallel</code></li> <li><code>cray-parallel-netcdf</code></li> </ul> </li> <li>Python: <code>cray-python</code>, already contains a selection of packages that interface with     other libraries of the HPE Cray PE, including mpi4py, NumPy, SciPy and pandas.</li> <li>R: <code>cray-R</code></li> </ul> <p>The HPE Cray PE also offers other modules for debugging, profiling, performance analysis, etc. that are not covered in this short version of the LUMI course. Many more are covered in the 4-day courses for developers that we organise several times per year with the help of HPE and AMD.</p>"},{"location":"1day-20230921/02_CPE/#warning-1-you-do-not-always-get-what-you-expect","title":"Warning 1: You do not always get what you expect...","text":"<p>The HPE Cray PE packs a surprise in terms of the libraries it uses, certainly for users who come from an environment where the software is managed through EasyBuild, but also for most other users.</p> <p>The PE does not use the versions of many libraries determined by the loaded modules at runtime but instead uses default versions of libraries (which are actually in <code>/opt/cray/pe/lib64</code> on the system) which correspond to the version of the programming environment that is set as the default when installed. This is very much the behaviour of Linux applications also that pick standard libraries in a few standard directories and it enables many programs build with the HPE Cray PE to run without reconstructing the environment and in some cases to mix programs compiled with different compilers with ease (with the emphasis on some as there may still be library conflicts between other libraries when not using the  so-called rpath linking). This does have an annoying side effect though: If the default PE on the system  changes, all applications will use different libraries and hence the behaviour of your application may  change. </p> <p>Luckily there are some solutions to this problem.</p> <p>By default the Cray PE uses dynamic linking, and does not use rpath linking, which is a form of dynamic linking where the search path for the libraries is stored in each executable separately. On Linux, the search path for libraries is set through the environment variable <code>LD_LIBRARY_PATH</code>. Those Cray PE modules that have their libraries also in the default location, add the directories that contain the actual version of the libraries corresponding to the version of the module to the PATH-style environment variable <code>CRAY_LD_LIBRARY_PATH</code>. Hence all one needs to do is to ensure that those directories are put in <code>LD_LIBRARY_PATH</code> which is searched before the default location: <pre><code>export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n</code></pre></p> Small demo of adapting <code>LD_LIBRARY_PATH</code>: <p>An example that can only be fully understood after the section on the LUMI software stacks: <pre><code>$ module load LUMI/22.08\n$ module load lumi-CPEtools/1.0-cpeGNU-22.08\n$ ldd $EBROOTLUMIMINCPETOOLS/bin/mpi_check\n      linux-vdso.so.1 (0x00007f420cd55000)\n      libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f420c929000)\n      libmpi_gnu_91.so.12 =&gt; /opt/cray/pe/lib64/libmpi_gnu_91.so.12 (0x00007f4209da4000)\n      ...\n$ export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n$ ldd $EBROOTLUMIMINCPETOOLS/bin/mpi_check\n        linux-vdso.so.1 (0x00007fb38c1e0000)\n      libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fb38bdb4000)\n      libmpi_gnu_91.so.12 =&gt; /opt/cray/pe/mpich/8.1.18/ofi/gnu/9.1/lib/libmpi_gnu_91.so.12 (0x00007fb389198000)\n      ...\n</code></pre> The <code>ldd</code> command shows which libraries are used by an executable. Only a part of the very long output is shown in the above example. But we can already see that in the first case, the library <code>libmpi_gnu_91.so.12</code> is taken from <code>opt/cray/pe/lib64</code> which is the directory with the default versions, while in the second case it is taken from <code>/opt/cray/pe/mpich/8.1.18/ofi/gnu/9.1/lib/</code> which clearly is for a specific version of <code>cray-mpich</code>.</p> <p>We do provide an experimental module <code>lumi-CrayPath</code>  that tries to fix <code>LD_LIBRARY_PATH</code> in a way that unloading the module fixes <code>LD_LIBRARY_PATH</code> again to the state before adding <code>CRAY_LD_LIBRARY_PATH</code> and that reloading the module adapts <code>LD_LIBRARY_PATH</code> to the current value of <code>CRAY_LD_LIBRARY_PATH</code>. Loading that module after loading all other modules should fix this issue for most if not all software.</p> <p>The second solution would be to use rpath-linking for the Cray PE libraries, which can be done by setting the <code>CRAY_ADD_RPATH</code>environment variable: <pre><code>export CRAY_ADD_RPATH=yes\n</code></pre></p> <p>However, there is also a good side to the standard Cray PE behaviour. Updates of the underlying operating system or network software stack may break older versions of the MPI library. By letting the applications use the default libraries and updating the defaults to a newer version, most applications will still run while they would fail if any of the two tricks to force the use of the intended library version are used. This has actually happened after a big LUMI update in March 2023, when all software that used rpath-linking had to be rebuild as the MPICH library that was present before the update did not longer work.</p>"},{"location":"1day-20230921/02_CPE/#warning-2-order-matters","title":"Warning 2: Order matters","text":"<p>Lmod is a hierarchical module scheme and this is exploited by the HPE Cray PE. Not all modules are available right away and some only become available after loading other modules. E.g.,</p> <ul> <li><code>cray-fftw</code> only becomes available when a processor target module is loaded</li> <li><code>cray-mpich</code> requires both the network target module <code>craype-network-ofi</code> and a compiler module to be loaded</li> <li><code>cray-hdf5</code> requires a compiler module to be loaded and <code>cray-netcdf</code> in turn requires <code>cray-hdf5</code></li> </ul> <p>but there are many more examples in the programming environment.</p> <p>In the next section of the course we will see how unavailable modules can still be found with <code>module spider</code>. That command can also tell which other modules should be loaded  before a module can be loaded, but unfortunately due to the sometimes non-standard way  the HPE Cray PE uses Lmod that information is not always complete for the PE, which is also why we didn't demonstrate it here.</p>"},{"location":"1day-20230921/03_Modules/","title":"Modules on LUMI","text":"<p>Intended audience</p> <p>As this course is designed for people already familiar with HPC systems.  As virtually any cluster nowadays uses some form of module environment, this section assumes that the reader is already familiar with a module environment but not necessarily the one used on LUMI.</p>"},{"location":"1day-20230921/03_Modules/#module-environments","title":"Module environments","text":"<p>An HPC cluster is a multi-user machine. Different users may need different  versions of the same application, and each user has their own preferences for the environment. Hence there is no \"one size fits all\" for HPC and mechanisms are needed to support the diverse requirements of multiple users on a single machine. This is where modules play an important role. They  are commonly used on HPC systems to enable users to create  custom environments and select between multiple versions of applications. Note that this also implies that applications on HPC systems are often not installed in the regular directories one would expect from the documentation of some packages, as that location may not even always support proper multi-version installations and as one prefers to have a software stack which is as isolated as possible from the system installation to keep the image that has to be loaded on the compute nodes small.</p> <p>Another use of modules not mentioned on the slide is to configure the programs that are being activated. E.g., some packages expect certain additional environment variables to be set and modules can often take care of that also.</p> <p>There are 3 systems in use for module management. The oldest is a C implementation of the commands using module files written in Tcl. The development of that system stopped around 2012, with version 3.2.10.  This system is supported by the HPE Cray Programming Environment. A second system builds upon the C implementation but now uses Tcl also for the module command and not only for the module files. It is developed in France at the C\u00c9A compute centre. The version numbering was continued from the C implementation, starting with version 4.0.0.  The third system and currently probably the most popular one is Lmod, a version written in Lua with module files also written in Lua. Lmod also supports most Tcl module files. It is also supported by HPE Cray, though they tend to be a bit slow in following versions. The original developer of Lmod, Robert McLay, retired  at the end of August 2023, but TACC, the centre where he worked, is committed to at least maintain Lmod though it may not see much new development anymore.</p> <p>On LUMI we have chosen to use Lmod. As it is very popular, many users may already be familiar with it, though it does make sense to revisit some of the commands that are specific for Lmod and differ from those in the two other implementations.</p> <p>It is important to realise that each module that you see in the overview corresponds to a module file that contains the actual instructions that should be executed when loading  or unloading a module, but also other information such as some properties of the module, information for search and help information.</p> Links <ul> <li>Old-style environment modules on SourceForge</li> <li>TCL Environment Modules home page on SourceForge and the     development on GitHub</li> <li>Lmod documentation and      Lmod development on GitHub</li> </ul> <p>I know Lmod, should I continue?</p> <p>Lmod is a very flexible tool. Not all sides using Lmod use all features, and Lmod can be configured in different ways to the extent that it may even look like a very different module system for people coming from another cluster. So yes, it makes sense to continue reading as Lmod on LUMI may have some tricks that are not available on your home cluster.</p>"},{"location":"1day-20230921/03_Modules/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the few modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"1day-20230921/03_Modules/#benefits-of-a-hierarchy","title":"Benefits of a hierarchy","text":"<p>When the hierarchy is well designed, you get some protection from loading modules that do not work together well. E.g., in the HPE Cray PE it is not possible to load the MPI library built for another compiler than your current main compiler. This is currently not exploited as much as we could on LUMI, mainly because we realised at the start that too many users are not familiar enough with hierarchies and would get confused more than the hierarchy helps them.</p> <p>Another benefit is that when \"swapping\" a module that makes other modules available with a different one, Lmod will try to look for equivalent modules in the list of modules made available by the newly loaded module.</p> <p>An easy example (though a tricky one as there are other mechanisms at play also) it to load a different programming environment in the default login environment right after login:</p> <pre><code>$ module load PrgEnv-aocc\n</code></pre> <p>which results in</p> <p></p> <p>The first two lines of output are due to to other mechanisms that are at work here,  and the order of the lines may seem strange but that has to do with the way Lmod works internally. Each of the PrgEnv modules hard loads a compiler module which is why Lmod tells you that it is loading <code>aocc/3.2.0</code>. However, there is also another mechanism at work that causes <code>cce/15.0.0</code> and <code>PrgEnv-cray/8.3.3</code> to be unloaded, but more about that in the next subsection (next slide).</p> <p>The important line for the hierarchy in the output are the lines starting with  \"Due to MODULEPATH changes...\". Remember that we said that each module has a corresponding module file. Just as binaries on a system, these are organised in a directory structure, and there is a path, in this case MODULEPATH, that determines where Lmod will look for module files. The hierarchy is implemented with a directory structure and the environment variable MODULEPATH, and when the <code>cce/15.0.0</code> module was unloaded and <code>aocc/3.2.0</code> module was loaded, that  MODULEPATH was changed. As a result, the version of the cray-mpich module for the  <code>cce/15.0.0</code> compiler became unavailable, but one with the same module name for the <code>aocc/3.2.0</code> compiler became available and hence Lmod unloaded the version for the <code>cce/15.0.0</code> compiler as it is no longer available but loaded the matching one for the <code>aocc/3.2.0</code> compiler. </p>"},{"location":"1day-20230921/03_Modules/#about-module-names-and-families","title":"About module names and families","text":"<p>In Lmod you cannot have two modules with the same name loaded at the same time. On LUMI, when you load a module with the same name as an already loaded module, that other module will be unloaded automatically before loading the new one. There is  even no need to use the <code>module swap</code> command for that (which in Lmod corresponds to a <code>module unload</code> of the first module and a <code>module load</code> of the second). This gives you an automatic protection against some conflicts if the names of the modules are properly chosen. </p> <p>Note</p> <p>Some clusters do not allow the automatic unloading of a module with the same name as the one you're trying to load, but on LUMI we felt that this is a  necessary feature to fully exploit a hierarchy.</p> <p>Lmod goes further also. It also has a family concept: A module can belong to a family (and at most 1) and no two modules of the same family can be loaded together.  The family property is something that is defined in the module file. It is commonly  used on systems with multiple compilers and multiple MPI implementations to ensure  that each compiler and each MPI implementation can have a logical name without  encoding that name in the version string (like needing to have <code>compiler/gcc-11.2.0</code> or <code>compiler/gcc/11.2.0</code> rather than <code>gcc/11.2.0</code>), while still having an easy way to avoid having two  compilers or MPI implementations loaded at the same time.  On LUMI, the conflicting module of the same family will be unloaded automatically when loading another module of that particular family.</p> <p>This is shown in the example in the previous subsection (the <code>module load PrgEnv-aocc</code> in  a fresh long shell) in two places. It is the mechanism that unloaded <code>PrgEnv-cray</code> when loading <code>PrgEnv-aocc</code> and that then unloaded <code>cce/14.0.1</code> when the  <code>PrgEnv-aocc</code> module loaded the <code>aocc/3.2.0</code> module.</p> <p>Note</p> <p>Some clusters do not allow the automatic unloading of a module of the same family as the one you're trying to load and produce an error message instead. On LUMI, we felt that this is a necessary feature to fully exploit the  hierarchy and the HPE Cray Programming Environment also relies very much on this feature being enabled to make live easier for users.</p>"},{"location":"1day-20230921/03_Modules/#extensions","title":"Extensions","text":"<p>It would not make sense to have a separate module for each of the hundreds of R packages or tens of Python packages that a software stack may contain. In fact, as the software for each module is installed in a separate directory it would also create a performance problem due to excess directory accesses simply to find out where a command is located, and very long search path environment variables such as PATH or the various variables packages such as Python, R or Julia use to find extension packages. On LUMI related packages are often bundled in a single module. </p> <p>Now you may wonder: If a module cannot be simply named after the package it contains as it contains several ones, how can I then find the appropriate module to load? Lmod has a solution for that through the so-called extension mechanism. An Lmod module can define extensions, and some of the search commands for modules will also search in the extensions of a module. Unfortunately, the HPE Cray PE cray-python and cray-R modules do not provide that  information at the moment as they too contain several packages that may benefit from linking to optimised math libraries.</p>"},{"location":"1day-20230921/03_Modules/#searching-for-modules-the-module-spider-command","title":"Searching for modules: the module spider command","text":"<p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive.      The spider command will not only search in module names for the package, but also in extensions     of the modules and so will be able to tell you that a package is delivered by another module. See      Example 4 below where we will search for the CMake tools.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module.      This shows two kinds of information. First it shows which combinations of other modules one     might have to load to get access to the package. That works for both modules and extensions     of modules. In the latter case it will show both the module, and other modules that you might     have to load first to make the module available.     Second it will also show help information for the module if the module file provides      such information. </p> </li> </ol>"},{"location":"1day-20230921/03_Modules/#example-1-running-module-spider-on-lumi","title":"Example 1: Running <code>module spider</code> on LUMI","text":"<p>Let's first run the <code>module spider</code> command. The output varies over time, but at the time of writing, and leaving out a lot of the output, one would have gotten:</p> <p></p> <p></p> <p></p> <p>On the second screen we see, e.g., the ARMForge module which was available in just a single version at that time, and then Autoconf where the version is in blue and followed by <code>(E)</code>. This denotes that the Autoconf package is actually provided as an extension of another module, and one of the next examples will tell us how to figure out which one.</p> <p>The third screen shows the last few lines of the output, which actually also shows some help information for the command.</p>"},{"location":"1day-20230921/03_Modules/#example-2-searching-for-the-fftw-module-which-happens-to-be-provided-by-the-pe","title":"Example 2: Searching for the FFTW module which happens to be provided by the PE","text":"<p>Next let us search for the popular FFTW library on LUMI:</p> <pre><code>$ module spider FFTW\n</code></pre> <p>produces</p> <p></p> <p>This shows that the FFTW library is actually provided by the <code>cray-fftw</code> module and was at the time that this was tested available in 3 versions.  Note that (a) it is not case sensitive as FFTW is not in capitals in the module name and (b) it also finds modules where the argument of module spider is only part of the name.</p> <p>The output also suggests us to dig a bit deeper and  check for a specific version, so let's run</p> <pre><code>$ module spider cray-fftw/3.3.10.3\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>We now get a long list of possible combinations of modules that would enable us to load this module. What these modules are will be explained in the next session of this course. However, it does show a weakness when module spider is used with the HPE Cray PE. In some cases, not all possible combinations are shown (and this is the case here as the module is actually available directly after login and also via some other combinations of modules that are not shown). This is because the HPE Cray Programming Environment is system-installed and sits next to the application software stacks that are managed differently, but in some cases also because the HPE Cray PE sometimes fails to give the complete combination of modules that is needed. The command does work well with the software managed by the LUMI User Support Team as the next two examples will show.</p>"},{"location":"1day-20230921/03_Modules/#example-3-searching-for-gnuplot","title":"Example 3: Searching for GNUplot","text":"<p>To see if GNUplot is available, we'd first search for the name of the package:</p> <pre><code>$ module spider GNUplot\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>The output again shows that the search is not case sensitive which is fortunate as uppercase and lowercase letters are not always used in the same way on different clusters. Some management tools for scientific software stacks will only use lowercase letters, while the package we use for the LUMI software stacks often uses both.</p> <p>We see that there are a lot of versions installed on the system and that the version actually contains more  information (e.g., <code>-cpeGNU-22.12</code>) that we will explain in the next part of this course. But you might of course guess that it has to do with the compilers that were used. It may look strange to you to have the same software built with different compilers. However, mixing compilers is sometimes risky as a library compiled with one compiler may not work in an executable compiled with another one, so to enable workflows that use multiple tools we try  to offer many tools compiled with multiple compilers (as for most software we don't use rpath linking which could help to solve that problem). So you want to chose the appropriate line in terms of the other software that you will be using.</p> <p>The output again suggests to dig a bit further for more information, so let's try</p> <pre><code>$ module spider gnuplot/5.4.6-cpeGNU-22.12\n</code></pre> <p>This produces:</p> <p></p> <p></p> <p>In this case, this module is provided by 3 different combinations of modules that also will be explained in the next part of this course. Furthermore, the output of the command now also shows some help information about the module, with some links to further documentation available on the system or on the web. The format of the output is generated automatically by the software installation tool that we use and we sometimes have to do some effort to fit all information in there.</p> <p>For some packages we also have additional information in our LUMI Software Library web site so it is often worth looking there also.</p>"},{"location":"1day-20230921/03_Modules/#example-4-searching-for-an-extension-of-a-module-cmake","title":"Example 4: Searching for an extension of a module: CMake.","text":"<p>The <code>cmake</code> command on LUMI is available in the operating system image, but as is often the case with such tools distributed with the OS, it is a rather old version and you may want to use a newer one.</p> <p>If you would just look through the list of available modules, even after loading some other modules to activate a larger software stack, you will not find any module called <code>CMake</code> though. But let's use the powers of <code>module spider</code> and try</p> <pre><code>$ module spider CMake\n</code></pre> <p>which produces</p> <p></p> <p>The output above shows us that there are actually four other versions of CMake on the system, but their version is followed by <code>(E)</code> which says that they are extensions of other modules. There is no module called <code>CMake</code> on the system.  But Lmod already tells us how to find out which module actually provides the CMake tools. So let's try</p> <pre><code>$ module spider CMake/3.25.2\n</code></pre> <p>which produces</p> <p></p> <p></p> <p>This shows us that the version is provided by a number of <code>buildtools</code> modules, and for each of those modules also shows us which other modules should be loaded to get access to the commands. E.g., the first line tells us that there is a module <code>buildtools/23.03</code> that provides that version of CMake, but that we first need to load some other modules, with <code>LUMI/23.03</code> and <code>partition/L</code> (in that order)  one such combination.</p> <p>So in this case, after</p> <pre><code>$ module load LUMI/23.03 partition/L buildtools/23.03\n</code></pre> <p>the <code>cmake</code> command would be available.</p> <p>And you could of course also use</p> <pre><code>$ module spider buildtools/23.03\n</code></pre> <p>to get even more information about the buildtools module, including any help included in the module.</p>"},{"location":"1day-20230921/03_Modules/#alternative-search-the-module-keyword-command","title":"Alternative search: the module keyword command","text":"<p>Lmod has a second way of searching for modules: <code>module keyword</code>, but unfortunately it does not yet work very well on LUMI as the version of Lmod is rather old and still has some bugs in the processing of the command. </p> <p>The <code>module keyword</code> command searches in some of the information included in module files for the given keyword, and shows in which modules the keyword was found.</p> <p>We do an effort to put enough information in the modules to make this a suitable additional way to discover software that is installed on the system.</p> <p>Let us look for packages that allow us to download software via the <code>https</code> protocol. One could try</p> <pre><code>$ module keyword https\n</code></pre> <p>which produces a lot of output:</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>The bug in the Lmod 8.3 version on LUMI is that all extensions are shown in the output while they are irrelevant. On the second screen though we see <code>cURL</code> and on the fourth screen <code>wget</code> which are two tools that can be used to fetch files from the internet.</p> <p>LUMI Software Library</p> <p>The LUMI Software Library also has a search box in the upper right. We will see in the next section of this course that much of the software of LUMI is managed through a tool called EasyBuild, and each module file corresponds to an EasyBuild recipe which is a file with the <code>.eb</code> extension. Hence the keywords can also be found in the EasyBuild recipes which are included in this web site, and from a page with an EasyBuild recipe (which may not mean much for you) it is easy to go back to the software package page itself for more information. Hence you can use the search box to search for packages that may not be installed on the system.</p> <p>The example given above though, searching for <code>https</code>, would not work via that box as most EasyBuild recipes include https web links to refer to, e.g., documentation and would be  shown in the result.</p> <p>The LUMI Software Library site includes both software installed in our central software stack and software for which we make customisable build recipes available for user installation, but more about that in the tutorial section on LUMI software stacks.</p>"},{"location":"1day-20230921/03_Modules/#sticky-modules-and-the-module-purge-command","title":"Sticky modules and the module purge command","text":"<p>On some systems you will be taught to avoid <code>module purge</code> as many HPC systems do their default user configuration also through modules. This advice is often given on Cray systems as it is a common practice to preload a suitable set of target modules and a programming environment. On LUMI both are used. A default programming environment and set of target modules suitable for the login nodes is preloaded when you log in to the system, and next the <code>init-lumi</code> module is loaded which in turn makes the LUMI software stacks available that we will discuss in the next session.</p> <p>Lmod however has a trick that helps to avoid removing necessary modules and it is called sticky modules. When issuing the <code>module purge</code> command these modules are automatically reloaded. It is very important to realise that those modules will not just be kept \"as is\" but are in fact unloaded and loaded again as we shall see later that this may have consequences. It is still possible to force unload all these modules using <code>module --force purge</code> or selectively unload those using <code>module --force unload</code>.</p> <p>The sticky property is something that is defined in the module file and not used by the module files ot the HPE Cray Programming Environment, but we shall see that there is a partial workaround for this in some of the LUMI software stacks. The <code>init-lumi</code> module mentioned above though is a sticky module, as are the modules that activate a software stack so that you don't have to start from scratch if you have already chosen a software stack but want to clean up your environment.</p> <p>Let us look at the output of the <code>module avail</code> command, taken just after login on the system at the time of writing of these notes (the exact list of modules shown is a bit fluid):</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>Next to the names of modules you sometimes see one or more letters. The <code>(D)</code> means that that is currently the default version of the module, the one that will be loaded if you do not specify a version. Note that the default version may depend on other modules that are already loaded as we have seen in the discussion of the programming environment.</p> <p>The <code>(L)</code> means that a module is currently loaded.</p> <p>The <code>(S)</code> means that the module is a sticky module.</p> <p>Next to the <code>rocm</code> module you see <code>(D:5.0.2:5.2.0)</code>.  The <code>D</code> means that this version of the module, <code>5.2.3</code>, is currently the default on the system. The two version numbers next to this module show that the module can also  be loaded as <code>rocm/5.0.2</code> and <code>rocm/5.2.0</code>. These are two modules that were removed from the system during the last update of the system, but version 5.2.3 can be loaded as a replacement of these modules so that software that used the removed modules may still work without recompiling.</p> <p>At the end of the overview the extensions are also shown. If this would be fully implemented on LUMI, the list might become very long. There is a way in Lmod to hide that output but unfortunately it does not work on LUMI yet due to another bug in the already old version of Lmod.</p>"},{"location":"1day-20230921/03_Modules/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed in the above example that we don't show directories of module files in the overview (as is the case on most clusters) but descriptive texts about the module group. This is just one view on the module tree though, and it can be changed easily by loading a  version of the <code>ModuleLabel</code> module.</p> <ul> <li><code>ModuleLabel/label</code> produces the default view of the previous example</li> <li><code>ModuleLabel/PEhierarchy</code> still uses descriptive texts but will show the whole      module hierarchy of the HPE Cray Programming Environment.</li> <li><code>ModuleLabel/system</code> does not use the descriptive texts but shows module directories instead.</li> </ul> <p>When using any kind of descriptive labels, Lmod can actually bundle module files from different  directories in a single category and this is used heavily when <code>ModuleLabel/label</code> is loaded  and to some extent also when <code>ModuleLabel/PEhierarchy</code> is loaded.</p> <p>It is rather hard to provide multiple colour schemes in Lmod, and as we do not know how your  terminal is configured it is also impossible to find a colour scheme that works for all users. Hence we made it possible to turn on and off the use of colours by Lmod through the <code>ModuleColour/on</code> and <code>ModuleColour/off</code> modules.</p> <p>In the future, as soon as we have a version of Lmod where module extensions function properly, we will also provide a module to turn on and off the display of extension in the output of <code>module avail</code> .</p> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment.  You can still load them if you know they exist and specify the full version but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work if you use modules that are hidden in the context you're in or if you try to use any module that was designed for us to maintain the system and is therefore hidden  from regular users.</p> <p>Example</p> <p>An example that will only become clear in the next session: When working with the software stack called <code>LUMI/22.08</code>, which is built upon the HPE Cray Programming Environment version 22.08, all (well, most) of the modules corresponding to other version of the Cray PE are hidden.</p>"},{"location":"1day-20230921/03_Modules/#getting-help-with-the-module-help-command","title":"Getting help with the module help command","text":"<p>Lmod has the <code>module help</code> command to get help on modules</p> <pre><code>$ module help\n</code></pre> <p>without further arguments will show some help on the <code>module</code> command. </p> <p>With the name of a module specified, it will show the help information for the default version of that module, and with a full name and version specified it will show this information specifically for that version of the module. But note that <code>module help</code> can only show help for currently available modules.</p> <p>Try, e.g., the following commands:</p> <pre><code>$ module help cray-mpich\n$ module help cray-python/3.9.13.1\n$ module help buildtools/22.12\n</code></pre> <p>Lmod also has another command that produces more limited information (and is currently not fully exploited on LUMI): <code>module whatis</code>. It is more a way to tag a module with different kinds of information, some of  which has a special meaning for Lmod and is used at some places, e.g., in the output of <code>module spider</code> without arguments.</p> <p>Try, e.g.,:</p> <pre><code>$ module whatis Subversion\n$ module whatis Subversion/1.14.2\n</code></pre>"},{"location":"1day-20230921/03_Modules/#a-note-on-caching","title":"A note on caching","text":"<p>Modules are stored as (small) files in the file system. Having a large module system with much software preinstalled for everybody means a lot of small files which will make our Lustre file system very unhappy. Fortunately Lmod does use caches by default. On LUMI we currently have no  system cache and only a user cache. That cache can be found in <code>$HOME/.lmod.d/.cache</code>. </p> <p>That cache is also refreshed automatically every 24 hours. You'll notice when this happens as, e.g., the <code>module spider</code> and <code>module available</code> commands will be slow during the rebuild. you may need to clean the cache after installing new software as on LUMI Lmod does not always detect changes to the installed software,</p> <p>Sometimes you may have to clear the cache also if you get very strange answers from  <code>module spider</code>. It looks like the non-standard way in which the HPE Cray Programming Environment does certain things in Lmod can cause inconsistencies in the cache. This is also one of the reasons whey we do not yet have a central cache for that  software that is installed in the central stacks as we are not sure when that cache is in good shape.</p>"},{"location":"1day-20230921/03_Modules/#a-note-on-other-commands","title":"A note on other commands","text":"<p>As this tutorial assumes some experience with using modules on other clusters, we haven't paid much attention to some of the basic commands that are mostly the same across all three module environments implementations.  The <code>module load</code>, <code>module unload</code> and <code>module list</code> commands work largely as you would expect, though the output style of <code>module list</code> may be a little different from what you expect. The latter may show some inactive modules. These are modules that were loaded at some point, got unloaded when a module closer to the root of the hierarchy of the module system got unloaded, and they will be reloaded automatically when that module or an equivalent (family or name) module is loaded that makes this one or an equivalent module available again.</p> <p>Example</p> <p>To demonstrate this, try in a fresh login shell (with the lines starting with a <code>$</code> the commands that you should enter at the command prompt):</p> <pre><code>$ module unload craype-network-ofi\n\nInactive Modules:\n  1) cray-mpich\n\n$ module load craype-network-ofi\n\nActivating Modules:\n  1) cray-mpich/8.1.23\n</code></pre> <p>The <code>cray-mpich</code> module needs both a valid network architecture target module to be loaded (not <code>craype-network-none</code>) and a compiler module. Here we remove the network target module which inactivates the <code>cray-mpich</code> module, but the module gets reactivated again as soon as the network target module is reloaded.</p> <p>The <code>module swap</code> command is basically equivalent to a <code>module unload</code> followed by a <code>module load</code>.  With one argument it will look for a module with the same name that is loaded and unload that one  before loading the given module. With two modules, it will unload the first one and then load the second one. The <code>module swap</code> command is not really needed on LUMI as loading a conflicting module (name or family) will automatically unload the previously loaded one. However, in case of replacing  a module of the same family with a different name, <code>module swap</code> can be a little faster than just a <code>module load</code> as that command will need additional operations as in the first step it will  discover the family conflict and then try to resolve that in the following steps (but explaining that in detail would take us too far in the internals of Lmod).</p>"},{"location":"1day-20230921/03_Modules/#links","title":"Links","text":"<p>These links were OK at the time of the course. This tutorial will age over time though and is not maintained but may be replaced with evolved versions when the course is organised again, so links may break over time.</p> <ul> <li>Lmod documentation and more specifically     the User Guide for Lmod which is the part specifically for regular users who do not     want to design their own modules.</li> <li>Information on the module environment in the LUMI documentation</li> </ul>"},{"location":"1day-20230921/04_Software_stacks/","title":"LUMI Software Stacks","text":"<p>In this section we discuss</p> <ul> <li>Several of the ways in which we offer software on LUMI</li> <li>Managing software in our primary software stack which is based on EasyBuild</li> </ul>"},{"location":"1day-20230921/04_Software_stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"1day-20230921/04_Software_stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: the option to use a partly coherent fully unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in Apple Silicon M-series but then without the NUMA character     (except maybe for the Ultra version that consists of two dies).</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a a talk in the     EasyBuild user meeting in 2022.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"1day-20230921/04_Software_stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparent way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. Both have their own strengths and weaknesses. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be accustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. </p> <p>We do offer some help to set up Spack also but it is mostly offered \"as is\" and we will not do bug-fixing or development in Spack package files. Spack is very attractive for users who want to set up a personal environment with fully customised versions of the software rather than the rather fixed versions provided by EasyBuild for every version of the software stack. It is possible to specify versions for the main packages that you need and then let Spack figure out a minimal compatible set of dependencies to install  those packages.</p>"},{"location":"1day-20230921/04_Software_stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionnaire sent out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, the so-called Cassini provider,      so any software compiled with an MPI library that     requires UCX, or any other distributed memory model built on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intra-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-Bus comes to mind.</li> </ul> <p>Also, the LUMI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that I did not yet mention is that software that accesses tens of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. On LUMI the tool is called lumi-container-wrapper but it may by some from CSC also be known as Tykky. As an alternative we also offer cotainr, a tool developed by the Danish LUMI-partner DeIC that helps with building some types of containers that can be built in user space and can be used to containerise a conda-installation.</p>"},{"location":"1day-20230921/04_Software_stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the minimal software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 3 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes and zen3 + MI250X for the LUMI-G partition. We were also planning to have a fourth version for the visualisation nodes with  zen2 CPUs combined with NVIDIA GPUs, but that may never materialise and we may manage those differently.</p> <p>We also have an extensible software stack based on Spack which has been pre-configured to use the compilers from the Cray PE. This stack is offered as-is for users who know how to use Spack, but we don't offer much support nor do we do any bugfixing in Spack.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p>"},{"location":"1day-20230921/04_Software_stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"1day-20230921/04_Software_stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"1day-20230921/04_Software_stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It is also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiling Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. </p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"1day-20230921/04_Software_stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/22.08, LUMI/22.12 and LUMI/23.03 modules.  Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules.  There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes and  partition/G for the AMD GPU nodes. There may be a separate partition for the visualisation nodes in the future  but that is not clear yet.</p> <p>There is also a hidden partition/common module in which software is installed that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"1day-20230921/04_Software_stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"1day-20230921/04_Software_stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs (a popular format to package Linux software distributed as binaries) or any other similar format for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system.  This is expected to happen especially with packages that require specific MPI versions or implementations. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And LUMI needs a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"1day-20230921/04_Software_stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is the primary software installation tool.  EasyBuild was selected as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the build-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain there would be problems with MPI. EasyBuild uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures with some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     or the classic Intel compilers will simply optimize for a two decades old CPU.     The situation is better with the new LLVM-based compilers though, and it looks like     very recent versions of MKL are less AMD-hostile. Problems have also been reported     with Intel MPI running on LUMI.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system. </p> <p>We also have the LUMI Software Library which documents all software for which we have EasyBuild recipes available.  This includes both the pre-installed software and the software for which we provide recipes in the LUMI-EasyBuild-contrib GitHub repository, and even instructions for some software that is not suitable for installation through EasyBuild or Spack, e.g., because it likes to write in its own directories while running.</p>"},{"location":"1day-20230921/04_Software_stacks/#easybuild-recipes-easyconfigs","title":"EasyBuild recipes - easyconfigs","text":"<p>EasyBuild uses a build recipe for each individual package, or better said, each individual module as it is possible to install more than one software package in the same module. That installation description relies on either a generic or a specific installation process provided by an easyblock. The build recipes are called easyconfig files or simply easyconfigs and are Python files with  the extension <code>.eb</code>. </p> <p>The typical steps in an installation process are:</p> <ol> <li>Downloading sources and patches. For licensed software you may have to provide the sources as     often they cannot be downloaded automatically.</li> <li>A typical configure - build - test - install process, where the test process is optional and     depends on the package providing useable pre-installation tests.</li> <li>An extension mechanism can be used to install perl/python/R extension packages</li> <li>Then EasyBuild will do some simple checks (some default ones or checks defined in the recipe)</li> <li>And finally it will generate the module file using lots of information specified in the      EasyBuild recipe.</li> </ol> <p>Most or all of these steps can be influenced by parameters in the easyconfig.</p>"},{"location":"1day-20230921/04_Software_stacks/#the-toolchain-concept","title":"The toolchain concept","text":"<p>EasyBuild uses the toolchain concept. A toolchain consists of compilers, an MPI implementation and some basic mathematics libraries. The latter two are optional in a toolchain. All these  components have a level of exchangeability as there are language standards, as MPI is standardised, and the math libraries that are typically included are those that provide a standard API for which several implementations exist. All these components also have in common that it is risky to combine  pieces of code compiled with different sets of such libraries and compilers because there can be conflicts in names in the libraries.</p> <p>On LUMI we don't use the standard EasyBuild toolchains but our own toolchains specifically for Cray and these are precisely the <code>cpeCray</code>, <code>cpeGNU</code>, <code>cpeAOCC</code> and <code>cpeAMD</code> modules already mentioned  before.</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiling Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p></p> <p>There is also a special toolchain called the SYSTEM toolchain that uses the compiler provided by the operating system. This toolchain does not fully function in the same way as the other toolchains when it comes to handling dependencies of a package and is therefore a bit harder to use. The EasyBuild designers had in mind that this compiler would only be used to bootstrap an EasyBuild-managed software stack, but we do use it for a bit more on LUMI as it offers us a relatively easy way to compile some packages also for the CrayEnv stack and do this in a way that they interact as little as possible with other software.</p> <p>It is not possible to load packages from different cpe toolchains at the same time. This is an EasyBuild restriction, because mixing libraries compiled with different compilers does not always work. This could happen, e.g., if a package compiled with the Cray Compiling Environment and one compiled with the GNU compiler collection would both use a particular  library, as these would have the same name and hence the last loaded one would be used by both executables (we don't use rpath or runpath linking in EasyBuild for those familiar with that technique).</p> <p>However, as we did not implement a hierarchy in the Lmod implementation of our software stack at the toolchain level, the module system will not protect you from these mistakes.  When we set up the software stack, most people in the support team considered it too misleading and difficult to ask users to first select the toolchain they want to use and then see the  software for that toolchain.</p> <p>It is however possible to combine packages compiled with one CPE-based toolchain with packages compiled with the system toolchain, but you should avoid mixing those when linking as that may cause problems. The reason that it works when running software is because static linking is used as much as possible in the SYSTEM toolchain so that these packages are as independent as possible.</p> <p>And with some tricks it might also be possible to combine packages from the LUMI software stack with packages compiled with Spack, but one should make sure that no Spack packages are available when building as mixing libraries could cause problems. Spack uses rpath linking which is why this may work.</p>"},{"location":"1day-20230921/04_Software_stacks/#easyconfig-names-and-module-names","title":"EasyConfig names and module names","text":"<p>There is a convention for the naming of an EasyConfig as shown on the slide. This is not mandatory, but EasyBuild will fail to automatically locate easyconfigs for dependencies  of a package that are not yet installed if the easyconfigs don't follow the naming convention. Each part of the name also corresponds to a parameter in the easyconfig  file.</p> <p>Consider, e.g., the easyconfig file <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.</p> <ol> <li>The first part of the name, <code>GROMACS</code>, is the name of the package, specified by the     <code>name</code> parameter in the easyconfig, and is after installation also the name of the     module.</li> <li>The second part, <code>2021.4</code>, is the version of GROMACS and specified by the     <code>version</code> parameter in the easyconfig.</li> <li> <p>The next part, <code>cpeCray-22.08</code> is the name and version of the toolchain,     specified by the <code>toolchain</code> parameter in the easyconfig. The version of the     toolchain must always correspond to the version of the LUMI stack. So this is     an easyconfig for installation in <code>LUMI/22.08</code>.</p> <p>This part is not present for the SYSTEM toolchain</p> </li> <li> <p>The final part, <code>-PLUMED-2.8.0-CPU</code>, is the version suffix and used to provide     additional information and distinguish different builds with different options     of the same package. It is specified in the <code>versionsuffix</code> parameter of the     easyconfig.</p> <p>This part is optional.</p> </li> </ol> <p>The version, toolchain + toolchain version and versionsuffix together also combine to the version of the module that will be generated during the installation process. Hence this easyconfig file will generate the module  <code>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.8.0-CPE</code>.</p>"},{"location":"1day-20230921/04_Software_stacks/#installing","title":"Installing","text":""},{"location":"1day-20230921/04_Software_stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"1day-20230921/04_Software_stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>The next step is to configure your environment. First load the proper version of the LUMI stack for which you want to install software, and you may want to change to the proper partition also if you are cross-compiling.</p> <p>Once you have selected the software stack and partition, all you need to do to activate EasyBuild to install additional software is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition. </p> <p>Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p> <p>Note that the <code>EasyBuild-user</code> module is only needed for the installation process. For using the software that is installed that way it is sufficient to ensure that <code>EBU_USER_PREFIX</code> has the proper value before loading the <code>LUMI</code> module.</p>"},{"location":"1day-20230921/04_Software_stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS there is already support on LUMI. An easy way to do that is to simply check the LUMI Software Library. This web site lists all software that we manage via EasyBuild and make available either pre-installed on the system or as an EasyBuild recipe for user installation. Alternatively one can use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre></p> <p>Output of the search commands:</p> <p><code>eb --search GROMACS</code> produces:</p> <p> </p> <p>while <code>eb -S GROMACS</code> produces:</p> <p> </p> <p>The information provided by both variants of the search command is the same, but <code>-S</code> presents the information in a more compact form.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS there already is a GPU version for AMD GPUs in active development so even before LUMI-G was active we chose to ensure that we could distinguish between GPU and CPU-only versions. To install it, we first run  <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The installation of dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>The output of this command looks like:</p> <p></p> <p></p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb -r\n</code></pre></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p>"},{"location":"1day-20230921/04_Software_stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work.</p> <p>Lmod does keep a user cache of modules. EasyBuild will try to erase that cache after a software installation to ensure that the newly installed module(s) show up immediately. We have seen some very rare cases where clearing the cache did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>In case you see strange behaviour using modules you can also try to manually remove the Lmod user cache which is in <code>$HOME/.lmod.d/.cache</code>. You can do this with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre></p>"},{"location":"1day-20230921/04_Software_stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r . </code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.0-cpeGNU-22.08.eb \u2013r . </code></pre></p>"},{"location":"1day-20230921/04_Software_stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greatest before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/UserRepo/easybuild/easyconfigs</code>.</p>"},{"location":"1day-20230921/04_Software_stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory (unless the sources are already available elswhere where EasyBuild can find them, e.g., in the system EasyBuild sources directory),  and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software.</p> <p>Moreover, EasyBuild also keeps copies of all installed easyconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"1day-20230921/04_Software_stacks/#easybuild-tips-and-tricks","title":"EasyBuild tips and tricks","text":"<p>Updating the version of a package often requires only trivial changes in the easyconfig file. However, we do tend to use checksums for the sources so that we can detect if the available sources have changed. This may point to files being tampered with, or other changes that might need us to be a bit more careful when installing software and check a bit more again.  Should the checksum sit in the way, you can always disable it by using  <code>--ignore-checksums</code> with the <code>eb</code> command.</p> <p>Updating an existing recipe to a new toolchain might be a bit more involving as you also have to make build recipes for all dependencies. When we update a toolchain on the system, we often bump the versions of all installed libraries to one of the latest versions to have most bug fixes and security patches in the software stack, so you need to check for those versions also to avoid installing yet another unneeded version of a library.</p> <p>We provide documentation on the available software that is either pre-installed or can be user-installed with EasyBuild in the  LUMI Software Library. For most packages this documentation does also contain information about the license. The user documentation for some packages gives more information about how to use the package on LUMI, or sometimes also about things that do not work. The documentation also shows all EasyBuild recipes, and for many packages there is  also some technical documentation that is more geared towards users who want to build or modify recipes. It sometimes also tells why we did things in a particular way.</p>"},{"location":"1day-20230921/04_Software_stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>There is also a later course developed by LUST for developers of EasyConfigs for LUMI that can be found on  lumi-supercomputer.github.io/easybuild-tutorial.</p>"},{"location":"1day-20230921/05_Exercises_1/","title":"Exercises 1: Modules, the HPE Cray PE and EasyBuild","text":"<p>See the instructions to set up for the exercises.</p>"},{"location":"1day-20230921/05_Exercises_1/#exercises-on-the-use-of-modules","title":"Exercises on the use of modules","text":"<ol> <li> <p>The <code>Bison</code> program installed in the OS image is pretty old (version 3.0.4) and     we want to use a newer one. Is there one available on LUMI?</p> Click to see the solution. <pre><code>module spider Bison\n</code></pre> <p>tells us that there are indeed newer versions available on the system. </p> <p>The versions that have a compiler name (usually <code>gcc</code>) in their name followed by some seemingly random characters are installed with Spack and not in the CrayEnv or LUMI environments.</p> <p>If there would be more than one version of Bison reported, you could  get more information about a specific version, e.g., <code>Bison/3.8.2</code> with: </p> <pre><code>module spider Bison/3.8.2\n</code></pre> <p>tells us that Bison 3.8.2 is provided by a couple of <code>buildtools</code> modules and available in all partitions in several versions of the <code>LUMI</code> software stack and in <code>CrayEnv</code>.</p> <p>Alternatively, in this case</p> <pre><code>module keyword Bison\n</code></pre> <p>would also have shown that Bison is part of several versions of the <code>buildtools</code> module.</p> <p>The <code>module spider</code> command is often the better command if you use names that with a high  likelihood could be the name of a package, while <code>module keyword</code> is often the better choice for words that are more a keyword. But if one does not return the solution it is a good idea  to try the other one also.</p> </li> <li> <p>The <code>htop</code> command is a nice alternative for the <code>top</code> command with a more powerful user interface.     However, typing <code>htop</code> on the command line produces an error message. Can you find and run <code>htop</code>?</p> Click to see the solution. <p>We can use either <code>module spider htop</code> or <code>module keyword htop</code> to find out that <code>htop</code> is indeed available on the system. With <code>module keyword htop</code> we'll find out immediately that it is in the  <code>systools</code> modules and some of those seem to be numbered after editions of the LUMI stack suggesting that they may be linked to a stack, with <code>module spider</code> you'll first see that it is an extension of a module and see the versions. You may again see some versions installed with Spack.</p> <p>Let's check further for <code>htop/3.2.1</code> that should exist according to <code>module spider htop</code>:</p> <pre><code>module spider htop/3.2.1\n</code></pre> <p>tells us that this version of <code>htop</code> is available in all partitions of <code>LUMI/23.03</code>,  <code>LUMI/22.12</code>, <code>LUMI/22.08</code> and <code>LUMI/22.06</code>, and in <code>CrayEnv</code>. Let us just run it in the <code>CrayEnv</code> environment:</p> <pre><code>module load CrayEnv\nmodule load systools/22.08\nhtop\n</code></pre> <p>(You can quit <code>htop</code> by pressing <code>q</code> on the keyboard.)</p> </li> <li> <p>In the future LUMI will offer Open OnDemand as a browser-based interface to LUMI that will also enable     running some graphical programs. At the moment the way to do this is through a so-called VNC server.     Do we have such a tool on LUMI, and if so, how can we use it?</p> Click to see the solution. <p><code>module spider VNC</code> and <code>module keyword VNC</code> can again both be used to check if there is software available to use VNC.  There is currently only one available version of the module, but at times there may be more.  In those cases loading the older ones (the version number points at the date of some scripts in that module) you will notice that they may produce a warning about being deprecated. You may wonder why they were not uninstalled right away. This is because we cannot remove older versions when installing a newer one right away as it may be in use by users, and for non-interactive job scripts, there may also be job scripts in the queue that have the older version hard-coded in the script. </p> <p>As there is currently only one version on the system, you get the help information right away. If there were more versions you could still get the help information of the newest version by simply using <code>module spider</code>  with the full module name and version. E.g., if the <code>module spider VNC</code> would have shown that <code>lumi-vnc/20230110</code>  exists, you could get the help information using</p> <pre><code>module spider lumi-vnc/20230110\n</code></pre> <p>The output may look a little strange as it mentions <code>init-lumi</code> as one of the modules that you can load. That is because this tool is available even outside <code>CrayEnv</code> or the LUMI stacks. But this command also shows a long help text telling you how to use this module (though it does assume some familiarity with how X11 graphics work on Linux).</p> <p>Note that if there is only a single version on the system, as is the case for the course in September 2023, the <code>module spider VNC</code> command without specific version or correct module name will already display the help information.</p> </li> <li> <p>Search for the <code>bzip2</code> tool (and not just the <code>bunzip2</code> command as we also need the <code>bzip2</code> command) and make      sure that you can use software compiled with the Cray compilers in the LUMI stacks in the same session.</p> Click to see the solution. <pre><code>module spider bzip2\n</code></pre> <p>shows that there are versions of <code>bzip2</code> for several of the <code>cpe*</code> toolchains and in several versions of the LUMI software stack.</p> <p>Of course we prefer to use a recent software stack, the <code>22.08</code> or <code>22.12</code> (but as of September 2023,  there is still more software ready-to-install for <code>22.08</code>).  And since we want to use other software compiled with the Cray compilers also, we really want a <code>cpeCray</code> version to avoid conflicts between  different toolchains. So the module we want to load is <code>bzip2/1.0.8-cpeCray-22.08</code>.</p> <p>To figure out how to load it, use</p> <pre><code>module spider bzip2/1.0.8-cpeCray-22.08\n</code></pre> <p>and see that (as expected from the name) we need to load <code>LUMI/22.08</code> and can then use it in any of the partitions.</p> </li> </ol>"},{"location":"1day-20230921/05_Exercises_1/#exercises-on-compiling-software-by-hand","title":"Exercises on compiling software by hand","text":"<p>These exercises are optional during the session, but useful if you expect  to be compiling software yourself. The source files mentioned can be found in the subdirectory CPE of the download.</p>"},{"location":"1day-20230921/05_Exercises_1/#compilation-of-a-program-1-a-simple-hello-world-program","title":"Compilation of a program 1: A simple \"Hello, world\" program","text":"<p>Four different implementations of a simple \"Hello, World!\" program are provided in the <code>CPE</code> subdirectory:</p> <ul> <li><code>hello_world.c</code> is an implementation in C,</li> <li><code>hello_world.cc</code> is an implementation in C++,</li> <li><code>hello_world.f</code> is an implementation in Fortran using the fixed format source form,</li> <li><code>hello_world.f90</code> is an implementation in Fortran using the more modern free format source form.</li> </ul> <p>Try to compile these programs using the programming environment of your choice.</p> Click to see the solution. <p>We'll use the default version of the programming environment (22.12 at the moment of the course in May 2023), but in case you want to use a particular version, e.g., the 22.08 version, and want to be very sure that all modules are loaded correctly from the start you could consider using</p> <pre><code>module load cpe/22.08\nmodule load cpe/22.08\n</code></pre> <p>So note that we do twice the same command as the first iteration does not always succeed to reload all modules in the correct version. Do not combine both lines into a single <code>module load</code> statement as that would again trigger the bug that prevents all modules to be reloaded in the first iteration.</p> <p>The sample programs that we asked you to compile do not use the GPU. So there are three programming environments that we can use: <code>PrgEnv-gnu</code>, <code>PrgEnv-cray</code> and <code>PrgEnv-aocc</code>. All three will work, and they work almost the same.</p> <p>Let's start with an easy case, compiling the C version of the program with the GNU C compiler. For this all we need to do is</p> <pre><code>module load PrgEnv-gnu\ncc hello_world.c\n</code></pre> <p>which will generate an executable named <code>a.out</code>.  If you are not comfortable using the default version of <code>gcc</code> (which produces the warning message when loading the <code>PrgEnv-gnu</code> module) you can always load the <code>gcc/11.2.0</code> module instead after loading <code>PrgEnv-gnu</code>.</p> <p>Of course it is better to give the executable a proper name which can be done with the <code>-o</code> compiler option:</p> <pre><code>module load PrgEnv-gnu\ncc hello_world.c -o hello_world.x\n</code></pre> <p>Try running this program:</p> <pre><code>./hello_world.x\n</code></pre> <p>to see that it indeed works. We did forget another important compiler option, but we'll discover that in the next exercise.</p> <p>The other programs are equally easy to compile using the compiler wrappers:</p> <pre><code>CC hello_world.cc -o hello_world.x\nftn hello_world.f -o hello_world.x\nftn hello_world.f90 -o hello_world.x\n</code></pre>"},{"location":"1day-20230921/05_Exercises_1/#compilation-of-a-program-2-a-program-with-blas","title":"Compilation of a program 2: A program with BLAS","text":"<p>In the <code>CPE</code> subdirectory you'll find the C program <code>matrix_mult_C.c</code> and the Fortran program <code>matrix_mult_F.f90</code>. Both do the same thing: a matrix-matrix multiplication using the 6 different orders of the three nested loops involved in doing a matrix-matrix multiplication, and a call to the BLAS routine DGEMM that does the same for comparison.</p> <p>Compile either of these programs using the Cray LibSci library for the BLAS routine. Do not use OpenMP shared memory parallelisation. The code does not use MPI.</p> <p>The resulting executable takes one command line argument, the size of the square matrix. Run the script using <code>1000</code> for the matrix size and see what happens.</p> <p>Note that the time results may be very unreliable as we are currently doing this on the login nodes. In the session of Slurm you'll learn how to request compute nodes and it might be interesting to redo this on a compute node with a larger matrix size as the with a matrix size of 1000 all data may stay in the third level cache and you will not notice the differences that you should note. Also, because these nodes are shared with a lot of people any benchmarking is completely unreliable.</p> <p>If this program takes more than half a minute or so before the first result line in the table, starting with <code>ijk-variant</code>, is printed, you've very likely done something wrong (unless the load on the system is extreme). In fact, if you've done things well the time reported for the <code>ijk</code>-variant should be well under 3 seconds for both the C and Fortran versions...</p> Click to see the solution. <p>Just as in the previous exercise, this is a pure CPU program so we can chose between the same three programming environments.</p> <p>The one additional \"difficulty\" is that we need to link with the BLAS library. This is very easy however in  the HPE Cray PE if you use the compiler wrappers rather than calling the compilers yourself: you only need to make sure that the <code>cray-libsci</code> module is loaded and the wrappers will take care of the rest. And on most systems (including LUMI) this module will be loaded automatically when you load the <code>PrgEnv-*</code> module.</p> <p>To compile with the GNU C compiler, all you need to do is</p> <pre><code>module load PrgEnv-gnu\ncc -O3 matrix_mult_C.c -o matrix_mult_C_gnu.x\n</code></pre> <p>will generate the executable <code>matrix_mult_C_gnu.x</code>.</p> <p>Note that we add the <code>-O3</code> option and it is very important to add either <code>-O2</code> or <code>-O3</code> as by default the GNU compiler will generate code without any optimization for debugging purposes, and that code is in this case easily five times or more slower. So if you got much longer run times than indicated this is likely the mistake that you made.</p> <p>To use the Cray C compiler instead only one small change is needed: Loading a different programming  environment module:</p> <pre><code>module load PrgEnv-cray\ncc -O3 matrix_mult_C.c -o matrix_mult_C_cray.x\n</code></pre> <p>will generate the executable <code>matrix_mult_C_cray.x</code>.</p> <p>Likewise for the AMD AOCC compiler we can try with loading yet another <code>PrgEnv-*</code> module:</p> <pre><code>module load PrgEnv-aocc\ncc -O3 matrix_mult_C.c -o matrix_mult_C_aocc.x\n</code></pre> <p>but it turns out that this fails with linker error messages about not being able to find the <code>sin</code> and <code>cos</code> functions. When using the AOCC compiler the <code>libm</code> library with basic math functions is not linked automatically, but this is easily done by adding the <code>-lm</code> flag:</p> <pre><code>module load PrgEnv-aocc\ncc -O3 matrix_mult_C.c -lm -o matrix_mult_C_aocc.x\n</code></pre> <p>For the Fortran version of the program we have to use the <code>ftn</code> compiler wrapper instead, and the issue with the math libraries in the AOCC compiler does not occur. So we get</p> <pre><code>module load PrgEnv-gnu\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_gnu.x\n</code></pre> <p>for the GNU Fortran compiler,</p> <pre><code>module load PrgEnv-cray\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_cray.x\n</code></pre> <p>for the Cray Fortran compiler and</p> <pre><code>module load PrgEnv-aocc\nftn -O3 matrix_mult_F.f90 -o matrix_mult_F_aocc.x\n</code></pre> <p>for the AMD Fortran compiler.</p> <p>When running the program you will see that even though the 6 different loop orderings  produce the same result, the time needed to compile the matrix-matrix product is very different and those differences would be even more pronounced with bigger matrices (which you can do after the session on using Slurm).</p> <p>The exercise also shows that not all codes are equal even if they produce a result of the same quality. The six different loop orderings run at very different speed, and none of our simple implementations can beat a good library, in this case the BLAS library included in LibSci.</p> <p>The results with the Cray Fortran compiler are particularly interesting. The result for the BLAS library is slower which we do not yet understand, but it also turns out that  for four of the six loop orderings we get the same result as with the BLAS library DGEMM routine. It looks like the compiler simply recognized that this was code for a matrix-matrix multiplication and replaced it with a call to the BLAS library. The Fortran 90 matrix multiplication is also replaced by a call of the DGEMM routine. To confirm all this, unload the <code>cray-libsci</code> module and try to compile again and you will see five error messages about not being able to find DGEMM.</p>"},{"location":"1day-20230921/05_Exercises_1/#compilation-of-a-program-3-a-hybrid-mpiopenmp-program","title":"Compilation of a program 3: A hybrid MPI/OpenMP program","text":"<p>The file <code>mpi_omp_hello.c</code> is a hybrid MPI and OpenMP C program that sends a message from each thread in each MPI rank. It is basically a simplified version of the programs found in the <code>lumi-CPEtools</code> modules that can be used to quickly check  the core assignment in a hybrid MPI and OpenMP job (see later in this tutorial). It is again just a CPU-based program.</p> <p>Compile the program with your favourite C compiler on LUMI.</p> <p>We have not yet seen how to start an MPI program. However, you can run the executable on the login nodes and it will then contain just a single MPI rank. </p> Click to see the solution. <p>In the HPE Cray PE environment, you don't use <code>mpicc</code> to compile a C MPI program, but you just use the <code>cc</code> wrapper as for any other C program. To enable MPI you  have to make sure that the <code>cray-mpich</code> module is loaded. This module will usually be loaded by loading one of the <code>PrgEnv-*</code> modules, but only if the right network target module, which is <code>craype-network-ofi</code>, is also already loaded. </p> <p>Compiling the program is very simple:</p> <pre><code>module load PrgEnv-gnu\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_gnu.x\n</code></pre> <p>to compile with the GNU C compiler, </p> <pre><code>module load PrgEnv-cray\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_cray.x\n</code></pre> <p>to compile with the Cray C compiler, and</p> <pre><code>module load PrgEnv-aocc\ncc -O3 -fopenmp mpi_omp_hello.c -o mpi_omp_hello_aocc.x\n</code></pre> <p>to compile with the AMD AOCC compiler.</p> <p>To run the executables it is not even needed to have the respective <code>PrgEnv-*</code> module loaded since the binaries will use a copy of the libraries stored in a default directory, though there have been bugs in the past preventing this to work with <code>PrgEnv-aocc</code>.</p>"},{"location":"1day-20230921/05_Exercises_1/#information-in-the-lumi-software-library","title":"Information in the LUMI Software Library","text":"<p>Explore the LUMI Software Library.</p> <ul> <li>Search for information for the package ParaView and quickly read through the page</li> </ul> Click to see the solution. <p>Link to the ParaView documentation</p> <p>It is an example of a package for which we have both user-level and some technical information. The page will first show some license information, then the actual user information which in case of this package is very detailed and long. But it is also a somewhat complicated package to use. It will become easier when LUMI evolves a bit further, but there will always be some pain. Next comes the more technical part: Links to the EasyBuild recipe and some information about how we build the package.</p> <p>We currently only provide ParaView in the cpeGNU toolchain. This is because it has a lot of dependencies that are not trivial to compile and to port to the other compilers on the system, and EasyBuild is  strict about mixing compilers basically because it can cause a lot of problems, e.g., due to conflicts between OpenMP runtimes.</p>"},{"location":"1day-20230921/05_Exercises_1/#installing-software-with-easybuild","title":"Installing software with EasyBuild","text":"<p>These exercises are based on material from the EasyBuild tutorials (and we have a special version for LUMI also).</p> <p>Note: If you want to be able to uninstall all software installed through the exercises easily, we suggest you make a separate EasyBuild installation for the course, e.g., in <code>/scratch/project_465000688/$USER/eb-course</code> if you make the exercises during the course:</p> <ul> <li>Start from a clean login shell with only the standard modules loaded.</li> <li> <p>Create the directory for the EasyBuild installation (if you haven't done this yet):</p> <pre><code>mkdir -p /scratch/project_465000688/$USER/eb-course\n</code></pre> </li> <li> <p>Set <code>EBU_USER_PREFIX</code>: </p> <pre><code>export EBU_USER_PREFIX=/scratch/project_465000688/$USER/eb-course\n</code></pre> <p>You'll need to do that in every shell session where you want to install or use that software.</p> </li> <li> <p>From now on you can again safely load the necessary <code>LUMI</code> and <code>partition</code> modules for the exercise.</p> </li> <li> <p>At the end, when you don't need the software installation anymore, you can simply remove the directory     that you just created.</p> <pre><code>rm -rf /scratch/project_465000688/$USER/eb-course\n</code></pre> </li> </ul>"},{"location":"1day-20230921/05_Exercises_1/#installing-a-simple-program-without-dependencies-with-easybuild","title":"Installing a simple program without dependencies with EasyBuild","text":"<p>The LUMI Software Library contains the package <code>eb-tutorial</code>. Install the version of the package for the <code>cpeCray</code> toolchain in the 22.12 version of the software stack.</p> Click to see the solution. <ul> <li> <p>We can check the      eb-tutorial page     in the      LUMI Software Library     if we want to see more information about the package.</p> <p>You'll notice that there are versions of the EasyConfigs for <code>cpeGNU</code> and <code>cpeCray</code>. As we want to install software with the <code>cpeCray</code> toolchain for <code>LUMI/22.12</code>, we'll need the <code>cpeCray-22.12</code> version which is the EasyConfig <code>eb-tutorial-1.0.1-cpeCray-22.12.eb</code>.</p> </li> <li> <p>Obviously we need to load the <code>LUMI/22.08</code> module. If we would like to install software     for the CPU compute nodes, you need to also load <code>partition/C</code>.     To be able to use EasyBuild, we also need the <code>EasyBuild-user</code> module.</p> <pre><code>module load LUMI/22.12 partition/C\nmodule load EasyBuild-user\n</code></pre> </li> <li> <p>Now all we need to do is run the <code>eb</code> command from EasyBuild to install the software.</p> <p>Let's however take the slow approach and first check if what dependencies the package needs:</p> <pre><code>eb eb-tutorial-1.0.1-cpeCray-22.12.eb -D\n</code></pre> <p>We can do this from any directory as the EasyConfig file is already in the LUMI Software Library and will be located automatically by EasyBuild. You'll see that all dependencies are already on  the system so we can proceed with the installation:</p> <pre><code>eb eb-tutorial-1.0.1-cpeCray-22.12.eb \n</code></pre> </li> <li> <p>After this you should have a module <code>eb-tutorial/1.0.1-cpeCray-22.12</code> but it may not show up      yet due to the caching of Lmod. Try</p> <pre><code>module av eb-tutorial/1.0.1-cpeCray-22.12\n</code></pre> <p>If this produces an error message complaining that the module cannot be found, it is time to clear the Lmod cache:</p> <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> </li> <li> <p>Now that we have the module, we can check what it actually does:</p> <pre><code>module help eb-tutorial/1.0.1-cpeCray-22.12\n</code></pre> <p>and we see that it provides the <code>eb-tutorial</code> command.</p> </li> <li> <p>So let's now try to run this command:</p> <pre><code>module load eb-tutorial/1.0.1-cpeCray-22.12\neb-tutorial\n</code></pre> <p>Note that if you now want to install one of the other versions of this module, EasyBuild will complain that some modules are loaded that it doesn't like to see, including the <code>eb-tutorial</code> module and the <code>cpeCray</code> modules so it is better to unload those first:</p> <pre><code>module unload cpeCray eb-tutorial\n</code></pre> </li> </ul> Clean before proceeding <p>After this exercise you'll have to clean your environment before being able to make the next exercise:</p> <ul> <li>Unload the <code>eb-tutorial</code> modules</li> <li>The <code>cpeCray</code> module would also produce a warning</li> </ul> <pre><code>module unload eb-tutorial cpeCray\n</code></pre>"},{"location":"1day-20230921/05_Exercises_1/#installing-an-easyconfig-given-to-you-by-lumi-user-support","title":"Installing an EasyConfig given to you by LUMI User Support","text":"<p>Sometimes we have no solution ready in the LUMI Software Library, but we prepare one or more custom EasyBuild recipes for you. Let's mimic this case. In practice we would likely send  those as attachments to a mail from the ticketing system and you would be asked to put them in a separate directory (basically since putting them at the top of your home directory would in some cases let EasyBuild search your whole home directory for dependencies which would be a very slow process).</p> <p>You've been given two EasyConfig files to install a tool called <code>py-eb-tutorial</code> which is in fact a Python package that uses the <code>eb-tutorial</code> package installed in the previous exercise. These EasyConfig files are in the <code>EasyBuild</code> subdirectory of the exercises for this course. In the first exercise you are asked to install the version of <code>py-eb-tutorial</code> for the <code>cpeCray/22.12</code> toolchain.</p> Click to see the solution. <ul> <li> <p>Go to the <code>EasyBuild</code> subdirectory of the exercises and check that it indeed contains the     <code>py-eb-tutorial-1.0.0-cpeCray-22.12-cray-python-3.9.13.1.eb</code> and     <code>py-eb-tutorial-1.0.0-cpeGNU-22.12-cray-python-3.9.13.1.eb</code> files.     It is the first one that we need for this exercise.</p> <p>You can see that we have used a very long name as we are also using a version suffix to make clear which version of Python we'll be using.</p> </li> <li> <p>Let's first check for the dependencies (out of curiosity):</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeCray-22.12-cray-python-3.9.13.1.eb -D\n</code></pre> <p>and you'll see that all dependencies are found (at least if you made the previous exercise  successfully). You may find it strange that it shows no Python module but that is because we are using the <code>cray-python</code> module which is not installed through EasyBuild and only known to EasyBuild as an external module.</p> </li> <li> <p>And now we can install the package:</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeCray-22.12-cray-python-3.9.13.1.eb\n</code></pre> </li> <li> <p>To use the package all we need to do is to load the module and to run the command that it     defines:</p> <pre><code>module load py-eb-tutorial/1.0.0-cpeCray-22.12-cray-python-3.9.13.1\npy-eb-tutorial\n</code></pre> <p>with the same remark as in the previous exercise if Lmod fails to find the module.</p> <p>You may want to do this step in a separate terminal session set up the same way, or you will get an error message in the next exercise with EasyBuild complaining that there are some modules loaded that should not be loaded.</p> </li> </ul> Clean before proceeding <p>After this exercise you'll have to clean your environment before being able to make the next exercise:</p> <ul> <li>Unload the <code>py-eb-tutorial</code> and <code>eb-tutorial</code> modules</li> <li>The <code>cpeCray</code> module would also produce a warning</li> <li>And the <code>py-eb-tutorial</code> also loaded the <code>cray-python</code> module which causes EasyBuild to     produce a nasty error messages if it is loaded when the <code>eb</code> command is called</li> </ul> <pre><code>module unload py-eb-tutorial eb-tutorial cpeCray cray-python\n</code></pre>"},{"location":"1day-20230921/05_Exercises_1/#installing-software-with-uninstalled-dependencies","title":"Installing software with uninstalled dependencies","text":"<p>Now you're asked to also install the version of <code>py-eb-tutorial</code> for the <code>cpeGNU</code> toolchain in <code>LUMI/22.12</code> (and the solution given below assumes you haven't accidentally installed the wrong EasyBuild recipe in one of the previous two exercises).</p> Click to see the solution. <ul> <li> <p>We again work in the same environment as in the previous two exercises. Nothing has changed here.     Hence if not done yet we need</p> <pre><code>module load LUMI/22.12 partition/C\nmodule load EasyBuild-user\n</code></pre> </li> <li> <p>Now go to the <code>EasyBuild</code> subdirectory of the exercises (if not there yet from the previous     exercise) and check what the <code>py-eb-tutorial-1.0.0-cpeGNU-22.12-cray-python-3.9.13.1.eb</code> needs:</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeGNU-22.12-cray-python-3.9.13.1.eb -D\n</code></pre> <p>We'll now see that there are two missing modules. Not only is the  <code>py-eb-tutorial/1.0.0-cpeGNU-22.12-cray-python-3.9.13.1</code> that we try to install missing, but also the <code>eb-tutorial/1.0.1-cpeGNU-22.12</code>. EasyBuild does however manage to find a recipe from which this module can be built in the pre-installed build recipes.</p> </li> <li> <p>We can install both packages separately, but it is perfectly possible to install both packages in a single     <code>eb</code> command by using the <code>-r</code> option to tell EasyBuild to also install all dependencies.</p> <pre><code>eb py-eb-tutorial-1.0.0-cpeGNU-22.12-cray-python-3.9.13.1.eb -r\n</code></pre> </li> <li> <p>At the end you'll now notice (with <code>module avail</code>) that both the module      <code>eb-tutorial/1.0.1-cpeGNU-22.12</code> and <code>py-eb-tutorial/1.0.0-cpeGNU-22.12-cray-python-3.9.13.1</code>     are now present.</p> <p>To run you can use</p> <pre><code>module load py-eb-tutorial/1.0.0-cpeGNU-22.12-cray-python-3.9.13.1\npy-eb-tutorial\n</code></pre> </li> </ul>"},{"location":"1day-20230921/06_Running_jobs/","title":"Running jobs","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230921/07_Exercises_2/","title":"Exercises 2: Running jobs with Slurm","text":""},{"location":"1day-20230921/07_Exercises_2/#exercises-on-the-slurm-allocation-modes","title":"Exercises on the Slurm allocation modes","text":"<ol> <li> <p>Run single task with a job step of <code>srun</code> using multiple cpu cores. Inspect default task allocation with <code>taskset</code> command (<code>taskset -cp $$</code> will show you cpu numbers allocated to a current process). Try with <code>standard-g</code> and <code>small-g</code> partitions. Are there any diffences? You may need to use specific reservation for <code>standard-g</code> partition to avoid long waiting. </p> Click to see the solution. <pre><code>srun --partition=small-g --nodes=1 --tasks=1 --cpus-per-task=16 --time=5 --account=&lt;project_id&gt; bash -c 'taskset -cp $$' \n</code></pre> <p>Note you need to replace <code>&lt;project_id&gt;</code> with actual project account ID in a form of <code>project_</code> plus 9 digits number.</p> <pre><code>srun --partition=standard-g --nodes=1 --tasks=1 --cpus-per-task=16 --time=5 --account=&lt;project_id&gt; --reservation=&lt;res_id&gt; bash -c 'taskset -cp $$' \n</code></pre> <p>The command runs single process (<code>bash</code> shell with a native Linux <code>taskset</code> tool showing process's CPU affinity) on a compute node. You can use <code>man taskset</code> command to see how the tool works.</p> </li> <li> <p>Try Slurm allocations with <code>hybrid_check</code> tool program from the LUMI Software Stack. The program is preinstalled on the system. </p> <p>Use the simple job script to run parallel program with multiple tasks (MPI ranks) and threads (OpenMP). Test task/threads affinity with <code>sbatch</code> submission on the CPU partition.</p> <pre><code>#!/bin/bash -l\n#SBATCH --partition=small-g         # Partition name\n#SBATCH --nodes=1                   # Total number of nodes\n#SBATCH --ntasks-per-node=8         # 8 MPI ranks per node\n#SBATCH --cpus-per-task=6           # 6 threads per task\n#SBATCH --time=5                    # Run time (minutes)\n#SBATCH --account=&lt;project_id&gt;      # Project for billing\n\nmodule load LUMI/22.12\nmodule load lumi-CPEtools\n\nsrun hybrid_check -n -r\n</code></pre> <p>Be careful with copy/paste of script body while it may brake some specific characters.</p> Click to see the solution. <p>Save script contents into <code>job.sh</code> file (you can use <code>nano</code> console text editor for instance), remember to use valid project account name.</p> <p>Submit job script using <code>sbatch</code> command. </p> <pre><code>sbatch job.sh\n</code></pre> <p>The job output is saved in the <code>slurm-&lt;job_id&gt;.out</code> file. You can view it's contents with either <code>less</code> or <code>more</code> shell commands.</p> <p>Actual task/threads affinity may depend on the specific OpenMP runtime but you should see \"block\" thread affinity as a default behaviour.</p> </li> <li> <p>Improve threads affinity with OpenMP runtime variables. Alter your script and add MPI runtime variable to see another cpu mask summary. </p> Click to see the solution. <p>Export <code>SRUN_CPUS_PER_TASK</code> environment variable to follow convention from recent Slurm's versions in your script. Add this line before the <code>hybrid_check</code> call:</p> <pre><code>export SRUN_CPUS_PER_TASK=16 \n</code></pre> <p>Add OpenMP environment variables definition to your script:</p> <pre><code>export OMP_NUM_THREADS=${SRUN_CPUS_PER_TASK}\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n</code></pre> <p>You can also add MPI runtime variable to see another cpu mask summary:</p> <pre><code>export MPICH_CPUMASK_DISPLAY=1\n</code></pre> <p>Note <code>hybrid_check</code> and MPICH cpu mask may not be consistent. It is found to be confusing.</p> </li> <li> <p>Use <code>gpu_check</code> program tool using interactive shell on a GPU node to inspect device binding. Check on which CCD task's CPU core and GPU device are allocated (this is shown with <code>-l</code> option of the tool program).  </p> Click to see the solution. <p>Allocate resources for a single task with a single GPU with <code>salloc</code>:</p> <pre><code>salloc --partition=small-g --nodes=1 --tasks=1 --cpus-per-task=1 --gpus-per-node=1 --time=10 --account=&lt;project_id&gt;\n</code></pre> <p>Note that, after allocation being granted, you receive new shell but still on the compute node. You need to use <code>srun</code> to execute on the allocated node. </p> <p>You need to load specific modules to access tools with GPU support. </p> <pre><code>module load LUMI/22.12 partition/G\n</code></pre> <pre><code>module load lumi-CPEtools\n</code></pre> <pre><code>Run `gpu_check` interactively on a compute node:\n\n    ```\n    srun gpu_check -l\n    ```\n</code></pre> <p>Still remember to terminate your interactive session with <code>exit</code> command.</p> <pre><code>exit\n</code></pre> </li> </ol>"},{"location":"1day-20230921/07_Exercises_2/#slurm-custom-binding-on-gpu-nodes","title":"Slurm custom binding on GPU nodes","text":"<ol> <li> <p>Allocate one GPU node with one task per GPU and bind tasks to each CCD (8-core group sharing L3 cache). Use 7 threads per task having low noise mode of the GPU nodes in mind. Use <code>select_gpu</code> wrapper to map exactly one GPU per task.</p> Click to see the solution. <p>Begin with the example from the slides with 7 cores per task:</p> <pre><code>#!/bin/bash -l\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=1               # Total number of nodes\n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=5                # Run time (minutes)\n#SBATCH --account=&lt;project_id&gt;  # Project for billing\n#SBATCH --hint=nomultithread\n\n        module load LUMI/22.12\n        module load partition/G\n        module load lumi-CPEtools\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\n\nchmod +x ./select_gpu\n\nexport OMP_NUM_THREADS=7\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n\nsrun --cpus-per-task=${OMP_NUM_THREADS} ./select_gpu gpu_check -l\n</code></pre> <p>You need to add explicit <code>--cpus-per-task</code> option for srun to get correct GPU mapping. If you save the script in the <code>job_step.sh</code> then simply submit it with sbatch. Inspect the job output.</p> </li> <li> <p>Change your CPU binding leaving first (#0) and last (#7) cores unused. Run a program with 6 threads per task and inspect actual task/threads affinity.</p> Click to see the solution. <p>Now you would need to alter masks to disable 7th core of each of the group (CCD). Base mask is then <code>01111110</code> which is <code>0x7e</code> in hexadecimal notation.</p> <p>Try to apply new bitmask, change the corresponding variable to spawn 6 threads per task and check how new binding works.</p> <pre><code>#!/bin/bash -l\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=1               # Total number of nodes\n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=5                # Run time (minutes)\n#SBATCH --account=&lt;project_id&gt;  # Project for billing\n#SBATCH --hint=nomultithread\n\n        module load LUMI/22.12\n        module load partition/G\n        module load lumi-CPEtools\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\n\nchmod +x ./select_gpu\n\nCPU_BIND=\"mask_cpu:0x7e000000000000,0x7e00000000000000,\"\nCPU_BIND=\"${CPU_BIND}0x7e0000,0x7e000000,\"\nCPU_BIND=\"${CPU_BIND}0x7e,0x7e00,\"\nCPU_BIND=\"${CPU_BIND}0x7e00000000,0x7e0000000000\"\n\nexport OMP_NUM_THREADS=6\nexport OMP_PROC_BIND=close\nexport OMP_PLACES=cores\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu gpu_check -l\n</code></pre> </li> </ol>"},{"location":"1day-20230921/08_Lustre_intro/","title":"I/O and file systems","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230921/09_LUMI_support/","title":"How to get support and documentation","text":"<p>No notes for now.</p> <p>See the slides (PDF).</p>"},{"location":"1day-20230921/A01_Documentation/","title":"Documentation links","text":"<p>Note that documentation, and especially web based documentation, is very fluid. Links change rapidly and were correct when this page was developed right after the course. However, there is no guarantee that they are still correct when you read this and will only be updated at the next course on the pages of that course.</p> <p>This documentation page is far from complete but bundles a lot of links mentioned during the presentations, and some more.</p>"},{"location":"1day-20230921/A01_Documentation/#web-documentation","title":"Web documentation","text":"<ul> <li> <p>Slurm version 22.05.8, on the system at the time of the course</p> </li> <li> <p>HPE Cray Programming Environment web documentation has only become available in      May 2023 and is a work-in-progress. It does contain a lot of HTML-processed man pages in an easier-to-browse      format than the man pages on the system.</p> <p>The presentations on debugging and profiling tools referred a lot to pages that can be found on this web site.  The manual pages mentioned in those presentations are also in the web documentation and are the easiest way  to access that documentation.</p> </li> <li> <p>Cray PE Github account with whitepapers and some documentation.</p> </li> <li> <p>Cray DSMML - Distributed Symmetric Memory Management Library</p> </li> <li> <p>Cray Library previously provides as TPSL build instructions</p> </li> <li> <p>Clang latest version documentation (Usually for the latest version)</p> <ul> <li> <p>Clang 13.0.0 version (basis for aocc/3.2.0)</p> </li> <li> <p>Clang 14.0.0 version (basis for rocm/5.2.3 and amd/5.2.3)</p> </li> <li> <p>Clang 15.0.0 version (cce/15.0.0 and cce/15.0.1 in 22.12/23.03)</p> </li> </ul> </li> <li> <p>AMD Developer Information</p> <ul> <li> <p>AOCC 4.0 Compiler Options Quick Reference Guide      (Version 4.0 compilers will come when the 23.05 or later CPE release gets installed on LUMI)</p> </li> <li> <p>AOCC 4.0 User Guide</p> </li> </ul> </li> <li> <p>ROCmTM documentation overview</p> <ul> <li> <p>rocminfo application for reporting system info.</p> </li> <li> <p>rocm-smi</p> </li> <li> <p>HIP porting guide</p> </li> <li> <p>ROCm Software Platform GitHub repository</p> </li> <li> <p>Libraries:</p> <ul> <li> <p>BLAS: rocBLAS and hipBLAS</p> </li> <li> <p>FFTs: rocFFT and hipFFT</p> </li> <li> <p>Random number generation: rocRAND</p> </li> <li> <p>Sparse linear algebra: rocSPARSE and hipSPARSE</p> </li> <li> <p>Iterative solvers: rocALUTION</p> </li> <li> <p>Parallel primitives: rocPRIM and hipCUB</p> </li> <li> <p>Machine Learning Libraries: MIOpen (similar to cuDNN),      Tensile (GEMM Autotuner),     RCCL (ROCm analogue of NCCL) and      Horovod (Distributed ML)</p> </li> <li> <p>Machine Learning Frameworks: Tensorflow,     Pytorch and     Caffe</p> </li> <li> <p>Machine Learning Benchmarks:     DeepBench and      MLPerf</p> </li> </ul> </li> <li> <p>Development tools:</p> <ul> <li> <p>rocgdb resources:</p> <ul> <li> <p>AMD documentation</p> </li> <li> <p>2021 presentation by Justin Chang</p> </li> <li> <p>2021 Linux Plumbers Conference presentation     with youTube video with a part of the presentation</p> </li> </ul> </li> <li> <p>rocprof profiler</p> </li> <li> <p>OmniTrace</p> </li> <li> <p>Omniperf</p> </li> </ul> </li> </ul> </li> <li> <p>HDF5 generic documentation</p> </li> </ul>"},{"location":"1day-20230921/A01_Documentation/#man-pages","title":"Man pages","text":"<p>A selection of man pages explicitly mentioned during the course:</p> <ul> <li> <p>Compilers</p> PrgEnv C C++ Fortran PrgEnv-cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> PrgEnv-gnu <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> PrgEnv-aocc/PrgEnv-amd - - - Compiler wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> </li> <li> <p>OpenMP in CCE</p> <ul> <li><code>man intro_openmp</code></li> </ul> </li> <li> <p>OpenACC in CCE</p> <ul> <li><code>man intro_openacc</code></li> </ul> </li> <li> <p>MPI:</p> <ul> <li> <p>MPI itself: <code>man intro_mpi</code> or <code>man mpi</code></p> </li> <li> <p>libfabric: <code>man fabric</code></p> </li> <li> <p>CXI: `man fi_cxi'</p> </li> </ul> </li> <li> <p>LibSci</p> <ul> <li> <p><code>man intro_libsci</code> and <code>man intro_libsci_acc</code></p> </li> <li> <p><code>man intro_blas1</code>,     <code>man intro_blas2</code>,     <code>man intro_blas3</code>,     <code>man intro_cblas</code></p> </li> <li> <p><code>man intro_lapack</code></p> </li> <li> <p><code>man intro_scalapack</code> and <code>man intro_blacs</code></p> </li> <li> <p><code>man intro_irt</code></p> </li> <li> <p><code>man intro_fftw3</code></p> </li> </ul> </li> <li> <p>DSMML - Distributed Symmetric Memory Management Library </p> <ul> <li><code>man intro_dsmml</code></li> </ul> </li> <li> <p>Slurm manual pages are also all on the web      and are easily found by Google, but are usually those for the latest version.</p> <ul> <li> <p><code>man sbatch</code></p> </li> <li> <p><code>man srun</code></p> </li> <li> <p><code>man salloc</code></p> </li> <li> <p><code>man squeue</code></p> </li> <li> <p><code>man scancel</code></p> </li> <li> <p><code>man sinfo</code></p> </li> <li> <p><code>man sstat</code></p> </li> <li> <p><code>man sacct</code></p> </li> <li> <p><code>man scontrol</code></p> </li> </ul> </li> </ul>"},{"location":"1day-20230921/A01_Documentation/#via-the-module-system","title":"Via the module system","text":"<p>Most HPE Cray PE modules contain links to further documentation. Try <code>module help cce</code> etc.</p>"},{"location":"1day-20230921/A01_Documentation/#from-the-commands-themselves","title":"From the commands themselves","text":"PrgEnv C C++ Fortran PrgEnv-cray <code>craycc --help</code> <code>crayCC --help</code> <code>crayftn --help</code> <code>craycc --craype-help</code> <code>crayCC --craype-help</code> <code>crayftn --craype-help</code> PrgEnv-gnu <code>gcc --help</code> <code>g++ --help</code> <code>gfortran --help</code> PrgEnv-aocc <code>clang --help</code> <code>clang++ --help</code> <code>flang --help</code> PrgEnv-amd <code>amdclang --help</code> <code>amdclang++ --help</code> <code>amdflang --help</code> Compiler wrappers <code>cc --help</code> <code>CC --help</code> <code>ftn --help</code> <p>For the PrgEnv-gnu compiler, the <code>--help</code> option only shows a little bit of help information, but mentions further options to get help about specific topics.</p> <p>Further commands that provide extensive help on the command line:</p> <ul> <li><code>rocm-smi --help</code>, even on the login nodes.</li> </ul>"},{"location":"1day-20230921/A01_Documentation/#documentation-of-other-cray-ex-systems","title":"Documentation of other Cray EX systems","text":"<p>Note that these systems may be configured differently, and this especially applies to the scheduler. So not all documentations of those systems applies to LUMI. Yet these web sites do contain a lot of useful information.</p> <ul> <li> <p>Archer2 documentation.      Archer2 is the national supercomputer of the UK, operated by EPCC. It is an AMD CPU-only cluster.     Two important differences with LUMI are that (a) the cluster uses AMD Rome CPUs with groups of 4 instead     of 8 cores sharing L3 cache and (b) the cluster uses Slingshot 10 instead of Slinshot 11 which has its     own bugs and workarounds.</p> <p>It includes a page on cray-python referred to during the course.</p> </li> <li> <p>ORNL Frontier User Guide and      ORNL Crusher Qucik-Start Guide.     Frontier is the first USA exascale cluster and is built up of nodes that are very similar to the     LUMI-G nodes (same CPA and GPUs but a different storage configuration) while Crusher is the     192-node early access system for Frontier. One important difference is the configuration of     the scheduler which has 1 core reserved in each CCD to have a more regular structure than LUMI.</p> </li> <li> <p>KTH Dardel documentation. Dardel is the Swedish \"baby-LUMI\" system.     Its CPU nodes use the AMD Rome CPU instead of AMD Milan, but its GPU nodes are the same as in LUMI.</p> </li> <li> <p>Setonix User Guide.     Setonix is a Cray EX system at Pawsey Supercomputing Centre in Australia. The CPU and GPU compute     nodes are the same as on LUMI.</p> </li> </ul>"},{"location":"1day-20230921/notes_20230921/","title":"Questions session 21 September 2023","text":""},{"location":"1day-20230921/notes_20230921/#lumi-hardware","title":"LUMI Hardware","text":"<ol> <li> <p>When we run <code>sbatch</code> with <code>--cpus-per-node=X</code> are we allocating X cores or X CCDs or X NUMA nodes ...?</p> <ul> <li> <p>You allocate cores (not threads). But admittedly the slurm nomenclature is really confusing.</p> </li> <li> <p>Slurm had threads (hardware threads), cores (physical cores) and CPUs. A CPU is the smallest individually allocatable unit which on LUMI is configured to be the core. Unfortunately Slurm does not fully understand the full hierarchy of a modern cluster which makes it different to request all cores in a single CCD or single NUMA domain.</p> </li> </ul> </li> <li> <p>I have been experiencing very long queueing times recently and have been warned that i am out of storage hours although i have more or less cleaned my output (|I am aware disk space and storage hours are not the same thing) but i am wondering if these long times are related to storage hours</p> <ul> <li>It's not related. Removing files when running out of storage allocation (in TB/hours) does make the TB/hours as each file stored on LUMI will consumes these TB/hours from your allocation as long as it's present on the system. When you delete a file, it will stop being billed but the TB/hours consumed will still be definitively gone.</li> </ul> <p>Thanks, then what is the way to go forward as i have yet only spent 30% of my CPU hours :)</p> <ul> <li>Is your allocation granted by a consortium country or EuroHPC JU?</li> </ul> <p>Consortium country</p> <ul> <li>Contact the resource allocator of your country to request additional TB/hours</li> </ul> <p>Will do so, thanks a lot :)</p> <ul> <li> <p>For the queue time, we are sorry, it's caused by three things:</p> <ol> <li>An oversubscription factor that was way to high</li> <li>Lots of huge jobs in the queue. To start a big job, the scheduler has to collect nodes that in the mean time can only be used for backfill by small jobs but we don't always have enough of those small jobs. So you may note a lot of idle nodes while your job still does not start quickly.</li> <li> <p>A lot of CPU nodes have been down lately which with the large oversubscription factor create long queueing time The oversubscription factor will be reduced next year and the new LUMI-C nodes will be put in production at the end of october. It should improve the situation. Resource allocators have also been asked to not use LUMI-C for extreme scale projects anymore that require running lots of very large jobs (large in terms of node counts)</p> </li> <li> <p>I see, thanks then we need to live with for now :)</p> </li> </ol> </li> </ul> </li> <li> <p>Out of curiosity, if LUMI is a GPU-first system, why offer (what remains a quite large amount of) CPU-only nodes?</p> <ul> <li> <p>I think there are many answers to that question. I guess that some are political, but they idea is also to support heterogenous jobs with some parts of a workflow to run on CPU nodes with others running on GPUs.</p> </li> <li> <p>Additionally, LUMI performance is 2% LUMI-C and 98% LUMI-G.</p> </li> </ul> </li> <li> <p>Same question as 1. What about when we run <code>sbatch</code> with <code>--gpus-per-node=X</code>, what are we allocating?</p> <ul> <li>One GCD, so you can ask for a maximum of 8 per LUMI-G node.</li> </ul> </li> <li> <p>I've been communicated that GPUs process batches of 32 items in 1 cycle on Nvidia (ie. using batch size of 33 first does 32 items in one cycle and 1 item in a separate cycle). Is this the same on AMD? And is this a hardware feature, as one could assume?</p> <ul> <li> <p>AMD compute GPUs use 64-wide wavefronts but there is a catch. In practice, the wavefront will be divided in 4x16 workitems which match the compute units (CUs) architecture that feature 4x16-wide SIMD units. Each of these units are assigned a wavefront. The wavefront once assigned to one SIMD unit will be processed in 4 cycles (16 workitems/cycle). As there is 4 SIMD units per CU, 4 wavefronts can be active at the same time in a CU and the total throughput of a CU can be seen as 1x 64-wide wavefront/cycle/CU.</p> </li> <li> <p>See the documentation for more details about the MI250x GPUs.</p> </li> </ul> </li> <li> <p>How are GPU hours billed on standard-g and on small-g? Is it the number of GPU hours that you request for a job, using the argument #SBATCH --time, or is it the actual GPU usage per job, which is usually less than the requested hours? </p> <ul> <li> <p>For GPU compute, your project is allocated GPU-core-hours that are consumed when running jobs on the GPU nodes https://docs.lumi-supercomputer.eu/runjobs/lumi_env/billing/#gpu-billing</p> </li> <li> <p>For the standard-g partition, where full nodes are allocated, the 4 GPUs modules are billed. For the small-g and dev-g Slurm partitions, where allocation can be done at the level of Graphics Compute Dies (GCD), you will be billed at a 0.5 rate per GCD allocated.</p> </li> </ul> <p>Thanks! I understand this, but if e.g. I request #SBATCH --time=24h and my job fails after 2 hours, am I billed for 24h or for 2h?</p> <ul> <li>You should be billed for 2 hours if your job is killed. Beware that there is a possibility that your job hangs when your job fails and you'd be billed for the time it hangs as well.</li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#programming-environment-modules","title":"Programming Environment &amp; modules","text":"<ol> <li> <p>The slide mentioned the cray-*-ofi for OFI. Do we still need to use the AWS OFI mentioned in some compiling instructions?</p> <ul> <li> <p>Do you mean the AWS OFI plugin for RCCL? That's different for the <code>cray-*-ofi</code> module. The <code>craype-network-ofi</code> is meant to select the Cray MPI network backend. With the Slingshot-11 network only libfabric/OFI is supported. In the past we had Slingshiot-10 interconnects and the <code>craype-network-ucx</code> module can be use to select the UCX backend. It's no longer supported. However, the <code>craype-network-*</code> modules are still useful as it's basically a way to switch MPI on and off in the compiler wrapper:</p> <ul> <li><code>module load craype-network-none</code>: disable MPI</li> <li><code>module load craype-network-ofi</code>: enable MPI</li> </ul> </li> <li> <p>The AWS OFI plugin is a plugin for RCCL (AMD GPU collective communication library, replacement for NVIDIA NCCL). This plugin is used so that RCCL can use the Slingshot-11 interconnect as it does not support it out of the box.</p> </li> </ul> </li> <li> <p>If we need to compile a library with gcc to generate our executables with support for MPI, do we have to load all the corresponding Cray modules or one of the PrgEnvs and the cray MPI module?</p> <ul> <li>Most of the time only loading <code>PrgEnv-gnu</code> is sufficient as the MPI module is loaded by default. The Cray compiler wrapper will automatically link to the correct MPI library for the Programming Environment you selected by loading a <code>PrgEnv-*</code> module.</li> </ul> </li> <li> <p>What does it mean that a module is hidden?, it seems that it would be silently skipped, how we can change that state?</p> <ul> <li>It means that the is not listed in any searches by default because it might have problems or incompatibilities. you can display all modules including the hidden ones by loading the <code>ModulePowerUser/LUMI</code> module.</li> </ul> </li> <li> <p>Do we have a PyTorch module?</p> <ul> <li>Yes, as user installable with EasyBuild (https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/p/PyTorch/) or in CSC software collecion (https://docs.lumi-supercomputer.eu/software/local/csc/)</li> </ul> </li> <li> <p>I just want to point out that the slides of today seem to be inaccessible, as are the ones from previous training days. E.g. https://lumi-supercomputer.github.io/LUMI-training-materials/1day-20230509/ and clicking on any \"slides\" link fails.</p> <ul> <li> <p>Works for me. Both the old and new slides load as expected.</p> </li> <li> <p>I get network errors (PR_CONNECT_RESET_ERROR) in both Firefox and Chrome. Not a big issue in any case.</p> </li> </ul> </li> <li> <p>Same issue as above. Can the slides be hosted somewhere else so that they are accessible to everyone?</p> <ul> <li>You could download it from LUMI with <code>wget</code> and then move to your computer from there.</li> </ul> <p>This worked for me, but accessing it with three different browsers did not work.</p> <ul> <li> <p>I also guess that is something firewall related but weird that you can access lumi via ssh but not LUMI-O.</p> </li> <li> <p>I read that some browser extensions and some proxies can also cause this problem. Most of these connection problems are actually not caused by the server (LUMI-O for the slides and recordings) but somewhere else between the server and your browser or the browser itself. It's a bit weird, we've been using LUMI-O as the source for big files for a while now and never got complaints or tickets.</p> <p>Sysadmins did note some random problems with LUMI-O recently and are investigating, it may or may not be related to that also. But I (KL) have been pushing lots of data to and pulling lots of data from LUMI-O in the past days from different computers and browsers while preparing this course and the upcoming 4-day course without issues.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#lumi-software-stacks","title":"LUMI Software Stacks","text":"<ol> <li> <p>What is the difference between <code>lumi-container-wrapper/cotainr</code> and Singularity containers?</p> <ul> <li>Both our tools use singularity in the background but help you with creating the containers, so you don't have to build the container yourself.</li> </ul> </li> <li> <p>Let's say I want to build PyTorch (with GPU support of course). Am I understanding correctly that I should load PrgEnv-amd?</p> <ul> <li> <p>Both <code>PrgEnv-amd</code>, <code>-cray</code> and <code>-gnu</code> work with <code>rocm</code> which GPU enabled codes rely on. Basically first two environmnents give you Clang/LLVM based compilers. I doubt PyTorch requires Clang as a host compiler to be compiled for AMD GPUs.</p> </li> <li> <p>For PyTorch the way to go is to use GNU for the host (CPU) compilation in conjunction with the <code>rocm</code> module to have access to <code>hipcc</code> for GPU code compilation. Compiling PyTorch with <code>PrgEnv-cray</code> or <code>PrgEnv-amd</code> is likely to fail due to some packages using intel flavoured inline assembly that is not supported by Clang based compilers.</p> <ul> <li>Okay. Got it. But the latest rocm module available is 5.3.3 that is very old (current that is VERY new is 5.7.0). Do I need to compile my own rocm also?</li> </ul> </li> <li> <p>ROCm version is related to AMD GPU driver version. With current SLES kernel version Cray OS is based on, ROCm versions &gt; 5.4 are not supported, unfortunately.      A major system update with new AMD GPU driver will be at the end of the year at the earliest.</p> </li> <li> <p>You can try other ROCm versions in containers. It does turn out that some newer versions work for some users even with the current driver. E.g., one of our AMD support people has used PyTorch with ROCm 5.5 in a container. The problem with newer ROCm versions is that (a) they are based around gcc 12 and the gcc 12 on the system is broken so we cannot fully support it and (b) ROCm libraries are also used by, e.g., GPU-aware MPICH and newer versions cause problems with cray-mpich. </p> <p>Recent ROCm versions show improvements in particular in the support libraries for AI so I can understand why as a user of PyTorch or Tensorflow you'd like a newer version.</p> <p>We realise many users are frustrated by this. The problem is that installing ROCm on a supercomputer is not as simple as it is on a workstation. On LUMI, it triggers a chain of events. We need a newer GPU driver. That in turn needs a newer OS kernel. However, software on a supercomputer is managed through a management environment and that management environment needs an update also to support that newer kernel. So at the end updating ROCm requires updating the full software stack on LUMI and likely a week or more of downtime, and extensive testing before starting the process. There are only a few systems like LUMI in the world which also implies that the installation procedures are not thoroughly tested and that whenever a big update of LUMI is done, problems show up. Nowadays we have a test system to detect most of the problems before they are actually rolled out on the big systems, but in the early days we didn't and the first big update which was scheduled to take 3 weeks took 7 weeks in the end due to problems... So I hope you can understand why a big machine as LUMI is not the best environment if you want the very latest... It is only a pity that there is no second smaller development machine on which we could take more risks as it wouldn't matter as much if that one would be down for a few weeks.</p> </li> <li> <p>Our AMD support person has also been building a properly set up container for PyTorch. I'd have to check in the LUMI documentation where to find it but that may be a more easy way. Compiling PyTorch can be tricky.</p> </li> </ul> </li> <li> <p>Regarding the long queue times i ve asked in question 2, would using the small nodes instead of the standard nodes help as some of the runs are literally taking only 2 minutes to run, which prepare the model for the actual production run that should be run in standard nodes?</p> <ul> <li>It may or may not and the answer is time-dependent. They are scheduled fairly independently. There was actually a mail after the last downtime to users to ask to use small/small-g more for jobs that can run in that partition. I'd have to check what the partition sizes are today, but the sysadmins at some point also moved some nodes from small to standard to try to balance the waiting times more. If those 2-minute jobs are also very small in node count (which I assume as you want to run them in small) and if the time you request is then also very low (like 10 minutes or so to be sure), they are ideal as backfill though and may start quickly on standard/standard-g actually and actually only use time that would otherwise been wasted. I've been rather successful with that strategy when preparing this and another course I am teaching about LUMI ;-) Sometimes my waiting times on standard/standard-g also became longer, and I assume an overloaded scheduler was partly to blame.</li> </ul> <p>So instead of asking standard with 48 hours request, asking small with say 1 hour (or smaller?) does not really change? another reason i use standard is because the model runs hardcored with 88 CPUs whether or not it is a preperation run or a production run.</p> <ul> <li> <p>The element that really matters if you want your job to start quickly, is to be realistic with the time your request. If you know that it is something that finishes quickly, don't request the maximum allowed time. On standard and standard-g there is usually quite some room to run programs as backfill. The scheduler will schedule lower priority jobs on idle nodes that it is saving for a big job if it knows that that job will have finished before it expects to have collected enough nodes for that big highest priority job. If you always request the maximum wall time even if you know that it will not be needed, the job will never be used as backfill. But if you know a job will end in 5 minutes and then only request like, say, 10 minutes to have some safety margin, there is a high chance that the scheduler will select it to fill up holes in the machine. Nothing worse for a scheduler than all users just requesting the default maximum wall time rather than a realistic walltime as then it has no room to play with to fill up gaps in the machine.</p> </li> <li> <p>And there is even another element to be realistic with wall times. There are ways in which a job can crash where the scheduler fails to detect that the job has terminated and so keeps the allocation. It looks like in particular on LUMI some MPI crashes can remain undetected, probably because MPI fails to kill all processes involved. You will then be billed for the whole time that the job keeps the allocation, not for the time before it crashed. </p> </li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#exercise-session-1","title":"Exercise session 1","text":"<p>/</p>"},{"location":"1day-20230921/notes_20230921/#running-jobs","title":"Running jobs","text":"<ol> <li> <p>Why does the <code>small</code> partition allow to allocate 256G memory per node while <code>debug</code> allows only 224G?</p> <ul> <li>It's because the high-memory nodes (512GB and 1TB) are in the <code>small</code> partition. Standard nodes in both <code>small</code> and <code>debug</code> have the same amount of memory available (224GB). If you go above that in the <code>small</code> partition, you will get an allocation on one of the high-memory nodes instead of a a standard one. Note that if you go above 2GB/cores you will be billed for this extra memory usage. See here for details of the billing policy.</li> </ul> <p>I see, thanks. So from this I understand that when I request <code>--partition=small; --mem=256G;</code>, the job will not be assigned to a standard node. Only high-memory nodes will be available. It is not made clear on CPU nodes - LUMI-C that not all of the memory can be allocated. I assumed that I can request all 256G from a standard node.</p> <ul> <li>It's explained here but you are right it's not stated in the hardware section. The reason is that in reality, the node actually have 256GB of memory but part of it is reserved for the operating system. LUMI nodes are diskless, so we have to reserve quite a big chunk of the memory to make sure the OS has enough space.</li> </ul> <p>How much memory can be allocated on 512G and 1TB nodes?</p> <ul> <li>On all nodes of LUMI it is the physcial amount of RAM minus 32 GB (480 GB and 992 GB). For the LUMI-G nodes: 512 GB installed, 480 GB available.</li> </ul> </li> <li> <p>Is the <code>--mail-user</code> functionality already working for LUMI slurm jobs? It is working on our national clusters, but so far hasn't worked for me on LUMI (with <code>--mail-type=all</code>)</p> <ul> <li>Unfortunately, it's not active. The LUMI User Support Team has raised the issue multiple times (since the start of the LUMI-C pilot actually) but sysadmins never made the necessary configuration. I understand it can be frustrating for users as it's a very basic feature that should be working.</li> </ul> </li> <li> <p>Does <code>--ntasks=X</code>  signify the number of <code>srun</code> calls, i.e. number of steps in a job?</p> <ul> <li> <p>No. It is used inside <code>srun</code>. <code>srun</code> creates one job step with multiple tasks, each task basically being a copy of a process that is started. It is possible though to ask sbatch for, e.g, 5 tasks with 4 cores each, and then use multiple <code>srun</code> commands with each <code>srun</code> asking to create 1 task with 4 cores. Unfortunately we do see problems with network configurations when trying to run multiple job steps with multple <code>srun</code> commands simultaneously (by starting them in the background with an &amp; and then waiting untill all have ended).</p> <p>You would use <code>--ntasks=X</code>, e.g., to start an MPI job with X ranks.</p> </li> </ul> <p>I am confused when you could define, say <code>--ntasks=8</code> and <code>--cpus-per-task=2</code>. Are we then allocating 16 cores or 8 cores?</p> <ul> <li>16 cores. Each task can then use 2 cores which would be the case for a hybrid MPI/OpenMP job. It would also guarantee that these cores are in groups of 2,     because on <code>small</code> you would have no guarantee that all cores are on a single node. It may instead use cores from several nodes.</li> </ul> </li> <li> <p>I just want to comment on the question on <code>--mail-user</code>. In Norway, on the Saga HPC cluster it was used until a user directed the emails from a large array to the helpdesk of Saga, that filled the helpdesk server. Then it was decided to stop the functionality. </p> <ul> <li> <p>Even without users redirecting them to the help desk there are potential problems. Not that much on LUMI as we have a very low limit on the number of jobs, but no mail administrators would be happy with a user running a large array job on the cluster as each job in the array is a separate job and would send a mail. Imagine a user doing throughput computing and starting a few 1000s of jobs in a short time.... It might actually lead to mail systems thinking they're being spammed.</p> <p>Another problem is failures of the receiver etc.</p> <p>And another problem on LUMI is what to do if no mail user is given in the job script. Due to the way user accounts are created on LUMI (there are several channels) it is not as easy as on some university systems to link a mail address to a userID.</p> </li> </ul> </li> <li> <p>There was a comment that using <code>--gpus-per-task</code> was tricky. Perhaps I missed it, what was the pitfall of using it?</p> <ul> <li> <p>The problem is the way in which Slurm does GPU binding which is not compatible with GPU-aware MPI. I'm not sure how technical you are and hence if you can understand my answer, but let's try.</p> <p>For CPUs Linux has two mechanisms to limit access to cores by a process or threads. One is so-called control groups and another one is affinity masks. Control groups really limit what a process can see and Slurm uses it at the job step level with one control group shared by all tasks in a job step on a node. That means that the tasks (processes) on a node can, e.g., share memory, which is used to communicate through memory. At the task/process level affinity masks are used which do not block sharing memory etc.</p> <p>For GPU binding there are also two mechanisms. One is a Linux mechanism, again the control groups. The other one is via the ROCm runtime via the ROCR_VISIBLE_DEVICES mentioned during the presentation. You can compare this a little bit with affinity masks except that it is not OS-controlled and hence can be overwritten. The problem with <code>--gpus-per-task</code> is that Slurm uses both mechanisms and uses them both at the task level. The consequence is that two tasks cannot see each others memory and that hence communication via shared GPU memory is no longer possible. The funny thing is that Slurm will actually still set ROCR_VISIBLE_DEVICES also in some cases. So it is basically a bug or feature in the way Slurm works with AMD GPUs. It should use control groups only at the job step level, not at the task level, and then things could work.</p> </li> </ul> <p>I don't use MPI, I only have ML applications in Python. Is this still a relevant problem?</p> <ul> <li>Yes, if you have multiple tasks. I gave MPI as the example but it holds for all communication mechanisms that go via shared memory for efficiency. RCCL for instance will also be affected. If you have something with <code>--ntasks=1</code> it should not matter though.</li> </ul> </li> <li> <p>I am using <code>torch.distributed.run()</code> for starting my multi-GPU computation. I provide <code>--ntasks=1</code> (I use only single node). Then as a parameter to <code>torch.distributed.run</code>, I give <code>--nproc_per_node=#NUM_GPUS</code>. AFAIK, the torch.distributed.run then starts #NUM_GPUS processes. Does this cause binding problems? If so, can I somehow provide a custom mapping for this setup?</p> <ul> <li> <p>Torch will have to do the binding itself if it starts the processes. Our PyTorch expert is not in the call though, I'm not sure about the right answer. </p> <p>Does it start #NUM_GPUS processes because it has that many GPUs or because it has that many cores? If it is the former I would actually consider to give Torch access to all CPU cores. </p> <p>I suspect Torch could benefit from a proper mapping, not only a proper mapping of CPU-to-GPU but also even a correct ordering of the GPUs. I understand that RCCL often communicates in a ring fashion so it would be usefull to exploit the fact that there are rings hidden in the topology of the node. But I don't think that anybody in our team has ever experimented with that.</p> </li> </ul> <p>One process per GPU. Thanks! Something that I will have to look into..</p> </li> <li> <p>What does the numbers in <code>srun --cpu-bind</code> option represent <code>fe00</code> etc?</p> <ul> <li>These are hexadecimal numbers where each bit represents a core (actually hardware thread to be precise) with the lowest order bit representing core 0. So for <code>fe00</code>: do not use core 0-7 (the last two 0's, so 8 zero bits), then the e corresponds to the bit pattern <code>1110</code> so do not use core 8 but use core 9, 10 and 11, and <code>f</code> corresponds to the bit pattern <code>1111</code> which is then use cores 12, 13, 14 and 15. So effectively: this concrete example means use CCD 1 (they are numbered from 0) except for the first core of that CCD which cannot be used because it is set aside for the OS and not available to Slurm.</li> </ul> </li> <li> <p>Adding to the previous question: would this specific example cpu binding scheme also work for jobs on the small-g partition?</p> <ul> <li>Only if you request the whole node with <code>--exclusive</code>. Manual binding is only possible if you have access to the full node as otherwise you cannot know which subset of cores is assigned to your application, and as currently Slurm is not capable to make sure that you get a reasonable set of cores and matching GPUs on the small-g partition. Which is one of the reasons why the <code>small-g</code> partition is so small: It is not a very good way to work with the GPUs.</li> </ul> </li> <li> <p>To which Numa domain I should bind which GCD? I remember it was not Numa domain 0 to GCD 0, etc.</p> <ul> <li>Good question. There are examples of valid masks in the GPU examples in the LUMI documentation but that is not the clearest way to present things. There is a graphical view on the GPU nodes page in the LUMI documentation. I've put the information in tabular form in the notes I made for my presentations.</li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#exercises-2","title":"Exercises 2","text":"<ol> <li> <p>Will we get some information today on how to (in practice) profile (and afterwards, improve) existing code for use on LUMI? </p> <ul> <li> <p>No. Profiling is a big topic on our 4-day courses that we have two or three times a year. However, if you have a userid on LUMI you have access to recordings of previous presentations. Check material from the course in Tallinn in June 2023 and we'll soon have new material after the course in Warsaw in two weeks. That course is on October 3-6 but I'm not sure if it is still possible to join. On-site is full I believe and online is also pretty full.</p> <p>There is also some material from a profiling course in April 2023 but especially the HPE part there was a bit more \"phylosophical\" discussing how to intepret data from profiles and how to use that to improve your application.</p> </li> </ul> <p>Thank you very much, that material will be very useful!</p> <ul> <li>If you are interested in GPU profiling there are also some examples on Rocprof and Omnitrace here https://hackmd.io/@gmarkoma/lumi_training_ee#Rocprof (it is a part of materials from course in Tallin).</li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#introduction-to-lustre","title":"Introduction to Lustre","text":"<ol> <li> <p>What is the default striping behaviour if we write a file without calling <code>lfs setstripe</code>?</p> <ul> <li> <p>By default only a single OST will be used. This is to avoid problems with users who don't understand LUSTRE and create lots of small files. The more OSTs a file is spread over, the more servers the metadata server has to talk to when opening and closing a file, and if these are not used anyway this is a waste of resources. It may not seem logical though on a system that is built for large applications and large files...</p> <p>However, I'm sure there are plenty of people in the course who in practice dump a dataset on LUMI as thousands of 100 kB files and refuse to do the effort to use a structured file format to host the whole dataset in a single file. And then there are those Conda installations with 100k small files.</p> </li> </ul> </li> <li> <p>Does striping matter only if I/O is the bottleneck?</p> <ul> <li>Mostly. But then we have users who write files that are literally 100s of GB and then it really matters. One user has reported 50 GB/s on LUMI P after optimising the striping for the file...</li> </ul> </li> <li> <p>I just checked. My python venv seems to contain ~6k files. Did not know about the possibility to containerize it before today. Is it worth doing in this case, or if not, how many files should I have before containerizing?</p> <ul> <li> <p>It's hard to put a hard number on it as it also depends on how the files are used. We tend to consider 6k as still acceptable though it is a lot.  It also depends on how you use them. If you run jobs that would start that Python process on 100's of cores simultaneously it is of course a bigger problem than if you have only one instance of Python running at a time.</p> <p>But as a reference: HPE Cray during the course mentions that one LUMI-P file system is capable of probably 200k metadata operations per second which is not much and surprising little if you compare that to what you can do on a local SSD in a laptop. IOPS don't scale well when you try to build larger storage systems.</p> <p>If your venv works well with lumi-container-wrapper it may not be much work though to test if it is worth trying.</p> </li> <li> <p>It is also not just a LUMI thing but a problem on all large supercomputers. When I worked on a PRACE project on a cluster at BSC,     I had a Python installation that took 30 minutes to install on the parallel file system but installed in 10s or so on my laptop...</p> </li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#lumi-support","title":"LUMI support","text":"<ol> <li> <p>Does LUMI support Jupyter notebooks or has a Jupyter hub? As one of the task of my project is to create catalogs / jupyter notebooks for the data generated in the project.</p> <ul> <li> <p>No official support but we know that users have gotten notebooks to work. Something will come with Open OnDemand but not date set yet for availability of that. After all, LUMI is in the first place a system to process large batch jobs and not a system for interactive work or workstation replacement, so it does not have a high priority for us.</p> </li> <li> <p>Since the data cannot stay on LUMI after your project - LUMI is not a data archive solution - I wonder if LUMI is even the ideal machine to develop those notebooks or if that should be done with the machine where the data will ultimately land on?</p> </li> <li> <p>And if the data is really important to you: Please be aware that there are no backups on LUMI!</p> </li> </ul> </li> <li> <p>Does LUMI has interactive nodes through VNC (as in the exercise) to use the visualization nodes interactively?</p> <ul> <li> <p>VNC is available through the lumi-vnc module which contains help about how it works. But otherwise the visualisation nodes are still pretty broken, not sure if vgl-run actually works. As for the previous question, it is not a very high priority at the moment, not for LUST and not for CSC who has to do much of the basic setup. Support should improve when Open OnDemand becomes available which is being worked on by CSC.</p> <p>Light VNC sessions can run on the login nodes, but you can always start an interactive job on a compute node, start VNC there and the <code>start-vnc</code> script will actually tell you how you can connect to the VNC server from outside using either a VNC client (the server is TurboVNC) or via a web browser (less efficient though for heavy graphics).</p> </li> </ul> </li> <li> <p>Are the tickets publicly viewable? Is there any plan to add some public issue tracker system? We have something like this on our local cluster, and it's quite nice for seeing what the current problems are and what is being done about them.</p> <ul> <li>There are no such plans at the moment. Security and privacy are big issues. And since LUMI accounts come onto the system via so many ways organising login is also not easy as we have to interface with multiple IdM systems. We do have a status page at https://www.lumi-supercomputer.eu/lumi-service-status/ but that one is also limited.</li> </ul> </li> </ol>"},{"location":"1day-20230921/notes_20230921/#general-qa","title":"General Q&amp;A","text":"<ol> <li> <p>One question regarding SLURM job scripts: on our clusters, I am using the command <code>seff $SLURM_JOBID</code> at the end of the file to get output on the consumed resources. But I think <code>seff</code> is not available on LUMI?</p> <ul> <li> <p>It is not on LUMI. It is actually an optional command and not part of core Slurm. We've tested <code>seff</code> and it turns out that the numbers that it produces on LUMI are wrong because it doesn't deal correctly with the way we do hyperthreading and report about that in the Slurm database.</p> <p>If you really want to try: seff in the LUMI Software Library but don't send us tickets about the wrong output. We know the output is wrong in most cases.</p> </li> </ul> </li> </ol>"},{"location":"1day-20230921/schedule/","title":"Schedule (tentative)","text":"09:00 CEST\u00a0\u00a0             10:00 EEST              Welcome and introduction             Presenter: J\u00f8rn Dietze (LUST)              09:10 CEST             10:10 EEST              LUMI Architecture             Presenter: Kurt Lust              09:40 CEST             10:40 EEST              HPE Cray Programming Environment             Presenter: Kurt Lust              10:10 CEST             11:10 EEST              Modules on LUMI             Presenter: Kurt Lust              10:45 CEST             11:45 EEST Break              11:00 CEST             12:00 EEST              LUMI Software Stacks             Presenter: Kurt Lust              11:45 CEST             12:45 EEST              Hands-on             Exercise assignments and solutions              12:15 CEST             13:15 EEST Lunch break              13:15 CEST             14:15 EEST              Running jobs on LUMI             Presenter: Maciej Szpindler              14:45 CEST             15:4 EEST              Hands-on             Exercise assignments and solutions              15:15 CEST             16:15 EEST Break              15:30 CEST             16:30 EEST              Introduction to Lustre and Best Practices             Presenter: J\u00f8rn Dietze              15:50 CEST             16:50 EEST              LUMI User Support             Presenter: J\u00f8rn Dietze              16:15 CEST             17:15 EEST General Q&amp;A              16:30 CEST             17:30 EEST Course end"},{"location":"1day-20230921/video_00_Introduction/","title":"Welcome and introduction","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p>"},{"location":"1day-20230921/video_01_LUMI_Architecture/","title":"LUMI Architecture","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230921/video_02_HPE_Cray_Programming_Environment/","title":"HPE Cray Programming Environment","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230921/video_03_Modules_on_LUMI/","title":"Modules on LUMI","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230921/video_04_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"1day-20230921/video_06_Running_Jobs_on_LUMI/","title":"Running Jobs on LUMI","text":"<p>Presenter: Maciej Szpindler (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"1day-20230921/video_08_Introduction_to_Lustre_and_Best_Practices/","title":"Introduction to Lustre and Best Practices","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"1day-20230921/video_09_LUMI_User_Support/","title":"LUMI User Support","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"4day-20230214/","title":"Comprehensive General LUMI Training, February 14-17, 2023","text":""},{"location":"4day-20230214/#course-organisation","title":"Course organisation","text":"<ul> <li> <p>Course schedule</p> <p>The full filename for the slides and the video recording of each presentation is also mentioned in that table,  if that file is only available on LUMI.</p> </li> <li> <p>HedgeDoc for questions</p> </li> </ul>"},{"location":"4day-20230214/#downloads","title":"Downloads","text":"<ul> <li>Slides presentation \"LUMI Software Stacks\"      (but you may prefer reading the notes)</li> <li>Slides AMD:<ul> <li>Introduction to the AMD ROCmTM Ecosystem</li> <li>AMD Debugger: ROCgdb</li> <li>Introduction to Rocporf Profiling Tool</li> <li>Introduction to OmniTools</li> </ul> </li> <li>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but      a browser application. Some browsers nowadays offer the option to install it on your     system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</li> </ul>"},{"location":"4day-20230214/#videos","title":"Videos","text":"<ul> <li>Welcome and introduction</li> <li>Additional software on LUMI</li> <li>LUMI support and LUMI documentation</li> </ul>"},{"location":"4day-20230214/#other-material-only-available-on-lumi","title":"Other material only available on LUMI","text":"<p>The following materials are available to members of the <code>project_465000388</code> project only:</p> <ul> <li>Slides of presentations given by HPE people are in     <code>/project/project_465000388/slides/HPE</code> on LUMI</li> <li>Exercises from the HPE sessions are in     <code>/project/project_465000388/exercises/HPE</code> on LUMI</li> </ul>"},{"location":"4day-20230214/#notes","title":"Notes","text":"<ul> <li> <p>Notes from the HedgeDOC pages:</p> <ul> <li>Day 1</li> <li>Day 2</li> <li>Day 3</li> <li>Day 4</li> </ul> <p>Published with delay.</p> </li> <li> <p>Notes on the presentation \"LUMI Software Stacks\"</p> </li> <li> <p>Additional notes and exercises from the AMD session (External link!)</p> </li> </ul>"},{"location":"4day-20230214/#exercises","title":"Exercises","text":"<p>Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:</p> <ul> <li>OSU benchmark</li> <li>Fortran OpenACC examples</li> <li>Fortran OpenMP examples</li> <li>Collections of examples in BabelStream</li> <li>hello_jobstep example</li> <li>Run OpenMP example in the HPE Suport Center</li> <li>ROCm HIP examples</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day1/","title":"Notes from the HedgeDoc page - day 1","text":"<p>These are the notes from the LUMI training, 1114-17.02.2023, 9:00--17:30 (CET) on Zoom.</p> <ul> <li>Day 1: This page</li> <li>Day 2</li> <li>Day 3</li> <li>Day 4</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day1/#other-questions-regarding-organisation-or-lumi-in-general","title":"Other questions regarding organisation or LUMI in general","text":"<ol> <li> <p>I managed to log onto Lumi, but after a few minutes everything \"freezes\" and I have to use a different terminal to log in again: is it normal? That already happened several times since this morning, even using different login nodes).</p> <ul> <li>It depends. If it freezes forever than it may be your terminal application or unstable connection. Shorter freezes that can still last 30 seconds or more are currently unfortunately a common problem on LUMI and caused by file system issues for which the technicians still haven't found a proper solution. There's only two of the four login nodes operating at the moment I think (one down for repair and one crashed yesterday evening and is not up again yet, at least not when I checked half an hour ago) the load on the login nodes is also a bit higher than usual.<ul> <li>uan02 seems to work a bit better</li> </ul> </li> </ul> </li> <li> <p>Will we find material in the /scratch/project_465000388 folder?</p> <ul> <li>The location of the files will be posted on here and later appear in https://lumi-supercomputer.github.io/LUMI-training-materials/4day-20230214/schedule/</li> </ul> </li> <li> <p>Is LUMI up? I am not able to connect at all.</p> <ul> <li>One of the login nodes has crashed but is unfortunately still in lumi.csc.fi. Try lumi-uan01.csc.fi or lumi-uan02.csc.fi.</li> </ul> </li> <li> <p>Is LUMI planning to introduce MFA at some point in the near future?</p> <ul> <li>No such plans for ssh so far, it is already complicated enough and we already have enough \"connot log on tickets\"... But identity providers may require it independently of LUMI when you log in to MyAccessID.</li> </ul> </li> <li> <p>I read about a Lumi partition for \"visualization\", with Nvidia GPUs, is that meant for instance to use Jupyter notebooks?</p> <ul> <li>That service will be offered later via Open OnDemand. No date set yet, but hopefully before the summer. The nodes have only just become available and still need to be set up. Be aware though that you have to use Jupyter in a proper way or other people can break into your account via Jupyter, and that it is not meant for large amounts of interactive work, but to offer an interface to prepare batch jobs that you can then launch to the cluster. LUMI-G is the most important part of the LUMI investment so it is only normal that getting that partition working properly has the highest priority.<ul> <li>That makes perfect sense</li> <li>Looking forward to it</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#introduction-to-hpe-cray-hardware-and-programming-environment","title":"Introduction to HPE Cray Hardware and Programming Environment","text":"<ol> <li> <p>Once a job starts on a particular node, can we get direct access to this node (I mean while the job is running, can we interact with it, for monitoring purposes for example)?</p> <ul> <li>https://docs.lumi-supercomputer.eu/runjobs/scheduled-jobs/interactive/</li> <li>See the sessions on Slurm. Currently only with <code>srun</code>, not with <code>ssh</code>, as <code>srun</code> is the only command that can guarantee your session would end up in the CPU sets of your job.</li> </ul> </li> <li> <p>Why was LUSTRE chosen as the FileSystem? What others were considered?</p> <ul> <li>Almost all really big clusters run Lustre. Spectrum Scale is very expensive and BeeGFS probably doesn't have the maturity for such a cluster. And it is actually not a choice of CSC but a choice made by vendors when answering the tender. HPE Cray only offers Lustre on clusters the size of LUMI, with their own storage system which is actually a beautiful design.</li> <li>There is an ongoing discussion in the supercomputing community whether the whole concept of a global parallel file system will work in the future. There might be a scale, when it simply does not work any longer.</li> <li>I agree. And it is part of the reason why the main parallel file system is split in four. But there is currently no other affordable and sufficiently scalable technology that can also run on affordable hardware. I know a flash based technology that claims to scale better, but just the hardware cost would be 10 times the hardware cost of the current main storage. There is a reason why we bill storage on the flash file system at ten times the rate of the disk based storage, as that is also the price difference of the system. And HPE is working on local buffers that are rumoured to be used in El Capitan, but even that is still a system that integrates with Lustre. Google for \"Rabbit storage HPE\" or something like that.</li> </ul> </li> <li> <p>Can you use MPI MPMD to run one program on LUMI-C and another on LUMI-G including communication between the two programs?</p> <ul> <li>Yes, it is possible, but not so well tested yet. We are interested in your experiences if you try this!     There is a known problem with the scheduler if you do this across partitions though. In trying to make life easier for \"basic\" users a decision was taken that makes MPMD more difficult. So the LUMI-C + LUMI-G scenario is currently difficult basically because those jobs have difficulties getting scheduled.<ul> <li>That's too bad. Are there plans to improve it?</li> </ul> </li> <li>If you can convince the sysadmins and technical responsible of the project... It would mean that every user has to change the way they work with LUMI so I'm afraid it is rather unlikely and will require a lot of discussion. I'm in favour though as this is also the model EuroHPC promotes via the DEEP series of projects.<ul> <li>Indeed and it is one of the advantages of having two or more separate partitions.</li> </ul> </li> <li>If you look at the EuroHPC supercomputers, they are all designed with different specialised partitions. The problem is probably that a select group of researchers and compute centres directly involved in the projects that explored this design are very aware of this but many other centres or in the case of LUMI also other groups involved in the decision process on scheduler policies are not enough aware of this way of designing applications. We do see it used by climate scientists already with codes where simulation, I/O and in-situ visualisation are collaborating but different programs, but I'm only aware of one project which asked this for LUMI-C and LUMI-G so my answer is based on what the technical responsible of the LUMI project answered about the problems that can be expected.<ul> <li>Ok. Thanks alot for the answers. I will try it in the near future so perhaps you will see another request soon :) In my case it is for multiscale molecular dynamics simulations (computational chemistry).</li> </ul> </li> <li>I've added the request to the items to be discussed with sysadmins and technical responsibles of the project.<ul> <li>Thanks!</li> </ul> </li> </ul> </li> <li> <p>Is there any difference between Trento and Milan that the user should care about?</p> <ul> <li>The only difference I know is the link to the GPUs. From the ISA point-of-view they are the same.</li> <li>The main difference seems to be in the I/O die as now all 128 lanes coming out of the chip support xGNI/Infinity Fabric rather than only 64 of them while the other 64 only supported PCIe. I wouldn't expect much more changes as this is a really low production part, only used in HPE Cray systems with MI250x.</li> </ul> </li> <li> <p>Is it possible to use RStudio Server (for interactive programming with R) on LUMI (probably as a singularity container)?</p> <ul> <li>Singularity is installed, so if you have a container, it should run.</li> <li>It might also come in Open OnDemand, a service that is still under development, but in that case it might be more to simply prepare data for a job that would then be launched or to postprocess data. </li> </ul> </li> <li> <p>When will be the recordings available?</p> <ul> <li>Some days after the course. We don't have a pipeline yet to upload them immediately after the training.</li> <li>It takes some postprocessing and this requires time. We are all busy with the course so this is basically evening work and work for after the course. The place where they are stored will be announced in https://lumi-supercomputer.github.io/LUMI-training-materials/4day-20230214/schedule/</li> </ul> </li> <li> <p>It seems that the On Demand service will provide things like Rstudio, Jupyter, etc. but most users do not need the \"basic\" Rstudio or Jupyter but a lot of various packages with them: how will that be managed?</p> <ul> <li>Not clear as we don't have the personpower to install everything for everybody so we focus on the main components that have a lot of users. I guess local support teams will have to develop containers that we can then fit in the setup. <ul> <li>Will this On Demand service allow users to run their own containers with all they need inside? (because nobody really uses bare Jupyter or Rstudio, do they?)</li> </ul> </li> <li>We cannot answer these questions yet as the service is not being set up by us but offered by one of the LUMI partners (in this case CSC) who will do the main setup.  </li> </ul> </li> <li> <p>What is the typical daily KWh of LUMI?</p> <ul> <li>It has rarely run at full load I think but from what I remember its design power is around 6 MW.</li> </ul> </li> <li> <p>Is there a way for users to get accurate figures about the actual electrical power consumption of particular jobs, on CPUs</p> <ul> <li>Not at the moment and I doubt this will appear soon. It is also largely impossible as measurements are on the node level so it doesn't make sense for shared nodes. And on exclusive nodes you only get data for the node as a whole, so if you use only one core you'd likely still see 80W or 100W basically because of all the power consumed by the I/O die and network interface, even wehn idle.<ul> <li>even at that level electrical consumption information would be useful, to compare several simulations, etc.</li> </ul> </li> <li>I don't know what your experiences are with it, but I have used it on one PRACE cluster and the results were totally worthless as a comparison as there was too much background power consumption. So I don't think this has a high level of priority for LUMI. Profiling an application and getting an idea of how well it uses the cache hierarhcy and how much bandwidth it requires to memory would be a much better comparison. But unfortunately even that is limited on LUMI at the moment I believe. Hardware counter monitoring by users had to be turned off due to security problems in the Linux kernel.</li> <li>I was thinking about comparisons between a single run on Lumi using thousands of CPUs vs. a similar run on a smaller machine with less CPUs during a longer time</li> <li>I hope you realise how much power is consumed by, e.g., the network? Every switch blade in LUMI actually has a power consumption of up to 250W (and is therefore also water cooled), about as much as a processor socket, so any measurement would still have a very large error margin. And in fact, the answer is obvious. The run wil less CPUs on a smaller cluster will always consume less assuming the cluster has a similar design with respect to efficiency, as with more CPUs for the same problem you always loose parallel efficiency and as the bigger the network becomes the more power you consume. The latter is also nicely shown in the Green500 list, You'll see there bunches of similar machines together with the smaller one always on top since the network power is less. Which is whey the Frontier TDS (which is not Frontier but just its test system) is in that list ahead of Adastra, Frontier itself and LUMI even though these are all systems with the same design. I guess the reason why Frontier is above LUMI in that list is probably because they seemed to have access to a different version of some software for their Top500 run as they also get better scalability than LUMI despite using the same node and network design.</li> </ul> </li> <li> <p>Is see that there are plans for a Container Orchestration Platform - LUMI-K. What will be the purpose of this partition?</p> <ul> <li>It will likely never appear due to lack of personpower to implement the service. The idea was to have a platform for microservices (the Galaxy's etc. of this world)</li> </ul> </li> <li> <p>What is the average waiting time until a SLURM job get submitted to LUMI [I understand this may vary depeding on the requested RAM/time/etc, but I mean is it a matter of hours or days...]? How the priority of jobs is determined?</p> <ul> <li>Generally speaking, LUMI, like many HPC clusters, is optimized for throughput and not short waiting times. It is not really meant for \"interactive\" use like this. That being said, there are special queues for short interactive jobs and debugging, where the waiting time is short, but you cannot run large jobs there.</li> <li>We don't know ourselves what goes in the priority system. Currently the waiting time is often very low but that will change when LUMI becomes used a lot more.</li> <li>The maximum walltime in the standard queue is 2 days, meaning that if your job has top priority (for example, if you have run very little in your project), it will start within 2 days. It will often be a lot faster than that.<ul> <li>Is it possible to have walltime more than 2 days for specific jobs expected to need more time?<ul> <li>Unfortunately not. You have to use so-called \"checkpointing\", i.e. saving intermediate results to disk, so that your job can be restarted. Even if you have a lot of data in RAM, this should be possible to do using e.g. flash file system. Also given the general instability seen on LUMI now, it is not advisble to try to run very long jobs, hardware may break... This is not necessarily a \"fault\" in the LUMI design, as clusters grow larger, with many components, some nodes in your jobs will eventually fail if you run e.g. a 1000-node job.</li> <li>LUMI is meant for scalable applications. Also on big clusters you can expect a lot of failures so it is not wise to have long running jobs that you cannot restart. Longer jobs also make maintenance difficult. And they lead to monopolisation of resources by a single user.</li> </ul> </li> <li>is it possible to request an extension for already running job, if it is expected to be finished in longer time?<ul> <li>No.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Is it possible to provide some hints on the role of containers and its possible role in LUMI ?</p> <ul> <li>We will discuss containers tomorrow. But we expect more and more workloads to use containers. But be aware that containers need to be optimized/adapted to run efficiently (or at all) on LUMI. Usually, MPI is the problem.</li> </ul> </li> <li> <p>When will GCC 12 become available on LUMI?</p> <ul> <li>In a future version of the Cray programming environment. We do not know the exact date yet. Which special feature of GCC 12 do you need?<ul> <li>We need it just because it makes the installation of our software dependencies, especially ExaTensor, much easier. We have recently HIPified this but it's not easy to tune for the new supercomputer https://github.com/ORNL-QCI/ExaTENSOR (distributed tensor library)</li> </ul> </li> <li>There is a chance that the CPE 23.02 will be installed during the next maintenance period as it contains some patches that we really need in other compilers also, and that one contains 12.2. The next maintenance period is currently expected in March but may need to shift if the software contained in it turns out to be too immature.</li> </ul> </li> <li> <p>Which visualization software will be available on the nvidia-visualization nodes? ParaView? VisIT? COVISE? VISTLE?</p> <ul> <li>Partly based on user demand and partly based on what other support organisations also contribute as we are too small a team to do everything for everybody. The whole LUMI project is set up with the idea that all individual countries also contribute to support. More info about that in a presentation tomorrow afternoon. Just remember the visualisation team at HLRS is as big as the whole LUMI User Support Team so we cannot do miracles. We already have a ParaVeiwe server build recipe with software rendering so I guess you can expect that one to be adapted.</li> </ul> </li> <li> <p>Looking at the software list, is distributed computing/ shared computing supported/ have been tested? https://en.wikipedia.org/wiki/Folding%40home</p> <ul> <li>It would normally not make sense to use LUMI for workloads which could run in a distributed setup, like e.g. Folding at Home. The whole point with a supercomputer system like LUMI is to have a very fast network that connects the different servers in the system.</li> <li>LUMI is in the first place a capability computing system, build to run jobs that require lots of compute power with very low latency and very high bandwidth between the processing elements to be able to scale applications. Using it for stuff that could run on simple servers like Folding@Home that can do with much cheaper hardware is a waste of money.</li> </ul> </li> <li> <p>Regarding Python: What do I have to consider to run Python code in an optimised way? We have heard about cray-python before.</p> <ul> <li>See tomorrow, and some other presentations that may mention cray-python which is really mostly a normal Python with some pre-installed packages carefully linked to optimised math libraries from Cray. The bigger problem is the way Python uses the file system but that will be discussed tomorrow afternoon.</li> <li>Please note that we hope to include more content related to Python in future (HPE) presentations.</li> </ul> </li> <li> <p>On Lumi-G is there Tensorflow and Pytorch available?</p> <ul> <li>Not preinstalled as there are really too many combinations with other Python packages that users may want and as due to the setup of LUMI there is currently even only some GPU software that we can install properly but you can use containers or download wheels yourself and there is actually info on how to run it in the docs.</li> <li>Again, available software is discussed in its own presentation tomorrow afternoon.</li> <li>TF and PyTorch are available in the CSC local software collection https://docs.lumi-supercomputer.eu/software/local/csc/ (not maintained/supported by LUST)</li> </ul> </li> <li> <p>Which ROCm version is the \"most\" compatible with what is on Lumi-G?</p> <ul> <li>The only ones that we can truly support are the ones that come with the Cray PE (so not the 5.2.5 and 5.3.3). HPE Cray tested the version of the software that is on LUMI with ROCm 5.0, 5.1 and 5.2. The driver should be recent enough to run 5.3.x but no guarantee that it will work together with, e.g., Cray MPICH (though it seems to work in the testing we have done so far but that can never be exhaustive)</li> </ul> </li> <li> <p>Why for some modules (e.g. python) there are several options with the same version number (3.9.12-gcc-n7, 3.9.12-gcc-v4, etc.). Are there any differences? How could we tell?</p> <ul> <li>The modules with the \"funny names\" in the end \"-n7\", \"-v4\" are generated by Spack. These are shortened hash codes identifying the version. You will normally not see them unless you load the Spack module. You will have to check the complete Spack \"spec\" of the module to determine exactly how they were built. You can use the command <code>spack find -lv python</code>, for example.</li> <li>And for those installed through EasyBuild (which have things like cpeGNU-22.08 etc. in their name): see tomorrow afternoon.<ul> <li>I checked and they are exactly the same :/.</li> </ul> </li> </ul> </li> <li> <p>Nob question: I'm confused on what is PrgEnv and modules such as PerfTools. What is the difference between them?</p> <ul> <li>PrgEnv sets modules for a given env (i.e. compiler base: gnu, amd, aocc, cray). This is the entry point of the Programming Environment (PE). Given that, all other modules will be set to that PE. Therefore, you can have PrgEnv-cray and then perftools module will be set for the cray environment. We discuss more on the next lectures (and hands-on).</li> <li>There are separate presentations on all that is in perftools coming over the next days.</li> </ul> </li> <li> <p>Follow up question: I'm interested in working with AMD developement tools. How do I set my PrgEnv to use the AMD compilers and compatible libs?</p> <ul> <li>We will discuss that in the Compiler session. But yes, you can use PrgEnv-amd for that (if you want GPU support) or PrgEnv-aocc (CPU support only). Just do <code>module swap PrgEnv-cray PrgEnv-amd</code>. More on the next lectures.</li> <li>KL: No need for <code>module swap</code> on LUMI as Lmod is configured with auto-swap. So <code>module load PrgEnv-amd</code> would also do.</li> </ul> </li> <li> <p>What is the minimal environment I have to load to run a singularity container on Lumi-G (with GPUs mainly)?</p> <ul> <li>https://docs.lumi-supercomputer.eu/runjobs/scheduled-jobs/container-jobs/ </li> <li>Depends on what part of the environment is already in the container...<ul> <li>Assuming it is an \"official\" rocm-tensorflow image (so with the drivers, python, etc), which Lumi modules do I need to load?</li> <li>We only have a longer description for PyTorch, right now: https://docs.lumi-supercomputer.eu/software/packages/pytorch/</li> </ul> </li> <li>Very likely none at all as you then only need singularity which is installed in the OS. Unless you need the RCCL plugin for better communication. It should not be that different for Tensorflow as it is for PyTorch.</li> </ul> </li> <li> <p>Is the environment firewall set as DENY for all outgoing (internet) TCP. i guess reverse proxy is not recommended     <pre><code>ping  google.com\nPING google.com (142.250.179.174) 56(84) bytes of data \n</code></pre>     ..hangs</p> <ul> <li>Internet access from the compute nodes should be enabled soon if not enabled yet. Some nodes might still need a reboot for that.</li> <li>Ping is never a good test as that is blocked on many systems nowadays.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#first-steps-for-running-on-cray-ex-hardware","title":"First steps for running on Cray EX Hardware","text":"<ol> <li> <p>Is that possible to change cpu numbers per task in one slurm script to optimize the CPU utilization?</p> <ul> <li>You mean different number of CPUs for each task, e.g. first task 2 cores, second task 8 cpus? <ul> <li>Yes, exactly, and these tasks are running in order</li> </ul> </li> <li>You can request the total number of tasks and then start the individual programs with <code>srun -n N</code></li> </ul> </li> <li> <p>When I execute <code>sinfo</code>, I get almost 40 lines of output. For example, I see 20 lines that start with <code>standard-g</code>. What is the meaning of that?</p> <ul> <li>use <code>sinfo -s</code> or pipe it through <code>less</code> or <code>head</code></li> <li><code>sinfo</code> reports a line for each status of the nodes, e.g. standard-g for drained nodes, idle, resv... (check the 5th column). <code>man sinfo</code> for more details.</li> </ul> </li> <li> <p>Is it possible to pass arguments to #SBATCH parameters in the jobscript?(not possible with PBS e.g.)</p> <ul> <li>I am not sure that I understand what you mean, but if it is what I think the answer is no. But instead of using #SBATCH lines you can also pass those settings via environment variables or via command line parameters. Typing <code>man sbatch</code> may bring you quickly to the manual page of <code>sbatch</code> if you need more information (for me it is the first hit but that is probably because I've used it soo often). <ul> <li>environment variables would work fine I guess, thanks</li> </ul> </li> </ul> </li> <li> <p>Sometimes <code>srun</code> knows what you asked for (#SBATCH) and then it is enough to just run <code>srun</code> without, e.g., the <code>-n</code> option. Is that not the case on LUMI?</p> <ul> <li>It is the case on LUMI also. </li> <li>There are some defaults but it is always better to be explicit in your job script.</li> </ul> </li> <li> <p>Sometimes I need to download large satellite images (~200 GB), it only use one CPU in login node, however, considering the I/O issues recently, should I move downloading in compute node or can I continue in login node?</p> <ul> <li>The I/O problem to the outside world was a defective cable and has been repaired. </li> <li>It might be better to chose for a push strategy to move data onto LUMI rather than a pull strategy from LUMI. Soon there will be the object file system also which will likely be the prefered way to use as an intermediate for large files.</li> <li>Given the slow speeds of single stream downloads/uploads from and to LUMI doing this in a compute job seems like a waste of billing units and it won't help with the reliability problem.</li> </ul> </li> <li> <p>is --gres per node or total number of GPUs?</p> <ul> <li>per each node</li> </ul> </li> <li> <p>I think it was mentioned but I didn't catch if all jobs get exclusive node access, i.e., <code>--exclusive</code>? Ok, it was just answered. Since it is not exclusive by default, I guess one should also specify memory?</p> <ul> <li>It depends on the partition, see https://docs.lumi-supercomputer.eu/runjobs/scheduled-jobs/partitions/</li> </ul> </li> <li> <p>Is it possible to see the std/err output of the running batch job?</p> <ul> <li>each job will dump a file for stdout and a file for stderr. Just answered in the presentation.<ul> <li>But I mean when job is still running</li> </ul> </li> <li>Yes. There is some buffering so output is not always immediate but it is not stored elsewhere first and only copied to your account at the end of the job as on some other systems.<ul> <li>perfect, thanks</li> <li>Is it possible to define the size of that buffer, to minimise the time it takes for the contents of the stdout/stderr files to be updated?</li> </ul> </li> <li>Yes, there is an option to activate unbuffered output with srun. <code>srun --unbuffered ..</code>. But this in not adviced as it increases the load on the file system if your program does lots of small writes.<ul> <li>OK, thank you.</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#exercise-setup","title":"Exercise setup","text":"<p>Exercise</p> <p>Copy the exercises to your home or project folder  <code>cp /project/project_465000388/exercises/HPE/ProgrammingModels.tar $HOME</code> Unpack it with <code>tar xf ProgrammingModels.tar</code> and read the <code>README</code> file or better transfer the pdf to your local machine with <code>scp</code> (run it from your local machine). To set the necessary environment variables, source <code>lumi_c.sh</code> with  <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (or <code>lumi_g.sh</code> equivalent for GPU nodes)</p> <ol> <li> <p>Should we copy the exercise to the scratch directory?</p> <ul> <li>I'd suggest copying to your home directory, and if you would use the scratch of project_465000388 then keep in mind that there are many people in that project so create a directory with your login name. But doing this in you home directory will give you more privacy.</li> </ul> </li> <li> <p>Is there a scratch area ? Or should run in home ? (bit slow at times)</p> <ul> <li>scratch, project and home are really on the same four file systems so there is no speed difference between them, What differs is the policy: Number of files allowed, maximum capacity allowed, how long does data remain before it is cleaned automatically, ... Yes, we know we have file system problems and that sometimes the file systems are slow and we do not yet know to which extent this is caused by hardware problems that are not yet discovered, by software problems (for example with VASP or simply in the file system software) or simply by users abusing the file systems and causing a slowdown for everybody. It is very likely that there is more than one factor that plays a role.</li> </ul> </li> <li> <p>I still failed to get my account of my new csc account (I had an old csc account). When I applied it via MyAccessID, it prompted that \"The level of assurance provided by your home organization for you does not meet the required level when logging in to the service. From March 1, 2023, you will not be able to access the service.\"</p> <ul> <li>Just ignore that. It is just a warning about future changes in the background.</li> <li>So what I need is just to fill in the registration? It needs the project number 465000388 and project manager email, what should I fill in for the project manager email?</li> <li>I link MyAccessID with my csc account now, but the project 4659000388 is not shown on the list of projects.</li> </ul> </li> <li> <p>sbatch: error: Batch job submission failed: Requested node configuration is not available     from sbatch pi.slurm</p> <ul> <li>Have you run <code>source lumi_c.sh</code>?</li> <li>no, sorry, did lumi_g</li> <li>Is there a job script for lumi_g trial ? <ul> <li>In the next lectures, but yes, you can use one of the GPU examples or adjust the existing job launcher (this is pi_acc.slurm)</li> <li>okay, but for now lumi_c is intended for ALL scripts ( without adjusting anything) ? Then I do that.</li> <li>but also with source lumi_c.sh + make clean + make and sbatch pi.slurm same error for me</li> </ul> </li> <li>yes, standard works; thanks</li> <li>I have got the same error, although I sourced lumi_c. Do I need to fill something into the job account area within the script?<ul> <li>Could you check you have the right partition in the file? I've changed the scripts, so you maybe using an old version?</li> <li>May I ask you, what you entered for these options? For SBATCH -p I am not sure what to fill in. <ul> <li><code>standard</code> or <code>standard-g</code>. Please check the lumi_g.sh and lumi_c.sh for the updated version.</li> </ul> </li> <li>Thank you! That helped me! I am new in this area, so it is still a bit confusing, but now I get a clue.</li> </ul> </li> </ul> </li> <li> <p>How to compile pi_hip (in C)? Tried make clean &amp; source lumi_g.sh &amp; make but that fails</p> <ul> <li>Use source ../setup_modules/setup_LUMI-G.sh (also change in job submission script) and check loaded modules:     <pre><code>  1) libfabric/1.15.0.0       4) xpmem/2.4.4-2.3_9.1__gff0e1d9.shasta   7) cray-dsmml/0.2.2       10) PrgEnv-cray/8.3.3      13) init-lumi/0.1           (S)  16) rocm/5.0.2\n  2) craype-network-ofi       5) cce/14.0.2                             8) cray-mpich/8.1.18      11) ModuleLabel/label (S)  14) craype-x86-trento\n  3) perftools-base/22.06.0   6) craype/2.7.17                          9) cray-libsci/22.08.1.1  12) lumi-tools/23.01  (S)  15) craype-accel-amd-gfx90a\n</code></pre></li> </ul> </li> <li> <p>I managed to Unpack it with <code>tar xf ProgrammingModels.tar</code>, but where are lumi_g.sh and lumi_c.sh?</p> <ul> <li>It is in the main directory (<code>/projappl/project_465000388/exercises/HPE/</code>) since it is common to all exercises.</li> <li>So, the instructions to do the excercises are in the PDF file?</li> <li>yes and README too</li> </ul> </li> <li> <p>pi_hip with 8 GPUs takes about 2.3s whereas it is faster with only 8 MPI ranks (and marginally slower with 2 MPIs), is it normal? I expected the GPU version to be much faster than the CPU...</p> <ul> <li>the example is not really using multiple gpus... BTW, it is not using MPI...</li> <li>First, yes it is using one GPU, secondly some of these examples are really just there so you can see what that example looks like in the programming model chosen. The HIP example in a way is an outlier because it needs a reduction ( add up all the counts) and I want the example to do everything on the GPU, it is doing this by a simple method (atomic addition). If we cared about performance we would do that in another way but it would really complicate the example. If you run the HIP example on 8 tasks it will run the single-GPU example eight times.  I have not yet created an MPI/HIP version.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#overview-of-compilers-and-parallel-programming-models","title":"Overview of compilers and Parallel Programming Models","text":"<ol> <li> <p>Are there any SYCL implementation available on LUMI? For example hipSYCL with HIP backend.</p> <ul> <li>Not installed by default and without any guarantee that they work in all cases, but we do have a build recipe for hipSYCL (which actually renamed to Open SYCL a couple of days ago) and someone has also succeeded in building the open-sourced version of DPC++. No guarantee though that it works for all cases or always plays nice with Cray MPICH. See tomorrow afternoon about how to expand the LUMI software stack. https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib/tree/main/easybuild/easyconfigs/h/hipSYCL or even better https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/h/hipSYCL/</li> <li>I'd wish though that HPE Cray and AMD would offer proper support as this is a good model to be able to target all three main HPC GPU families and even more exotic hardware.</li> <li>(Harvey) We have built SYCL at another site but I'm not sure of the status. As for officially supporting it, I don't know of any plans but you could equally argue that Raja or Kokkos could be supported as an alternative higher-level framework.</li> </ul> </li> <li> <p>Apologies if this was explained while I was away, are there any plans / roadmap for moving the Cray Fortran compiler to be LLVM-based, or is it expected it will remain based on Cray's proprietary backend? </p> <ul> <li>No. The Fortran compiler has always been extremely good, The C++ compiler specifically was not keeping up with standards and had very long compilation times and these were some of the drivers to make the change there. I think open source Fortran is also a moving target, the new Flang (f18) seems a work in progres.<ul> <li>(user comment) OK, thank you (Intel also moved their C compiler backend to LLVM and they seem to be now following the same path with their Fortran compiler, so we were wondering if Cray's strategy would be the same; really happy to hear it's not, since this gives us access to a wider range of implementations).</li> </ul> </li> <li>(Harvey) Best I don't comment on Intel. I'm interested to see how the classic Intel compilers and the OneAPI ones develop, particularly for Fortran.</li> <li>(Kurt) I keep wondering what Intel is actually doing with Fortran. Are they indeed fully moving to a new flang (and contributing to it) or did they really just port their frontend to an LLVM backend?<ul> <li>I think they re-built their frontend on top of an LLVM backend (sorry for the off-topic)</li> </ul> </li> </ul> </li> <li> <p>Is (or will) HIP also be compatible with Intel Habana GPUs?</p> <ul> <li>I have no idea, but I assume hipSYCL can work for that...</li> <li> <p>(Kurt) Habana is not a GPU but an AI accelerator with a different architecture. Or do you mean the XE line (Ponte Vecchio, Rialto Bridge, Falcon Shores)?</p> <p>But even there the answer is no. AMD will not do it. The way they also can support CUDA is because it is only an API translation. And Intel will not do it either, their preferred programming models for XE are Data Parallel C++ which is their SYCL implementation and OpenMP offload.</p> <ul> <li>(User comment) Project to enable HIP applications to run on Intel hardware exists. See here as well as this presentation. No idea if it will run on a specialized hardware like the Habana AI processors.</li> </ul> </li> <li> <p>(Kurt) I really doubt HIP can do anything on Habana when I check their web site. I suspect it is more of a matrix processor and not a vector processing and they even say very little about programming on their web site. It doesn't really look like hardware that fits the CUDA/HIP programming model. I hadn't heard about the ANL project to port HIP yet. The only one I had seen already was a project that did something similar as HIP but was basically a one person effort that had died already.</p> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#exercise","title":"Exercise","text":"<p>Exercise</p> <ol> <li>Copy the exercises to your home or project folder  <code>cp /project/project_465000388/exercises/HPE/ProgrammingModels.tar $HOME</code></li> <li>Unpack it with <code>tar xf ProgrammingModels.tar</code> and read the <code>README</code> file or the pdf at <code>doc/ProgrammingModelExamples.pdf</code>.</li> <li>To set the necessary environment variables, source <code>lumi_c.sh</code> with  <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (or <code>lumi_g.sh</code> equivalent for GPU nodes)</li> <li>Try out different compilers (by switching compiler environments, e.g. <code>module swap PrgEnv-gnu</code>) either manually e.g. <code>cc C/pi_mpi.c</code> or use <code>make Makefile.allcompilers</code></li> </ol> <ol> <li>is there a simple command to restore the default module configuration? <ul> <li>People more expert than me can give better advice here: I do <code>module purge</code> and then <code>module load PrgEnv-cray</code></li> <li>But note that that does not load the target modules! We'll see a LUMI-specific way tomorrow afternoon.</li> <li>If you have loaded the GPU modules then the longhand way is:     <pre><code>module unload rocm\nmodule unload craype-accel-amd-gfx90a\nmodule swap craype-x86-trento craype-x86-rome\n</code></pre></li> </ul> </li> <li> <p>How does the compilation of the acceleration example work? I have been trying some modules, but it did not work.</p> <ul> <li>See pi/setup_modules, there is a script setup_LUMI-G.sh that you can source to load the modules that Alfio talked about. You need to load the new environment variables from lumi_g.sh or put the right options in the batch script to select partition and request gpus. The standard Makefile has a target acc that should build those examples with CCE.</li> <li>For non-pi examples you would need to check any relevant instructions</li> <li><code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code></li> <li>Please share error messages or explain more if you are still stuck.</li> <li>Thanks for your help! I will try to implement.</li> </ul> </li> <li> <p>I tried to use the pi_acc.slurm script, but sbatch says the requested node configuration is not available. The changes I did was add -A project_465000388</p> <ul> <li>could you update your <code>lumi_g_sh</code> script? We udpated it with the new partition.<ul> <li>I copied lumi_g just now, but looks like it's the same as lumi_c.sh</li> </ul> </li> <li> <p>It runs through, but there is a complaint in the out file that <code>/var/spool/slurmd/job2843827/slurm_script: line 33: ../../setup_acc.sh: No such file or directory</code></p> </li> <li> <p>You need to point it to a script that sets up the gpu modules, so the file in the setup_modules, I should have fixed that so it did not need editing.</p> <ul> <li>so <code>setup-LUMI-G.sh</code>?</li> </ul> </li> <li>yes<ul> <li>I'd already done the setup manually, so it still worked</li> </ul> </li> <li>Finally works for me</li> <li>Sorry for the incovenient...</li> </ul> </li> <li> <p>I still try to run exercise one, but not success? \"No partition specified or system default partition\"</p> <ul> <li>please, source lumi_c.sh or lumi_g.sh first.<ul> <li>is there a way to check if the sourcing process worked?</li> </ul> </li> <li><code>echo $SLURM_ACCOUNT</code> should report <code>project_465000388</code><ul> <li>still got error should I remove some arguments?</li> </ul> </li> <li>pi.slurm?</li> <li>Also please copy those two files again as they were updated (lumi_c.sh, lumi_g.sh)<ul> <li>I did, my I have the content of pi.slurm to be excuted?</li> <li>I still can't excute pi.slurm!!! </li> </ul> </li> <li>via <code>sbatch pi.slurm</code>?</li> <li>I just change the content<ul> <li>SBATCH -A project_465000388</li> <li>is this correct or #SBATCH -A y11?</li> <li>this the error \".........../ProgrammingModels/jobscripts/../C/pi_serial: No such file or directory\"</li> <li>should i set the directory?</li> </ul> </li> </ul> </li> <li> <p>I'm trying to run my own application with MPI+gpus following the explaination in the slides, but I either get the error<code>MPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked</code>     if I set <code>MPICH_GPU_SUPPORT_ENABLED=1</code> or     <pre><code>MPICH ERROR [Rank 0] [job id 2843791.3] [Tue Feb 14 16:11:55 2023] [nid007564] - Abort(1616271) (rank 0 in comm 0): Fatal error in PMPI_Init: Other MPI error, error stack:\nMPIR_Init_thread(171).......: \nMPID_Init(506)..............: \nMPIDI_OFI_mpi_init_hook(837): \ncreate_endpoint(1382).......: OFI EP enable failed (ofi_init.c:1382:create_endpoint:Address already in use)\n</code></pre>     if I set <code>MPICH_GPU_SUPPORT_ENABLED=0</code></p> <ul> <li>Is the GPU target module loaded? You need the GPU target (and recompile) to tell MPI to use the GPU. It will discussed tomorrow. <ul> <li>ok, thanks! And I believe so, I do <code>module load craype-accel-amd-gfx90a</code></li> </ul> </li> <li>Then you have to recompile. Did you?<ul> <li>Yes, everything was compiled with that line already loaded</li> </ul> </li> <li>can you show the <code>module list</code> output?<ul> <li>Here: <pre><code>Currently Loaded Modules:\n  1) ModuleColour/on                      (S)  \n  2) LUMI/22.08                           (S)  \n  3) libfabric/1.15.0.0                        \n  4) craype-network-ofi                        \n  5) xpmem/2.4.4-2.3_9.1__gff0e1d9.shasta      \n  6) partition/G               (S)  \n  7) cce/14.0.2                     \n  8) perftools-base/22.06.0         \n  9) cpeCray/22.08                  \n 1)  METIS/5.1.0-cpeCray-22.08      \n 2)  buildtools/22.08     \n 3)  craype/2.7.17        \n 4)  cray-dsmml/0.2.2     \n 5)  cray-libsci/22.08.1.1\n 6)  PrgEnv-cray/8.3.3    \n 7)  cray-python/3.9.12.1\n 8)  cray-mpich/8.1.18\n 9)  craype-x86-trento\n 10) craype-accel-amd-gfx90a\n 11) rocm/5.0.2\n</code></pre></li> </ul> </li> <li>OK, what's the <code>ldd &lt;exe&gt;</code> output? We just need to check if the gtl library (used by MPI) is linked in. Just grep for gtl.<ul> <li>Do you want the complete version or should I grep something?     <pre><code>ldd ./libslim4.so | grep mpi\n    libmpi_cray.so.12 =&gt; /opt/cray/pe/lib64/libmpi_cray.so.12 (0x00007fd88af32000)\n    libmpi_gtl_hsa.so.0 =&gt; /opt/cray/pe/lib64/libmpi_gtl_hsa.so.0 (0x00007fd88accf000)\n</code></pre></li> </ul> </li> <li>OK, it is there... Can you run within the jobscript? <ul> <li>What does that mean?</li> </ul> </li> <li>Put ldd command in the job script just before the srun of your executable. It would be better to have ldd of your executable. Somehow the gtl library is not present when you run, so I can assume you have to load the module in the jobscript.<ul> <li>It's a python package, so I don't have an executable</li> </ul> </li> <li>OK, then, can you do <code>export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH</code>? Please note that the wrappers does the magic for you, but here you have python... (actually it is <code>export LD_LIBRARY_PATH=/opt/cray/pe/lib64/:$LD_LIBRARY_PATH</code>)<ul> <li>I still get the same two outcomes, depending on <code>MPICH_GPU_SUPPORT_ENABLED</code> (everything being recompiled on a fresh environment)</li> </ul> </li> </ul> </li> <li> <p>Are the timings correct? In the previous exercise, it claimed the serial code took 6 seconds, but it was done almost instantly</p> <ul> <li>Are you saying that if you time the srun or srun time ... that the time reported is shorter than that reported by the program?<ul> <li>I ran the Fortran_timings programs and it seemed to claim that pi_serial took six seconds, but the job was done almost instantly. I didn't have a watch and autocomplete struggles, so it took some time to open the file, but my impression was that it was much faster than it claimed in the output file</li> </ul> </li> <li>It might be just that you see all the output at once so when you see it start it is really finishing     <pre><code>harveyri@uan04:~/workshop/2023_02/ProgrammingModels/Fortran_timing&gt; time srun -n 1 time ./pi_serial\nsrun: job 2843939 queued and waiting for resources\nsrun: job 2843939 has been allocated resources\nPI approximation by serial program\nPI = 3.141592653589793120\nmyPI = 3.141592647959183800\ndiff = 0.00000018%\nElapsed time was 6.02s\n6.02user 0.01system 0:06.05elapsed 99%CPU (0avgtext+0avgdata 6884maxresident)k\n48inputs+0outputs (0major+446minor)pagefaults 0swaps\n\nreal    0m7.002s\nuser    0m0.037s\nsys     0m0.001s\n\nsys     0m0.020s\n</code></pre></li> </ul> </li> <li> <p>You wrote in hints for the 2nd exercise: \"Try out different compilers (by switching compiler environments, e.g. module swap PrgEnv-gnu) either manually e.g. cc C/pi_mpi.c or use make Makefile.allcompilers\", but the variant - make Makefile.allcompilers, does not work properly <code>make: Nothing to be done for 'Makefile.allcompilers'</code></p> <ul> <li><code>make clean</code></li> <li><code>make -f Makefile.allcompilers</code></li> <li>It won't build binaries that are already there.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#cray-scientific-libraries","title":"Cray Scientific Libraries","text":"<p>No questions during the session.</p>"},{"location":"4day-20230214/hedgedoc_notes_day1/#exercises","title":"Exercises","text":"<p>Exercise</p> <ol> <li>Copy the exercises to your home or project folder  <code>cp /project/project_465000388/exercises/HPE/ProgrammingModels.tar $HOME</code></li> <li>Unpack it with <code>tar xf ProgrammingModels.tar</code> and read the <code>README</code> file or the pdf at <code>doc/ProgrammingModelExamples.pdf</code>.</li> <li> <p>To set the necessary environment variables, source <code>lumi_c.sh</code> with  <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (or <code>lumi_g.sh</code> equivalent for GPU nodes)</p> </li> <li> <p>Directory <code>libsci_acc</code>: Test with LibSci_ACC, check the different interfaces and environment variables</p> </li> </ol> <ol> <li> <p>Just to clarify? for the 3rd exercise, to copy from /project/project_465000388/exercises/HPE/libsci_acc ? The file called \"ProgrammingModels.tar\" does not contain dir \"libsci_acc\"</p> <ul> <li>Yes, this is another example. Need to copy it.</li> <li>The slide being shared at the moment is tying to convey that these are different directories.</li> </ul> </li> <li> <p>This is rather a compilers/packages question. I compile the software using cmake on the login node using ftn (Cray Fortran : Version 14.0.2). In the submission script I do \"module load CrayEnv\" and the following is printed on the *.e file: <code>Lmod is automatically replacing \"craype-x86-rome\" with \"craype-x86-milan\"</code>. My question is if the <code>milan</code> architecture was indeed taken into account during compilation, since this was done on the login node </p> <ul> <li>If you didn't load the <code>craype-x86-milan</code> module on the login node before compilation, then your binary is optimized for Rome. See the slides of the morning session about cross-compilation for more information.</li> <li>We'll discuss <code>CrayEnv</code> tomorrow. It always loads the most suitable target module for the node on which you execute the load (or the <code>module purge</code> which causes an automatic reload), though there is currently a bug that manifests on the <code>dev-g</code> partition (basically because there were some nodes added to the system that I did not know about so did not adapt the code). So to compile with zen3 optimizations on the login nodes you'd still have to make sure <code>craype-x86-milan</code> is loaded as that is not what <code>CrayEnv</code> will do for you.</li> <li>Also note that cross-compilation does not always work as some programs come with configuration scripts that think it is wise to add a <code>-march=native</code>(or <code>-xHost</code> for Intel) to the command line which may overwrite options that the Cray wrapper passes to cross-compile.<ul> <li>I see, thanks. So would it make sense to compile on a compute nodes to make sure everything is setup correctly without me having to load the appropriate modules?</li> </ul> </li> <li>Yes, it is always safer to do so. Though so far for our software stack we do compile on a login node. For most programs so far this seems OK. It is most often \"research code quality\" applications that I have trouble with.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day1/#qa-day-1","title":"Q&amp;A day 1","text":"<ol> <li> <p>I have a program writting with cuda module, for optimization purpose and getting it run on AMD GPU on LUMI. Based on what I learned today, first, I need to convert my code with hip (or something else?), then compile it with proper enviroment, am I right?</p> <ul> <li>AMD presentations will cover the hipification tools that can be used for this.</li> </ul> </li> <li> <p>Not a question but I am working on Python and so far using Pytorch Lightning works, not sure if optimized though, so it's nice to see that we have some abstraction without fiddling too much with the code.</p> <ul> <li>https://docs.amd.com/bundle/ROCm-Deep-Learning-Guide-v5.3/page/Frameworks_Installation.html. The relevant bit is how to instruct pip to get the right wheels: <code>--extra-index-url https://download.pytorch.org/whl/nightly/rocm5.2/</code><ul> <li>Yup, it is also important to do some <code>export</code> to use more than 1 GPU. CSC has a modules for pytorch that sets it right. https://docs.lumi-supercomputer.eu/software/local/csc/</li> </ul> </li> </ul> </li> <li> <p>Are the python libraries global or are libraries supposed to be local venv</p> <ul> <li>Users should manage their libraries but can ellect a given python instalation to use it directly or to create virtual environments. Special care should be given to not have many files in the virtual environments. More details on what users can do will be explained tomorrow.</li> </ul> </li> <li> <p>Are tools to synchronize between local and remote supported and advisable to use? (e.g. Synchting) Can a user continously run a single-core job to keep alive the server?</p> <ul> <li>No. That is a waste of your billing units and you should also not do it on the login nodes. Use a more clever way of synching that doesn't need to be running all the time.<ul> <li>Any suggestions for a cleverer way?</li> </ul> </li> <li>It depends what it is for. E.g., my development directories are synchronised but for that I simply use Eclipse as the IDE. </li> <li>check VS code remote plugin</li> <li>(Kurt) That one is for remote editing, you still have to synch via another plugin or in another way. I did notice the visual studio remote can be a bit unreliable on a high latency connection so take that into account.</li> <li>And of course I just use rsync from time to time but start it only when I need it.</li> </ul> </li> <li> <p>Is there a list of essential modules that we should have to run jobs both for CPU and GPU particions? I accidentaly purged a lot of them and now is too difficult to add them 1-1.</p> <ul> <li>It depends on the PrgEnv. You can use a script to put your modules so that you can source it. CPU is out-of-the-box. For GPU you need: <code>module load craype-accel-amd-gfx90a rocm</code></li> <li>We'll talk about another solution also that is implemented on LUMI.</li> </ul> </li> <li> <p>If you require a specific name for mpi compilation (e.g. mpifort), do you recommend using alias or update-alternatives to change the name? </p> <ul> <li>If you can set an alias it implies you can change the command I think? If this was hardcoded I would write a wrapper script in your path.</li> <li>(Kurt) The wrapper script might be the better alternative as you need to do something in a bash script to be able to use aliases. By default they are not available in shell scripts.</li> </ul> </li> <li> <p>About VS Code, are you aware of any way that allows it to run on compute nodes and not on the login node?</p> <ul> <li>We have not tested this yet. </li> <li>There should be a way to just start vscoded server and use it via a web browser. But I've never tried it, and you'd still need to create an ssh tunnel from the machine on which you run the browser to a login node which then forwards all data to the compute node (the way one would also use the <code>lumi-vnc</code> module to contact a VNC server) </li> </ul> </li> <li> <p>Will SSHing into allocated compute nodes be allowed?</p> <ul> <li>Not clear if they will ever allow it. It does make it more difficult to clean up a node. So far the only solution is to go to the node with an interactive srun, which sometimes needs an option to overlap with tasks that are already on the node.<ul> <li>Precisely, rocm-smi or some other monitoring tool (e.g. htop).</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/","title":"Notes from the HedgeDoc page","text":"<p>These are the notes from the LUMI training, 1114-17.02.2023, 9:00--17:30 (CET) on Zoom.</p> <ul> <li>Day 1</li> <li>Day 2: This page</li> <li>Day 3</li> <li>Day 4</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day2/#openacc-and-openmp-offload-with-cray-compilation-environment","title":"OpenACC and OpenMP offload with Cray Compilation Environment","text":"<ol> <li> <p>Can you have both OpenMP and OpenACC directives in a code (assuming you only activate one of them)?</p> <ul> <li>Yes. This is quite common to mix OpenMP for multithreading on  the host and OpenACC for the device. For OpenMP and OpenACC, both on the device, yes you can selectively select one of the other using macros. Note that OpenACC is enabled by default for the Cray Fortran compiler so if you don't want to use OpenACC you have to explicitly disable it. OpenMP need to be enabled explicitly.</li> </ul> </li> <li> <p>Are there features in OpenACC that are not available (and not planned) in OpenMP?</p> <ul> <li>I will raise this at the end of the talk.<ul> <li>Thanks for the answer. Very useful.</li> </ul> </li> <li>In practice, we have seen that people only stay with OpenACC if they already have in their (Fortran) code (i.e. from previous work with enabling Nvidia GPU support), new porting projects tend to choose OpenMP offloading. <ul> <li>Follow-up question: How is the support of OpenACC vs OpenMP in compilers. I would maybe expect that OpenMP would be more widely supported, now and especially in the future?</li> </ul> </li> <li>The assumption is correct, OpenMP is the target for most compilers. As far I know, GNU will target Mi250 in GCC 13. I'm not aware of a real OpenACC in GNU. NVIDIA is supporting OpenACC for their compilers.</li> </ul> </li> <li> <p>What gives better performance on LUMI-G OpenMP offloading or OpenACC offloading? (C/C++)</p> <ul> <li>There is no OpenACC support for C/C++.</li> <li>Hypothetically speaking, there is no big performance difference between OpenACC and OpenMP offload in theory, sometimes they even share the same back-end. In practice, OpenMP offers somewhat more control at the programmer level for optimizations, whereas in OpenACC, they compiler has more freedom in optimizing.</li> </ul> </li> <li> <p>T his is not related to the presented topic, but every time I login to Lumi I get this message: \"/usr/bin/manpath: can't set the locale; make sure $LC_* and $LANG are correct\", how can I fix it?</p> <ul> <li>I think I saw that on Mac ssh consoles<ul> <li>I am using a Mac, so that is probably related</li> </ul> </li> <li>I have had the same problem before and fixed it by adding <code>SendEnv LANG LC_*</code> in my SSH config file.<ul> <li>Will try that - No difference<ul> <li>Did you simply add a line in the .ssh/config with <code>SendEnv LANG LC_*</code>?</li> </ul> </li> </ul> </li> <li>The other problem that I have also had on a Mac was that it had sent a locale that was not recognized by the system I was logging on to.<ul> <li>Nothing seems to fix it, I will leave it like that for now since it does not affect anything else</li> </ul> </li> </ul> </li> <li> <p>Working on a Fortran+OpenACC+hipBlas/hipFFT code which has currently a CPU and a GPU version. The two versions have become very different: CPU version has lots of function calls inside the OpenMP loop. GPU version has all the parallelism at the lowest level. Looking for ways to get back to one code base. Any chance to use craype-accel-host to get good performance on CPU and GPU targets?!</p> <ul> <li>the host is not meant to be for performance, for instance it will likely use a single thread. Check the man page intro_openmp for more details.</li> <li>How to (best) organize the code to support multiple GPU architectures is still an open question. Before, you could \"get away\" with only having support for 1 type of GPUs, and have that as a special branch of compilation, but with several types of GPUs and/or accelerators in the future (at least Nvidia, Intel, AMD...) it will become more difficult to do it like that. I have seen a few projects with successful support of several kinds of accelerators, what they typically do is to abstract it to a common matrix/vector library in the application (a \"matrix class\" or similar) and then have this module support different GPU/accelerator backends (including pure CPU execution).<ul> <li>Yes, this a common issue. Moreover, it you have multiple libraries accessing to the GPU, they don't talk each other (even worse for a multi-gpu case), so memory pooling is quite difficult. </li> </ul> </li> </ul> </li> <li> <p>Can we print out some of the slides from yesterday, for personal use? \"Programming Environment and Modules\"</p> <ul> <li>Sure, but please do not redistribute the digital form.<ul> <li>Ok, thank you.</li> </ul> </li> <li>The HPE slides and exercises can be copied for personal use by people attending the course. Some of the exercise examples are open source and were downloaded from the relevant repositories.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#exercises","title":"Exercises","text":"<p>Exercise</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directories for this exercise: <code>openmp-target</code>, <code>openacc-mpi-demos</code>, <code>BabelStream</code></li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file.</li> <li>T  o run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> (GPU) or <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Try different parallel offload programming models (openACC, OpenMP, HIP) and examples.</p> <ol> <li> <p>Has anything changed in the exercise files since yesterday, i.e., should we update our copy?</p> <ul> <li>Probably no changes to these folders but better copy again. Some other files for later changed.</li> </ul> </li> <li> <p>Are there job scripts available for today's exercise or I make them myself ?</p> <ul> <li>they are available (follow the readme)</li> <li>readme says Execute ... srun -n1 ... </li> <li>yes, correct. If you would like to submit (they are quite short runs), you can use one of the yesterday batch script.</li> <li>sorry, in my build/ there is no file ctest; nto sure I understand what to submit +1<ul> <li>ctest is a command, it will run the tests produced by cmake. If you are interested in the single binaries, then they are in the directories <code>build/tests/bin</code>. Otherwise ctest will execute all.</li> </ul> </li> <li>test all worked; thanks</li> <li>Might be an easy one, sorry: I got the return that No partition was specified. Has anyone experience with that?<ul> <li>Need to source the lumi_g.sh file to get SLURM configurtion.</li> </ul> </li> <li>is there a useful sequence in which to study the tests/*/.cpp s ? Seem many of those<ul> <li>So, check the original code at https://github.com/ye-luo/openmp-target. The idea is to check OpenMP offload functionalities and check if they are supported by Compilers. If the tests are OK, then the assumption is that the compile is working.</li> <li>The exercise is not to understand the workings of the source files ? but to apply this comprehensive test then ? (tests were all passed according to job output)<ul> <li>It depends if you want to understand how OpenMP works, then you are welcome to check the code, sure. Otherwise the exercises is to give examples on how to use the Offload OpenMP with CCE.</li> <li>okay, got it, thanks.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>In openmp-target exercise I got the following error after the last make command \"An accelerator module must be loaded for the compiler to support \"target\" related directive !$OMP TARGET\"</p> <ul> <li>Have you loaded the GPU module? (<code>source setup_modules/setup_LUMI-G.sh</code>)</li> <li>I use the command \"source /project/project_465000388/exercises/HPE/lumi_g.sh\"<ul> <li>This one is to set SLURM, you need to set the modules for the GPU (a different file)</li> </ul> </li> </ul> </li> <li> <p>Modules were loaded, but <code>make</code> couldn't find the compiler - BabelStream</p> <ul> <li>Which example are you trying to run? </li> <li>What's the error? could check the modules too? <ul> <li><code>Currently Loaded Modules:1) libfabric/1.15.0.0   3) xpmem/2.4.4-2.3_9.1__gff0e1d9.shasta       5) LUMI/22.08        (S)   7) craype-accel-amd-gfx90a 2) craype-network-ofi   4) partition/L</code></li> <li>You are missing PrgEnv-cray...</li> </ul> </li> </ul> </li> <li> <p>Inside the <code>makefile</code> of <code>/exercises/HPE/openacc-mpi-demos/src/</code>, there are some comments after FC and FFLAGS. Are they meant as a guide for something?</p> <ul> <li>Those examples are taken from https://github.com/RonRahaman/openacc-mpi-demos which uses the NVIDIA compiler as baseline. I agree that I can remove the comments... Sorry for the confusion.<ul> <li>Thanks, actually I find those comments useful, I might try in a machine with NVIDIA. Some comment that these are for NVIDIA would clarify things.</li> </ul> </li> <li>Then you are welcome to use the original code. Note, it requires the nvidia compiler (previously PGI).</li> </ul> </li> <li> <p>In BabelStream example, the OpenMP compilation (with <code>make</code>) gives an error:     <pre><code>CC -fopenmp -O3 -DOMP src/main.cpp src/omp/OMPStream.cpp -I src/ -I src/omp -DOMP_TARGET_GPU -o omp.x\nwarning: src/omp/OMPStream.cpp:108:3: loop not vectorized: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering [-Wpass-failed=transform-warning]\n</code></pre>     The HIP compilation works fine.</p> <ul> <li>this is a warning. It says that it cannot vectorize the loop (O3 enables vectorization), but this is fine since we are running on the GPU anyway. BTW, if you want to inspect more, I suggest to add the listing flag (-fsave-loopmark) to get more info.<ul> <li>I added the flag in Makefile (CC -fopenmp -O3 -fsave-loopmark -DOMP src/main.cpp src/omp/OMPStream.cpp -I src/ -I src/omp -DOMP_TARGET_GPU -o omp.x) but the output is the same as before</li> </ul> </li> <li>It will generate a file .lst that you can inspect and get more info.<ul> <li>Ah, ok, thanks</li> </ul> </li> </ul> </li> <li> <p>In BabelStream, the OpenMP code OMPStream.cpp, there is #pragma omp target enter data map... I assume this defines mapping of data onto devices. Where is the device list for OMP further defined in the code? or is this all?</p> <ul> <li>This is an OpenMP question, actually. With the call <code>pragma omp target enter data map(alloc: a[0:array_size], b[0:array_size], c[0:array_size])</code> (line 31) you map those data to the GPUs (it does allocate them). Then there will be an <code>#pragma omp target exit data map(release: a[0:array_size], b[0:array_size], c[0:array_size])</code> (line 46) to release the data. Then, the way OpenMP offload works is that if you do another map for the same data, OpenMP will check that data exists already on the device and it will reuse those allocations.<ul> <li>Thanks! Could you please clarify where is the device list itself defined in the code, so that OMP knows which devices it should map the data to?</li> </ul> </li> <li>This the default device, i.e. device_id 0.<ul> <li>Ahh, ok, thanks. I saw this device_id 0, but I thought it can't be so easy :)</li> </ul> </li> <li>Yeah, it is done via <code>omp_set_default_device(device);</code> (line 26). You can also use the clause <code>device</code> (this is for multi-gpus, actually).<ul> <li>the id 0 means graphic card 0 on a multi-card node?</li> </ul> </li> <li>It is part of the current talk. It is GPU 0, but then you can set <code>HIP_VISIBLE_DEVICES=2</code> and OpenMP will have GPU_ID=0 for the device 2 (maybe I'm confusing you). The point is that OpenMP uses at runtime the available GPUs, provided by ROCM. But then you can change the GPU order via <code>HIP_VISIBLE_DEVICES=1,0</code>. Wait for this afternoon exercises...<ul> <li>perfect, thanks!</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#advanced-application-placement","title":"Advanced Application Placement","text":"<ol> <li> <p>I was a bit confused by this definition of CPU. Can it be repeated and expanded?</p> <ul> <li>I have uploaded the talk</li> <li>We will try to use cpu in this talk to mean what Linux calls a cpu which is a hardware thread in a core - so 2 per core. </li> </ul> </li> <li> <p>Could it be the case that when a thread needs to access data in a remote cache (different core), OS rather migrates the thread instead of accessing (or even copying) the data? I'm suspecting such a behavior since sometimes pinning threads is slower than allowing OS to migrate them inside a NUMA domain. Any suggestions what to check?</p> <ul> <li>Well, this is definitely the case. Within the same NUMA can be a good trade-off. This is a bit experimental, you have to try which affinity is best for you.</li> </ul> </li> <li> <p>Any possibility to identify who did a binding (the different SW components)?</p> <ul> <li>You can get various components to report what they did (Slurm/MPI/OpenMP) but in general anything can override the binding or at least further constrain it. This is why it is good to run an application (as a proxy for your own) from your job script to double check this.</li> <li>It is not obvious when it comes to frameworks and applications that do their own thing to set the binding. We are covering MPI, MPI/OpenMP as they are the most common. We can at least use Slurm to set the binding of any process it starts and as long as that keeps within the binding it was given that at least gives us some control.</li> <li>In general, there is no trace on what is setting the binding...</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#exercises_1","title":"Exercises","text":"<p>Exercise</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directories for this exercise: <code>XTHI</code> (try out application) and <code>ACHECK</code> (pdf doc &amp; application similar to xthi but nicer output)</li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file. Check that you don't have unnecessary (GPU) modules loaded.</li> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Try different parallel different binding options for CPU execution (look at slides and use envars to change and display the order</p> <ol> <li> <p>Is it common to use different bindings depending on the size of the computations? </p> <ul> <li>No sure I understand the question on what you mean by \"different\". Usually you have to check the best match for your application. For example, if you are memory bound, then you may decide to spread your threads such that they will use multiple memory channels.</li> <li>The most common situation at scale is just to fill up multiple nodes using cores in sequence and if you use threads then choose OMP_NUM_THREADS so tasks fit nicely in NUMA regions and don't span them. It is when you want to do something special where other options come into play.</li> </ul> </li> <li> <p>While compiling xthi.c I got the following error     <pre><code>ld.lld: error: undefined symbol: omp_get_thread_num\n&gt;&gt;&gt; referenced by xthi.c\n&gt;&gt;&gt;               /tmp/xthi-c56fa1.o:(main)\nclang-14: error: linker command failed with exit code 1 (use -v to see invocation)\n</code></pre></p> <ul> <li>Sorry, the readme is missing <code>-fopenmp</code>.<ul> <li>I'm a bit confused, the Cray cc wasn't supposed to have openmp ON by default?</li> </ul> </li> <li>Only OpenACC is the default.</li> <li>Not anymore, but it was before yes !</li> </ul> </li> <li> <p>I'm trying the example ACHECK and I get <code>./acheck-cray: error while loading shared libraries: libamdhip64.so.5: cannot open shared object file: No such file or directory</code>. I have done <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code>. What am I missing here ?</p> <ul> <li>I think you will need to <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> instead to get the relevant modules for the GPUs.</li> <li>Those modules are setting the SLURM environment. I assume you have the GPU modules loaded. Please, unload them, recompile and run.</li> <li>I suggest you do the exercise on LUMI-C for this session.  Perhaps you built it with gpu modules and are running on LUMI-C.  (it would work on LUMI-G if you have LUMI-G Slurm and modules setup but there is no need to)</li> </ul> </li> <li> <p>Why? -&gt; slurmstepd: error: execve(): xthi.c: Permission denied!!!</p> <ul> <li>are you using the provided job.slurm?<ul> <li>yes</li> </ul> </li> <li>I have the following there:     <pre><code>#!/bin/bash\n\n#SBATCH -t 1\n\nexport OMP_NUM_THREADS=1\n\necho srun a.out\nsrun a.out | sort\n</code></pre>     then ou have to run via <code>sbatch job.slurm</code>. Is it what you are doing?<ul> <li>a.out I have change it to xthi.c as the above script cause an error \"execve(): xthi: No such file or directory\"</li> </ul> </li> <li>Put it back to a.out...<ul> <li>Error: execve(): xthi: No such file or directory</li> </ul> </li> <li> <p>OK, you compile and it will produce a.out, do you have it? Then, <code>sbatch job.slurm</code> will submit it. The job.slurm above doesn't mention any <code>xthi</code>, so I don't know where you error is coming from...</p> <pre><code>#!/bin/bash\n\n#SBATCH -t 1\n\nexport OMP_NUM_THREADS=1\n\necho srun a.out\nsrun a.out | sort\n</code></pre> <ul> <li>Sorry, this is the error :      <pre><code>srun a.out\nslurmstepd: error: execve(): a.out: No such file or directory\nsrun: error: nid005032: task 0: Exited with exit code 2\nsrun: launch/slurm: _step_signal: Terminating StepId=2876961.0\n</code></pre></li> </ul> </li> <li> <p>Then you have to compile first...</p> <ul> <li>when i try to compile i got </li> <li>ld.lld: error: undefined symbol: omp_get_thread_num</li> </ul> </li> <li>Need to add -fopenmp flag. I've update the Readme.<ul> <li>I cant see the update letme try copy it again</li> <li>Done, thank you</li> </ul> </li> </ul> </li> <li> <p>I tried \"cc -fopenmp xthi.c \" but got many errors like \"xthi.c:65:27: error: use of undeclared identifier 'hnbuf'             rank, thread, hnbuf, clbuf);             \"</p> <ul> <li>Need to set for LUMI_C. Unload the GPU modules and recompile.<ul> <li>Yes.. I use \"source /project/project_465000388/exercises/HPE/lumi_c.sh\"..still the same error.</li> </ul> </li> <li>This is for setting SLURM stuff. Do you hav ethe modules <code>rocm</code> and <code>craype-accel-amd-gfx90a</code>? If so, please unload them and recompile.<ul> <li>Now I got the error \"fatal error: mpi.h: No such file or directory\"..</li> </ul> </li> <li>Which modules do you have? I suggest to open a new and fresh terminal connection...<ul> <li>Got it ..working now</li> </ul> </li> </ul> </li> <li> <p>Run make on openmp-target and it went well. Next ran     <pre><code>srun -v -n1 --gres=gpu:8 ctest\nsrun: error: Unable to allocate resources: Requested node configuration is not available\n</code></pre>     What node configuration was it looking for or is there a way to see what is required there.     should we swap back to rome for that use case : swap craype-x86-rome craype-x86-trento</p> <ul> <li>openmp-target example is usig GPU. Are you setting SLURM for the GPU nodes (script lumi_g.sh)?</li> </ul> </li> <li> <p>Is the Lumi-D partition mentionned yesterday accessible now to try, or should we make a new application for that?</p> <ul> <li>There is a session this afternoon describing the LUMI environment in detail, suggest you ask again if this is not covered there.</li> <li>LUMI-D is two things:<ul> <li>The large memory nodes that are available and have the same architecture as the login nodes</li> <li>The visualisation nodes. They were releases again on February 13 but have hardly any software installed at the moment.     Given the relative investment in LUMI-G, LUMI-C and the visualisation nodes it is clear that they won't get too much     attention anytime soon.</li> </ul> </li> </ul> </li> <li> <p>Bit Mask: Slurm Script -&gt; sbatch: error: Batch job submission failed: Requested node configuration is not available, why?</p> <ul> <li>is the SLURM setting done? (script lumi_c.sh)<ul> <li>Yes, i will do it again</li> </ul> </li> <li>Could post the job.slum script?<ul> <li>I just copy and paste from slides, am I correct? page 50</li> </ul> </li> <li>let me try... Works for me. <ul> <li>please share job.slum.</li> </ul> </li> <li>There are other problems that I'm investigating. but at least I can submit it. Check at <code>/pfs/lustrep1/projappl/project_465000388/alfiolaz/training_exercises/XTHI/mask.slurm</code></li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#understanding-cray-mpi-on-slingshot-rank-reordering-and-mpmd-launch","title":"Understanding Cray MPI on Slingshot, rank reordering and MPMD launch","text":"<ol> <li> <p>Is the overlap really happens in practice? Or only when there is extra core available with openmp?</p> <ul> <li>Threads have little to do with cores. One core can run multiple threads, but in case of computational threads this is not a good idea as they will fight for the cache. But having a background thread on top of a computational thread is sometimes a good idea. And actually a good use of hyperthreading also (using the Intel term, AMD calls them SMT I believe)</li> <li>And sometimes part of the background work is also done by the network adapter, which should be the case for SlingShot 11.<ul> <li>Is there a way to check that the communications really happen while the computation is done and not just at the mpi_Wait?<ul> <li>No, unfortunatelly</li> </ul> </li> <li>Some answers were given at slides 21-24. </li> </ul> </li> </ul> </li> <li> <p>Could one for example use a hyperthread for a MPI async thread even if the application doesn't use hyperthreading?</p> <ul> <li>Yes, but likely it would not help that much</li> </ul> </li> <li> <p>In terms of overlapping computation/communication, what happens when one uses neighbourhood collectives? They have the non-blocking alternative and all processes involved know who they are sending to and receiving from. eg: MPI_Ineighbor_alltoall</p> <ul> <li>I'm not sure that we provide special optimizations for those collectives. I assume it is just like all others... It is worth to try!<ul> <li>MPI expert reply: We do support non-blocking neighborhood collectives. They are functional but not super optimized. If there are specific use cases then we suggest to open a ticket and we can investigate more.</li> </ul> </li> <li>I understand that the nonblocking collectives can be progressed by the progress thread, the neighbourhood collectives are much newer to I'm not sure of the status of that.</li> </ul> </li> <li> <p>With NVIDIA gpu-aware MPI, MPI calls perform a whole-device barrier call before/after the communications, rendering async calls ... not async. Does LUMI's implementation do the same?</p> <ul> <li>I'm not sure if we do the same blocking, but the LUMI design is different and NIC are attached to the GPUs memory directly. As far I can see, we use streams for the communications, so it should not be blocking.<ul> <li>MPI expert reply: Cray MPI does not do a device-level barrier before/after sync. More specifically, we do not do a hipStreamSynchronize before/after MPI. But, an application still needs to do a device-level sync on their own to make sure specific compute kernels have completed and the buffers used for MPI ops are correctly updated before MPI ops can be issued. They need to do MPI_Waitall to make sure MPI non-blocking ops have completed. They do not have to do a cuda(hip)StreamSynchronize/cuda(hip)DeviceSynchronize before starting the next round of kernels.</li> </ul> </li> <li>Is there a way for the user to interact with the stream used by MPI, or to direct MPI to a specific stream?<ul> <li>I don't think so, at least the man page doesn't report any hint for that.</li> </ul> </li> </ul> </li> <li> <p>How many times does rank re-ordering really helped in performance according to your experience?</p> <ul> <li>Answered by the speaker: HPE Cray's internal benchmarking team has found it useful on many occasions.</li> </ul> </li> <li> <p>I asked this yesterday and understand that is \"difficult\" to use MPMD on LUMI-C and LUMI-G at the same time which I hope will change. Can you comment on that?</p> <ul> <li>I've basically said everything I can say about that yesterday. It is not an MPI issue but an issue with the way the scheduler works when different parts of the job run in different partitions.<ul> <li>Does difficult effectively mean impossible? If not, are there any tricks to make it work better?</li> </ul> </li> <li>It is just not well-tested. Remember that LUMI-G is very new, so there has simple not been enough time and/or people trying it out to establish \"best practice\" yet. We need brave users (like you!) to try it out and bring some feedback.<ul> <li>:+1:</li> </ul> </li> <li>(Kurt) I don't think the previous remark is right. From the technical staff of LUMI I heard that the problem is that if a job uses 2 (or more) partitions, it does not follow the regular route through the scheduler but uses backfill slots.</li> </ul> </li> <li> <p>Related to question 30, what is the recommended way on LUMI to perform async communications between GPUs, ideally with control of the GPU stream, sot that the synchronisation is done in the background and we avoid the latency of StreamSynchronise. GPU-aware MPI? RCCL? One-sided MPI? </p> <ul> <li>RCCL is not really MPI. Then, GPU-aware uses a special library (called GTL = GPU Transfer library), so MPI P2P and one-sided follows the same route. I don't think you have controls on streams used in the MPI.</li> <li>RCCL allows asynchronous control of the streams and also computes the collective on the GPU. </li> <li>The problem of RCCL is that you have to use the Slingshot plugin to use the network, otherwise it would not work (and it is only collectives, btw). I would stick with MPI, unless yo have an application which already uses RCCL...<ul> <li>Is the Slingshot plugin bad? at the moment, I can choose between RCCL (I cannot use collectives, so I use ncclGroupStart), CPU-based MPI and GPU-aware MPI in my app, but all of these options are kind of unsatisfactory at the moment. (CPU-based MPI is the fastest...)</li> </ul> </li> <li>Then, I suggest to open a ticket and ask help for your particular case... without knowing the details is hard to reply.<ul> <li>ok, thank you, I'll do that. </li> </ul> </li> <li>There are good reasons to use RCCL over MPI - you can have collectives queued in the device while previous compute are being done. This is important for latency bound codes. The plugin should work well. I'm only aware of a bug that can be exposed with heavy threading - but that is a libfabric bug not really a plugin bug. RCCL also allows point to point.</li> <li>This is a good question and in fact is the low-level layer I alluded to in the presentation without naming it. At the moment I'm inclined to say we have to look at this on a case by case basis.</li> </ul> </li> <li> <p>What benchmarks for async MPI (comp./comm overlap) are you exactly referring?</p> <ul> <li>Who are you asking? I did not mention a benchmark in the talk other than the osu on or off device bandwidth test.<ul> <li>I was asking Harvey. Sorry, I thought you said some people are doing benchmarking on MPI communication and computation overlapping. I'm quite interested in enabling that. Do you know any materials or examples how exactly this should be implemented (e.g. the use of buffers that you mentioned), configured, and checked?</li> </ul> </li> <li>(Alfio) A lot of work in this context was done in CP2K code. Unfortunately, there are no special tricks. For large message MPI will wait... It depends on your case.<ul> <li>my usecase is grid based algorithm (LBM) with a process sending rather small messages only to neigbours (stencil) but in very short timesteps, meaning the MPI latency is significant for large scales. My feeling is it is suitable for the overlapping, but not sure how to enable that.</li> <li>And follow-up question: why the expected improvement is only 10-15% (as mentioned)? I would expect theoretically near to 100% overlap in case of sufficient computation portion (similar to GPU computation/data transfer overlaping)</li> </ul> </li> <li>(Peter): I interpreted what Harvey said as 10-15% application performance improvment. So even if the MPI communication is improved a lot, there is still compute to do...<ul> <li>thanks, then that really depends on application, not sure about the numbers. Any suggestions about the material requested?</li> </ul> </li> <li>(Harvey) I'm just reporting examples people have mentioned to me, that does not mean that you can't do better, as with all optimizations it all depends on the specific situation.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#exercises_2","title":"Exercises","text":"<p>Exercise</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directories for this exercise: <code>ProgrammingModels</code> or any other you want to try.</li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file. Check that you don't have unnecessary (GPU) modules loaded.</li> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU) or <code></code> (GPU).</li> </ul> <p>Suggestions: </p> <ol> <li>Test the Pi Example with MPI or MPI/openMP on 4 nodes and 4 tasks</li> <li>Show where the ranks/threads are running by using the appropriate MPICH-environment variable</li> <li>Use environment variables to change this order (rank-reordering)</li> </ol> <p>Alternatively: Try different different binding options for GPU execution. Files are in <code>gpu_perf_binding</code>, see <code>Exercise_day1-2.pdf</code> (<code>/project/project_465000388/slides/HPE/</code>)</p> <p>:::</p> <ol> <li> <p>I did not understand how to generate the report for gpu binding, sorry. Is there a script or are we still using xthi?</p> <ul> <li>This is the hello_jobstep tool, xthi does not report anything about GPUs<ul> <li>Thank you!</li> </ul> </li> <li>You can also find it here https://code.ornl.gov/olcf/hello_jobstep/-/tree/master</li> </ul> </li> <li> <p>went through the exercise pdf steps; but get HIP Error - hello_jobstep.cpp:54: 'hipErrorNoDevice'; submitted to standard-g</p> <ul> <li>did you use --gres to request gpus?<ul> <li>yes, that was missing</li> </ul> </li> <li>Have you updated the exercice's folder since yesterday ? I think the 'gres' part has been added this morning.<ul> <li>did not for this directory; will do</li> </ul> </li> <li>Ok great !</li> </ul> </li> <li> <p>When I try to run job.slurm in hello_jobstep, an error arise \"sbatch: error: Batch job submission failed: Requested node configuration is not available\"!!!</p> <ul> <li>Have you source the ../lumi_g.sh script ?<ul> <li>yes source /project/project_465000388/exercises/HPE/lumi_c.sh, is it?</li> <li>so, why the error arise, have tried for the second folder, but the same error!!!</li> </ul> </li> <li>Use lumi_g.sh, this is gpu_perf_binding<ul> <li>I havew used both</li> </ul> </li> <li>In which order?<ul> <li>Perfect, thank you...</li> </ul> </li> </ul> </li> <li> <p>I am trying to run the gpu_perf_binding test, but in the slurm output I get:      <code>HIP Error - hello_jobstep.cpp:54: 'hipErrorNoDevice'</code></p> <ul> <li>you are missing the \"#SBATCH --gres=gpu:8\" option in the batch file, so you don't reserve any GPU.</li> <li> <p>In fact, this has been corrected this morning, if you download the exercices folder again, it should work fine now</p> <ul> <li>No, I am using:     <pre><code>#!/bin/bash \n#SBATCH -J himeno_gpu\n#SBATCH --ntasks-per-node=8\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:10:00\n#SBATCH --gres=gpu:8\n#SBATCH --hint=nomultithread\n</code></pre>     I will try to download the folder again, maybe it is something else. </li> </ul> </li> <li> <p>ok ! let me know. Don't forget to source both lumi_g.sh and gpu_env.sh</p> <ul> <li>It works now, the problem seems to have been an interactive run that didn't shut down properly. <ul> <li>Ok that's great then :)</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>What do you mean by \"Launch himeno from the root directory\"? the job.slurm is located in the dir gpu_perf_binding/himeno</p> <ul> <li>sorry this is not up to date, you can launch it from the himeno directory directly.</li> <li>you can launch the job.slurm directly from /himeno directory<ul> <li>but the file \"select_gpu.sh\" is located in another dir &amp; the error mesage is generated: \"slurmstepd: error: execve(): select_gpu.sh\"</li> </ul> </li> <li>could you update the entire directory? We did update it before lunch, sorry for the incovenience. <ul> <li>OK, understood.     -- still does not work as the file \"select_gpu.sh\" is located in another dir (one level above, i.e. in gpu_perf_binding/ dir), not in the gpu_perf_binding/himeno/ dir     it works only in case if in file job.job.slurm the shown below lines are both kept commented : ## UNCOMMENT to add proper binding #gpu_bind=select_gpu.sh cpu_bind=\"--cpu-bind=map_cpu:50,58,18,26,2,10,34,42\"     what for is used the \"## UNCOMMENT to add proper binding\"</li> </ul> </li> </ul> </li> <li> <p>Not related to this tutorial's material.     I have a problem with one of my applications which does domain decomposition and uses MPI. I could run 4 tasks on 4 nodes (1 task/node) without issues. Or run 128 tasks in a single node. However, MPI crashes start when running more tasks per node (&gt;=4). MPI appears to crash with <code>MPIDI_OFI_handle_cq_error(1062): OFI poll failed (ofi_events.c:1064:MPIDI_OFI_handle_cq_error:Input/output error - PTLTE_NOT_FOUND)</code>. This software was run on another cray machine (ARCHER2 to be precise) on ~ 200 nodes and no issues were observed. So at least, there is some confidence that the communication/MPI part was implemented correctly. Any quick advice/hints, or if anyone has experienced something similar? (sorry for the off-topic)</p> <ul> <li>Open a ticket...</li> <li>(Harvey) That error signature can be a secondary effect, some other node/rank may have failed before you got that message, for example running out of memory. But I agree if you submit a ticket we can investigate.<ul> <li>A colleague of mine had open a ticket on December and we tried all suggestions but unfortunately did not solve our problem. Even after the update, this issue still occurs. Thanks anyway!</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#additional-software-on-lumi","title":"Additional software on LUMI","text":"<ol> <li> <p>Do we have a strategy/recommended practice for storing parameterised 'passwords', hashes, etc. Or is there a vault ala Terraform/Azure?</p> <ul> <li>We do not have any such service running on LUMI.</li> </ul> </li> <li> <p>Typical workflow is to compile on a login node and run on LUMI-C or LUMI-G. For compilation, what module should we use: partition/L (because we are on a longin node) or partition/C or /G (to match the one optimised for the partition where we will be running the compiled binaries)?</p> <ul> <li>Yes, when compiling on the login nodes, you need to load the partition module  for the hardware you want to target/run. It means replacing partition/L by partition/C for LUMI-C and partition/G for LUMI-G.</li> <li>It is often possible to compile software for GPU nodes on the login nodes, using the <code>rocm</code> module, but it is better to compile GPU software on a GPU node, because the login nodes do not have any GPUs installed, which sometimes confuses installations scripts.<ul> <li>So partition/L module should only be used to run directly on the login nodes stuff that will not be used later on LUMI-C/LUMI-G? (e.g., post-processing)?</li> </ul> </li> <li>Yes, or if you plan to use the \"largemem\" or LUMI-D nodes that have Zen 2 CPUs. It will work, you may gain some efficiency from using partition/C or partition/G, and it will not support compilation of GPU software properly<ul> <li>OK, thank you.</li> </ul> </li> </ul> </li> <li> <p>How do you get the paths that are set by a module if you need to give them explicitely (include/lib folders)?</p> <ul> <li><code>module show modulename</code> shows what the module is really doing</li> <li>Easybuild installed packages define a <code>EBROOT&lt;UPPERCASENAME&gt;</code> environment variable. For example the zlib module will define the <code>EBROOTZLIB</code> environment variable. This variable can be used to provide installroot to autotools and cmake. Use <code>env | grep EBROOT</code> to list such variables</li> </ul> </li> <li> <p>Is lumi-workspaces still deprecated? I got once or twice this message while loading it.</p> <ul> <li><code>lumi-workspaces</code> is not deprecated but the module is. The command is available by default now. It has been extended to also show the compute and storage billing units consumption/allocation.</li> <li>As I said in the presentation, it is replaced by <code>lumi-tools</code> which is loaded by default. Try <code>module help lumi-tools</code> for more info on the commands that are in the current version as this will evolve over time.</li> </ul> </li> <li> <p>I think he just mentioned it but I missed it. Is it possible for anyone to add LUMI EasyBuild recipes?</p> <ul> <li>Yes, we accept pull requests on GitHub into the LUMI-EasyBuild-Contrib repository, which is available by default on LUMI for everyone. But you do not need to have your recipe accepted there, you just write own and use it with our toolchains.<ul> <li>Sounds good. In case one would like it to be generally available to other users.</li> </ul> </li> <li>Then it should be on Github.<ul> <li>:+1:</li> </ul> </li> <li>And of course you can also use your own repository if it is only for your own project. See also the notes for the presentation</li> </ul> </li> <li> <p>What's the recommended way of building new packages with easybuild for LUMI-G? Launching an interactive job?</p> <ul> <li>This is definitely the safest thing to do. Hint: For now if you have CPU billing units and if the process does not take too long you could use the partition <code>eap</code> which is still free, but that might not be for long anymore.</li> </ul> </li> <li> <p>I wrapped my conda env uisng lumi container wrapper, and usually I need to export some specific PATH and PYTHONPATH from Conda env to excute some programs directly from command line, how can I do the similar thing with lumi container wrapper?</p> <ul> <li> <p>I'm not sure I understand the question sufficiently to take it to the developer. Is there a small example that we could try without having to install too much stuff?</p> <ul> <li>for example, under conda environment, i need to export the following paths <code>ISCE_HOME=/project/project_465000359/EasyBuild/SW/LUMI-22.08/C/Anaconda3/2021.04/envs/isce_test/lib/python3.8/site-packages/isce</code>, <code>export PATH=\"$PATH:$ISCE_HOME/bin:$ISCE_HOME/applications:$ISCE_HOME/components/contrib/stack/topsStack\"</code> to run applications under topsStack from command line. </li> </ul> </li> <li> <p>if you export <code>SINGULARITYENV_ISCE_HOME=&lt;value&gt;</code>, then <code>ISCE_HOME</code> will be set in the container</p> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day2/#general-qa-day-2","title":"General Q&amp;A day 2","text":"<ol> <li> <p>How long will we have access to this project for?</p> <ul> <li>3 months as for all expired LUMI project.</li> </ul> </li> <li> <p>Will the number of files quota (100K) be a hard quota? As in it would be impossible to create more than 100K files.</p> <ul> <li>For the project and home directories, yes. Exception may be possible but it really need to have a very good motivation. You can have up to 2M files in your <code>/scratch</code> but the files there will be removed after 3 months.</li> </ul> </li> <li> <p>How do you verify that frameworks like pytorch or other complex program packages use the resources efficiently?</p> <ul> <li>We have started planning some course material tackling that question. But early stage.</li> </ul> </li> <li> <p>I am running the hello_jobstep example and for each rank RT_GPU_ID is zero, while GPU_ID is the one expected. Probably it is not so clear to me the meaning of RT_GPU_ID, but why is it zero? Thank you!     PS: I found this https://github.com/olcf-tutorials/jsrun_quick_start_guide/blob/master/README.md ; is this number always zero because this is the only GPU seen by the rank?</p> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/","title":"Notes from the HedgeDoc page - day 3","text":"<p>These are the notes from the LUMI training, 1114-17.02.2023, 9:00--17:30 (CET) on Zoom.</p> <ul> <li>Day 1</li> <li>Day 2</li> <li>Day 3: This page</li> <li>Day 4</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day3/#performance-optimization-improving-single-core-efficiency","title":"Performance Optimization: Improving single-core efficiency","text":"<ol> <li> <p>Sorry, I have a question from yesterday.  I run the hello_jobstep example, and for each rank RT_GPU_ID is zero, while GPU_ID is the one expected. Probably it is not so clear to me the meaning of RT_GPU_ID, but why is it zero? Thank you!     PS: I found this https://github.com/olcf-tutorials/jsrun_quick_start_guide/blob/master/README.md ; is this number zero for all GPU_IDs because this is the only GPU seen by the rank?</p> <ul> <li>So, RT is the runtime value taken from the get <code>hipGetDevice</code>. Now, you run by forcing <code>ROCR_VISIBLE_DEVICES</code> to a given GPU per each rank (via the select_gpu scripts). Let's assume we do <code>ROCR_VISIBLE_DEVICES=2</code>, then at runtime you will access a single GPU whose id is 0. If you set <code>ROCR_VISIBLE_DEVICES=2,3</code>, then runtime ID will be <code>0, 1</code>. I'm not sure if I'm confusing you... You can find more examples at <code>https://docs.olcf.ornl.gov/systems/crusher_quick_start_guide.html#mapping-1-task-per-gpu</code>.<ul> <li>I think I understood! Thank you very much!</li> </ul> </li> <li>This is why that code can print the busid of the GPU, so that you can tell which physical GPU was being used.</li> </ul> </li> <li> <p>I might have missed it, but what is the motivation for padding arrays? Don't we destroy the locality of our original arrays if there is something in-between ?</p> <ul> <li>(Alfio) this is for memory access, you access the data in cache lines (64 bytes), so you want to align your data for that size. Note that also MI250x can require data alignemnt. I think AMD will discuss that. A CPU example: https://stackoverflow.com/questions/3994035/what-is-aligned-memory-allocation</li> <li>(Harvey) The point (as noted below) is that often you index into both arrays by the same offset and both of those accesses might collide on cache resources. The point of the presentation is to really give you a feel for the transformations the compilers can and might do so that if you start to delve into optimizing an important part of your code then this is useful to understand, even if you just look at compiler commentry and optimization options and don't want to consider restructuring the code. The compilers (and hardware) get better and better all the time.</li> <li>(Kurt) A data element at a particular address cannot end up everywhere in cache, but only in a limited set of cache elements (for L1/L2 cache often only 4 or 8 locations). Now with the original declarations, assume that array A starts at address addr_a, then array B will start at address addr_b = addr_a + 64648 (number of elements in the array times 8 bytes per data element). Alignment of B will still be OK if that for A is OK (and actually for modern CPUs doesn't matter too much according to two experts of Erlangen I recnetly talked to). But as addr_b = addr_A + 2^15, so shifted by a power of two, it is rather likely that B(1,1) ends up in the same small set of cache lines as A(1,1), and the same for C(1,1). So doing operations in the same index region in A, B and C simultaneously may have the effect that they kick each other out of the cache. This is most easily seen if we would have cache associativity 1 (imaginary case), where each data element can be in only one cache location, and with a cache size of 2^15 bytes. Then B(1,1) and C(1,1) would map to the same cache location as A(1,1) and even doing something simple as C(i,j) = sin(A(i,j)) + cos(B(i,j)) would cause cache conflicts. By shifting with 128 bytes as in the example this is avoided. </li> </ul> </li> <li> <p>How do you know what loop unroll level and strip mining size to use? Trial and error? Or is there some information to look for?</p> <ul> <li>(Alfio) Most of the compilers are doing a good job already. It really depends on the instructions of the loop (number of loads/store and computation intensity). You can check the listings to check what the compiler is doing for you and then you can add some directives to try to force more unrolling. Unrolling by hand is quite unsual nowadays...</li> <li>(Kurt) But it is one of those points were selecting the right architecture in the compiler can make a difference, and something that will definitely matter with Zen4 (which we do not have on LUMI). But the AVX-512 instruction set supported by Zen4 (code named Genoa) has features that enable the compiler to generate more elegant loop unrolling code. Some users may think that there cannot be a difference since the vector units still process in 256-bit chunks in that version of the CPU, but it is one of those cases where using new instructions can improve performance, which is why I stressed so much yesterday that it is important to optimize for the architecture. For zen2 and zen3, even though the core design is different and latencies for instructions have changed, I don't know if the differences are large enough that the compiler would chose for different unrolling strategies. In a course on program optimization I recently took we got an example where it turned out that AVX-512 even when restricted to 256 bit registers had a big advantage over AVX-2 even though with both instruction sets you get the same theoretical peak performance on the processor we were using for the training (which was in Intel Skylake, it was not on LUMI).</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#debugging-at-scale-gdb4hpc-valgrind4hpc-atp-stat","title":"Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat","text":"<ol> <li>Is STAT and ATP for cray compiler only?<ul> <li>They are not restricted to just the Cray compiler<ul> <li>Are all the tools in this morning lecture for cray compiler only? I anticipate the question :)</li> </ul> </li> <li>No, you can use with any compilers (PrgEnv's)<ul> <li>Thank you!</li> </ul> </li> <li>Please be aware that there are some known issues with the current software on LUMI so some of these tools are not operating properly. Until the software can be updated we recommend using gdb4hpc.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#exercise","title":"Exercise","text":"<p>Exercise</p> <p>General remarks: -   Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code> -   Directory for this exercise: <code>debugging</code> -   Copy the files to your home or project folder before working on the exercises. -   In some exercises you have source additional files to load the right modules necessary, check the README file.</p> <ul> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> (GPU) or <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Exercise:</p> <ol> <li>deadlock subfolder: gdb4hpc for CPU example      Don't forget to <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code></li> <li>subfolder: environment variables for GPU example      Don't forget to <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> &amp; load GPU modules</li> </ol> <ol> <li> <p>launcher-args -N2 is the one identical to srun argument list ? (in valgrind4hpc call)</p> <ul> <li>yes: it sets the number of nodes used for the underlying srun command used by valgrind4hpc<ul> <li>but -n1 is given by valgrid arg</li> </ul> </li> <li>yes -n is the number of processes used by valgrind4hpc (and also the number of processes for the underlying srun command used by valgrind4hpc)<ul> <li>valgrind4hpc \u2013n1 --launcher-args... gives me cannot find exec n1</li> <li>when I post the code line I cannot edit anymore; trying to modify pi_threads.slurm; added module load; put the srun args into --launcher-args; but -n1 seems to be a problem</li> </ul> </li> <li>The launcher-args are for you to specify extra arguments about the distribution of the tasks (you don't put -n though)</li> </ul> </li> <li> <p>With gdb4hpc in an interactive job, how to check I'm on the allocated compute node and not the login node? (hostname doesn't work there)</p> <ul> <li>the launch command in gdb4hpc uses an underlying srun command and thus, used the ressources of the salloc command <ul> <li>ok thanks, and theoretically in case of multiple allocated jobs, how to select which to use?</li> </ul> </li> <li>focus p{0}, check the slides (page 24). The man page is also giving some good examples<ul> <li>Sorry, I don't understand how to use the focus comand to select a job (not process). On page 24 I can see only how to select set of processes.</li> </ul> </li> <li>Ah, you want to attach to an existing job? <ul> <li>yes, I mean if I allocate multiple interactive jobs and then I want to launch gdb4hpc on one of them</li> </ul> </li> <li>You have to run gdb4hpc in the same salloc. You start salloc and then run the app under gdb4hpc. <ul> <li>ok, probably I have to check how really salloc works, I'm PBS user, thanks</li> </ul> </li> <li>So, salloc gives you a set of reserved nodes and it will return with a shell on the login node. Then you can run <code>srun</code> to submit to the reserved nodes. The equivalent on batch processing is sbatch.<ul> <li>oh I see, I was confused with the login shell - so even its a login, it is already linked with the particular interactive job (allocated nodes), right?</li> </ul> </li> <li>correct, everyting you run after salloc with <code>srun</code> (gdb4hpc or valgrind4hpc use srun under the hood) will run on the reserved nodes. You can check that with salloc you get a lot of <code>SLURM_</code> environment variables set by SLURM, for example <code>echo $SLURM_NODELIST</code><ul> <li>ok, understand, cool tip, thank you</li> </ul> </li> <li>the corresponding PBS is <code>qsub -I</code>, if recall correctly...<ul> <li>yes, but it returns directly the first node shell</li> </ul> </li> <li>ah, this can be configured on SLURM too (sysadmin SLURM conf). However, on LUMI you will still remain on the login node.</li> </ul> </li> <li> <p>When in an gdb4hpc session, I can switch to one process with <code>focus $p{0}</code>. But how do I get a listing of that process to see the source of where it is stuck or breaked?</p> <ul> <li>this is the standard gdb command then, for instance <code>where</code></li> <li>use the list (short 1) gdb command. Since you \"have\" a focus on 0, gdb will list source file for process 0</li> </ul> </li> <li> <p>For the valgrind4hpc exercise, I did it a first time and got the expected output, then I fixed the code, recompiled and ran the ./hello directly to make sure it worked. However when running valgring4hpc again I still get the same output as the first time (whereas this time obviously there was no more bug): is there something I should have reset to get the correct output instead of:     <pre><code>HEAP SUMMARY:\n  in use at exit: 16 bytes in 1 blocks\n\nLEAK SUMMARY:\n   definitely lost: 16 bytes in 1 blocks\n   indirectly lost: 0 bytes in 0 blocks\n     possibly lost: 0 bytes in 0 blocks\n   still reachable: 0 bytes in 0 blocks\n\nERROR SUMMARY: 31 errors from 109 contexts (suppressed 1259\n</code></pre></p> <ul> <li>you have the same error on the 16 bytes lost because you do not free(test) in both cases. But the invalid write of size 4 are removed if you change test[6]= and test[10]= by for example test[2]= and test[3]=<ul> <li>OK, so now I added free(test) and things seem to have improved:     <pre><code>All heap blocks were freed -- no leaks are possible\n\nERROR SUMMARY: 30 errors from 54 contexts (suppressed 1259)\n</code></pre>     so there is no more leak and all blocks were freed, but why are there still 30 errors???</li> </ul> </li> <li>these are in the libraries, no related to users. You can expect masking of those errors in the future.</li> <li>yes the library where the errors occur in the outputs is /usr/lib64/libcxi.so.1 and you can see the errors are in cxil_* functions from this library</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#io-optimisation-parallel-io","title":"I/O Optimisation - Parallel I/O","text":"<ol> <li> <p>How does Lustre work with HDF5?</p> <ul> <li>HDF5 is built on top of MPI-IO, which means that HDF5 will make good use of all the underlying infrastructure provided for Lustre by MPI-IO.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#exercise_1","title":"Exercise","text":"<p>Exercise</p> <p>Remarks:</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directory for this exercise: <code>io_lustre</code></li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file.</li> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> (GPU) or <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Exercise</p> <ul> <li>Try out different Lustre striping parameters and use relevant MPI environment variables<ul> <li>Do the environmental variables (like MPICH_MPIIO_HINTS) always prevail over what could be explicitely set in the code/script?</li> </ul> </li> </ul> <ol> <li>Do the environmental variables (like MPICH_MPIIO_HINTS) always prevail over what could be explicitely set in the code/script?<ul> <li>If you set striping on a file by lfs setstripe then that is fixed. For a directory then I expect an API or the envar to override the default policy when files are created.</li> <li>I'm not sure if the envar will override something set explicity in an API, for example hints passed to an Open function, I would doubt it.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#introduction-to-the-amd-rocmtm-ecosystem","title":"Introduction to the AMD ROCmTM ecosystem","text":"<ol> <li> <p>When we use <code>gres=gpu:2</code> are we guaranteed that the two dies will be on the same card?</p> <ul> <li>I doubt. The scheduler is not very good at assigning only a part of a GPU node. And the same actually holds for the CPU where you are not guaranteed to have all cores in, e.g., the same socket even if your allocations can fit into a single socket. If you are performance concerned you should really allocate nodes exclusively and then organise multiple jobs within the node yourself if you want to make good use of your GPU billing units.</li> </ul> </li> <li> <p>Is there some slurm option gpus per node?</p> <ul> <li>I'm not sure how you would like to use it, as we only have one type of GPU node and as you would be billed the full node anyway even if you would use only two GPUs on a node as noone else can use them?<ul> <li>Good point. </li> </ul> </li> <li>It actually exists in Slurm and you will see it in some examples in the documentation but it is one of those options that should be used with care as you may get more than you want. </li> </ul> </li> <li> <p>hipcc calls nvcc on nvidia platforms. What is it calling on amd platforms? Is it hip-clang?</p> <ul> <li>It is calling clang - HIP support has been upstreamed to the clang compiler.</li> <li>Basic idea is that <code>hipcc</code> calls <code>clang++ -xhip</code>. In practice it adds more flags. If you are really curious about what <code>hipcc</code> is doing, you can have a look at the source code.</li> </ul> </li> <li> <p>On CUDA we can set --gpu-architecture=all, to compile for all supported architectures by this CUDA Toolkit version, this way our code is more portable. Is there a HIP equivalent to compile for all supported AMD architectures by this HIP version? I know we can set multiple architectures (using multiple uses of -offload-arch=), but is there also a way not to have to list them one by one (this would also make it future proof, so that we would not need to add new GPU architectures)?</p> <ul> <li>AMD can confirm but I don't think there is an equivalent to <code>--gpu-architecture=all</code> for the AMD GPUs compilation.</li> <li>No, there is not, as there is no promise of backward compatibility between ISAs for the different GPUs. Typically the relevant/tested targets are listed in the build system of an application. If not set explicitly, the tools will try to determine the GPUs available on the machine where the compile job is running. The GPUs are detected by the ROCm tools <code>rocminfo</code> and <code>rocm_agent_enumerate</code>. This means that the right automatic GPU identification happens if you compile in the compute nodes. I'd say, is always a good practice to list explicitly the targets.</li> <li>On the login nodes you can \"trick\" the <code>rocm_agent_enumerator</code> by setting an environment variable (<code>ROCM_TARGET_LST</code>) that points to a file with a list of targets. These targets will then be used by hipcc.</li> </ul> </li> <li> <p>4 SIMD per CU. Does this mean that 4 wavefronts are needed to utilize the CU 100%?</p> <ul> <li>No. You have 4 x 16-wide SIMD units. The wavefront is 64 wide. Each SIMD unit takes 4 cycles to process an instruction, as you have 4 of them you can imagine that, throughput wise, you have one wavefront being computed in each cycle.<ul> <li>So the wavefront execution is splitted among the 4 SIMD units?</li> </ul> </li> <li>Correct, having said that, most likely you want several wavefronts running to enable them to hide latencies from each other. </li> </ul> </li> <li> <p>What about the support for C++17 stdpar (GPU offloading) on LUMI. Is it possible? </p> <ul> <li>Need to get back to you on that and check if the current version of clang enables that. I can say however that the thrust paradigm is supported and very much where the std::par inspiration comes from. </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#exercises","title":"Exercises","text":"<p>Exercise</p> <p>Find the instructions here</p> <ol> <li> <p>I'm just compiled the exercise vectoradd.cpp, but I'm getting the following output:     <pre><code>$ make vectoradd_hip.exe \n/opt/rocm/hip/bin/hipcc --offload-arch=gfx90a -g   -c -o vectoradd_hip.o vectoradd_hip.cpp\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\n/opt/rocm/hip/bin/hipcc --offload-arch=gfx90a vectoradd_hip.o -o vectoradd_hip.exe\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\n</code></pre>     But to my surprise I was able to submit and run the example:     <pre><code>$ srun -n 1 ./vectoradd_hip.exe System minor 0\nSystem major 9\nagent prop name \nhip Device prop succeeded \nPASSED!\n</code></pre>     The questions are: </p> <ul> <li>Is this normal? </li> <li>am I forgetting something?</li> </ul> <p>Just for reference, I have loaded my PrgEnv as follows:</p> <pre><code>$ salloc -N 1 -p small-g --gpus=1 -t 10:00 -A project_465000388\nsalloc: Pending job allocation 2907604\nsalloc: job 2907604 queued and waiting for resources\nsalloc: job 2907604 has been allocated resources\nsalloc: Granted job allocation 2907604\n$ module load rocm\n$ module load craype-accel-amd-gfx90a\n$ module load PrgEnv-amd\n</code></pre> <ul> <li> <p>These are error messages coming from Perl which I assume is used in the hipcc wrapper. This error message has little to do with our system and likely more to do with information that your client PC passes to LUMI. When I log on to LUMI I have LANG set to <code>en_US.UTF-8</code> but I remember having problems one one system (don't remember if it was LUMI) when logging in from my Mac as it tried to pass a locale that was not supported on the system I was logging on into. It is not something you will correct with loading modules.</p> </li> <li> <p>The LOCAL warnings are harmless when it comes to the code generation. I have in my SSH configuration:     <pre><code>Host lumi*\nSetEnv LC_CTYPE=\"C\"\n</code></pre></p> </li> <li>You could also try <code>export LC_ALL=en_US.utf8</code> or some other language.</li> </ul> </li> <li> <p>I get the following output when I request <code>hipcc --version</code>:      <pre><code>$ module load PrgEnv-amd\n$ module load craype-accel-amd-gfx90a\n$ module load rocm\n$ hipcc --version\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nHIP version: 5.0.13601-ded05588\nAMD clang version 14.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.0.2 22065 030a405a181176f1a7749819092f4ef8ea5f0758)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /opt/rocm-5.0.2/llvm/bin\n</code></pre></p> <ul> <li>See the previous question, it is the same issue.</li> </ul> </li> <li> <p>I'm getting annoying output from the hipify-perl.sh script</p> <pre><code>$ROCM_PATH/hip/bin/hipify-perl -inplace -print-stats  nbody-orig.cu \nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n    LANGUAGE = (unset),\n    LC_ALL = (unset),\n    LC_CTYPE = \"UTF-8\",\n    LANG = (unset)\nare supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\n  info: converted 10 CUDA-&gt;HIP refs ( error:0 init:0 version:0 device:0 context:0 module:0 memory:4 virtual_memory:0 stream_ordered_memory:0 addressing:0 stream:0 event:0 external_resource_interop:0 stream_memory:0 execution:0 graph:0 occupancy:0 texture:0 surface:0 peer:0 graphics:0 interactions:0 profiler:0 openGL:0 D3D9:0 D3D10:0 D3D11:0 VDPAU:0 EGL:0 thread:0 complex:0 library:0 device_library:0 device_function:3 include:0 include_cuda_main_header:0 type:0 literal:0 numeric_literal:2 define:0 extern_shared:0 kernel_launch:1 )\nwarning:0 LOC:91 in 'nbody-orig.cu'\nhipMemcpy 2\nhipLaunchKernelGGL 1\nhipFree 1\nhipMemcpyDeviceToHost 1\nhipMalloc 1\nhipMemcpyHostToDevice 1\n</code></pre> <p>but I can see that the script produced the expected modifications. Is there a way to correct this so I can obtain the expected output?</p> <ul> <li>See the two previous questions</li> <li>did you login from a Mac?</li> <li>setting LANGUAGE=C or something like that should fix the problem. This is a Linux issue that your LANGUAGE is not set. It was also an issue mentioned in previous days. I'd have to look up the exact syntax and variables to set. I think there was a solution posted a day or two ago that if you are on a Mac you can set something in the terminal program to set these variables.</li> </ul> </li> <li> <p>make gives error; does it need additional modules ? I sourced the setup_LUMI-G.sh</p> <ul> <li>You can use the ROCm stack directly without using the CPE modules if you want if you don't need integration with MPI etc.. There are a set of module commands at the top of the document.</li> <li>See below, the order of modules at the top of the docuement are not correct.<ul> <li>but where should the vectoradd example be made ? </li> <li>Ah, sorry, make was trying to execute vectoradd; which failed; so the build must be done one a gpu node ?</li> <li>where to do need to salloc here ?</li> <li>I made and salloc -n1 --gres=gpu:1 now; module swapped to PrgEnv-amd; make clean &amp; make vector... ; then srun -n 1 ./vector...exe; error message ierror while loading shared libraries: libamdhip64.so.5</li> </ul> </li> <li>execute module load rocm<ul> <li>okay, PASSED; thanks</li> </ul> </li> </ul> </li> <li> <p>I get the error: Lmod has detected the following error:  Cannot load module \"amd/5.0.2\" because these module(s) are loaded:     rocm</p> <ul> <li>unload rocm. I suggest to load <code>PrgEnv-amd</code></li> <li>The rocm module of the Cray PE is for use with the GNU and Cray compilers. The <code>amd</code> module is the compiler module for <code>PrgEnv-amd</code> and provides these tools already.<ul> <li>When I try 'module load PrgEnv-amd', I got the same error</li> </ul> </li> <li>Then use the universal trick in case of errors: Log out and log in again to have a proper clean shell as you've probably screwed up something in your modules. Just after login, <code>PrgEnv-amd</code> should load properly unless you screwed up something your <code>.profile</code> or <code>.bashrc</code> file.</li> <li>Another solution is to modify the LD_LIBRARY_PATH</li> <li>export LD_LIBRARY_PATH=/opt/rocm/llvm/lib:$LD_LIBRARY_PATH </li> <li>The error is because the front-end has rocm 5.0.2 and the compute node has rocm 5.1.0. Going to /opt/rocm avoids the problem. You can also compile on the compute node (srun make) and it will avoid the problem.</li> </ul> </li> <li> <p>Module swap PrgEnv-cray PrgEnv-amd causes this error ?     <pre><code>Lmod has detected the following error:  Cannot load module \"amd/5.0.2\" because these module(s) are loaded:\nrocm\n\nWhile processing the following module(s):\nModule fullname   Module Filename\n---------------   ---------------\namd/5.0.2         /opt/cray/pe/lmod/modulefiles/core/amd/5.0.2.lua\nPrgEnv-amd/8.3.3  /opt/cray/pe/lmod/modulefiles/core/PrgEnv-amd/8.3.3.lua'\n</code></pre></p> <ul> <li>same as the previous question, unload rocm. Note that PrgEnv-amd is using rocm under the hood<ul> <li>When I try 'module load PrgEnv-amd', I got the same error</li> </ul> </li> <li>Did you run <code>module unload rocm</code> first?</li> </ul> </li> <li> <p>When the command is applied <code>salloc -N 1 -p small-g --gpus=1 -t 10:00 -A project_465000388</code>, I am getting the following error message <code>salloc: error: Job submit/allocate failed: Requested node configuration is not available</code></p> <ul> <li>This works for me. Try to reset your environment see if it helps.<ul> <li>logout &amp; login again to lumi, it works fine now, thank you!</li> </ul> </li> </ul> </li> <li> <p>Can somone confirm the correct order of the module commands listed at the top of the training page. https://hackmd.io/rhopZnwTSm2xIYM3OUhwUA</p> <ul> <li> <p>Yes, indeed, the order is incorrect. Please use:     <pre><code>module rm rocm\nmodule load craype-accel-amd-gfx90a\nmodule load PrgEnv-amd\nmodule load rocm\n</code></pre></p> <p>(I have confirmed that is the right order)</p> <ul> <li>what about ? source /project/project_465000388/exercises/HPE/lumi_g.sh</li> </ul> </li> <li> <p>This file is to set SLURM, no relation with modules. And it was for the HPE exercises</p> </li> </ul> </li> <li> <p>Nob question: where are located the perl scripts to test hipify the examples?</p> <ul> <li>/opt/rocm/bin/hipify-perl They are inside ROCm bin directory </li> </ul> </li> <li> <p>I am getting errors when I try to run for instance <code>./stream</code>:     <pre><code>srun: Job xxx step creation still disabled, retrying (Requested nodes are busy)\n</code></pre>     What does it mean (I did the salloc, etc.)?</p> <ul> <li>try <code>srun -n 1 ./stream</code><ul> <li>This is what I did</li> </ul> </li> <li>was the salloc success? or maybe you wait for a free node? run: srun -n 1 hostname<ul> <li>I had the impression that I was allocated a node, but srun -n 1 hostname is stalled</li> </ul> </li> <li>ok run salloc again and wait to be sure  <ul> <li>Did everything again and now I get this error:     <pre><code>srun: error: nid005062: task 0: Segmentation fault (core dumped)\nsrun: launch/slurm: _step_signal: Terminating StepId=2908932.4\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Once I  login to LUMI, I got the following modules:     <pre><code>Currently Loaded Modules:\n  1) craype-x86-rome      3) craype-network-ofi       5) xpmem/2.4.4-2.3_9.1__gff0e1d9.shasta   7) craype/2.7.17      9) cray-mpich/8.1.18      11) PrgEnv-cray/8.3.3      13) lumi-tools/23.01 (S)\n  2) libfabric/1.15.0.0   4) perftools-base/22.06.0   6) cce/14.0.2                             8) cray-dsmml/0.2.2  10) cray-libsci/22.08.1.1  12) ModuleLabel/label (S)  14) init-lumi/0.1    (S)\n\n  Where:\n   S:  Module is Sticky, requires --force to unload or purge\n</code></pre>     Supposing that now I want to run on the GPU partition, what's the recommend modules I should load or swap? I've seen a few ways of loading the modules, but I wonder if there's one recommended way of doing that. Specifically I'd like to run a code with HIP and GPU-aware MPI. Also, what should I do if I'm to install a new library using the interactive node.</p> <ul> <li>You have a few different options. You can run with the Cray and AMD and I think the GNU Programming Environments. The modules need to loaded in the proper order or a fix used for the path to work around the different rocm paths on the front-end and the compute node. Your choice between these three options is usually driven by what your code is usually compiled with. All of them have rocm support for the HIP code. The only question is if there is an issue with GPU-aware MPI, but I think it works with all of them.</li> <li>You can enable GPU-aware MPI via <code>export MPICH_GPU_SUPPORT_ENABLED=1</code>. Check HPE slides on MPI (day 2) for more details.</li> </ul> </li> <li> <p>For Exercise 2: Code conversion from CUDA to HIP using HIPify tools (10 min) it says that <code>hipify-perl.sh is in $ROCM_PATH/hip/bin</code> however I cannot see it in <code>/opt/rocm/hip/bin</code>: is it <code>hipify-perl</code> (without <code>.sh</code>) that we should use? </p> <ul> <li>yes sorry use <code>hipify-perl</code>   -   I think this changed with ROCm versions. This version is <code>hipify-perl</code> and later ones use <code>hipify-perl.sh</code><ul> <li>could be, I will check </li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#amd-debugging-rocgdb","title":"AMD Debugging: ROCgdb","text":"<ol> <li>(How) does ROCgdb with multiple nodes/GPUS? or what are the differences to gdb4hpc in the end?<ul> <li>(Alfio) gdb4hpc enables debugging of MPI applications, then you can use it to debug GPU kernels too. For GPU, gdb4hpc uses rocgdb</li> <li>note that we do need a software update to enable GPU kernel debugging (breaking inside the kernel) with gdb4hpc at the moment</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#exercise_2","title":"Exercise","text":"<p>Exercise</p> <p>Find the instructions here Try the debugging section.</p> <p>To get the <code>saxpy.cpp</code> file:</p> <ul> <li>Get the exercise: <code>git clone https://github.com/AMD/HPCTrainingExamples.git</code></li> <li>Go to <code>HPCTrainingExamples/HIP/saxpy</code></li> </ul> <p>Also try the TUI (graphical interface) with <code>rocgdb -tui</code> interface Hint: Get an interactive session on the compute node to use the TUI interface with:  <pre><code>srun --interactive --pty [--jobid=&lt;jobid&gt;] bash\n</code></pre> which assumes that you already have an allocation with <code>salloc</code>.</p> <p>The slides of the presentation are available on LUMI at <code>/projappl/project_465000388/slides/AMD/02_Rocgdb_Tutorial.pdf</code></p> <ol> <li>Where exactly \"saxpy\" (Go to HPCTrainingExamples/HIP/saxpy) is located? in /project/project_465000388/exercises/AMD/HIP-Examples/ ?<ul> <li>Get the exercise:      <pre><code>git clone https://github.com/AMD/HPCTrainingExamples.git\n</code></pre></li> <li>Go to <code>HPCTrainingExamples/HIP/saxpy</code></li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#introduction-to-rocprof-profiling-tool","title":"Introduction to Rocprof Profiling Tool","text":"<ol> <li> <p>It is a more general question, rather than practical. Some of us participate in EU projects and utilise AMDs technology, can you suggest how we can effectively implement Digital Twin Objects $applications, using this monitoring interface? Just suggetions =&gt; We can discuss it tomorrow during the Q&amp;A!</p> <ul> <li>(Harvey) For anyone interested in CSC/LUMI connection here have a look at https://stories.ecmwf.int/finlands-csc-leads-international-partnership-to-deliver-destination-earths-climate-change-adaptation-digital-twin/index.html</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day3/#exercises_1","title":"Exercises","text":"<p>Exercise</p> <p>Find the instructions here. Try the rocprof section.</p> <p>The slides of the presentation are available on LUMI at <code>/projappl/project_465000388/slides/AMD/03_intro_rocprof.pdf</code></p> <ol> <li> <p>Can you refer where/when the \"manual\" from your colleague will be published?</p> <ul> <li>What do you mean by manual?<ul> <li>The presenter mentioned, that some of his colleagues is preparing some kind of manual about rocm profiling (probably metrics, counters, etc.). I would be interested in that, so I'm basically just asking where to look.</li> </ul> </li> </ul> </li> <li> <p>I am getting an error message that the module called \"rocminfo\" is not loaded (when \"rocprof --stats nbody-orig 65536\" is executed)</p> <ul> <li>rocminfo should be in the path, not a module. Could this be a path or environment problem? <ul> <li>rocprof --stats nbody-orig 65536     <pre><code>RPL: on '230216_180254' from '/opt/rocm-5.0.2/rocprofiler' in '/...path.../HPCTrainingExamples/HIPIFY/mini-nbody/hip'\nRPL: profiling '\"nbody-orig\" \"65536\"'\nRPL: input file ''\nRPL: output dir '/tmp/rpl_data_230216_180254_38827'\nRPL: result dir '/tmp/rpl_data_230216_180254_38827/input_results_230216_180254'\n65536, 6227.599\nTraceback (most recent call last):\nFile \"/opt/rocm-5.0.2/rocprofiler/bin/tblextr.py\", line 777, in &lt;module&gt;\n    metadata_gen(sysinfo_file, 'rocminfo')\nFile \"/opt/rocm-5.0.2/rocprofiler/bin/tblextr.py\", line 107, in metadata_gen\n    raise Exception('Could not run command: \"' + sysinfo_cmd + '\"')\nException: Could not run command: \"rocminfo\"\nProfiling data corrupted: ' /tmp/rpl_data_230216_180254_38827/input_results_230216_180254/results.txt'\n</code></pre></li> </ul> </li> <li> <p>Definitely a path problem due to the mismatch in ROCm versions. Try     <pre><code>export LD_LIBRARY_PATH=/opt/rocm/llvm/lib:$LD_LIBRARY_PATH\n</code></pre>     You can see that it is trying to load rocm 5.0.2. Loading the modules in the right order will also fix the problem. You can see this by doing a srun ls -l /opt and you will see that compute nodes have /opt/rocm-5.1.0.</p> <ul> <li>But there is only rocm/5.0.2 available, it is loaded by default (checked with module list)     Which order is correct??</li> </ul> </li> <li> <p>Try     <pre><code>module rm rocm\nmodule load craype-accel-amd-gfx90a\nmodule load PrgEnv-amd\nmodule load rocm\n</code></pre></p> </li> <li>login nodes have rocm/5.0.2, while compute nodes have rocm/5.1.0. Try <code>export PATH=/opt/rocm:$PATH</code> (same for LD_LIBRARY_PATH). Check question 19.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/","title":"Notes from the HedgeDoc page - day 4","text":"<p>These are the notes from the LUMI training, 1114-17.02.2023, 9:00--17:30 (CET) on Zoom.</p> <ul> <li>Day 1</li> <li>Day 2</li> <li>Day 3</li> <li>Day 4: This page</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day4/#introduction-to-perftools","title":"Introduction to Perftools","text":"<ol> <li> <p>A question from the first day, sorry :-) My Fortran code with OpenMP offload does not compile with -O2 (cray compiler) due to inlining issues; is it possible to quench inlining for a specific routine only? </p> <ul> <li>(Harvey) <code>man inline</code>     it might apply to whole file though so need to check, manpage might indicate this.</li> <li>The ipa compiler option (man crayftn) also affects inlining.<ul> <li>yes, I discovered it does not compile due to inling, ao I reduced to level 1, 2 gives errors as well..</li> <li>Thank you!</li> </ul> </li> <li>(Peter) Setting <code>__attribute__((noinline))</code> before the subroutine can be done in standard Clang, at least. CrayCC seems to accept it when I compile a simple program.</li> <li>It might also be worth to compile with -O2 but just turn of inlining with the appropriate compiler option (-hipa0 I believe for Fortran).</li> </ul> </li> <li> <p>Would it be possible to use a pointer / annotate / ??? to visually guide the narration through complex slides ? not sure whether technically possible</p> <ul> <li>(Harvey) It looks like Zoom does now have this capability but it has to be enabled before sharing a presentation and is embedded in menus,  I really don't want to interrupt Alfio to try this live but we will look into this.  Thanks for the suggestion.</li> <li>(not Harvey) It is certainly possible but depending on the software that is used for the presentation and the way of sharing (just a window or the whole screen) it requires additional software that the speaker may not have installed.<ul> <li>okay</li> </ul> </li> <li>It's a remark to take with us should there once again be a fully virtual course but it looks like the next two will be in-person with broadcast and then the technique that works for the room will determine how slides are broadcast.<ul> <li>thank you</li> <li>I second the suggestion/request for future courses, it was especially difficult to follow through Alfio's slides. Maybe consider a different meeting software (one more targeted at teaching like BigBlueButton which supports the pointer) in the future? At least for me on Linux it is hit-and-miss if Zoom finds my audio (no problems with BBB or jitsi or even Teams, though)</li> </ul> </li> </ul> </li> <li> <p>Is there a maximum duration of the measurement session supported, more or less?</p> <ul> <li>Not in time terms but you can use a lot of disk space with a very large number of ranks and specifically if you turn off the statistics aggregation in time.  There are controls to help here, for example only tracing a subset of the ranks or turning on and off collection at certain points.</li> </ul> </li> <li> <p>Where can I find the apprentice downloads?</p> <ul> <li>On LUMI, in <code>$CRAYPAT_ROOT/share/desktop_installers/</code> (with <code>perftools-base</code> loaded, which is loaded in the login environment)</li> <li>See also <code>module help perftools-base</code>.</li> <li>(Note that on LUMI the perftools default is the latest version installed. If you were using a system somewhere else with a newer perftools available than the default you can download the desktop installer of the latest version.)</li> <li>(Kurt) Actually the above about the default is only true at login and at the moment as currently it is indeed the latest version of the PE which is the default at login. If you load a <code>cpe</code> module of an older environmont (<code>cpe/21.12</code> for example) the default version of <code>perftools-base</code> will be the one that came with that release of the PE, and the same holds if you use the an older version of the <code>LUMI</code> software stacks.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#exercises","title":"Exercises","text":"<p>Exercise</p> <p>General remarks</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directories for this exercise: <code>perftools-lite</code>, <code>perftools-lite-gpu</code></li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file.</li> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> (GPU) or <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Exercise: </p> <ul> <li>Follow the readme and get familiar with the perftools-lite commands and outputs</li> </ul> <ol> <li> <p>Can we connect jupyternotebook on Lumi? How to set the environments?  </p> <ul> <li>Answered on Tuesday already. At your own risk at the moment, and you'll have to use ssh tunneling to connect to the Jupyter Notebook. A better solution will come when Open OnDemand is installed. Keep in mind that LUMI is not meant to be an interactive workstation, so big Jupyter sessions have to go on the compute node and it is walltime that is being billed, so you'll pay for the time that Jupyter is waiting for your input which is not a very efficient way of using a supercomputer... It is more meant to prepare data and some simple postprocessing, but doing most of the work in regular jobs.<ul> <li>Follow up: When launching Jupyter from compute nodes, is it possible to forward on the login node the ports? I tried and the SSH fails (asks for password) <code>ssh -N -L 5000:localhost:5000 -i ID_FILE uan4</code></li> </ul> </li> <li>You'd be running ssh on the client where you want to run the browser connecting to your Jupyter Notebook, loging in to one of the login nodes but doing the port forwarding to the compute node. See what happens when you use the <code>lumi-vnc</code> module on a compute node for instance. So something along the lines      <pre><code>ssh -N -L :nid001060:5000 -i ID_FILE myname@lumi.csc.fi\n</code></pre><ul> <li>Running SSH from the local machine indeed works, but we have to know the nid in advance. I was thinking to do the tunneling in two steps, first from the compute node, and then complete it from the local machine. This way it can be automated. (Yes, local machine would be remote forwarding)</li> </ul> </li> <li>That will not work, tunneling has to go in the right direction. Maybe with -R. But also be aware that the port that you want on the login node has a high chance of being taken already. The correct process is to (1) log on to LUMI and start your job that starts the Jupyter Notebook, then (2) look on what node the job is running (possible to see with Slurm commands) and (3) then start your ssh tunnel as given above.<ul> <li>Understood, thanks!</li> </ul> </li> </ul> </li> <li> <p>what exactly is \"exclusive time\" mentioned in report ?</p> <ul> <li>you have inclusive and exclusive time per each function: the latter is the amount of time spent purely in that function, excluding time spent in child functions (inclusive is the opposite).</li> </ul> </li> <li> <p>What tool is suitable for tracing memory allocations/free? </p> <ul> <li>you can use the perftools and analyse the memory traffic. Check the man page for pat_build, option -g memory (and wait for next talk on pat_build description).</li> <li>If you are more interested in debugging memory allocations then valgrind/valgrind4hpc might be more relevant</li> <li>I would be interested to detect where the allocations and frees happen (for analysing different applications, without knowing the details from source codes)<ul> <li>wrapping them would it be an option? https://stackoverflow.com/questions/262439/create-a-wrapper-function-for-malloc-and-free-in-c I think jemalloc has something similar too (no sure though), see https://github.com/jemalloc/jemalloc/wiki/Use-Case%3A-Heap-Profiling</li> </ul> </li> <li>I'm not aware of that, I'll check it, thank you</li> </ul> </li> <li> <p>Are the perftools available also outside LUMI, e.g. outside Cray environment?</p> <ul> <li>No they are not. They are designed for analysis of large scale applications in the HPE Cray EX environment, there are a lot of dependencies and assumptions (fast file system for example), I'm not sure it would be that easy to do this.</li> <li>You can get the HPE Cray PE for certain HPE servers also but it is a commercial product and I don't know the pricing. I know a non-Cray HPE cluster that has them though.<ul> <li>yes, I'm thinking about non-Cray HPE cluster. Can you reveal what is the name of that non-Cray HPE cluster with perftools installed? I think I've heard about HLRS, but not sure.</li> </ul> </li> <li>HLRS doesn't have them from what I remember (I worked on that machine two years ago). That is a cluster that was ordered before the HPE-Cray merger I believe. It has some older modules from HPE, like aan HPE MPI implementation. Unless things have changed recently. But Lucia, a very recent cluster in Belgium (and not a EuroHPC cluster), came with the HPE Cray PE so likely also perftools (I don't have an account on that machine so I cannot verify). Not sure if Karolina, one of the EuroHPC petascale systems and also an HPE system has them.<ul> <li>Karolina unfortunately doesn't have them</li> </ul> </li> </ul> </li> <li> <p>pat[WARNING][0]: performance counters are disabled because PAPI initialization failed ; perftool-lite-gpu can not measure gpu performance and hardware counters with papi together?</p> <ul> <li>This is OK, it will explained in the next presentation. LUMI doesn't allow hardware counters at the moment due to a security issue, but the rest of tracing information is fine. It is not a problem of the perftools, it is OS setup defined by LUMI system administration that does not allow performance counters (PAPI events are not available).<ul> <li>understood, thank you! papi_avail is quite martinet here.. is this so on all partitions?</li> </ul> </li> <li>LUST people can confirm, but I see that the put the kernel in paranoid mode on all compute nodes, so I would say yes... </li> <li>Indeed yes at the moment. They were disabled after some security issues were discovered.<ul> <li>Thank you!!</li> </ul> </li> </ul> </li> <li> <p>why \"pat_report expfile.lite-samples\" has no more information?</p> <ul> <li>could you elaborate more?<ul> <li>based on readme \"More information can be retrieved with pat_report expfile.lite-samples.*/\"\", but it is empty file?</li> </ul> </li> <li>OK, you are running <code>pat_report expfile.lite-samples.*/</code> and don't see the output?<ul> <li>ok now</li> </ul> </li> </ul> </li> <li> <p>my_output.lite-loops.* is empty!, I cant see any output after run?</p> <ul> <li>is it still running maybe? <ul> <li>yes, thank you</li> </ul> </li> </ul> </li> <li> <p>Can I see how many GPUs per rank from the summary and their ID? </p> <ul> <li>summary of craypat? Well, I would suggest to use the tools we presented for the affinity checking... <ul> <li>Yes and it worked perfectly thank you! But I would like to check with other tools if possible, and I guess that the kernel performances are summarized over GPUs here, maybe there is an option to resolve this information?</li> </ul> </li> <li>No sure, really. Check the man pages. If it is something we can get from rocprof, then I would say yes (assuming that craypat can do over MPI ranks). I have to check... Update: it seems it not possible, at least I cannot find anything useful for multigpus.. <ul> <li>Thank you very much! </li> </ul> </li> </ul> </li> <li> <p>There is an issue with OpenMP offload region?     <pre><code>Warnings:\nOpenMP regions included 2 regions with no end address, and\n2 regions with an invalid address range, and they were ignored.\n\nAn exit() call or a STOP statement can cause missing end addresses.\nInvalid address ranges indicate a problem with data collection.\n</code></pre></p> <ul> <li>This is a warning that it says you are using a STOP within the parallel region. Is it one of our example?<ul> <li>yes, I am in perftools-lite-gpu/ directory</li> </ul> </li> <li>This warning means that somehow the loop completed and the end address could not be recorded. If the reason is not clear by inspection of the loop (and it is hard to work out where it is) I'm afraid it needs knowledge of the perftools internals to investigate this further.</li> <li>OK, we will look into it. What matters is that you get the info you need in the profile of course.</li> </ul> </li> <li> <p>Related to the previous question on hardware counters. - if HW counters are disabled, how to identify the node-level performance efficiency (w.r.t. HW capabilities)? And follow-up: is it planned to enable the HW counters access (what timeframe if yes)?</p> <ul> <li>There is no time frame as we don't know when the security concerns that triggered disabling them will be resolved.<ul> <li>Can you please elaborate more on the security issue?</li> </ul> </li> <li>We have representatives from the LUMI Support Team here but policies around the system are set by the CSC staff managing the system and they are not represented in this training, and even then might not want to comment. If you want to make your voice heard that this capability should be enabled then you could put in a ticket.</li> <li>(Kurt) I cannot really say much as this is decided and followed up by the sysadmins, not by us. It is well known however that hardware counters can often be abused to get information about other processes running on the CPU which can be abused. But as that should have been known already when LUMI was set up and the counters were enabled initially, it appears that there has been more than that, or active exploits, that may have driven that decision. I'd hope a solution could be that some nodes are set aside with exclusive use, but maintining different settings on different nodes of the same type is always risky by itself, and it may have been decided that you could still gain crucial information about the OS... LUMI is a shared machine so we also have to take the right for privacy and the fact that we also have to cater to industrial research into account and hence that safety of data of other users is important. A shared machine always comes with compromises...</li> </ul> </li> <li> <p>Sorry, this question is still related to the CPU-GPU affinity check that I would like to run with an alternative approach than hello_jobstep. My concern is motivated by this result that I get when I check the affinity, by using a batch job and environmnet we are using for some tests on LUMI     <pre><code>Lmod is automatically replacing \"gcc/11.2.0\" with \"cce/14.0.2\".\n\nROCR_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7\nMPI 000 - OMP 000 - HWT 001 - Node nid005031 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID c1\nMPI 001 - OMP 000 - HWT 002 - Node nid005031 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID c6\nMPI 002 - OMP 000 - HWT 003 - Node nid005031 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID c9\nMPI 003 - OMP 000 - HWT 004 - Node nid005031 - RT_GPU_ID 0 - GPU_ID 0 - Bus_ID ce\n</code></pre></p> <p>Am I initializing something wrong in the environment? Do the MPI ranks see the same GPU? I see different BUS_ID</p> <ul> <li>(Alfio) Yes, indeed. These are different GPUs. What options slurm you are using?</li> <li>(Alfio) I see, you are using SLURM <code>--gpu-bind=per_task:1</code>. Although I am not sure SLURM does the right configuration, you should know that SLURM makes cgroups, so each rank gets its GPU, which has ID 0. So it seems fine. Note that in our examples we don't rely on SLURM options, but it is good you are testing the affinity program ;) (that's the goal of the entire discussion, always check!)     <pre><code>&gt; #SBATCH --job-name=myjob2             # Job name\n&gt; #SBATCH --partition=eap              # Partition (queue) name\n&gt; #SBATCH --nodes=1                    # Total number of nodes\n&gt; #SBATCH --exclusive\n&gt; #SBATCH --ntasks-per-node=4          # Number of mpi tasks per node  -8va..\n&gt; #SBATCH --cpus-per-task=1            # Number of cores (threads) per task\n&gt; #SBATCH --gpus-per-task=1\n&gt; #SBATCH --time=02:00:00              # Run time (d-hh:mm:ss)\n&gt; #SBATCH --gpu-bind=per_task:1\n</code></pre></li> <li>The ROCR runtime is enumerating the GPUS per task that are available.  So only one available and the numbering starts at 0.  You can see from the BUS ids in the output that there are different physical GPUs.<ul> <li>I compared with another job script that follows your example, and I see the same bus_id for each rank of the naive example. So the CPU-GPU affinity is suboptimal (?) [rank 0 : GPU 0 , rank 1 : GPU 1 ...]</li> </ul> </li> <li>(Alfio) same bus_id? Are you using select_gpu script? We don't rely on SLURM GPU affinity in our examples...</li> <li>I am intending to edit the acheck binding code to add GPU information, not done yet.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#advanced-performance-analysis","title":"Advanced performance analysis","text":"<ol> <li>Is there any user guide or tutorials for the advanced perftools (except the man/help pages of commands)?<ul> <li>These slides are the best material<ul> <li>Any plans?</li> </ul> </li> <li>(Alfio) https://support.hpe.com/hpesc/public/docDisplay?docId=a00114942en_us&amp;page=About_the_Performance_Analysis_Tools_User_Guide.html<ul> <li>Thank you, looks nice</li> </ul> </li> <li>There is more documentation on that site but it is a very hard one to find things on. There are, e.g., also PDF manuals.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#exercise","title":"Exercise","text":"<p>Exercise</p> <p>General remarks:</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI at <code>project/project_465000388/exercies/HPE</code></li> <li>Directory for this exercise: <code>perftools</code></li> <li>Copy the files to your home or project folder before working on the exercises.</li> <li>In some exercises you have source additional files to load the right modules necessary, check the README file.</li> <li>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000388/exercises/HPE/lumi_g.sh</code> (GPU) or <code>source /project/project_465000388/exercises/HPE/lumi_c.sh</code> (CPU)</li> </ul> <p>Exercise:</p> <ul> <li>Follow the Readme.md files in each subfolder of <code>perftools</code> and get familiar with the <code>perftools</code> commands and outputs</li> </ul>"},{"location":"4day-20230214/hedgedoc_notes_day4/#introduction-to-amd-omnitrace","title":"Introduction to AMD Omnitrace","text":"<ol> <li> <p>Related again to the hardware counter issues: Is there a workaround to get at least some basic metrics, e.g. IPC or bandwidth, with the disabled counters?</p> <ul> <li>Not that I know. Sampling-based tracing cannot generate these. I'm not sure if the kernel setting has also disabled all hardware counters on the GPUs though, worth testing.</li> <li>Omnitrace does have a variety of data collection methods including hardware counters and sampling. Some of these capabilities are still available even if hardware counters are blocked. </li> </ul> </li> <li> <p>Is ommitrace installed on LUMI as a module?</p> <ul> <li>Not yet. It is installed in a project directory for the exercises following the talk.</li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#exercise_1","title":"Exercise","text":"<p>Exercise</p> <p>Find the instructions here. Try the Omnitrace section.</p> <p>The slides of the presentation are available on LUMI at <code>/projappl/project_465000388/slides/AMD/</code></p> <ol> <li> <p>When can the users expect Omnitrace to become available? Okey, there is the easyconfig available in a branch omnitrace.</p> <ul> <li>We have two levels in the stack depending on how stable a package is, how many configurations are needed to cover all uses, and to what extent we can offer support for it. The reality is that we get requests for so many different tools that we can no longer follow it all with the central support team, let alone update it every time a new version of the PE is installed, and users would already want this to also happen more frequently.<ul> <li>The answer in the Zoom session went far from the question. Simply was asking, if you will provide the eb file. But I found it. ~~https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib/blob/omnitrace/easybuild/easyconfigs/o/omnitrace/omnitrace-1.7.3.eb~~</li> </ul> </li> <li>Yes, we are looking into it. No committed date yet, when it will be ready. The version you refer to above is not supported and in a branch where development happens.</li> <li>You can try to install it with the <code>spack</code> module also, but when I tried right now (<code>spack install omnitrace</code>) the installation failed (\"missing boost\"), likely some problem with the upstream package.py.</li> </ul> </li> <li> <p>I am having an issue trying to allocate resources <code>salloc: error: Job submit/allocate failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)</code> even trying for 10 mins allocation.</p> <ul> <li> <p>The lumi_g.sh file in the HPE exercises directory will setup Slurm for the LUMI-G nodes using the course project etc. If you have not loaded that can you share the Slurm options you used?</p> <ul> <li>Used before, with sourced the lumi_g , now after re-sourcing it returns:      <pre><code>salloc: error: Job submit/allocate failed: Requested node configuration is not available\nsalloc: Job allocation 2933626 has been revoked.\n</code></pre>     I am trying <code>salloc -N 1 -p small-g -t 120:00 -A project_465000388</code></li> </ul> </li> <li> <p>Did you have a previous salloc active? Yes and I cancelled it with <code>scancel &lt;jobid&gt;</code>.</p> </li> </ul> </li> <li> <p>I am trying \"srun -n 1 --gpus 1 omnitrace-avail --categories omnitrace\", but an error message is generated \"/project/project_465000388/software/omnitrace/1.7.3/bin/omnitrace-avail: error while loading shared libraries: libamdhip64.so.5: cannot open shared object file: No such file or directory\" +3</p> <ul> <li>some hip module missing?<ul> <li><code>module load rocm</code> seemed to fix it</li> </ul> </li> <li>yes, should be mentioned in the instructions..</li> </ul> </li> <li> <p>Is this output expected?     <pre><code>srun -n 1 omnitrace-avail -G omnitrace_all.cfg --all\n/project/project_465000388/software/omnitrace/1.7.3/bin/omnitrace-avail: /project/project_465000388/software/omnitrace/1.7.3/lib/libroctracer64.so.4: no version information available (required by /project/project_465000388/software/omnitrace/1.7.3/bin/omnitrace-avail)\n/project/project_465000388/software/omnitrace/1.7.3/bin/omnitrace-avail: /project/project_465000388/software/omnitrace/1.7.3/lib/libroctracer64.so.4: no version information available (required by /project/project_465000388/software/omnitrace/1.7.3/bin/omnitrace-avail)\n[omnitrace] /proc/sys/kernel/perf_event_paranoid has a value of 3. Disabling PAPI (requires a value &lt;= 2)...\n[omnitrace] In order to enable PAPI support, run 'echo N | sudo tee /proc/sys/kernel/perf_event_paranoid' where N is &lt;= 2\n[omnitrace][avail] No HIP devices found. GPU HW counters will not be available\n</code></pre></p> <ul> <li>I'm afraid you may not have loaded ROCm properly into your environment.</li> <li>I loaded rocm/5.0.2 module and exported the PATH and LD_LIBRARY_PATH environments as mentioned in instructions in an interactive job (salloc)</li> <li>What was your salloc command?<ul> <li>just sourced lumi_g.sh with longer walltime</li> </ul> </li> <li>(Alfio) see previous questions on hardware counters, PAPI events are not available on LUMI.    Have you added <code>--gres</code> option to allocate GPUs?<ul> <li>I'm aware of that, but not sure if related to e.g. <code>no version information available</code> or <code>No HIP devices found</code></li> <li>with <code>srun -n 1 --gres=gpu:8  omnitrace-avail -G omnitrace_all.cfg --all</code> the command hangs after the \"PAPI not supported\" lines</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#introduction-to-amd-omniperf","title":"Introduction to AMD Omniperf","text":"<ol> <li> <p>What is the issue with the GUI of OmniPerf?</p> <ul> <li> <p>It is browser based and starts a web server. The port on which the server runs is very easy to guess as the software uses a deterministic rule to try out ports, and access to the port is not protected by a password or better mechanism, so it is very easy to hack into an OmniPerf session of another user. As a support team, we do not want to take any responsibility for that so will not support it until better security in the package is in place.</p> <p>If you run the GUI on your laptop it might be best to ensure that access to your laptop is also restricted by a firewall or other people on the network you're on might be able to break into your session. </p> </li> </ul> </li> <li> <p>I find this tool very interesting, is there any HPC site supporting it? (centralized support)</p> <ul> <li>I don't know, I also cannot find the tool in the Frontier documentation so we are likely not the only one with concerns...</li> <li>ORNL has the tool they used it to many hackathons </li> <li>https://www.olcf.ornl.gov/wp-content/uploads/AMD_Hierarchical_Roofline_ORNL_10-12-22.pdf they had also an event just for roofline</li> </ul> </li> <li> <p>When I am executing \"srun -n 1 --gpus 1 omniperf profile -n vcopy_all -- ./vcopy 1048576 256\", an error is generated \"ROOFLINE ERROR: Unable to locate expected binary (/pfs/lustrep1/projappl/project_465000388/software/omniperf/bin/utils/rooflines/roofline-sle15sp3-mi200-rocm5)).\" It looks like : \"ls: cannot access '/pfs/lustrep1/projappl/project_465000388/software/omniperf/bin/utils/rooflines/roofline-sle15sp3-mi200-rocm5': Permission denied\"</p> <ul> <li>Permissions on the file are indeed wrong, I've messaged the owner of the files to change them.</li> <li>Try again please<ul> <li>yes, it works OK now</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#tools-in-action-an-example-with-pytorch","title":"Tools in Action - An Example with Pytorch","text":"<ol> <li> <p>Can we get ROCm 5.3.3 on the system?</p> <ul> <li>It is there but we cannot guarantee it will always play nicely with the HPE Cray PE nor that it will always work correctly as in the past there have been problems with hard-coded paths in some libraries etc. We cannot actively support it.</li> <li> <p>It is available in the CrayEnv or LUMI/22.08 + partition/G environments.</p> <p><pre><code>module load CrayEnv\nmodule load rocm/5.3.3\n</code></pre> or <pre><code>module load LUMI/22.08\nmodule load partition/G\nmodule load rocm/5.3.3\n</code></pre></p> <p>Note that, with MIOpen and this module, you will use the rocm installed in <code>/opt/rocm</code> for kernels JIT compilation due to some hardcoded paths in the MIOpen library.</p> </li> </ul> </li> <li> <p>This looks really interesting, can the presentation be uploaded?</p> <ul> <li>As with all presentations the video will be uploaded some time after the session. Slides should come also but they have some problems with slow upload speed from the machine from which they were trying.<ul> <li>Thanks   </li> </ul> </li> </ul> </li> <li> <p>(Harvey) Loved the srun command which flew by too fast to catch fully, I adapted it a little to avoid the hex map...     <pre><code>&gt; srun -c 7 -N 1 -n 4 bash -c 'echo \"Task $SLURM_PROCID RVD $ROCR_VISIBLE_DEVICES `taskset -c -p $$`\"' | sed 's/pid.*current //'\nTask 0 RVD 0,1,2,3,4,5,6,7 affinity list: 1-7\nTask 2 RVD 0,1,2,3,4,5,6,7 affinity list: 15-21\nTask 3 RVD 0,1,2,3,4,5,6,7 affinity list: 22-28\nTask 1 RVD 0,1,2,3,4,5,6,7 affinity list: 8-14\n</code></pre></p> </li> <li> <p>A late question on Perftools... should I use a particular approach if I compile my app with autotools? Or loading the module is enough?</p> <ul> <li>If you pass the compiler wrappers to configure script, i.e., <code>CC=cc CXX=CC FC=ftn F90=ftn</code> it should be enough to load the module. </li> <li>One small caveat: some autotools (and the same for CMake etc.) installation \"scripts\" do not follow all the conventions of those tools and in that case there can be difficulties. I have seen tools that had the compiler name or compiler options hardcoded instead of using the environment variables...<ul> <li>I confess I raised this question because I was trying measuring the application with perftools-lite, but without instrumenting and I get no report. Compiling with the module loaded fails but I did not reconfigure</li> </ul> </li> <li>Then it is rather likely you were using the system gcc, or if you were using PrgEnv-gnu it may have found that gcc. That is usually first in the search list when autotools tries to locate the compiler itselves. Which is kind of strange as the original name of the C compiler on UNIX was actually <code>cc</code> (but there was no C++ in those days, when dinosaurs like \"Mainframus Rex\" and \"Digitalus PDP\" still roamed the earth).<ul> <li>I am afraid is something nastier.. is parallel compilation discouraged with instrumentation?</li> </ul> </li> <li>For C or C++ code it would surprise me, but for fortran code parallel compilation (if you mean things like <code>make -j 16</code>) does not always work, independent from the fact that you are using instrumentation.   <ul> <li>It is Fortran.. hope sequential compilations solves, thank you for the help!</li> <li>sequential worked, at least to compile.. Can I understand somehow that the binary is instrumented? From ldd *.exe I don't know what to look for.</li> </ul> </li> <li>In a very simple Fortran test program that I tried, I see that among others <code>libpapi.so.6.0</code> is now shown in the output of <code>ldd</code> which is definitely a library that has to do with instrumentation.</li> </ul> </li> <li> <p>When we are pip installing a package that requires some compilation step using PyTorch as dependency (e.g. https://github.com/rusty1s/pytorch_scatter), what is the preferred approach to make sure that we are using the right compiler and flags for LUMI?</p> <ul> <li>There is unfortunately no fixed rule for Python. There are compilers hard-coded in a Python configuration file, but not all install scripts for <code>pip</code> look at these. Others will honour the environment variables given in the previous question. As a software installer, I despise Python as installing packages has become a complete mess with like 10 different official ways of installing packages in as many different styles of installation and yet packages that find something else to try. So it is sometimes really a case-by-case answer. And given that AI applications have a tradition of coming up with strange installation procedures...</li> <li>Please send us a ticket if you want us to have a closer look. We need more time than what such a QA provide to give you a proper answer regarding this particular package.<ul> <li>Thanks, will do! I completely agree with the broken packaging and distribution system of Python, but it seems that they are trying to amend with some recent PEPs (don't remember the numbers though).</li> </ul> </li> </ul> </li> </ol>"},{"location":"4day-20230214/hedgedoc_notes_day4/#general-qa","title":"General Q&amp;A","text":"<ol> <li> <p>For how long the access to this course account at lumi (project_465000388) and materials (in particular, to go through all exercises) will be available after the last day of the course? Do we expect to have updated instructions/ guidelines (cleaned from \"bugs\" &amp; more clearly written text) for exercises? or still to follow the older versions (and trying to find on what was/is missing and to fix somehow)?</p> <ul> <li>The data: I think for three months at least. But access to the compute time allocated to the project ends automatically at the end of the day.<ul> <li>It would be really valuable if we could run the exercises for 1-2 more days </li> <li>Agree (Thanasis) - keep it running for the weekend (+1)</li> </ul> </li> </ul> </li> <li> <p>Is this example Samuel is showing available somewhere?</p> <ul> <li>not the large example which was used to show a real application</li> <li>He promised a smaller example (easier managable) applicable to LUMI. Looking forward for that.</li> </ul> </li> <li> <p>Can we get examples from Samuel's presentation?</p> <ul> <li>I can share scripts and slides - the application would need to go with something more simple with no license issues.<ul> <li>Thanks alot</li> </ul> </li> <li>Look in <code>/project/project_465000388/slides/AMD/pytorch-based-examples</code></li> </ul> </li> <li> <p>When compiling for LUMI AMD GPU, what is the difference between the flags <code>--offload-arch=gfx90a</code> and <code>--amdgpu-target=gfx90a</code>? (sorry for the mistake)</p> <ul> <li>Answer from AMD in the session: <code>--amdgpu-target</code> is the older one that is deprecated.</li> <li>I saw it when compiling pip packages (see above) as output when <code>--debug --verbose</code> and on the frontier docs.<ul> <li>OK, thanks </li> </ul> </li> </ul> </li> <li> <p>Are there BLAS / LAPACK besides Cray LibSci available? </p> <ul> <li>Both OpenBLAS and BLIS tend to work well by themselves on LUMI (for CPU calculations), but watch out if you mix e.g. OpenBLAS and LibSci because they can contain identical symbols. Intel MKL works, in some cases, with some \"hacks\", but it can be difficult, hit and miss...<ul> <li>In which module are they included?</li> </ul> </li> <li>You can install some of them in your own home/project directory with Spack if you want, e.g. <code>spack install openblas</code>.</li> <li>And there are EasyBuild recipes for some of them also, check the LUMI Software Libary mentioned a few times over the course, but these will almost certainly cause problems when linked with other modules build with EasyBuild that employ BLAS or Lapack (but then the same would hold if you would start mixing spack generated libraries that are generated with a different BLAS and/or LAPACK library). We do not install software that so clearly can conflict with other software that we installed in the central stack.<ul> <li>Ok, thanks. </li> </ul> </li> </ul> </li> <li> <p>It would be cool to have a GH repo for the docs where we can send pull requests to.</p> <ul> <li>Our docs are hosted on GH and you can find the link in the bottom right (click on the little GH logo). https://github.com/Lumi-supercomputer/lumi-userguide/</li> <li>Pull request are of course the best but we are also grateful for issues about improvements or topics missing.<ul> <li>Very cool thanks! p.s. are typos fixes also accepted?</li> </ul> </li> <li>Sure. We will carefully review all PR and if we can support the changes, we will definitely merge it.</li> </ul> </li> <li> <p>We are porting an C++ MPI app to LUMI and getting MPI errors like:     (Cray MPI)     <pre><code>Assertion failed in file ../src/mpid/ch4/netmod/include/../ofi/ofi_events.c at line 379: dtp_ != NULL\nMPICH ERROR [Rank 1800] [job id 2932607.0] [Fri Feb 17 14:38:57 2023] [nid001179] - Abort(1): Internal error\n</code></pre>     or (AOCC)     <pre><code>MPICH ERROR [Rank 6088] [job id 2618312.0] [Sun Jan 22 20:58:44 2023] [nid001271] - Abort(404369807) (rank 6088 in comm 0): Fatal error in PMPI_Waitany: Other MPI error, error stack:\nPMPI_Waitany(277)..............: MPI_Waitany(count=13, req_array=0x2b7b970, index=0x7ffcc40da984, status=0x7ffcc40da988) failed\nPMPI_Waitany(245)..............: \nMPIDI_Progress_test(80)........: \nMPIDI_OFI_handle_cq_error(1062): OFI poll failed (ofi_events.c:1064:MPIDI_OFI_handle_cq_error:Input/output error - PTLTE_NOT_FOUND)\n</code></pre></p> <ul> <li>Please submit a ticket.<ul> <li>ok</li> </ul> </li> <li>We've had the same issue and opened a ticket but as you say the team is small and could not really dive deep because any suggestion the LUST team offered did not work. Would be interested it this problem is resolved.<ul> <li>Can you write the ticket number here, will review next week (or as per comment below)<ul> <li>\"LUMI #1059 MPICH errors\". Send by my colleague at UCL</li> </ul> </li> </ul> </li> <li> <p>This is an issue that probably requires a software upgrade that is outside the control of LUST. Sending a ticket is still useful as it help us detect recurring issues. The issue is with HPE already and discussed with the HPE person that assists the sysadmins as the OFI poll errors are very low level. They also often result from a failure on another node of your job. </p> <p>These errors are also not related to any specific compiler but come from errors that occur in layers underneath the MPI libraries.</p> </li> </ul> </li> </ol>"},{"location":"4day-20230214/schedule/","title":"Course schedule","text":"<p>All times CET.</p> <ul> <li>Day 1 <li>Day 2 <li>Day 3 <li>Day 4 DAY 1 09:00\u00a0\u00a0 Welcome and introduction Presenters: Emmanuel Ory (LUST), J\u00f8rn Dietze (LUST), Harvey Richardson (HPE) Recording 09:10 HPE Cray EX architecture Presenter: Harvey Richardson (HPE) Slide files: <code>/project/project_465000388/slides/HPE/01_EX_Architecture.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/01_Cray_EX_Architecture.mp4</code> on LUMI only. 10:10 Programming Environment and Modules Presenter: Harvey Richardson (HPE) Slide files: <code>/project/project_465000388/slides/HPE/02_PE_and_Modules.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/02_Programming_Environment_and_Modules.mp4</code> on LUMI only. 10:40 break (15 minutes) 10:55 Running Applications         <ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement (CPU/GPU/NIC)</li> </ul> Presenter: Harvey Richardson (HPE) Slide file: <code>/project/project_465000388/slides/HPE/03_Running_Applications_Slurm.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/03_Running_Applications.mp4</code> on LUMI only. 11:15 Exercises  Exercises are in <code>/project/project_465000388/exercises/HPE</code> on LUMI only.          12:00 lunch break (90 minutes) 13:30 Compilers and Parallel Programming Models          <ul> <li>An introduction to the compiler suites available, including examples of how to get additional information about the compilation process.</li> <li>Cray Compilation Environment (CCE) and options relevant to porting and performance. CCE classic to Clang transition.</li> <li>Description of the Parallel Programming models.</li> </ul> Presenter: Alfio Lazzaro (HPE) Slide files: <code>/project/project_465000388/slides/HPE/04_Compilers_and_Programming_Models.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/04_Compilers_and_Programming_Models.mp4</code> on LUMI only. 14:30 Exercises 15:00 break (30 minutes) <ul> <li>Exercises on programming models: Try swapping compilers and some GPU programs.</li> </ul> 15:30 Cray Scientific Libraries          <ul> <li>The Cray Scientific Libraries for CPU and GPU execution.</li> </ul> Presenter: Alfio Lazzaro (HPE) Slide files: <code>/project/project_465000388/slides/HPE/05_Libraries.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/05_Libraries.mp4</code> on LUMI only. 16:00 Exercises 16:45 Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)          17:30 End of the course day DAY 2 09:00 CCE Offloading Models         <ul> <li>Directive-based approach for GPU offloading execution with the Cray Compilation Environment.</li> </ul> Presenter: Alfio Lazzaro (HPE) Slide file: <code>/project/project_465000388/slides/HPE/06_Directives_Programming.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/06_Directives_programming.mp4</code> on LUMI only. 09:45 Exercises See also: <code>/project/project_465000388/slides/HPE/Exercises_alldays.pdf</code> on LUMI only. 10:15 break (30 minutes) 10:45 Advanced Placement         <ul> <li>More detailed treatment of Slurm binding technology and OpenMP controls.</li> </ul> Presenter: Jean Pourroy (HPE) Slide file: <code>/project/project_465000388/slides/HPE/07_Advanced_Placement.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/07_Advanced_Placement.mp4</code> on LUMI only. 11:40 Exercises 12:10 lunch break (65 minutes) 13:15 Understanding Cray MPI on Slingshot, rank reordering and MPMD launch         <ul> <li>High level overview of Cray MPI on Slingshot</li> <li>Useful environment variable controls</li> <li>Rank reordering and MPMD application launch</li> </ul> Presenter: Harvey Richardson (HPE) Slide file: <code>/project/project_465000388/slides/HPE/08_cray_mpi_MPMD_medium.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/08_MPI_Topics.mp4</code> on LUMI only. 14.15 Exercises 14:45 break (15 minutes) 15:00 Additional software on LUMI         <ul> <li>Software policy.</li> <li>Software environment on LUMI.</li> <li>Installing software with EasyBuild (concepts, contributed recipes)</li> <li>Containers for Python, R, VNC (container wrappers)</li> </ul> Presenter: Kurt Lust (LUST) Slides for download (PDF) Notes available Recording 16:30 LUMI support and LUMI documentation.         <ul> <li>What can we help you with and what not? How to get help, how to write good support requests.</li> <li>Some typical/frequent support questions of users on LUMI?</li> </ul> Presenter: J\u00f8rn Dietze (LUST) Recording 17:00 Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)          17:30 End of the course day DAY 3 09:00 Performance Optimization: Improving Single-core Efficiency Presenter: Jean Pourroy (HPE) Slide file: <code>/project/project_465000388/slides/HPE/09_cpu_performance_optimization.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/11_CPU_Performance_Optimization.mp4</code> on LUMI only. 09:45 Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat Presenter: Thierry Braconnier (HPE) Slide file: <code>/project/project_465000388/slides/HPE/10_debugging_at_scale.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/12_Debugging_at_Scale.mp4</code> on LUMI only. 10:10 Exercises 10:30 break 10:50 I/O Optimizing Large Scale I/O         <ul> <li>Introduction into the structure of the Lustre Parallel file system. </li> <li>Tips for optimising parallel bandwidth for a variety of parallel I/O schemes. </li> <li>Examples of using MPI-IO to improve overall application performance.</li> <li>Advanced Parallel I/O considerations</li> <li>Further considerations of parallel I/O and other APIs.</li> <li>Being nice to Lustre</li> <li>Consideration of how to avoid certain situations in I/O usage that don\u2019t specifically relate to data movement.</li> </ul> Presenter: Harvey Richardson (HPE) Slide file: <code>/project/project_465000388/slides/HPE/11_IO_medium_LUMI.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/13_IO_Optimization.mp4</code> on LUMI only. 11:40 Exercises 12:10 lunch break 13:30 Introduction to AMD ROCmTM ecosystem Presenter: George Markomanolis (AMD) Slides for download (PDF) Recording: <code>/project/project_465000388/recordings/14_Introduction_AMD_ROCm.mp4</code> on LUMI only. 14:30 Exercises Notes and exercises AMD 15:00 break 15:30 AMD Debugger: ROCgdb Presenter: Bob Robey (AMD) Slides for download (PDF) Recording: <code>/project/project_465000388/recordings/15_AMD_Rocgdb_Tutorial.mp4</code> on LUMI only. 16:05 Exercises Notes and exercises AMD 16:25 Introduction to Rocprof Profiling Tool Presenter: George Markomanolis (AMD) Slides for download (PDF) Recording: <code>/project/project_465000388/recordings/16_Introduction_Rocprof.mp4</code> on LUMI only. 16:45 Exercises Notes and exercises AMD 17:10 Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)          17:30 End of the course day DAY 4 09:00 Introduction to Perftools         <ul> <li>Overview of the Cray Performance and Analysis toolkit for profiling applications.</li> <li>Demo: Visualization of performance data with Apprentice2 Presenter: Alfio Lazzaro (HPE) Slide file: <code>/project/project_465000388/slides/HPE/12_introduction_to_perftools.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/17_Introduction_to_Perftools.mp4</code> on LUMI only. 09:40 Exercises Info about the exercises in <code>/project/project_465000388/slides/HPE/Exercises_alldays.pdf</code> on LUMI only. 10:10 break 10:30 Advanced Performance Analysis         <ul> <li>Automatic performance analysis and loop work estimated with perftools</li> <li>Communication Imbalance, Hardware Counters, Perftools API, OpenMP</li> <li>Compiler feedback and variable scoping with Reveal</li> </ul> Presenter: Thierry Braconnier (HPE) Slide file: <code>/project/project_465000388/slides/HPE/13_advanced_performance_analysis_merged.pdf</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/18_Advanced_Performance_Analysis.mp4</code> on LUMI only. 11:25 Exercises Info about the exercises in <code>/project/project_465000388/slides/HPE/Exercises_alldays.pdf</code> on LUMI only. 12:00 lunch break (90 minutes) 13:34 Introduction to OmniTools         (late start due to technical problems)         Presenter: Suyash Tandon (AMD) Slides for download (PDF) Recording: <code>/project/project_465000388/recordings/19_Introduction_to_OmniTools.mp4</code> on LUMI only. 14:20 Exercises 14:45 Introduction do AMD Omniperf Presenter: George Markomanolis (AMD) Recording: <code>/project/project_465000388/recordings/20_Introduction_to_Omniperf.mp4</code> on LUMI only. 15:20 break 15:40 Tools in Action - An Example with Pytorch         Presenter: Samuel Antao (AMD) 17:00 Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)         Some examples from the presentation: <code>/pfs/lustrep1/projappl/project_465000388/slides/AMD/pytorch-based-examples</code> on LUMI only. Recording: <code>/project/project_465000388/recordings/21_Tools_in_Action_Pytorch_Demo.mp4</code> on LUMI only. 17:30 End of the course"},{"location":"4day-20230214/software_stacks/","title":"LUMI Software Stacks","text":"<p>In this part of the training, we cover:</p> <ul> <li>Software stacks on LUMI, where we discuss the organisation of the software stacks     that we offer and some of the policies surrounding it</li> <li>Advanced Lmod use to make the best out of the software stacks</li> <li>Creating your customised environment with EasyBuild, the tool that we use to install     most software.</li> <li>Some remarks about using containers on LUMI.</li> </ul>"},{"location":"4day-20230214/software_stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"4day-20230214/software_stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: the option to use a coherent unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in Apple Silicon M-series but then without the NUMA character.</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a a talk in the     EasyBuild user meeting in 2022.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"4day-20230214/software_stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparant way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be acustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. </p> <p>We have a pre-configured Spack installation also but do not do any package development in Spack ourselves. The setup is meant for users familiar with Spack who can also solve problems that occur on the road, but we already did the work of ensuring that Spack is correctly configured for the HPE Cray compilers.</p>"},{"location":"4day-20230214/software_stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionaire send out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, the so-called Cassini provider,      so any software compiled with an MPI library that     requires UCX, or any other distributed memory model build on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intro-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions, driver versions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-bus comes to mind.</li> </ul> <p>Also, the LUNI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that has not yet been mentioned is that software that accesses tens of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. On LUMI the tool is called lumi-container-wrapper but it may by some from CSC also be known as Tykky.</p>"},{"location":"4day-20230214/software_stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using the that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 3 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes and zen3 + MI250X for the LUMI-G partition. We were also planning to have a fourth version for the visualisation nodes with  zen2 CPUs combined with NVIDIA GPUs, but that may never materialise and we may manage those differently.</p> <p>We also provide the spack modules which provide some support to install software with Spack. This stack is  meant for users who are very familiar with Spack and can deal with the problems Spack may throw at you. We have no intent to debug or modify Spack package files ourselves, but did an effort to configure Spack to use the compilers provided by the HPE Cray PE.</p> <p>In the distant future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p>"},{"location":"4day-20230214/software_stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"4day-20230214/software_stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"4day-20230214/software_stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It ia also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. E.g., the <code>PrgEnv-aocc/21.12</code> module can successfully use the <code>aocc/3.1.0</code> compilers.</p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"4day-20230214/software_stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/21.12 and LUMI/22.08 modules. Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules. There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes, partition/G for the GPU nodes and in the future we may have partition/D for the visualisation nodes.</p> <p>There is also a hidden partition/common module in which we install software that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"4day-20230214/software_stacks/#lmod-on-lumi","title":"Lmod on LUMI","text":""},{"location":"4day-20230214/software_stacks/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the small number of modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"4day-20230214/software_stacks/#module-spider-command","title":"Module spider command","text":"<p>Demo moment 1 (when infrastructure for a demo is available)</p> <p></p> <p>(The content of this slide is really meant to be shown in practice on a command line.)</p> <p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive. Let's try for instance <code>module spider gnuplot</code>. This     will show 10 versions of GNUplot. There are two installations of GNUplot 5.4.2 and eight of 5.4.3. The      remainder of the name shows us with what compilers gnuplot was compiled. The reason to have      versions for two or three compilers is that no two compiler modules can be loaded simultaneously,     and this offers a solution to use multiple tools without having to rebuild your environment for     every tool, and hence also to combine tools. </p> <p>Now try <code>module spider CMake</code>. We see that there are four versions, 3.21.2, 3.22.2, 3.23.2 and 3.24.0, but now they are shown in blue with an \"E\" behind the name. That is because there is no module called <code>CMake</code> on LUMI. Instead the tool is provided by another module that in this case contains a collection of popular build tools and that we will discover shortly.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module. Try for instance     <code>module spider gnuplot/5.4.3-cpeGNU-22.08</code>. This will now show full help information for     the specific module, including what should be done to make the module available. For      this GNUplot module we see that there are two ways to load the module: By loading <code>LUMI/22.08</code>      combined with <code>partition/C</code> or by loading <code>LUMI/22.08</code> combined with <code>partition/L</code>. So use only     a single line, but chose it in function of the other modules that you will also need. In this case     it means that that version of GNUplot is available in the <code>LUMI/22.08</code> stack which we could already     have guessed from its name, with binaries for the login and large memory nodes and the LUMI-C compute     partition. This does however not always work with the Cray Programming Environment modules.</p> <p>We can also use <code>module spider</code> with the name and version of an extension. So try <code>module spider CMake/3.24.0</code>. This will now show us that this tool is in the <code>buildtools/22.08</code> module (among others) and give us 6 different options to load that module as it is provided in the <code>CrayEnv</code> and the <code>LUMI/22.08</code> software stacks and for all partitions (basically because we don't do processor-specific optimisations for these tools).</p> </li> </ol> Demo module spider <p>Try the following commands:</p> <pre><code>module spider\nmodule spider gnuplot\nmodule spider cmake\nmodule spider gnuplot/5.4.3-cpeGNU-22.08\nmodule spider CMake/3.24.0\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"4day-20230214/software_stacks/#module-keyword-command","title":"Module keyword command","text":"<p><code>module keyword</code> will search for a module using a keyword but it is currently not very useful on LUMI because of a bug in the current version of Cray Lmod which is solved in the more recent versions. Currently the output contains a lot of irrelevant modules, basically all extensions of modules on the system.</p> <p>What <code>module keyword</code> really does is search in the module description and help for the word that  you give as an argument. Try for instance <code>module keyword quota</code> and you'll see two relevant modules, <code>lumi-workspaces</code> (which would actually show a depracation warning when you load the module) and <code>lumi-tools</code>.</p> <p>On LUMI we do try to put enough information in the module files to make this a suitable additional way to discover software that is already installed on the system, more so than in regular EasyBuild installations.</p> Demo module keyword <p>Try the following command:</p> <pre><code>module keyword quota\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"4day-20230214/software_stacks/#sticky-modules-and-module-purge","title":"Sticky modules and module purge","text":"<p>You may have been taught that <code>module purge</code> is a command that unloads all modules and on some systems they might tell you in trainings not to use it because it may also remove some basic  modules that you need to use the system. On LUMI for instance there is an <code>init-lumi</code> module that does some of the setup of the module system and should be reloaded after a normal <code>module purge</code>. On Cray systems <code>module purge</code> will also unload the target modules while those are typically not loaded by the <code>PrgEnv</code> modules so you'd need to reload them by hand before the <code>PrgEnv</code> modules would work.</p> <p>Lmod however does have the concept of \"sticky modules\". These are not unloaded by <code>module purge</code> but are re-loaded, so unloaded and almost immediately loaded again, though you can always force-unload them with <code>module --force purge</code> or <code>module --force unload</code> for individual modules.</p> Demo <p>Try the following command:</p> <pre><code>module av\n</code></pre> <p> </p> <p>Note the very descriptive titles in the above screenshot.</p> <p>The letter \"D\" next to a name denotes that this is the default version, the letter \"L\" denotes that the module is loaded, but we'll come back to  that later also.</p> <p>(Skipping a screen in the output as ther eis nothing special)</p> <p> </p> <p>Note the two categories for the PE modules. The target modules get their own block.</p> <p> </p> <p>Here we see the modules for the software stack that we have just discussed.</p> <p> </p> <p>And this screen shows the extensions of modules (like the CMake tool we've tried to locate before)</p> <p> </p> <p>At the end of the output we also get some information about the meaning of the  letters used in the display.</p> <p>Try the following commands and carefully observe the output:</p> <pre><code>module load LUMI/22.08 buildtools\nmodule list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <p>The sticky property has to be declared in the module file so we cannot add it to for instance the Cray Programming Environment target modules, but we can and do use it in some modules that we control ourselves. We use it on LUMI for the software stacks themselves and for the modules that set the display style of the modules. </p> <ul> <li>In the <code>CrayEnv</code> environment, <code>module purge</code> will clear the target     modules also but as <code>CrayEnv</code> is not just left untouched but reloaded instead, the load of <code>CrayEnv</code>     will load a suitable set of target modules for the node you're on again. But any customisations that     you did for cross-compiling will be lost. </li> <li>Similarly in the LUMI stacks, as the <code>LUMI</code> module itself     is reloaded, it will also reload a partition module. However, that partition module might not be the      one that you had loaded but it will be the one that the LUMI module deems the best for the node you're     on, and you may see some confusing messages that look like an error message but are not.</li> </ul>"},{"location":"4day-20230214/software_stacks/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed already that by default you don't see the directories in which the module files reside as is the case on many other clusters. Instead we try to show labels that tell you what that group of modules actually is. And sometimes this also combines modules from multiple directories that have the same purpose. For instance, in the default view we collapse all modules from the Cray Programming Environment in two categories, the target modules and other programming environment modules. But you can customise this by loading one of the <code>ModuleLabel</code> modules. One version, the <code>label</code> version, is the default view. But we also have <code>PEhierarchy</code> which  still provides descriptive texts but unfolds the whole hierarchy in the Cray Programming  Environment. And the third style is called <code>system</code> which shows you again the module directories.</p> Demo <p>Try the following commands:</p> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>We're also very much aware that the default colour view is not good for everybody. So far we are not  aware of an easy way to provide various colour schemes as one that is OK for people who like a black  background on their monitor might not be OK for people who prefer a white background. But it is possible to turn colour off alltogether by loading the <code>ModuleColour/off</code> module, and you can always turn it on again with <code>ModuleColour/on</code>.</p> Demo <p>Try the following commands:</p> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment. For instance, when working in the <code>LUMI/22.08</code> stack we prefer that users use the Cray programming environment modules that come with release 22.08 of that environment, and cannot guarantee compatibility of other modules with already installed software, so we hide the other ones from view. You can still load them if you know they exist but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work or to use any module that was designed for us to maintain the system.</p> Demo <p>Try the following commands:</p> <pre><code>module load LUMI/22.08\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <p>Note that we see a lot more Cray PE modules with <code>ModulePowerUser</code>!</p>"},{"location":"4day-20230214/software_stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"4day-20230214/software_stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and as including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system. We expect this to happen especially with packages that  require specific MPI versions. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And we need a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"4day-20230214/software_stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is our primary software installation tool. We selected this as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the built-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain we would have problems with MPI. EasyBuild there uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     with the classic compilers or the Intel compiler will simply optimize for a two decades old CPU.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system.  We also maintain a list of all EasyBuild recipes installed in the central stack maintained by LUST or available in the main EasyConfig repository LUMI-EasyBuild-contrib in  the LUMI Software Library.</p>"},{"location":"4day-20230214/software_stacks/#easybuild-recipes-easyconfigs","title":"EasyBuild recipes - easyconfigs","text":"<p>EasyBuild uses a build recipe for each individual package, or better said, each individual module as it is possible to install more than one software package in the same module. That installation description relies on either a generic or a specific installation process provided by an easyblock. The build recipes are called easyconfig files or simply easyconfigs are are Python files with  the extension <code>.eb</code>. </p> <p>The typical steps in an installation process are:</p> <ol> <li>Downloading sources and patches. For licensed software you may have to provide the sources as     often they cannot be downloaded automatically.</li> <li>A typical configure - build - test - install process, where the test process is optional and     depends on the package providing useable pre-installation tests.</li> <li>An extension mechanism can be used to install perl/python/R extension packages</li> <li>Then EasyBuild will do some simple checks (some default ones or checks defined in the recipe)</li> <li>And finally it will generate the module file using lots of information specified in the      EasyBuild recipe.</li> </ol> <p>Most or all of these steps can be influenced by parameters in the easyconfig.</p>"},{"location":"4day-20230214/software_stacks/#the-toolchain-concept","title":"The toolchain concept","text":"<p>EasyBuild uses the toolchain concept. A toolchain consists of compilers, an MPI implementation and some basic mathematics libraries. The latter two are optional in a toolchain. All these  components have a level of exchangeability as there are language standards, as MPI is standardised, and the math libraries that are typically included are those that provide a standard API for which several implementations exist. All these components also have in common that it is risky to combine  pieces of code compiled with different sets of such libraries and compilers because there can be conflicts in names in the libraries.</p> <p>On LUMI we don't use the standard EasyBuild toolchains but our own toolchains specifically for Cray and these are precisely the <code>cpeCray</code>, <code>cpeGNU</code>, <code>cpeAOCC</code> and <code>cpeAMD</code> modules already mentioned  before.</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p></p> <p>There is also a special toolchain called the SYSTEM toolchain that uses the compiler provided by the operating system. This toolchain does not fully function in the same way as the other toolchains when it comes to handling dependencies of a package and is therefore a bit harder to use. The EasyBuild designers had in mind that this compiler would only be used to bootstrap an EasyBuild-managed software stack, but we do use it for a bit more on LUMI as it offers us a relatively easy way to compile some packages also for the CrayEnv stack and do this in a way that they interact as little as possible with other software.</p> <p>It is not possible to load packages from different cpe toolchains at the same time. This is an EasyBuild restriction, because mixing libraries compiled with different compilers does not always work. This could happen, e.g., if a package compiled with the Cray Compiling Environment and one compiled with the GNU compiler collection would both use a particular  library, as these would have the same name and hence the last loaded one would be used by both executables (we don't use rpath or runpath linking in EasyBuild for those familiar with that technique).</p> <p>However, as we did not implement a hierarchy in the Lmod implementation of our software stack at the toolchain level, the module system will not protect you from these mistakes.  When we set up the software stack, most people in the support team considered it too misleading and difficult to ask users to first select the toolchain they want to use and then see the  software for that toolchain.</p> <p>It is however possible to combine packages compiled with one CPE-based toolchain with packages compiled with teh system toolchain, but we do avoid mixing those when linking as that may cause problems. The reason is that we try to use as much as possible static linking in the SYSTEM toolchain so that these packages are as independent as possible.</p> <p>And with some tricks it might also be possible to combine packages from the LUMI software stack with packages compiled with Spack, but one should make sure that no Spack packages are available when building as mixing libraries could cause problems. Spack uses rpath linking which is why this may work.</p>"},{"location":"4day-20230214/software_stacks/#easyconfig-names-and-module-names","title":"EasyConfig names and module names","text":"<p>There is a convention for the naming of an EasyConfig as shown on the slide. This is not mandatory, but EasyBuild will fail to automatically locate easyconfigs for dependencies  of a package that are not yet installed if the easyconfigs don't follow the naming convention. Each part of the name also corresponds to a parameter in the easyconfig  file.</p> <p>Consider, e.g., the easyconfig file <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.</p> <ol> <li>The first part of the name, <code>GROMACS</code>, is the name of the package, specified by the     <code>name</code> parameter in the easyconfig, and is after installation also the name of the     module.</li> <li>The second part, <code>2021.4</code>, is the version of GROMACS and specified by the     <code>version</code> parameter in the easyconfig.</li> <li> <p>The next part, <code>cpeCray-22.08</code> is the name and version of the toolchain,     specified by the <code>toolchain</code> parameter in the easyconfig. The version of the     toolchain must always correspond to the version of the LUMI stack. So this is     and easyconfig for installation in <code>LUMI/22.08</code>.</p> <p>This part is not present for the SYSTEM toolchain</p> </li> <li> <p>The final part, <code>-PLUMED-2.8.0-CPU</code>, is the version suffix and used to provide     additional information and distinguish different builds with different options     of the same package. It is specified in the <code>versionsuffix</code> parameter of the     easyconfig.</p> <p>This part is optional.</p> </li> </ol> <p>The version, toolchain + toolchain version and versionsuffix together also combine to the version of the module that will be generated during the installation process. Hence this easyconfig file will generate the module  <code>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.8.0-CPE</code>.</p>"},{"location":"4day-20230214/software_stacks/#installing-software","title":"Installing software","text":""},{"location":"4day-20230214/software_stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.bash_profile</code> or <code>.bashrc</code>.  This variable is not only used by the module that will load and configure EasyBuild (the EasyBuild-user module) to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"4day-20230214/software_stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>Once that environment variable is set, all you need to do to activate EasyBuild is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition.  Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p> <p>It is currently problematic for the GPU nodes as due to a misconfiguration of the system the ROCm  version is not the same on the login and GPU compute nodes, but that will hopefully be solved in the next update of the system.</p> <p></p>"},{"location":"4day-20230214/software_stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Demo moment 2</p> <p></p> <p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS we already have support. At the moment we have to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre> We now also have the LUMI Software Library which lists all software that we manage via EasyBuild and make available either preinstalled on the system or as an EasyBuild recipe for user installation.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS we do expect that GPU builds for LUMI will become available early on in the deployment of LUMI-G so we've already added a so-called version suffix to distinguish between CPU and GPU versions. To install it, we first run  <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The installation of dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb -r\n</code></pre></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p> Demo of the EasyBuild installation of GROMACS <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p>End of demo moment 2</p>"},{"location":"4day-20230214/software_stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>There is a little problem though that you may run into. Sometimes the module does not show up immediately. This is because Lmod keeps a cache when it feels that Lmod searches become too slow and often fails to detect that the cache is outdated. The easy solution is then to simply remove the cache which is in <code>$HOME/.lmod.d/.cache</code>,  which you can do with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> And we have seen some very rare cases where even that did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work. Often you also don't need to be an EasyBuild expert to adapt the build recipe to install, e.g., a slightly different version of the package that better suits your needs.</p>"},{"location":"4day-20230214/software_stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r .\n</code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.2-cpeGNU-22.08.eb -r .\n</code></pre></p>"},{"location":"4day-20230214/software_stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greates before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/easybuild/easyconfigs</code>.</p>"},{"location":"4day-20230214/software_stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory, and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software. Also, there are rare cases in which EasyBuild cannot save the sources because they are automatically downloaded during the installation procedure outside the control of EasyBuild with no way to teach EasyBuild where to download those files and place them to avoid them to be downloaded automatically. This is, e.g., often te case for software written in Rust.</p> <p>Moreover, EasyBuild also keeps copies of all installed easconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"4day-20230214/software_stacks/#easybuild-tips-tricks","title":"EasyBuild tips &amp; tricks","text":"<p>Updating the version of a package often requires only trivial changes in the easyconfig file. However, we do tend to use checksums for the sources so that we can detect if the available sources have changed. This may point to files being tampered with, or other changes that might need us to be a bit more careful when installing software and check a bit more again.  Should the checksum sit in the way, you can always disable it by using  <code>--ignore-checksums</code> with the <code>eb</code> command.</p> <p>Updating an existing recipe to a new toolchain might be a bit more involving as you also have to make build recipes for all dependencies. When we update a toolchain on the system, we often bump the versions of all installed libraries to one of the latest versions to have most bug fixes and security patches in the software stack, so you need to check for those versions also to avoid installing yet another unneeded version of a library.</p> <p>We provide documentation on the available software that is either pre-installed or can be user-installed with EasyBuild in the  LUMI Software Library. For most packages this documentation does also contain information about the license. The user documentation for some packages gives more information about how to use the package on LUMI, or sometimes also about things that do not work. The documentation also shows all EasyBuild recipes, and for many packages there is  also some technical documentation that is more geared towards users who want to build or modify recipes. It sometimes also tells why we did things in a particular way.</p>"},{"location":"4day-20230214/software_stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>I also want to give some pointers to more information in case you want to learn a lot more about, e.g., developing support for your code in EasyBuild, or for support people who want to adapt our EasyConfigs for users requesting a specific configuration of a package.</p> <p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>In the past we also organised a training for CSC staff and staff from other local support  organisations. The latest version of the training materials is currently available on klust.github.io/easybuild-tutorial.</p>"},{"location":"4day-20230214/software_stacks/#containers-on-lumi","title":"Containers on LUMI","text":"<p>Let's now switch to using containers on LUMI.  This section is about using containers on the login nodes and compute nodes.  Some of you may have heard that there were plans to also have an OpenShift Kubernetes container cloud platform for running microservices but at this point it is not clear if and when this will materialize due to a lack of manpower to get this running and then to support this.</p> <p>In this section, we will </p> <ul> <li> <p>discuss what to expect from containers on LUMI: what can they do and what can't they do,</p> </li> <li> <p>discuss how to get a container on LUMI,</p> </li> <li> <p>discuss how to run a container on LUMI,</p> </li> <li> <p>and discuss some enhancements we made to the LUMI environment that are based on containers or help     you use containers.</p> </li> </ul> <p>Remember though that the compute nodes of LUMI are an HPC infrastructure and not a container cloud!</p>"},{"location":"4day-20230214/software_stacks/#what-do-containers-not-provide","title":"What do containers not provide","text":"<p>What is being discussed in this subsection may be a bit surprising. Containers are often marketed as a way to provide reproducible science and as an easy way to transfer software from one machine to another machine. However, containers are neither of those and this becomes  very clear when using containers build on your typical Mellanox/NVIDIA InfiniBand based clusters with Intel processors and NVIDIA GPUs on LUMI.</p> <p>First, computational results are almost never 100% reproducible because of the very nature of how computers work. You can only expect reproducibility of sequential codes between equal hardware. As soon as you change the CPU type, some floating point computations may produce slightly different results, and as soon as you go parallel this may even be the case between two runs on exactly the same hardware and software.</p> <p>But full portability is a much greater myth. Containers are really only guaranteed to be portable between similar systems. They may be a little bit more portable than just a binary as you may be able to deal with missing or different libraries in the container, but that is where it stops. Containers are usually build for a particular CPU architecture and GPU architecture, two elements where everybody can easily see that if you change this, the container will not run. But  there is in fact more: containers talk to other hardware too, and on an HPC system the first piece of hardware that comes to mind is the interconnect. And they use the kernel of the host and the kernel modules and drivers provided by that kernel. Those can be a problem. A container that is not build to support the SlingShot interconnect, may fall back to TCP sockets in MPI, completely killing scalability. Containers that expect the knem kernel extension for good  intra-node MPI performance may not run as efficiently as LUMI uses xpmem instead.</p> <p>Even if a container is portable to LUMI, it may not yet be performance portable. E.g., without proper support for the interconnect it may still run but in a much slower mode. But one should also realise that speed gains in the x86 family over the years come to a large extent from adding new instructions to the CPU set, and that two processors with the same instructions set extensions may still benefit from different optimisations by the compilers.  Not using the proper instruction set extensions can have a lot of influence. At my local site we've seen GROMACS  doubling its speed by choosing proper options, and the difference can even be bigger.</p> <p>Many HPC sites try to build software as much as possible from sources to exploit the available hardware as much as  possible. You may not care much about 10% or 20% performance difference on your PC, but 20% on a 160 million EURO investment represents 32 million EURO and a lot of science can be done for that money...</p>"},{"location":"4day-20230214/software_stacks/#but-what-can-they-then-do-on-lumi","title":"But what can they then do on LUMI?","text":"<ul> <li> <p>A very important reason to use containers on LUMI is reducing the pressure on the file system by software     that accesses many thousands of small files (Python and R users, you know who we are talking about).     That software kills the metadata servers of almost any parallel file system when used at scale.</p> <p>As a container on LUMI is a single file, the metadata servers of the parallel file system have far less  work to do, and all the file caching mechanisms can also work much better.</p> </li> <li> <p>When setting up very large software environments, e.g., some Python and R environments, they can still      be very helpful, even if you may have to change some elements in your build recipes from your regular     cluster or workstation. Some software may also be simply too hard to install from sources in the     typical HPC way of working.</p> </li> <li> <p>And related to the previous point is also that some software may not even be suited for installation in     a multi-user HPC system. HPC systems want a lightweight <code>/usr</code> etc. structure as that part of the system     software is often stored in a RAM disk, and to reduce boot times. Moreover, different users may need     different versions of a software library so it cannot be installed in its default location in the system     library. However, some software is ill-behaved and doesn't allowed to be relocated to a different directory,     and in these cases containers help you to build a private installation that does not interfere with other     software on the system.</p> </li> </ul> <p>Remember though that whenever you use containers, you are the system administrator and not LUST. We can impossibly support all different software that users want to run in containers, and all possible Linux distributions they may want to run in those containers. We provide some advice on how to build a proper container, but if you chose to neglect it it is up to you to solve the problems that occur.</p>"},{"location":"4day-20230214/software_stacks/#managing-containers","title":"Managing containers","text":"<p>On LUMI, we currently support only one container runtime.</p> <p>Docker is not available, and will never be on the regular compute nodes as it requires elevated privileges to run the container which cannot be given safely to regular users of the system.</p> <p>Singularity is currently the only supported container runtime and is available on the login nodes and the compute nodes. It is a system command that is installed with the OS, so no module has to be loaded to enable it. We can also offer only a single version of singularity or its close cousin AppTainer  as singularity/AppTainer simply don't really like running multiple versions next to one another, and currently the version that we offer is determined by what is offered by the OS.</p> <p>To work with containers on LUMI you will either need to pull the container from a container registry, e.g., DockerHub, or bring in the container by copying the singularity <code>.sif</code> file.</p> <p>Singularity does offer a command to pull in a Docker container and to convert it to singularity format. E.g., to pull a container for the Julia language from DockerHub, you'd use</p> <pre><code>singularity pull docker://julia\n</code></pre> <p>Singularity uses a single flat sif file for storing containers. The <code>singularity pull</code> command does the  conversion from Docker format to the singularity format.</p> <p>Singularity caches files during pull operations and that may leave a mess of files in the <code>.singularity</code> cache directory or in <code>$XDG_RUNTIME_DIR</code> (works only on the login nodes).  The former can lead to exhaustion of your storage quota, so check and clean up from time to time. You may also want to clean up <code>$XDG_RUNTIME_DIR</code>, but this directory is also automatically cleaned when you log out from your last running session on that (login) node.</p> Demo singularity pull <p>Let's try the <code>singularity pull docker://julia</code> command:</p> <p> </p> <p>We do get a lot of warnings but usually this is perfectly normal and usually they can be safely ignored.</p> <p> </p> <p>The process ends with the creation of the file <code>jula_latest.sif</code>. </p> <p>Note however that the process has left a considerable number of files in <code>~/.singularity</code> also:</p> <p> </p> <p></p> <p>There is currently no support for building containers on LUMI and I do not expect that to change quickly. It would require enabling some features in the Linux kernel that have seen some very serious security vulnerabilities in recent years.</p> <p>So you should pull containers from a container repository, or build the container on your own workstation and then transfer it to LUMI.</p> <p>We are also working on a number of base images to build upon, where the base images are tested with the OS kernel on LUMI.</p>"},{"location":"4day-20230214/software_stacks/#interacting-with-containers","title":"Interacting with containers","text":"<p>There are basically three ways to interact with containers.</p> <p>If you have the sif file already on the system you can enter the container with an interactive shell:</p> <pre><code>singularity shell container.sif\n</code></pre> Demo singularity shell <p> </p> <p>In this screenshot we checked the contents of the <code>/opt</code> directory before and after the <code>singularity shell julia_latest.sif</code> command. This shows that we are clearly in a different environment. Checking the <code>/etc/os-release</code> file only confirms this as LUMI runs SUSE Linux on the login nodes, not a version of Debian.</p> <p>The second way is to execute a command in the container with <code>singularity exec</code>. E.g., assuming the  container has the <code>uname</code> executable installed in it,</p> <pre><code>singularity exec container.sif uname -a\n</code></pre> Demo singularity exec <p> </p> <p>In this screenshot we execute the <code>uname -a</code> command before and with the <code>singularity exec julia_latest.sif</code> command. There are some slight differences in the output though the same kernel version is reported as the container uses the host kernel. Executing</p> <pre><code>singularity exec julia_latest.sif cat /etc/os-release\n</code></pre> <p>confirms though that the commands are executed in the container.</p> <p>The third option is often called running a container, which is done with singularity run:</p> <pre><code>singularity run container.sif\n</code></pre> <p>It does require the container to have a special script that tells singularity what  running a container means. You can check if it is present and what it does with <code>singularity inspect</code>: </p> <pre><code>singularity inspect --runscript container.sif\n</code></pre> Demo singularity run <p> </p> <p>In this screenshot we start the julia interface in the container using <code>singularity run</code>. The second command shows that the contianer indeed includes a script to tell singularity what <code>singularity run</code> should do.</p> <p>You want your container to be able to interact with the files in your account on the system. Singularity will automatically mount <code>$HOME</code>, <code>/tmp</code>, <code>/proc</code>, <code>/sys</code> and <code>dev</code> in the container, but this is not enough as your home directory on LUMI is small and only meant to be used for storing program settings, etc., and not as your main work directory. (And it is also not billed and therefore no extension is allowed.) Most of the time you want to be able to access files in your project directories in <code>/project</code>, <code>/scratch</code> or <code>/flash</code>, or maybe even in <code>/appl</code>. To do this you need to tell singularity to also mount these directories in the container, either using the  <code>--bind src1:dest1,src2:dest2</code>  flag or via the <code>SINGULARITY_BIND</code> or <code>SINGULARITY_BINDPATH</code> environment variables.</p>"},{"location":"4day-20230214/software_stacks/#running-containers-on-lumi","title":"Running containers on LUMI","text":"<p>Just as for other jobs, you need to use Slurm to run containers on the compute nodes.</p> <p>For MPI containers one should use <code>srun</code> to run the <code>singularity exec</code> command, e.g,,</p> <pre><code>srun singularity exec --bind ${BIND_ARGS} \\\n${CONTAINER_PATH} mp_mpi_binary ${APP_PARAMS}\n</code></pre> <p>(and replace the environment variables above with the proper bind arguments for <code>--bind</code>, container file and parameters for the command that you want to run in the container).</p> <p>On LUMI, the software that you run in the container should be compatible with Cray MPICH, ie.e, use the MPICH ABI (currently Cray MPICH is based on MPICH 3.4). It is then possible to tell the container to use Cray MPICH (from outside the container) rather than the MPICH variant installed in the container, so that it can offer optimal performance on the LUMI SlingShot 11 interconnect.</p> <p>Open MPI containers are currently not well supported on LUMI and we do not recommend using them. We have no good solutions at the moment to run them with good performance. We only have a partial  solution for the CPU nodes, and on the GPU nodes Open MPI is very problematic at the moment. This is both due to some design issues in the design of Open MPI, and also to some piece of software that recent versions of Open MPI require but that HPE does not yet support on Cray EX systems. Open MPI has a slight preference for the UCX communication library over the OFI libraries, and  currently full GPU support requires UCX. Moreover, binaries using Open MPI often use the so-called rpath linking process so that it becomes a lot harder to inject an Open MPI library that is installed elsewhere. The good news though is that the Open MPI developers of course also want Open MPI to work on biggest systems in the USA, and all three currently operating or planned exascale systems use the SlingShot 11 interconnect so work is going on for better support for OFI and for full GPU support on systems that rely on OFI and do not support UCX.</p>"},{"location":"4day-20230214/software_stacks/#enhancements-to-the-environment","title":"Enhancements to the environment","text":"<p>To make life easier, LUST with the support of CSC did implement some modules that are either based on containers or help you run software with containers.</p> <p>The <code>singularity-bindings/system</code> module which can be installed via EasyBuild helps to set <code>SINGULARITY_BIND</code> and <code>SINGULARITY_LD_LIBRARY__PATH</code> to use  Cray MPICH. Figuring out those settings is tricky, and sometimes changes to the module are needed for a specific situation because of dependency conflicts between Cray MPICH and other software in the container, which is why we don't provide it in the standard software stacks but instead make it available as an EasyBuild recipe that you can adapt to your situation and install.</p> <p>As it needs to be installed through EasyBuild, it is really meant to be  used in the context of a LUMI software stack (so not in <code>CrayEnv</code>). To find the EasyConfig files, load the <code>EasyBuild-user</code> module and  run</p> <pre><code>eb --search singularity-bindings\n</code></pre> <p>You can also check the  page for the module in the LUMI Software Library.</p> <p></p> <p>The second tool is a container that we provide with some bash functions to start a VNC server as temporary way to be able to use some GUI programs on LUMI until the final setup which will be based on Open OnDemand is ready. It can be used in <code>CrayEnv</code> or in the LUMI stacks. The container also contains a poor men's window manager (and yes, we know that there are sometimes some problems with fonts). It is possible to connect to the VNC server either through a regular VNC client on your PC or a web browser, but in both cases you'll have to create an ssh tunnel to access the server. Try</p> <pre><code>module help lumi-vnc\n</code></pre> <p>for more information on how to use <code>lumi-vnc</code>.</p> <p>The final tool is a container wrapper tool that users from Finland may also know as Tykky. It is a tool to wrap Python and conda installations in a limited number of files in a transparent way. On LUMI, it is provided by the <code>lumi-container-wrapper</code> module which is available in the <code>CrayEnv</code> environment and in the LUMI software stacks. It is also documented in the LUMI documentation.</p> <p>The basic idea is that you run a tool to either do a conda installation or an installation of Python packages from a file that defines the environment in either standard conda format (a Yaml file) or in the <code>requirements.txt</code> format used by <code>pip</code>. </p> <p>The container wrapper will then perform the installation in a work directory, create some wrapper commands in the <code>bin</code> subdirectory of the directory where you tell the container wrapper tool to do the installation, and it will use SquashFS to create as single file that contains the conda or Python installation.</p> <p>We do strongly recommend to use the container wrapper tool for larger conda and Python installation. We will not raise your file quota if it is to house such installation in your <code>/project</code> directory.</p> Demo lumi-container-wrapper <p>Create a subdirectory to experiment. In that subdirectory, create a file named <code>env.yml</code> with the content:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.8.8\n  - scipy\n  - nglview\n</code></pre> <p>and create an empty subdirectory <code>conda-cont-1</code>.</p> <p>|Now you can follow the commands on the slides below:</p> <p> </p> <p>On the slide above we prepared the environment.</p> <p>Now lets run the command </p> <pre><code>conda-containerize new --prefix ./conda-cont-1 env.yml\n</code></pre> <p>and look at the output that scrolls over the screen. The screenshots don't show the full output as some parts of the screen get overwritten during the process:</p> <p> </p> <p>The tool will first build the conda installation in a temprorary work directory and also uses a base container for that purpose.</p> <p> </p> <p> </p> <p>The conda installation itself though is stored in a SquashFS file that is then used by the container.</p> <p> </p> <p> </p> <p>In the slide above we see the installation contains both a singularity container and a SquashFS file. They work together to get a working conda installation.</p> <p>The <code>bin</code> directory seems to contain the commands, but these are in fact scripts  that run those commands in the container with the SquashFS file system mounted in it.</p> <p> </p> <p>So as you can see above, we can simply use the <code>python3</code> command without realising what goes on behind the screen...</p> <p>The wrapper module also offers a pip-based command to build upon the Cray Python modules already present on the system</p>"},{"location":"4day-20230214/software_stacks/#conclusion-container-limitations-on-lumi-c","title":"Conclusion: Container limitations on LUMI-C","text":"<p>To conclude the information on using singularity containers on LUMI, we want to repeat the limitations:</p> <ul> <li> <p>Containers use the host's operating system kernel which is likely different and     may have different drivers and kernel extensions than your regular system.     This may cause the container to fail or run with poor performance.</p> </li> <li> <p>The LUMI hardware is almost certainly different from that of the systems on which     you may have used the container before and that may also cause problems.</p> <p>In particular a generic container may not offer sufficiently good support for the  SlingShot 11 interconnect on LUMI which requires OFI (libfabric) with the right  network provider (the so-called Cassini provider) for optimal performance. The software in the container may fall back to TCP sockets resulting in poor  performance and scalability for communication-heavy programs.</p> <p>For containers with an MPI implementation that follows the MPICH ABI the solution is often to tell it to use the Cray MPICH libraries from the system instead.</p> </li> <li> <p>Building containers is currently not supported on LUMI due to security concerns.</p> </li> </ul>"},{"location":"4day-20230214/video_00_Introduction/","title":"Welcome and introduction","text":"<p>Presenters: Emmanuel Ory (LUST), J\u00f8rn Dietze (LUST), Harvey Richardson (HPE)</p>"},{"location":"4day-20230214/video_09_LUMI_Software_Stack/","title":"Additional software on LUMI","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li>Slides (PDF)</li> <li>Notes</li> </ul>"},{"location":"4day-20230214/video_10_LUMI_User_Support/","title":"LUMI support and LUMI documentation","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p>"},{"location":"4day-20230530/","title":"Comprehensive General LUMI Training, May 30 - June 2, 2023","text":""},{"location":"4day-20230530/#course-organisation","title":"Course organisation","text":"<ul> <li> <p>Location: TalTech IT Kolled\u017e, Raja 4c, Tallinn, Estonia, room ICO-221</p> <p>Public transportation in Tallinn</p> </li> <li> <p>Original schedule (PDF)</p> <p>Dynamic schedule (adapted as the course progresses)</p> <p>The dynamic schedule also contains links to pages with information about the course materials, but   those links are also available below on this page.</p> </li> <li> <p>HedgeDoc for questions</p> </li> <li> <p>There are two Slurm reservations for the course:</p> <ul> <li>CPU nodes: <code>training_cpu</code></li> <li>GPU nodes: <code>training-gpu</code></li> </ul> </li> </ul>"},{"location":"4day-20230530/#course-materials","title":"Course materials","text":"<p>Course materials include the Q&amp;A of each session, slides when available and notes when available.</p> <p>Due to copyright issues some of the materials are only available to current LUMI users and have to be downloaded from LUMI.</p> Presentation slides notes recording Introduction / / web HPE Cray EX Architecture lumi / lumi Programming Environment and Modules lumi / lumi Running Applications lumi / lumi Exercises #1 / / / Compilers and Parallel Programming Models lumi / lumi Exercises #2 / / / Cray Scientific Libraries lumi / lumi Exercises #3 / / / CCE Offloading Models lumi / lumi Debugging at Scale lumi / lumi Exercises #4 / / / Advanced Placement lumi / lumi Exercises #5 / / / LUMI Software Stacks web web web Introduction to HIP Programming web / web Exercises #6 / / / Introduction to Perftools lumi / lumi Exercises #7 / / / Advanced Performance Analysis lumi / lumi Exercises #8 / / / MPI Topics on the HPE Cray EX Supercomputer lumi / lumi Exercises #9 / / / AMD Debugger: ROCgdb web / web Exercises #10 / / / Introduction to ROC-Profiler (rocprof) web / web Exercises #11 / / / Performance Optimization: Improving single-core Efficiency lumi / lumi Python and Frameworks lumi / lumi Exercises #12 / / / Optimizing Large Scale I/O lumi / lumi Exercises #13 / / / Introduction to OmniTrace web (until p. 61) / web Exercises #14 / / / Introduction to Omniperf web (from p. 62) / web Exercises #15 / / / Tools in Action - An Example with Pytorch web / web LUMI User Support web / web"},{"location":"4day-20230530/#making-the-exercises-after-the-course","title":"Making the exercises after the course","text":""},{"location":"4day-20230530/#hpe","title":"HPE","text":"<p>The exercise material remains available in the course archive on LUMI:</p> <ul> <li> <p>The PDF notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>The other files for the exercises in either a     bzip2-compressed tar file <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code> or     an uncompressed tar file <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code>.</p> </li> </ul> <p>To reconstruct the exercise material in your own home, project or scratch directory, all you need to do is run:</p> <pre><code>tar -xf /appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2\n</code></pre> <p>in the directory where you want to work on the exercises. This will create the <code>exercises/HPE</code> subdirectory from the training project. </p> <p>However, instead of running the <code>lumi_c.sh</code> or <code>liumi_g.sh</code> scripts that only work for the course as  they set the course project as the active project for Slurm and also set a reservation, use the <code>lumi_c_after.sh</code> and <code>lumi_g_after.sh</code> scripts instead, but first edit them to use one of your projects.</p>"},{"location":"4day-20230530/#amd","title":"AMD","text":"<p>There are online notes about the AMD exercises. A PDF print-out with less navigation features is also available and is particularly usefull should the online notes become unavailable.</p> <p>The other files for the exercises are available in  either a bzip2-compressed tar file <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD_.tar.bz2</code> or an uncompressed tar file <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code> and can also be downloaded.  ( bzip2-compressed tar download or  uncompressed tar download)</p> <p>To reconstruct the exercise material in your own home, project or scratch directory, all you need to do is run:</p> <pre><code>tar -xf /appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2\n</code></pre> <p>in the directory where you want to work on the exercises. This will create the <code>exercises/AMD</code> subdirectory from the training project. You can do so in the same directory where you installed the HPE exercises.</p> <p>The software that was installed in the training project is also available as a bzip2-compressed tar archive on LUMI as <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Software_AMD.tar.bz2</code>. You can install it in the same directory where you installed the files but beware when interpreting instructions as the path to the software installation is different now.</p> <p>Warning</p> <p>The software and exercises were tested thoroughly at the time of the course. LUMI however is in continuous evolution and changes to the system may break exercises and software</p>"},{"location":"4day-20230530/#links-to-documentation","title":"Links to documentation","text":"<p>The links to all documentation mentioned during the talks is on a separate page.</p>"},{"location":"4day-20230530/#external-material-for-exercises","title":"External material for exercises","text":"<p>Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:</p> <ul> <li>OSU benchmark</li> <li>Fortran OpenACC examples</li> <li>Fortran OpenMP examples</li> <li>Collections of examples in BabelStream</li> <li>hello_jobstep example</li> <li>Run OpenMP example in the HPE Suport Center</li> <li>ROCm HIP examples</li> </ul>"},{"location":"4day-20230530/documentation/","title":"Documentation links","text":"<p>Note that documentation, and especially web based documentation, is very fluid. Links change rapidly and were correct when this page was developed right after the course. However, there is no guarantee that they are still correct when you read this and will only be updated at the next course on the pages of that course.</p> <p>This documentation page is far from complete but bundles a lot of links mentioned during the presentations, and some more.</p>"},{"location":"4day-20230530/documentation/#web-documentation","title":"Web documentation","text":"<ul> <li> <p>HPE Cray Programming Environment web documentation has only become available in      May 2023 and is a work-in-progress. It does contain a lot of HTML-processed man pages in an easier-to-browse      format than the man pages on the system.</p> <p>The presentations on debugging and profiling tools referred a lot to pages that can be found on this web site.  The manual pages mentioned in those presentations are also in the web documentation and are the easiest way  to access that documentation.</p> </li> <li> <p>Cray PE Github account with whitepapers and some documentation.</p> </li> <li> <p>Cray DSMML - Distributed Symmetric Memory Management Library</p> </li> <li> <p>Cray Library previously provides as TPSL build instructions</p> </li> <li> <p>Clang latest version documentation (Usually for the latest version)</p> <ul> <li> <p>Clang 13.0.0 version (basis for aocc/3.2.0)</p> </li> <li> <p>Clang 14.0.0 version (basis for rocm/5.2.3 and amd/5.2.3)</p> </li> <li> <p>Clang 15.0.0 version (cce/15.0.0 and cce/15.0.1 in 22.12/23.03)</p> </li> </ul> </li> <li> <p>AMD Developer Information</p> <ul> <li> <p>AOCC 4.0 CompilerOptions Quick Reference Guide      (Version 4.0 compilers will come when the 23.05 or later CPE release gets installed on LUMI)</p> </li> <li> <p>AOCC 4.0 User Guide</p> </li> </ul> </li> <li> <p>ROCmTM documentation overview</p> <ul> <li> <p>rocminfo application for reporting system info.</p> </li> <li> <p>rocm-smi</p> </li> <li> <p>HIP porting guide</p> </li> <li> <p>ROCm Software Platform GitHub repository</p> </li> <li> <p>Libraries:</p> <ul> <li> <p>BLAS: rocBLAS and hipBLAS</p> </li> <li> <p>FFTs: rocFFT and hipFFT</p> </li> <li> <p>Random number generation: rocRAND</p> </li> <li> <p>Sparse linear algebra: rocSPARSE and hipSPARSE</p> </li> <li> <p>Iterative solvers: rocALUTION</p> </li> <li> <p>Parallel primitives: rocPRIM and hipCUB</p> </li> <li> <p>Machine Learning Libraries: MIOpen (similar to cuDNN),      Tensile (GEMM Autotuner),     RCCL (ROCm analogue of NCCL) and      Horovod (Distributed ML)</p> </li> <li> <p>Machine Learning Frameworks: Tensorflow,     Pytorch and     Caffe</p> </li> <li> <p>Machine Learning Benchmarks:     DeepBench and      MLPerf</p> </li> </ul> </li> <li> <p>Development tools:</p> <ul> <li> <p>rocgdb resources:</p> <ul> <li> <p>AMD documentation</p> </li> <li> <p>2021 presentation by Justin Chang</p> </li> <li> <p>2021 Linux Plumbers Conference presentation     with youTube video with a part of the presentation</p> </li> </ul> </li> <li> <p>rocprof profiler</p> </li> <li> <p>OmniTrace</p> </li> <li> <p>Omniperf</p> </li> </ul> </li> </ul> </li> <li> <p>HDF5 generic documentation</p> </li> <li> <p>Mentioned in the Lustre presentation: The      ExaIO project paper     \"Transparent Asynchronous Parallel I/O Using Background Threads\".</p> </li> </ul>"},{"location":"4day-20230530/documentation/#man-pages","title":"Man pages","text":"<p>A selection of man pages explicitly mentioned during the course:</p> <ul> <li> <p>Compilers</p> PrgEnv C C++ Fortran PrgEnv-cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> PrgEnv-gnu <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> PrgEnv-aocc/PrgEnv-amd - - - Compiler wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> </li> <li> <p>OpenMP in CCE</p> <ul> <li><code>man intro_openmp</code></li> </ul> </li> <li> <p>OpenACC in CCE</p> <ul> <li><code>man intro_openacc</code></li> </ul> </li> <li> <p>MPI:</p> <ul> <li> <p>MPI itself: <code>man intro_mpi</code> or <code>man mpi</code></p> </li> <li> <p>libfabric: <code>man fabric</code></p> </li> <li> <p>CXI: `man fi_cxi'</p> </li> </ul> </li> <li> <p>LibSci</p> <ul> <li> <p><code>man intro_libsci</code> and <code>man intro_libsci_acc</code></p> </li> <li> <p><code>man intro_blas1</code>,     <code>man intro_blas2</code>,     <code>man intro_blas3</code>,     <code>man intro_cblas</code></p> </li> <li> <p><code>man intro_lapack</code></p> </li> <li> <p><code>man intro_scalapack</code> and <code>man intro_blacs</code></p> </li> <li> <p><code>man intro_irt</code></p> </li> <li> <p><code>man intro_fftw3</code></p> </li> </ul> </li> <li> <p>DSMML - Distributed Symmetric Memory Management Library </p> <ul> <li><code>man intro_dsmml</code></li> </ul> </li> <li> <p>Slurm manual pages are also all on the web      and are easily found by Google, but are usually those for the latest version.</p> <ul> <li> <p><code>man sbatch</code></p> </li> <li> <p><code>man srun</code></p> </li> <li> <p><code>man salloc</code></p> </li> <li> <p><code>man squeue</code></p> </li> <li> <p><code>man scancel</code></p> </li> <li> <p><code>man sinfo</code></p> </li> <li> <p><code>man sstat</code></p> </li> <li> <p><code>man sacct</code></p> </li> <li> <p><code>man scontrol</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/documentation/#via-the-module-system","title":"Via the module system","text":"<p>Most HPE Cray PE modules contain links to further documentation. Try <code>module help cce</code> etc.</p>"},{"location":"4day-20230530/documentation/#from-the-commands-themselves","title":"From the commands themselves","text":"PrgEnv C C++ Fortran PrgEnv-cray <code>craycc --help</code> <code>crayCC --help</code> <code>crayftn --help</code> <code>craycc --craype-help</code> <code>crayCC --craype-help</code> <code>crayftn --craype-help</code> PrgEnv-gnu <code>gcc --help</code> <code>g++ --help</code> <code>gfortran --help</code> PrgEnv-aocc <code>clang --help</code> <code>clang++ --help</code> <code>flang --help</code> PrgEnv-amd <code>amdclang --help</code> <code>amdclang++ --help</code> <code>amdflang --help</code> Compiler wrappers <code>cc --help</code> <code>CC --help</code> <code>ftn --help</code> <p>For the PrgEnv-gnu compiler, the <code>--help</code> option only shows a little bit of help information, but mentions further options to get help about specific topics.</p> <p>Further commands that provide extensive help on the command line:</p> <ul> <li><code>rocm-smi --help</code>, even on the login nodes.</li> </ul>"},{"location":"4day-20230530/documentation/#documentation-of-other-cray-ex-systems","title":"Documentation of other Cray EX systems","text":"<p>Note that these systems may be configured differently, and this especially applies to the scheduler. So not all documentations of those systems applies to LUMI. Yet these web sites do contain a lot of useful information.</p> <ul> <li> <p>Archer2 documentation.      Archer2 is the national supercomputer of the UK, operated by EPCC. It is an AMD CPU-only cluster.     Two important differences with LUMI are that (a) the cluster uses AMD Rome CPUs with groups of 4 instead     of 8 cores sharing L3 cache and (b) the cluster uses Slingshot 10 instead of Slinshot 11 which has its     own bugs and workarounds.</p> <p>It includes a page on cray-python referred to during the course.</p> </li> <li> <p>ORNL Frontier User Guide and      ORNL Crusher Qucik-Start Guide.     Frontier is the first USA exascale cluster and is built up of nodes that are very similar to the     LUMI-G nodes (same CPA and GPUs but a different storage configuration) while Crusher is the     192-node early access system for Frontier. One important difference is the configuration of     the scheduler which has 1 core reserved in each CCD to have a more regular structure than LUMI.</p> </li> <li> <p>KTH Dardel documentation. Dardel is the Swedish \"baby-LUMI\" system.     Its CPU nodes use the AMD Rome CPU instead of AMD Milan, but its GPU nodes are the same as in LUMI.</p> </li> <li> <p>Setonix User Guide.     Setonix is a Cray EX system at Pawsey Supercomputing Centre in Australia. The CPU and GPU compute     nodes are the same as on LUMI.</p> </li> </ul>"},{"location":"4day-20230530/extra_1_00_Introduction/","title":"Introduction","text":"<p>Presenters: Emmanuel Ory (LUST), Harvey Richardson (HPE)</p>"},{"location":"4day-20230530/extra_1_01_HPE_Cray_EX_Architecture/","title":"HPE Cray EX Architecture","text":"<p>Presenter: Harvey Richardson (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_01_HPE_Cray_EX_Architecuture.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/01_EX_Architecture.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_01_HPE_Cray_EX_Architecture.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_1_01_HPE_Cray_EX_Architecture/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Could you elaborate what memory coherency between GPUs and CPUs means?</p> <p>Answer [Kurt] I'll ask the AMD people to comment a bit more on it during their presentation as it is something that is even unclear to the support team at the moment. There is a difference between what the hardware can do and what can be done with good performance. As the GPUs are connected through xGMI/InfinityFabric to the CPU full cache coherency is in theory possible but in practice there is a bandwidth problem so I don't think any user of LUMI has fully exploited this.</p> <p>Answer [Sam AMD] Coherency means there are some guarantees provided by the hardware and runtimes when it comes to make memory activity visible to the different resources in the system: CPUs and GPUs, as well as within the resources in each CPU and GPU. It is fair to think as memory being fully coherent accross CPU threads. When it comes to CPU and GPU memory that is still the case, though there are cases when that is true only at the synchroization points between the two devices.  It is important to distinguish between the so called coarse-grain memory and fine-grain memory. Coarse-grain memory is provided by default by the HIP runtime through its hipMalloc API whereas fine-grain memory is provided by default by the other memory allocators available on the system. For instance, it is only valid to do a system-wide atomic in fine-grained memory as course-grain memory coherency outside synchronization points is only guaranteed within a GCD (Graphics Compute Die). </p> <p>Followup [Juhan Taltech]: When thinking from the user point of view, e.g. using PyTorch, would there be some additional convenience or is this currently not yet available at 3rd party library level? There are separate instructions for moving tensors from/to differet memories.</p> <p>Answer [Sam AMD] There is no real difference in the memories - virtual address space is the same - is just in the allocators which provide different coherency semantics. E.g. if Pytorch allocates a piece of memory it has to work with its semantics. This is not different than what Pytorch has been doing for other GPU vendors. If someone uses the high-level Pytorch interface to control the placement of tensors, he/she  can trust the implementation to do the right thing, e.g. if there is coarse-grained memory being used makes sure a synchroniation or some mechanism of assuring dependencies (stream) is in place. If an implementation is making assumptions on some coherency semantic it has to make sure the allocators are correct. E.g. OpenMP requires the user to indicate unified shared memory to prevent the runtime from creating coarse-grain memory transfers.</p> <p>For completeness, the coherency mechanism between CPU-GPUs is fueled by the xGMI link hability to force the retry of a memory access in the presence of a page-fault. This is enabled by default and can be disabled per-process by doing <code>export HSA_XNACK=0</code>. Doing so will result in a seg-fault if the program tries to access physical memory on a GPU that belongs to the CPU or vice-versa.</p> </li> </ol>"},{"location":"4day-20230530/extra_1_02_Programming_Environment_and_Modules/","title":"Programming Environment and Modules","text":"<p>Presenter: Harvey Richardson (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_02_Programming_Environment_and_Modules.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/02_PE_and_Modules.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_02_Programming_Environment_and_Modules.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_1_02_Programming_Environment_and_Modules/#qa","title":"Q&amp;A","text":"<ol> <li> <p>What are the differences between <code>module</code> and <code>spack</code>? When should we install software using <code>module</code> and <code>spack</code>?</p> <p>Answer By default we install software using EasyBuild which is done via the LUMI modules. Spack is provided as an alternative without much support for those who know Spack. It is configured to use the compilers on the system, but we will not do any debugging or package development in Spack. A bit more about this in the presentation on LUMI software stacks on Wednesday afternoon (day 2). Spack can also generate module files, if you want, but it is not mandatory, and other options might be better (Spack environments or <code>spack load</code>).</p> </li> <li> <p>Regarding module load. Are <code>CDO command</code>, <code>NCO command</code>, and <code>ncview</code> modules available? If so, how can one correctly load them? Any documentation available?     seems that they are available via easy build  https://lumi-supercomputer.github.io/LUMI-EasyBuild-docs/</p> <p>Answer See the presentation on the afternoon of day 2 about how to find software on LUMI and how we deal with software and all possible configurations, and how to install with EasyBuild.</p> </li> <li> <p>What is the difference between <code>PrgEnv-xxx</code> and <code>CCE</code>?</p> <p>Answer PrgEnv-... set up the whole environment: Compiler, MPI and LibSci and the compiler wrappers. CCE is just the compiler module corresponding to PrgEnv-cray, but does not yet offer MPI, LibSci or the compiler wrappers.</p> </li> </ol>"},{"location":"4day-20230530/extra_1_03_Running_Applications/","title":"Running Applications","text":"<p>Presenter: Harvey Richardson (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_03_Running_Applications.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/03_Running_Applications_Slurm.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_03_Running_Applications.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_1_03_Running_Applications/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_1_04_Exercises_1/","title":"Exercise session 1","text":"<ul> <li> <p>Exercise materials in      <code>/project/project_465000524/exercises/HPE/day1/ProgrammingModels</code> for the lifetime of      the project and only for project members.</p> <p>See <code>/project/project_465000524/exercises/HPE/day1/ProgrammingModelExamples_SLURM.pdf</code></p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_1_04_Exercises_1/#qa","title":"Q&amp;A","text":"<ol> <li> <p>sprun command in the very end of the exercise pdf, is that a typo ?</p> <pre><code>**Answer** Yes\n</code></pre> </li> <li> <p>I have following modules loaded on a GPU node:</p> <pre><code>Currently Loaded Modules:\n  1) init-lumi/0.2     (S)   4) cce/15.0.0         7) libfabric/1.15.2.0  10) cray-libsci/22.12.1.1    13) rocm/5.2.3\n  2) lumi-tools/23.04  (S)   5) craype/2.7.19      8) craype-network-ofi  11) PrgEnv-cray/8.3.3\n  3) ModuleLabel/label (S)   6) cray-dsmml/0.2.2   9) cray-mpich/8.1.23   12) craype-accel-amd-gfx90a\n</code></pre> <p>When I compile the <code>pi_hip</code> target, I get a warning: <pre><code>No supported cpu target is set, CRAY_CPU_TARGET=x86-64 will be used.\n</code></pre> Is this ok, am I missing a module to set this variable, or should it be set manually?</p> <p>Answer Can you try with a fresh shell? I've just tried and it works: <pre><code>&gt; module load craype-accel-amd-gfx90a rocm\n&gt; make acc\ncc -o pi_openmp_device pi_openmp_device.c -fopenmp\nCC -xhip -o pi_hip pi_hip.cpp\nIn file included from pi_hip.cpp:9:\n</code></pre> Ignore the warnings...</p> </li> <li> <p>With <code>lumi_c.sh, PrgEnv-cray, craype-x86-milan, craype-accel-host</code>: C_timers/pi_mpi compiles, but running it results in:     <pre><code>MPICH ERROR [Rank 0] [job id 3605521.0] [Tue May 30 12:41:09 2023] [nid002042] - Abort(-1) (rank 0 in comm 0): MPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked\n(Other MPI error)\n\naborting job:\nMPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked\n</code></pre>     (serial and openmpi tests worked fine)</p> <p>Answer Could you list your modules? You should not use <code>craype-accel-host</code> if you are running a CPU code on LUMI_c.</p> </li> <li> <p>With <code>PrgEnv-amd, craype-x86-milan, rocm/5.2.3</code>: compilation fails because <code>CC --cray-print-opts=libs</code> returns a string which includes, among others, <code>-lsci_amd -lsci_amd,-lflangrti,-lflang,-lpgmath -ldl</code> (note the commas and missing spacs between flags) and this is seen in the error <code>ld.lld: error: unable to find library -lsci_amd,-lflangrti,-lflang,-lpgmath</code>. A workaround is to set <code>HIPCC_LINK_FLAGS_APPEND</code> manually and call <code>hipcc</code> directly, but the <code>CC</code> call should be fixed for this combo.</p> <p>Answer [Alfio HPE] I cannot reproduce this problem, could you provide the list of modules? This is what I get: <pre><code>&gt; CC --cray-print-opts=libs\n-L/opt/cray/pe/mpich/8.1.23/ofi/amd/5.0/lib -L/opt/cray/pe/mpich/8.1.23/gtl/lib \n-L/opt/cray/pe/libsci/22.12.1.1/AMD/4.0/x86_64/lib -L/opt/rocm/lib64 -L/opt/rocm/lib -L/opt/rocm/rocprofiler/lib \n-L/opt/rocm/rocprofiler/tool -L/opt/rocm/roctracer/lib -L/opt/rocm/roctracer/tool -L/opt/rocm/hip/lib \n-L/opt/cray/xpmem/2.5.2-2.4_3.20__gd0f7936.shasta/lib64 -L/opt/cray/pe/dsmml/0.2.2/dsmml//lib -lamdhip64 \n-Wl,--as-needed,-lsci_amd_mpi,--no-as-needed -Wl,--as-needed,-lsci_amd,--no-as-needed -ldl -Wl,\n--as-needed,-lmpi_amd,--no-as-needed -lmpi_gtl_hsa -Wl,--as-needed,-ldsmml,--no-as-needed -lxpmem\n</code></pre></p> <p>Reply After quite a bit of testing, I found that repeated loading of modules <code>LUMI/22.08, PrgEnv-amd, partition/G</code> sometimes ended up loading also the module <code>cray-libsci/22.08.1.1</code> which results in the broken link flags. Switching to <code>cray-libsci/22.12.1.1</code> gives the correct flags again. But indeed, it's not deterministic which combo of modules you get unless you do a force purge first.</p> <p>[Kurt] As we shall also see tomorrow this is the wrong way of using the LUMI modules. You should not use the PrgEnv-* modules with the LUMI modules unlwss you understand what is happening and you should load the partition module immediately after the LUMI module.</p> <p>Due to the way Lmod works loading modules that change the defaults such as the cpe modules and the LUMI modules should not be used in a single module statement with modules for which you want the default version without specifying any version. What you see in different behaviour is likely the result of sometimes loading in a single module call and sometimes not. It may be better to switch to using the full CPE 22.12 set though. There are a few broken links in the LibSci installation for AMD in 22.08.</p> </li> </ol>"},{"location":"4day-20230530/extra_1_05_Compilers_and_Parallel_Programming_Models/","title":"Compilers and Parallel Programming Models","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_05_Compilers_and_Parallel_Programming_Models.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/04_Compilers_and_Programming_Models.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_05_Compilers_and_Parallel_Programming_Models.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_1_05_Compilers_and_Parallel_Programming_Models/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Rocm has two backends, HIP and OpenCL that cannot be made available at the same time, i.e. the packages conflict. Could you give some background why is that and why OpenCL and HIP in Rocm cannot coexist?</p> <p>Answer [Sam AMD] I believe OpenCL and HIP supporting libraries can coexist in the system. Having the two models coexist in the same application I'll have to investigate as I didn't try that before.</p> </li> <li> <p>So what approach should one use to compile code which uses MPI, OpenMP threads (but no OpenMP offload), and HIP all in one code and in the same source code files as well?</p> <p>Answer [Sam AMD] If you are building HIP code in the source file you need to rule out GNU. I'd try with the Cray wrappers (CC) with <code>-x hip</code> to point out you want that to be interpreted as an HIP source code. Because you care about OpenMP you need to enable it with -fopenmp. You could always use the ROCm clang and link MPI in if you feel confortable with it. Order matters: <code>-fopenmp</code> needs to come prior to <code>-x hip</code>.</p> <p>Reply Currently Loaded Modules:</p> <p>``` 1) craype-accel-amd-gfx90a   3) craype/2.7.19      5) libfabric/1.15.2.0   7) cray-mpich/8.1.23       9) PrgEnv-cray/8.3.3  11) craype-x86-trento 2) cce/15.0.0                4) cray-dsmml/0.2.2   6) craype-network-ofi   8) cray-libsci/22.12.1.1  10) rocm/5.2.3 ````</p> <p>I compile with: <code>CC -g -O3 -fopenmp -x hip</code> Trying to link with: <code>CC -fopenmp --hip-link -o executable sourceobjects.o libraries</code> I get Warning: Ignoring device section hip-amdgcn-amd-amdhsa-gfx90a</p> </li> </ol>"},{"location":"4day-20230530/extra_1_06_Exercises_2/","title":"Exercise session 2","text":"<ul> <li> <p>The exercises are basically the same as in      session #1. You can now play with different     programming models and optimisation options.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_1_06_Exercises_2/#qa","title":"Q&amp;A","text":"<ol> <li> <p>I changed my environment to <code>PrgEnv-gnu</code>, and trying to run the <code>Makefile</code>, but it gave me this message <code>Makefile:7: *** Currently PrgEnv-gnu is not supported, switch to PrgEnv-cray or use Makefile.allcompilers.  Stop.</code>. Could you please guide me how to run make for the gnu?</p> <p>Answer <code>make -f Makefile.allcompilers</code></p> <p>Follow up it gave me this: <code>make: Nothing to be done for 'all'.</code></p> <p>Answer You need to get rid of the previous compilation with       <code>make -f Makefile.allcompilers clean</code></p> </li> </ol>"},{"location":"4day-20230530/extra_1_07_Cray_Scientific_Libraries/","title":"Cray Scientific Libraries","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_07_Cray_Scientific_Libraries.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/05_Libraries.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_07_Cray_Scientific_Libraries.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_1_07_Cray_Scientific_Libraries/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Is it a good practice to run converted CUDA library by HIP in AMD GPUs? if no, any other better solution?</p> <p>Answer Usually it is a good starting point, especially if you know the code. But there are differences that you should take into account to optimise the code. E.g., the \"warp size\" is 64 instead of 32.</p> </li> </ol>"},{"location":"4day-20230530/extra_1_08_Exercises_3/","title":"Exercise session 3","text":"<ul> <li> <p>See <code>/project/project_465000524/slides/HPE/Exercises.pdf</code>.     The files for the exercises are in     <code>/project/project_465000524/exercises/HPE/day1/libsci_acc</code>.</p> <p>Test with LibSci_ACC, check the different interfaces and environment variables.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_1_08_Exercises_3/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Do we still need to modify the job script? I logged in (to get a fresh shell), did <code>source lumi_g.sh</code> and submitted the script.  The LibSci_ACC automatic interface runs terminates with:     <pre><code>srun: error: nid007242: task 3: Bus error\nsrun: launch/slurm: _step_signal: Terminating StepId=3606826.1\nslurmstepd: error: *** STEP 3606826.1 ON nid007242 CANCELLED AT 2023-05-30T15:48:22 ***\nsrun: error: nid007242: tasks 0,2: Terminated\nsrun: error: nid007242: task 1: Bus error (core dumped)\n</code></pre>     Similar problem for the third run (Adding avoiding heuristics on input data).</p> <p>The run titled \"Adding MPI G2G enabled\" runs fine again, and with 8s seems faster than what was shown in the presentation.</p> <p>Update</p> <p>The <code>job.slurm</code> file for this exercise has been updated compared to this morning, after making the following changes <pre><code>25,26c25\n&lt; module load cray-libsci_acc/22.08.1.1\n&lt; export LD_LIBRARY_PATH=${CRAY_LD_LIBRARY_PATH}:${LD_LIBRARY_PATH}\n---\n&gt; module load cray-libsci_acc\n</code></pre> the problem that was mentiond above goes away.</p> </li> </ol>"},{"location":"4day-20230530/extra_1_09_Offload_CCE/","title":"CCE Offloading Models","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-1_09_Offload_CCE.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/06_Directives_Programming.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/1_09_Offload_CCE.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_2_01_Debugging_at_Scale/","title":"Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat","text":"<p>Presenter: Thierry Braconnier (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-2_01_Debugging_at_Scale.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/08_debugging_at_scale.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/2_01_Debugging_at_Scale.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_2_01_Debugging_at_Scale/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Which tool should I use /study to get an output of specific parameters or a N-dimensional field for further debugging?</p> <p>Answer [Alfio] gdb4hpc is your friend. You can print values.</p> </li> </ol>"},{"location":"4day-20230530/extra_2_02_Exercises_4/","title":"Exercise session 4","text":"<ul> <li> <p>Files for the exercises are in <code>/project/project_465000524/exercises/HPE/day2/debugging</code> for the lifetime of      the project and only for project members.</p> <p>There are <code>Readme.md</code> files in every directory.</p> </li> <li> <p>There are also more information in     <code>/project/project_465000524/slides/HPE/Exercises.pdf</code>.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_2_02_Exercises_4/#qa","title":"Q&amp;A","text":"<ol> <li> <p>I am looking at the ATP exercise. The tool looks interesting, but even for the trivial program of the exercise, I get a stack trace with &gt; 30 levels containing calls I can't make sense of (<code>crayTrInitBytesOn</code>, <code>do_lookup_x</code>, <code>__GI__IO_file_doallocate</code>). Is there a way to suppress calls to some specific libraries? Do you just ignore that output? Or do they start making sense as you get more experience with stack traces?</p> <p>Answer Asked the Cray people and there is really no way. You should just train your brain to neglect anything below MPI. It is not the most popular tool.</p> </li> <li> <p>How can i fix this error?</p> <pre><code>/training/day2/debugging/ATP&gt; stat-view atpMergedBT.dot\nTraceback (most recent call last):\n  File \"/opt/cray/pe/stat/4.11.13/lib/python3.6/site-packages/STATmain.py\", line 73, in &lt;module&gt;\n    raise import_exception\n  File \"/opt/cray/pe/stat/4.11.13/lib/python3.6/site-packages/STATmain.py\", line 40, in &lt;module&gt;\n    from STATGUI import STATGUI_main\n  File \"/opt/cray/pe/stat/4.11.13/lib/python3.6/site-packages/STATGUI.py\", line 40, in &lt;module&gt;\n    import STATview\n  File \"/opt/cray/pe/stat/4.11.13/lib/python3.6/site-packages/STATview.py\", line 55, in &lt;module&gt;\n    raise Exception('$DISPLAY is not set.  Ensure that X11 forwarding is enabled.\\n')\nException: $DISPLAY is not set.  Ensure that X11 forwarding is enabled.\n</code></pre> <p>Answer It's an X11 program so either you need an X11 server on your local PC or whatever you are using and then connect with ssh -X, but that only works well on a fast enough connection (low latency). Or you use the VNC server pRovided by the lumi-vnc module. Run</p> <pre><code>module spider lumi-vnc\nmodule spider lumi-vnc/20230110\n</code></pre> <p>for more information.</p> </li> </ol>"},{"location":"4day-20230530/extra_2_03_Advanced_Application_Placement/","title":"Advanced Placement","text":"<p>Presenter: Jean Pourroy (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-2_03_Advanced_Application_Placement.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/07_Advanced_Placement.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/2_03_Advanced_Application_Placement.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p> <p>Remark</p> <p>The <code>lumi-CPEtools</code> module (in the LUMI software stacks, see this afternoon) contains an alternative for <code>xthi</code> but not yet for the <code>hello_jobstep</code> tool.</p>"},{"location":"4day-20230530/extra_2_03_Advanced_Application_Placement/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Why is it not possible to hardcode binding on system level? Are there usecases where no binding or non-standard bindings are preffered?</p> <p>Answer We want to give the freedom to users as there are non-standard use cases. Sometimes it is better to have all threads in the same NUMA domain, sometimes you want to spread that.</p> <p>And for the GPU mapping: you'd need to ask the Slurm developers... Even getting good defaults in Slurm is hard. We'd really have to be able to always allocate in multiples of chiplets each with the matching GPU.</p> </li> </ol>"},{"location":"4day-20230530/extra_2_04_Exercises_5/","title":"Exercise session 5","text":"<ul> <li> <p>Files for the exercises are in <code>/project/project_465000524/exercises/HPE/day2/Binding</code>     and <code>/project/project_465000524/exercises/HPE/day2/gpu_perf_binding</code></p> <p>There are <code>Readme.md</code> files or PDF files with more information in the directories..</p> </li> <li> <p>There are also more information in     <code>/project/project_465000524/slides/HPE/Exercises.pdf</code>.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_2_04_Exercises_5/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_2_05_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>Presenter: Kurt Lust (LUST)</p> <ul> <li>Notes</li> <li>Slides (PDF)</li> </ul> <p>Archive on LUMI:</p> <ul> <li> <p>Slides: <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-2_05_software_stacks.pdf</code></p> </li> <li> <p>Recording: <code>/appl/local/training/4day-20230530/recordings/2_05_LUMI_Software_Stacks.mp4</code></p> </li> </ul> <p>The information in this talk is also covered by the following talks from the 1-day courses:</p> <ul> <li>Modules on LUMI</li> <li>LUMI Software Stacks</li> </ul>"},{"location":"4day-20230530/extra_2_05_LUMI_Software_Stacks/#qa","title":"Q&amp;A","text":"<ol> <li> <p>How to install a specific version of Python, e.g., 3.10, in the userspace? Is there a shortcut allowing to use EasyBuild or other wrapper?</p> <ul> <li>Kurt will talk about this later in this talk</li> <li>I see a ticket were such install has been requested. Are you the user who requested it? Not on LUMI</li> <li>OK, so, it means we have mutliple users interested in a Python 3.10 install. Can you send a ticket? I will have a look. sure, thanks!</li> <li>Take a look at cotainr which allows you to easily create a Singularity/Apptainer container containing a Conda/pip environment. On LUMI you can <code>module load LUMI</code>, <code>module load cotainr</code> to get access to cotainr.</li> </ul> </li> <li> <p>Would it be more preferable to install with <code>EasyBuild</code> than <code>Spack</code> in LUMI? or maybe both are the same without any differences?</p> <ul> <li>(Peter) This is a bit like the Emacs vs Vim debate, it depends on what you are used to, and if the software that you want is available as a package/recipe. One important difference is that the install recipes for optimized and tested software by the LUMI support team and collaborators are for EasyBuild in the <code>LUMI-Easybuild-contrib</code> repository, but on the other hand, some popular software packages like Lammps, Trilinos etc from the US exascale program (for Frontier) have good Spack packages. Generally speaking, Spack tends to be popular with people who develop their own code, whereas it is easier to \"just install\" something with Easybuild as a user, if you only want to run the software, not develop it.</li> <li>Thanks!</li> </ul> </li> <li> <p>Some easybuild packages may be quite heavy regarding ammount of files.  i.e CDO has ~21k  after building with eb.   Thats nearly quarter of file quota of a user (100k) or ~1% project  file quota (2M). In a home system only final binary is needed to do the job.  Can the final EasyBuild/   directory be cleaned up after installation, to get only minimum ammount of files to run the aplication? Or are there any hints how to deal the file quota issue after eb installation.  </p> <ul> <li>(Peter) Do you mean that the final installation 21k files? Or just that 21k files are needed during the build? The build files (in <code>/tmp</code>) are automatically cleaned by EasyBuild. In general, many files is problem with the parallel file systems. In some cases, you may have to use containers to work around this. We can, in some cases, increase the quotas, but there needs to be good reasons. I do not think that there is some automatic way to \"strip out\" files in EasyBuild, you would probably have to do it by hand. Also, when I check the Spack package for CDO, it seems to install only the binary files, so it might be possible to modify the EB install script for CDO. </li> <li>EasyBuild creates 20k new files, which are counted. If clean up is automatically done, then, yes, they are there.</li> <li>It's not CDO itself, but ecCodes that is included as a dependency. (and other 2-3 aditional softs)</li> <li>spacks seems to be the proper solution for it  if it stores only few binaries after install.</li> <li>(Peter) the CDO module is already installed on the system, but you have to load the <code>spack</code> module to see it. If that is the only thing you need, it might be enough.</li> <li>(Kurt) If EasyBuild installs that many file than it is usually because the default <code>make install</code> does so, so it is also a problem with the installation procedure of that software.</li> </ul> </li> <li> <p>What way should I go, if I want to use PyOpenCL and mpi4py? Is there a way to install it threough EasyBuild?</p> <ul> <li>(Peter) We do not have much experience with OpenCL+MPI through Python. Generally speaking, OpenCL is not well-supported on LUMI, it sort-of works, but is not so popular. My spontaneous thought is that this is something that I would try to install by hand, at first. The <code>cray-mpich</code> module on the system has a nice MPI4Py, it is probably a good start. Then I would try to build PyOpenCL myself using the OpenCL runtime and headers in <code>/opt/rocm</code>.</li> <li>(Kurt) mpi4py was discussed yesterday as a component that is included in the cray-python modules because it needs to be compiled specifically for cray-mpich. We had the OpenCL discussion yesterday also: Support is unclear and it is basically a deprecated technology...</li> </ul> </li> <li> <p>Could the documentation on https://docs.lumi-supercomputer.eu/development/compiling/prgenv/ please be clarified? It's not exactly straightforward which combos of modules one should use. It would prevent a lot of lost effort due to trying to get unsupported combinations to work...</p> <ul> <li>(Peter) It is difficult for us, and not so meaningful, to try to reproduce or recreate the full documentation for the Cray Programming Environment.</li> <li>(Alfio) Cray PE documentation is available at https://cpe.ext.hpe.com/docs/</li> <li>The comment about \"every user wants software configured the way they want\" also applies to documentation. Users wish the documentation is written is such a way it describes exactly what they need. Unfortunately, it is impossible for us to describe every use cases. As a consequence, we can only provide an overview of the available PrgEnv and target modules. However, if you have any suggestion regarding the documentation please create an issue. </li> </ul> </li> </ol>"},{"location":"4day-20230530/extra_2_06_Introduction_to_AMD_ROCm_Ecosystem/","title":"Introduction to HIP Programming","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <ul> <li> <p>Slides on the web</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-2_06_Introduction_to_AMD_ROCm_Ecosystem.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-1-intro_hip_programming.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/2_06_Introduction_to_AMD_ROCm_Ecosystem.mp4</code></p> </li> </ul> <p>Note</p> <p>ROCm 5.5 for the brave:</p> <pre><code>module purge\nmodule load CrayEnv\nmodule load PrgEnv-cray/8.3.3\nmodule load craype-accel-amd-gfx90a\nmodule load gcc/11.2.0 \n\nmodule use /pfs/lustrep2/projappl/project_462000125/samantao-public/mymodules\nmodule load suse-repo-deps\nmodule load rocm/5.5.0.lua\n</code></pre> <p>(Not provided by LUST and as it says, for the brave, problems can be expected...)</p>"},{"location":"4day-20230530/extra_2_06_Introduction_to_AMD_ROCm_Ecosystem/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Are CUDA applications using tensor cores (through cuBLAS or similar libraries) expected to translate well to HIP/ROCm code using matrix cores (AMD\u2019s equivalent to NVIDIA tensor cores)? What is the current status regarding support for matrix cores on HIP/ROCm libraries?</p> <ul> <li>Yes, the libraries support matrix cores, for example hipBLAS will use cuBLAS if you run on NVIDIA and rocBLAS if you run on AMD GPUS. Matrix cores are supported through the libraries.</li> <li>(Peter) I know that at least rocBLAS and rocWMMA have matrix core support.</li> </ul> </li> <li> <p>What are the expected numbers for hip-stream? For instance for the <code>Copy</code> I get 1280GiB/s, while peak memory bandwidth is advertised to be above 3000GiB/s (https://www.amd.com/en/products/server-accelerators/instinct-mi250x)?</p> <ul> <li>This number sounds good, peak memory is theoretical 1.6 TB/s but achievable 1.3 TB/s per GCD, if you use both GCDs, then you get double close to 2.6 TB/s. This hip-stream works for one GCD only.  It is improtant to know when we compare data to be familiar with the GCDs, if you use 1 GCD, you use actually half the GPU. See this: https://www.servethehome.com/wp-content/uploads/2022/08/AMD-MI250X-MVM-at-HC34-Floorplan.jpg in the middle there is the connection between the GCDs.</li> </ul> </li> </ol>"},{"location":"4day-20230530/extra_2_07_Exercises_6/","title":"Exercise session 6","text":"<ul> <li> <p>On-line exercise notes.</p> <p>PDF backup</p> </li> <li> <p>Exercises can be copied from <code>/project/project_465000524/exercises/AMD/HPCTrainingExamples</code>     during the lifetime of the project, only by members of the project.</p> </li> <li> <p>Exercises are archived as compressed and uncompressed tar files:</p> <ul> <li> <p>Web download .tar.bz2     or web download .tar</p> </li> <li> <p>On LUMI:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2</code></li> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_2_07_Exercises_6/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_01_Introduction_to_Perftools/","title":"Introduction to Perftools","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-3_01_Introduction_to_Perftools.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/09_introduction_to_perftools.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/3_01_Introduction_to_Perftools.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p> <p>Info</p> <p>You can find the downloads of Apprentice2 and Reveal on LUMI in <code>$CRAYPAT_ROOT/share/desktop_installers/</code>. This only works when the <code>perftools-base</code> module is loaded, but this is the case at login.</p>"},{"location":"4day-20230530/extra_3_01_Introduction_to_Perftools/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_02_Exercises_7/","title":"Exercise session 7","text":"<ul> <li> <p>See <code>/project/project_465000524/slides/HPE/Exercises.pdf</code> for the exercises.</p> </li> <li> <p>Files are in      <code>/project/project_465000524/exercises/HPE/day3</code></p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_3_02_Exercises_7/#qa","title":"Q&amp;A","text":"<ol> <li> <p>I tried perfools-lite on another example and got the following message from pat-report:</p> <pre><code>Observation:  MPI Grid Detection\n\n    There appears to be point-to-point MPI communication in a 4 X 128\n    grid pattern. The 24.6% of the total execution time spent in MPI\n    functions might be reduced with a rank order that maximizes\n    communication between ranks on the same node. The effect of several\n    rank orders is estimated below.\n\n    No custom rank order was found that is better than the RoundRobin\n    order.\n\n    Rank Order    On-Node    On-Node  MPICH_RANK_REORDER_METHOD\n                 Bytes/PE  Bytes/PE%\n                            of Total\n                            Bytes/PE\n\n    RoundRobin  1.517e+11    100.00%  0\n          Fold  1.517e+11    100.00%  2\n           SMP  0.000e+00      0.00%  1\n</code></pre> <p>Normally for this code, SMP rank ordering should make sure that collective communication is all intra-node and inter-node communication is limited to point-to-point MPI calls. So I don't really get why the recommendation is to switch to RoundRobin (if I understand this remark correctly)? Is this recommendation only based on analysing point-to-point communication?</p> <p>Answer: Yes, you understood the remark correctly. This warning means that Cray PAT detected a suboptimal communication topology and according to the tool estimate, a round-robin rank ordering should maximize intra-node communications. There is a session about that at the beginning of the afternoon.</p> <p>Reply: I would be very surprised if round-robin rank ordering would be beneficial in this case. I tried to run a job with it, but this failed with:</p> <p><pre><code>srun: error: task 256 launch failed: Error configuring interconnect\n</code></pre> and similar lines for each task. The job script looks as follows:</p> <pre><code>module load LUMI/22.12 partition/C\nmodule load cpeCray/22.12\nmodule load cray-hdf5-parallel/1.12.2.1\nmodule load cray-fftw/3.3.10.3\n\nexport MPICH_RANK_REORDER_METHOD=0\nsrun ${executable}\n</code></pre> </li> </ol>"},{"location":"4day-20230530/extra_3_03_Advanced_Performance_Analysis/","title":"Advanced Performance Analysis","text":"<p>Presenter: Thierry Braconnier (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-3_03_Advanced_Performace_analysis.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/10_advanced_performance_analysis_merged.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/3_03_Advanced_Performance_Analysis.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_3_03_Advanced_Performance_Analysis/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Do I get it right that perftool  can actually point/suggest me the code  which will improve /benefit from GPUs?</p> <p>Answer: Not quite. Performance analysis is a pre-requisite for any optimization work. If the code spends a lot of time in MPI or I/O then concentrate on that. If you can identify areas of the code where computation is significant then think about taking those to the GPU.</p> </li> </ol>"},{"location":"4day-20230530/extra_3_04_Exercises_8/","title":"Exercise session 8","text":"<ul> <li> <p>See <code>/project/project_465000524/slides/HPE/Exercises.pdf</code> for the exercises.</p> </li> <li> <p>Files are in      <code>/project/project_465000524/exercises/HPE/day3</code></p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_3_04_Exercises_8/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Do I get it right that perftool  can actually point/suggest me the code  which will improve /benefit from GPUs?</p> <ul> <li>Not quite. Performance analysis is a pre-requisite for any optimization work. If the code spends a lot of time in MPI or I/O then concentrate on that. If you can identify areas of the code where computation is significant then think about taking those to the GPU. /thansk, got the discussion/</li> </ul> </li> <li> <p><code>MPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked</code> while running the python example (perftools-python)</p> <ul> <li>Are you compiling without the compiler wrappers, there is an extra library that needs to be linked otherwise.</li> <li>No compilation is involved as I run a Python script. It is odd that there is something \"compiler\"-related jumps out.</li> <li>Are you using mpi4py from cray-python?</li> <li><code>time srun -n 4 pat_run `which python` heat-p2p.py</code>, ah, yes, in the imports. <code>from mpi4py import MPI</code></li> <li>Are you online (remote) or in the room? online</li> <li>For GPU applications built without the wrappers you need libraries from here ${PE_MPICH_GTL_DIR_amd_gfx90a} ${PE_MPICH_GTL_LIBS_amd_gfx90a} I need to get that gtl library, I need to get Alfio to look. (Alfio is looking but has network issue at the moment)</li> <li>(Alfio) By any chance, do you have the MPICH_GPU_SUPPORT_ENABLED set? no idea, will check ... yes. Should I unset it?      yes, this is for G2G MPI. There is a way to preload the library in python, if needed.  </li> <li>Works, thanks!</li> <li>The issue here is that this envar tells the MPI you want to do GPU to GPU communication avoiding the cpu and to do that it needs this extra library.  As Alfo notes this needs special setup in python to get this library. Glad this fixed it. We will talk a little </li> <li>more about python in a later session.</li> </ul> <p>Comment: Hei! I would like to emphasize that Python is a rapidly developing language, which warrants fast version changes. As the language evolves, it introduces new features that users may want to use for their benefit. It also introduces backward incompatibility, as always. I see it as important that users have a choice of versions already as modules (userspace Python is a possibility, but a rather ugly one). The idea applies not only to the training but to LUMI in general.</p> <p>Answer to the comment: As long as Python does not have decent version management and decent package management what you ask is simply impossible. The Python community turned  Python into a complete mess. Breaking compatibility with older code every 18 months is just a crazy idea. It turns Python in an unstable platform. So users using it should be prepared to deal with an unstable platform that cannot be properly supported. Or just look at the extremely poor code management in crucial projects such as NumPy. If you're looking for an example for a computer science course about how to make something that is unsupportable, NumPy is your perfect example. You don't realise how much time people who work on software installation tools lose with each version trying to get that package to work properly on new platforms. In that light it is not surprising the the version that HPE Cray can provide to us is a bit behind the leading edge. Maybe the Python community should learn how to manage a project in an enterprise quality way if they want enterprise quality support for their tools.</p> <p>By the way, I don't know if we mean the same thing with \"user space software installation\", but as on an HPC cluster the amount of software that can be installed in the system image is very limited almost all software is installed in \"user space\", so an application that cannot be properly installed in \"user space\" is not suited for an HPC cluster. E.g., potential compatibility problems with new system software is not the only reason why we don't keep old versions of the PE on the system.</p> <p>Pure Python is also extremely inefficient and all efforts to make a proper JIT platform for Python so far have failed. All work only in a few cases. Now that we are in a era where transistors don't become cheaper anymore so it is no longer possible to get more performance in the next machine by using more transistors without raising budgets considerably, it is actually becoming important to look at better languages that can actually run efficiently.</p> <p>(Harvey) I think is is more a discussion for the pub</p> <p>(Philipp) I agree. I am old enough to witness 2.95 to 3.x transition in GCC, which makes me softer in these matters. Nevertheless, there is no right answer, indeed.</p> </li> </ol>"},{"location":"4day-20230530/extra_3_05_Cray_MPI_on_Slingshot/","title":"MPI Topics on the HPE Cray EX Supercomputer","text":"<p>Presenter: Harvey Richardson (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-3_05_Cray_MPI_on_Slingshot.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/11_cray_mpi_MPMD_medium.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/3_05_Cray_MPI_on_Slingshot.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_3_05_Cray_MPI_on_Slingshot/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_06_Exercises_9/","title":"Exercise session 9","text":"<ul> <li> <p>Continue with the previous exercises or go back to any of the former     examples (e.g., the ProgrammingModels one) and try out the material of      the talk.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_3_06_Exercises_9/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_07_AMD_ROCgdb_Debugger/","title":"AMD ROCgdb debugger","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <ul> <li> <p>Slides on the web</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-3_07_AMD_ROCgdb_Debugger.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-2-rocgdb-tutorial.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/3_07_AMD_ROCgdb_Debugger.mp4</code></p> </li> </ul>"},{"location":"4day-20230530/extra_3_07_AMD_ROCgdb_Debugger/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_08_Exercises_10/","title":"Exercise session 10","text":"<ul> <li> <p>On-line exercise notes.</p> <p>PDF backup</p> </li> <li> <p>Exercises can be copied from <code>/project/project_465000524/exercises/AMD/HPCTrainingExamples</code></p> </li> <li> <p>Exercises are archived as compressed and uncompressed tar files:</p> <ul> <li> <p>Web download .tar.bz2     or web download .tar</p> </li> <li> <p>On LUMI:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2</code></li> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_3_08_Exercises_10/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_3_09_Introduction_to_Rocprof_Profiling_Tool/","title":"Introduction to ROC-Profiler (rocprof)","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <ul> <li> <p>Slides on the web</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-3_09_Introduction_to_Rocprof_Profiling_Tool.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-2-intro_rocprof.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/3_09_Introduction_to_Rocprof_Profiling_Tool.mp4</code></p> </li> </ul> <p>Note</p> <p>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but  a browser application. Some browsers nowadays offer the option to install it on your system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</p>"},{"location":"4day-20230530/extra_3_09_Introduction_to_Rocprof_Profiling_Tool/#qa","title":"Q&amp;A","text":""},{"location":"4day-20230530/extra_3_10_Exercises_11/","title":"Exercise session 11","text":"<ul> <li> <p>On-line exercise notes.</p> <p>PDF backup</p> </li> <li> <p>Exercises can be copied from <code>/project/project_465000524/exercises/AMD/HPCTrainingExamples</code></p> </li> <li> <p>Exercises are archived as compressed and uncompressed tar files:</p> <ul> <li> <p>Web download .tar.bz2     or web download .tar</p> </li> <li> <p>On LUMI:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2</code></li> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_3_10_Exercises_11/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_01_Performance_Optimization_Improving_Single_Core/","title":"Performance Optimization: Improving Single-core Efficiency","text":"<p>Presenter: Jean Pourroy (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_01_Performance_Optimization_Improving_Single_Core.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/12_cpu_performance_optimization.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/4_01_Performance_Optimization_Improving_Single_Core.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_4_01_Performance_Optimization_Improving_Single_Core/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_02_Introduction_to_Python_on_Cray_EX/","title":"Introduction to Python on Cray EX","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_02_Introduction_to_Python_on_Cray_EX.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/13_Python_Frameworks.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/4_02_Introduction_to_Python_on_Cray_EX.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_4_02_Introduction_to_Python_on_Cray_EX/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Are Pytorch and Tensorflow installed on LUMI, or users shall install those themselves? I couldn't find any related modules with \"module spider pytorch\" or \"module keyword pytorch\". </p> <ul> <li>https://docs.lumi-supercomputer.eu/software/packages/pytorch/</li> <li>Most users want PyTorch with additional packages anyway so need a customised installation.</li> <li>(Christian) I would highly recommend to use a Singularity/Apptainer container. Take a look at the ROCm dockerhub containers to see if they fit your needs. If you need a more customized container and are used to conda/pip environments, have a look at cotainr which makes it very easy to build a container based on your conda/pip environment (just remember that you have make your conda/pip environment compatible with LUMI, e.g. installing a ROCm-enabled PyTorch wheel). On LUMI cotainr is available via <code>module load LUMI</code>, <code>module load cotainr</code>.</li> <li>(Christian) You may also use the container based modules from the local CSC software stack. Just be aware that these are primarily intended for the CSC users. Support for this local software stack is provided by CSC - the LUMI User Support Team can only provide very limited support.</li> </ul> </li> </ol>"},{"location":"4day-20230530/extra_4_03_Exercises_12/","title":"Exercise session 12","text":"<ul> <li> <p>See <code>/project/project_465000524/slides/HPE/Exercises.pdf</code> for the exercises.</p> </li> <li> <p>Files are in      <code>/project/project_465000524/exercises/HPE/day3</code></p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_4_03_Exercises_12/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_04_IO_Optimization_Parallel_IO/","title":"I/O Optimization - Parallel I/O","text":"<p>Presenter: Harvey Richardson (HPE)</p> <ul> <li>Slides available on LUMI as:<ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_04_IO_Optimization_Parallel_IO.pdf</code></li> <li><code>/project/project_465000524/slides/HPE/14_IO_medium_LUMI.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li>Recording available on LUMI as:     <code>/appl/local/training/4day-20230530/recordings/4_04_IO_Optimization_Parallel_IO.mp4</code></li> </ul> <p>These materials can only be distributed to actual users of LUMI (active user account).</p>"},{"location":"4day-20230530/extra_4_04_IO_Optimization_Parallel_IO/#links","title":"Links","text":"<ul> <li>The ExaIO project paper     \"Transparent Asynchronous Parallel I/O Using Background Threads\".</li> </ul>"},{"location":"4day-20230530/extra_4_04_IO_Optimization_Parallel_IO/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Could you please elaborate on using HDF5. What are pros and cons compared to using raw FS? Can it improve performance on LUMI?</p> <ul> <li>Passed to the speaker in the talk, will be in the recording.</li> </ul> </li> <li> <p>I have a dataset of 5 million files ranging from several KB to tens of GB, 50 TB in total. I am looking into optimilly merging files. What is a reasonable number of files and reasonable file sizes to aim at? Would it be ok if those files will range from several KB to several TB, or shall I try to balance them by size?</p> <ul> <li>Passed to the speaker in the talk, will be in the recording.</li> </ul> </li> <li> <p>I see that my previous question was too specific. But could you please give some general advice what is a reasonable range of file sizes on LUSTRE? And may it cause problems to work with files of several TB and of several KB at the same time in parallel (and independent) processes?</p> <p>Answer: The previous question was not too specific but not specific enough as the right answer depends on a lot of factors. Whether working with files of multiple TBs and files of multiple Kb's simultaneously is problematic or not also depends on how you use them and how many small files there are. I'd say that in general it may be better to organise them in a directory structure where small and big files are in different directories so that you can set optimal striping parameters for both. But then again this matters less if you use the Lustre API or the MPI I/O hints discussed in the talk when creating the large files. Then you could set the directory striping parameters to something that corresponds with the small files (there was a slide giving some hints depending on the number of files) and use the API to set a proper striping for the large files. Getting good performance from large files requires a different way of working with the files then getting good performance from small files. E.g., when I read sub-megabyte files I read them in a single operation (which may not be that important anymore with better buffering in the OS) and then process the files in-memory (for text files in C this would mean using sscanf instead of fscanf, etc.)</p> <p>The correct answer really depends on more details.</p> </li> <li> <p>There are modules called <code>cray-hdf5-parallel</code> on LUMI. Does that imply the <code>cray-hdf5</code> modules do not support parallel I/O?</p> <ul> <li>for HPD5 to get the parallel support you need the parallel version</li> </ul> </li> </ol>"},{"location":"4day-20230530/extra_4_05_Exercises_13/","title":"Exercise session 13","text":"<ul> <li> <p>See <code>/project/project_465000524/slides/HPE/Exercises.pdf</code> for the exercises.</p> </li> <li> <p>Material for the IO exercises is in      <code>/project/project_465000524/exercises/HPE/day4/VH1-io</code>.</p> <p>And of course you can continue on previous exercises.</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Exercise notes in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf</code></p> </li> <li> <p>Exercises as bizp2-compressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2</code></p> </li> <li> <p>Exercises as uncompressed tar file in     <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20230530/extra_4_05_Exercises_13/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_06_AMD_Ominitrace/","title":"Introduction to OmniTrace","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <ul> <li> <p>Slides on the web (up to slide 61)</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_06_AMD_Omnitrace.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-3-tutorial_omnitools.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/4_06_AMD_Ominitrace.mp4</code></p> </li> </ul>"},{"location":"4day-20230530/extra_4_06_AMD_Ominitrace/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_07_Exercises_14/","title":"Exercise session 14","text":"<ul> <li> <p>On-line exercise notes.</p> <p>PDF backup</p> </li> <li> <p>Exercises can be copied from <code>/project/project_465000524/exercises/AMD/HPCTrainingExamples</code></p> </li> <li> <p>Exercises are archived as compressed and uncompressed tar files:</p> <ul> <li> <p>Web download .tar.bz2     or web download .tar</p> </li> <li> <p>On LUMI:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2</code></li> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code></li> </ul> </li> </ul> </li> <li> <p>The necessary version of OmniTrace is installed in the software installation in      <code>/project/project_465000524/software</code>.</p> <p>The installation can be recovered from the archive (bzip2-compressed tar file) on LUMI:  <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Software_AMD.tar.bz2</code></p> <p>This installation was tested for the course but will fail at some point due to changes to the system.</p> </li> </ul>"},{"location":"4day-20230530/extra_4_07_Exercises_14/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_08_AMD_Ominiperf/","title":"AMD Omniperf","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <p>Slides in the same stack as the OmniTrace ones, starting from slide 62:</p> <ul> <li> <p>Slides on the web</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_06_AMD_Omnitrace.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-3-tutorial_omnitools.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/4_08_AMD_Ominiperf.mp4</code></p> </li> </ul>"},{"location":"4day-20230530/extra_4_08_AMD_Ominiperf/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_09_Exercises_15/","title":"Exercise session 15","text":"<ul> <li> <p>On-line exercise notes.</p> <p>PDF backup</p> </li> <li> <p>Exercises can be copied from <code>/project/project_465000524/exercises/AMD/HPCTrainingExamples</code></p> </li> <li> <p>Exercises are archived as compressed and uncompressed tar files:</p> <ul> <li> <p>Web download .tar.bz2     or web download .tar</p> </li> <li> <p>On LUMI:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2</code></li> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar</code></li> </ul> </li> </ul> </li> <li> <p>The necessary version of Omniperf is installed in the software installation in      <code>/project/project_465000524/software</code>.</p> <p>The installation can be recovered from the archive (bzip2-compressed tar file) on LUMI:  <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Software_AMD.tar.bz2</code></p> <p>This installation was tested for the course but will fail at some point due to changes to the system.</p> <p>Note that Omniperf poses security risks as it is based on an unprotected web server running on a predicable port number.</p> </li> </ul>"},{"location":"4day-20230530/extra_4_09_Exercises_15/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_10_Best_Practices_GPU_Optimization/","title":"Tools in Action - An Example with Pytorch","text":"<p>Presenter: Samuel Ant\u00e3o (AMD)</p> <ul> <li> <p>Slides on the web</p> </li> <li> <p>Downloadable scripts as     bzip2-compressed tar archive and      uncompressed tar archive</p> </li> <li> <p>Slides available on LUMI as:</p> <ul> <li><code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_10_Best_Practices_GPU_Optimization.pdf</code></li> <li><code>/project/project_465000524/slides/AMD/session-4-ToolsInActionPytorchExample-LUMI.pdf</code> (temporary, for the lifetime of the project)</li> </ul> </li> <li> <p>Scripts archived on lumi as     bzip2-compressed tar archive in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_10_scripts.tar.bz2</code> and     uncompressed tar archive in <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_10_scripts.tar</code>.</p> </li> <li> <p>Video also available on LUMI as     <code>/appl/local/training/4day-20230530/recordings/4_10_Best_Practices_GPU_Optimization.mp4</code></p> </li> </ul>"},{"location":"4day-20230530/extra_4_10_Best_Practices_GPU_Optimization/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20230530/extra_4_11_LUMI_Support_and_Documentation/","title":"LUMI User Support","text":"<p>Presenter: Anne Vomm</p> <ul> <li> <p>Slides (PDF)</p> </li> <li> <p>Permanent archive on LUMI:</p> <ul> <li> <p>Slides: <code>/appl/local/training/4day-20230530/files/LUMI-4day-20230530-4_11_LUMI_Support_and_Documentation.pdf</code></p> </li> <li> <p>Recording: <code>/appl/local/training/4day-20230530/recordings/4_11_LUMI_Support_and_Documentation.mp4</code></p> </li> </ul> </li> </ul> <p>The information in this talk is also covered by the following talk from the 1-day courses:</p> <ul> <li>LUMI User Support</li> </ul>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>In this part of the training, we cover:</p> <ul> <li>Software stacks on LUMI, where we discuss the organisation of the software stacks     that we offer and some of the policies surrounding it</li> <li>Advanced Lmod use to make the best out of the software stacks</li> <li>Creating your customised environment with EasyBuild, the tool that we use to install     most software.</li> <li>Some remarks about using containers on LUMI.</li> </ul>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: the option to use a coherent unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in Apple Silicon M-series but then without the NUMA character     (except maybe for the Ultra version that consists of two dies).</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a a talk in the     EasyBuild user meeting in 2022.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users, but one that is followed by more and more big centres.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. This did turn out to be a good decision after the system update of March 2023 as some packages were incapable of picking up new libraries. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparent way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be accustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. We do offer some help so set up Spack also but it is mostly offered \"as is\" an we will not do bug-fixing or development in Spack package files.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionnaire send out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, the so-called Cassini provider,      so any software compiled with an MPI library that     requires UCX, or any other distributed memory model build on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intra-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-bus comes to mind.</li> </ul> <p>Also, the LUMI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that I did not yet mention is that software that accesses tens of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. On LUMI the tool is called lumi-container-wrapper but it may by some from CSC also be known as Tykky.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 3 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes and zen3 + MI250X for the LUMI-G partition. We were also planning to have a fourth version for the visualisation nodes with  zen2 CPUs combined with NVIDIA GPUs, but that may never materialise and we may manage those differently.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p> <p>We also have an extensible software stack based on Spack which has been pre-configured to use the compilers from the Cray PE. This stack is offered as-is for users who know how to use Spack, but we don't offer much support nor do we do any bugfixing in Spack.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It ia also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. </p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/22.08, LUMI/22.12 and LUMI/23.03 modules. Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules. There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes and partition/G for the AMD GPU nodes. We may have a separate partition for the visualisation nodes in the future but that is not clear yet.</p> <p>There is also a hidden partition/common module in which we install software that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#lmod-on-lumi","title":"Lmod on LUMI","text":""},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the few modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#module-spider-command","title":"Module spider command","text":"<p>Demo moment 1 (when infrastructure for a demo is available)</p> <p></p> <p>(The content of this slide is really meant to be shown in practice on a command line.)</p> <p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive. Let's try for instance <code>module spider gnuplot</code>. This     will show 17 versions of GNUplot. There are 12 installations of GNUplot 5.4.3 (of which 3 with Spack,     their name has a different structure) and five of 5.4.6. The      remainder of the name shows us with what compilers gnuplot was compiled. The reason to have      versions for two or three compilers is that no two compiler modules can be loaded simultaneously,     and this offers a solution to use multiple tools without having to rebuild your environment for     every tool, and hence also to combine tools. </p> <p>Now try <code>module spider CMake</code>. We see that there are four versions,3.22.2, 3.23.2, 3.24.0 and 3.25.2,  that are shown in blue with an \"E\" behind the name. That is because these are not provided  by a module called <code>CMake</code> on LUMI, but by another module that in this case contains a collection of popular build tools and that we will discover shortly.</p> <p>There are also a couple of regular modules called <code>cmake</code> that come from software installed differently.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module. Try for instance     <code>module spider gnuplot/5.4.6-cpeGNU-22.12</code>. This will now show full help information for     the specific module, including what should be done to make the module available. For      this GNUplot module we see that there are three ways to load the module: By loading <code>LUMI/22.12</code>      combined with <code>partition/C</code>, by loading <code>LUMI/22.12</code> combined with <code>partition/G</code>     or by loading <code>LUMI/22.12</code> combined with <code>partition/L</code>. So use only     a single line, but chose it in function of the other modules that you will also need. In this case     it means that that version of GNUplot is available in the <code>LUMI/22.12</code> stack which we could already     have guessed from its name, with binaries for the login and large memory nodes and the LUMI-C compute     partition. This does however not always work with the Cray Programming Environment modules.</p> <p>We can also use <code>module spider</code> with the name and version of an extension. So try <code>module spider CMake/3.25.2</code>. This will now show us that this tool is in the <code>buildtools/22.12</code> module (among others) and give us 4 different options to load that module as it is provided in the <code>CrayEnv</code> and the <code>LUMI/22.12</code> software stacks and for all partitions (basically because we don't do processor-specific optimisations for these tools).</p> </li> </ol> Demo module spider <p>Try the following commands:</p> <pre><code>module spider\nmodule spider gnuplot\nmodule spider cmake\nmodule spider gnuplot/5.4.6-cpeGNU-22.12\nmodule spider CMake/3.25.2\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#module-keyword-command","title":"Module keyword command","text":"<p>Lmod has a second way of searching for modules: <code>module keyword</code>, but unfortunately it does not yet work very well on LUMI as the version of Lmod is rather old and still has some bugs in the processing of the command. </p> <p>The <code>module keyword</code> command searches in some of the information included in module files for the given keyword, and shows in which modules the keyword was found.</p> <p>We do an effort to put enough information in the modules to make this a suitable additional way to discover software that is installed on the system.</p> Demo module keyword <p>Try the following command:</p> <pre><code>module keyword https\n</code></pre> <p> </p> <p>The bug in the Lmod 8.3 version on LUMI is that all extensions are shown in the output  while they are irrelevant. </p> <p> </p> <p>On the second screen though we see <code>cURL</code> which is a tool to download files over, among others, https.</p> <p> </p> <p> </p> <p>And the fourth screen <code>wget</code> which is also a tool to download files from the internet over an https connection.</p> <p> </p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#sticky-modules-and-module-purge","title":"Sticky modules and module purge","text":"<p>On some systems you will be taught to avoid <code>module purge</code> as many HPC systems do their default user configuration also through modules. This advice is often given on Cray systems as it is a common practice to preload a suitable set of target modules and a programming environment. On LUMI both are used. A default programming environment and set of target modules suitable for the login nodes is preloaded when you log in to the system, and next the <code>init-lumi</code> module is loaded which in turn makes the LUMI software stacks available that we will discuss in the next session.</p> <p>Lmod however has a trick that help to avoid removing necessary modules and it is called sticky modules. When issuing the <code>module purge</code> command these modules are automatically reloaded. It is very important to realise that those modules will not just be kept \"as is\" but are in fact unloaded and loaded again as we shall see later that this may have consequences. It is still possible to force unload all these modules using <code>module --force purge</code> or selectively unload those using <code>module --force unload</code>.</p> <p>The sticky property is something that is defined in the module file and not used by the module files ot the HPE Cray Programming Environment, but we shall see that there is a partial workaround for this in some of the LUMI software stacks. The <code>init-lumi</code> module mentioned above though is a sticky module, as are the modules that activate a software stack so that you don't have to start from scratch if you have already chosen a software stack but want to clean up your environment.</p> Demo <p>Try the following command:</p> <pre><code>module av\n</code></pre> <p> </p> <p>Note the very descriptive titles in the above screenshot.</p> <p>The letter \"D\" next to a name denotes that this is the default version, the letter \"L\" denotes that the module is loaded, but we'll come back to  that later also.</p> <p> </p> <p>Note the two categories for the PE modules. The target modules get their own block. The screen below also shows <code>(D:5.0.2:5.2.0)</code> next to the <code>rocm</code> module.  The <code>D</code> means that this version of the module, <code>5.2.3</code>, is currently the default on the system. The two version numbers next to this module show that the module can also  be loaded as <code>rocm/5.0.2</code> and <code>rocm/5.2.0</code>. These are two modules that were removed from the system during the last update of the system, but version 5.2.3 can be loaded as a replacement of these modules so that software that used the removed modules may still work without recompiling.</p> <p> </p> <p>In the next screen we see the modules for the software stack that we have just discussed.</p> <p> </p> <p>And the screen below shows the extensions of modules (like the CMake tool we've tried to locate before)</p> <p> </p> <p> </p> <p>At the end of the output we also get some information about the meaning of the  letters used in the display.</p> <p>Try the following commands and carefully observe the output:</p> <pre><code>module load LUMI/22.08 buildtools\nmodule list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <p>The sticky property has to be declared in the module file so we cannot add it to for instance the Cray Programming Environment target modules, but we can and do use it in some modules that we control ourselves. We use it on LUMI for the software stacks themselves and for the modules that set the display style of the modules. </p> <ul> <li>In the <code>CrayEnv</code> environment, <code>module purge</code> will clear the target     modules also but as <code>CrayEnv</code> is not just left untouched but reloaded instead, the load of <code>CrayEnv</code>     will load a suitable set of target modules for the node you're on again. But any customisations that     you did for cross-compiling will be lost. </li> <li>Similarly in the LUMI stacks, as the <code>LUMI</code> module itself     is reloaded, it will also reload a partition module. However, that partition module might not be the      one that you had loaded but it will be the one that the LUMI module deems the best for the node you're     on, and you may see some confusing messages that look like an error message but are not.</li> </ul>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed already that by default you don't see the directories in which the module files reside as is the case on many other clusters. Instead we try to show labels that tell you what that group of modules actually is. And sometimes this also combines modules from multiple directories that have the same purpose. For instance, in the default view we collapse all modules from the Cray Programming Environment in two categories, the target modules and other programming environment modules. But you can customise this by loading one of the <code>ModuleLabel</code> modules. One version, the <code>label</code> version, is the default view. But we also have <code>PEhierarchy</code> which  still provides descriptive texts but unfolds the whole hierarchy in the Cray Programming  Environment. And the third style is called <code>system</code> which shows you again the module directories.</p> Demo <p>Try the following commands:</p> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>We're also very much aware that the default colour view is not good for everybody. So far we are not  aware of an easy way to provide various colour schemes as one that is OK for people who like a black  background on their monitor might not be OK for people who prefer a white background. But it is possible to turn colour off alltogether by loading the <code>ModuleColour/off</code> module, and you can always turn it on again with <code>ModuleColour/on</code>.</p> Demo <p>Try the following commands:</p> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment. For instance, when working in the <code>LUMI/22.12</code> stack we prefer that users use the Cray programming environment modules that come with release 22.12 of that environment, and cannot guarantee compatibility of other modules with already installed software, so we hide the other ones from view. You can still load them if you know they exist but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work or to use any module that was designed for us to maintain the system.</p> Demo <p>Try the following commands:</p> <pre><code>module load LUMI/22.12\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <p>Note that we see a lot more Cray PE modules with <code>ModulePowerUser</code>!</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system. We expect this to happen especially with packages that  require specific MPI versions. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And we need a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is our primary software installation tool. We selected this as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the build-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain we would have problems with MPI. EasyBuild uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures with some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     or the Intel compiler will simply optimize for a two decades old CPU.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system. </p> <p>We also have the LUMI Software Library which documents all software for which we have EasyBuild recipes available.  This includes both the pre-installed software and the software for which we provide recipes in the LUMI-EasyBuild-contrib GitHub repository, and even instructions for some software that is not suitable for installation through EasyBuild or Spack, e.g., because it likes to write in its own directories while running.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#easybuild-recipes-easyconfigs","title":"EasyBuild recipes - easyconfigs","text":"<p>EasyBuild uses a build recipe for each individual package, or better said, each individual module as it is possible to install more than one software package in the same module. That installation description relies on either a generic or a specific installation process provided by an easyblock. The build recipes are called easyconfig files or simply easyconfigs and are Python files with  the extension <code>.eb</code>. </p> <p>The typical steps in an installation process are:</p> <ol> <li>Downloading sources and patches. For licensed software you may have to provide the sources as     often they cannot be downloaded automatically.</li> <li>A typical configure - build - test - install process, where the test process is optional and     depends on the package providing useable pre-installation tests.</li> <li>An extension mechanism can be used to install perl/python/R extension packages</li> <li>Then EasyBuild will do some simple checks (some default ones or checks defined in the recipe)</li> <li>And finally it will generate the module file using lots of information specified in the      EasyBuild recipe.</li> </ol> <p>Most or all of these steps can be influenced by parameters in the easyconfig.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#the-toolchain-concept","title":"The toolchain concept","text":"<p>EasyBuild uses the toolchain concept. A toolchain consists of compilers, an MPI implementation and some basic mathematics libraries. The latter two are optional in a toolchain. All these  components have a level of exchangeability as there are language standards, as MPI is standardised, and the math libraries that are typically included are those that provide a standard API for which several implementations exist. All these components also have in common that it is risky to combine  pieces of code compiled with different sets of such libraries and compilers because there can be conflicts in names in the libraries.</p> <p>On LUMI we don't use the standard EasyBuild toolchains but our own toolchains specifically for Cray and these are precisely the <code>cpeCray</code>, <code>cpeGNU</code>, <code>cpeAOCC</code> and <code>cpeAMD</code> modules already mentioned  before.</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p></p> <p>There is also a special toolchain called the SYSTEM toolchain that uses the compiler provided by the operating system. This toolchain does not fully function in the same way as the other toolchains when it comes to handling dependencies of a package and is therefore a bit harder to use. The EasyBuild designers had in mind that this compiler would only be used to bootstrap an EasyBuild-managed software stack, but we do use it for a bit more on LUMI as it offers us a relatively easy way to compile some packages also for the CrayEnv stack and do this in a way that they interact as little as possible with other software.</p> <p>It is not possible to load packages from different cpe toolchains at the same time. This is an EasyBuild restriction, because mixing libraries compiled with different compilers does not always work. This could happen, e.g., if a package compiled with the Cray Compiling Environment and one compiled with the GNU compiler collection would both use a particular  library, as these would have the same name and hence the last loaded one would be used by both executables (we don't use rpath or runpath linking in EasyBuild for those familiar with that technique).</p> <p>However, as we did not implement a hierarchy in the Lmod implementation of our software stack at the toolchain level, the module system will not protect you from these mistakes.  When we set up the software stack, most people in the support team considered it too misleading and difficult to ask users to first select the toolchain they want to use and then see the  software for that toolchain.</p> <p>It is however possible to combine packages compiled with one CPE-based toolchain with packages compiled with teh system toolchain, but we do avoid mixing those when linking as that may cause problems. The reason is that we try to use as much as possible static linking in the SYSTEM toolchain so that these packages are as independent as possible.</p> <p>And with some tricks it might also be possible to combine packages from the LUMI software stack with packages compiled with Spack, but one should make sure that no Spack packages are available when building as mixing libraries could cause problems. Spack uses rpath linking which is why this may work.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#easyconfig-names-and-module-names","title":"EasyConfig names and module names","text":"<p>There is a convention for the naming of an EasyConfig as shown on the slide. This is not mandatory, but EasyBuild will fail to automatically locate easyconfigs for dependencies  of a package that are not yet installed if the easyconfigs don't follow the naming convention. Each part of the name also corresponds to a parameter in the easyconfig  file.</p> <p>Consider, e.g., the easyconfig file <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.</p> <ol> <li>The first part of the name, <code>GROMACS</code>, is the name of the package, specified by the     <code>name</code> parameter in the easyconfig, and is after installation also the name of the     module.</li> <li>The second part, <code>2021.4</code>, is the version of GROMACS and specified by the     <code>version</code> parameter in the easyconfig.</li> <li> <p>The next part, <code>cpeCray-22.08</code> is the name and version of the toolchain,     specified by the <code>toolchain</code> parameter in the easyconfig. The version of the     toolchain must always correspond to the version of the LUMI stack. So this is     an easyconfig for installation in <code>LUMI/22.08</code>.</p> <p>This part is not present for the SYSTEM toolchain</p> </li> <li> <p>The final part, <code>-PLUMED-2.8.0-CPU</code>, is the version suffix and used to provide     additional information and distinguish different builds with different options     of the same package. It is specified in the <code>versionsuffix</code> parameter of the     easyconfig.</p> <p>This part is optional.</p> </li> </ol> <p>The version, toolchain + toolchain version and versionsuffix together also combine to the version of the module that will be generated during the installation process. Hence this easyconfig file will generate the module  <code>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.8.0-CPE</code>.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#installing-software","title":"Installing software","text":""},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>The next step is to configure your environment. First load the proper version of the LUMI stack for which you want to install software, and you may want to change to the proper partition also if you are cross-compiling.</p> <p>Once you have selected the software stack and partition, all you need to do to activate EasyBuild to install additional software is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition. </p> <p>Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p> <p>Note that the <code>EasyBuild-user</code> module is only needed for the installation process. For using the software that is installed that way it is sufficient to ensure that <code>EBU_USER_PREFIX</code> has the proper value before loading the <code>LUMI</code> module.</p> <p></p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Demo moment 2</p> <p></p> <p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS we already have support. At the moment we have to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre> We now also have the LUMI Software Library which lists all software that we manage via EasyBuild and make available either pre-installed on the system or as an EasyBuild recipe for user installation.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS there already is a GPU version for AMD GPUs in active development so even before LUMI-G was active we chose to ensure that we could distinguish between GPU and CPU-only versions. To install it, we first run  <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The installation of dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb\n</code></pre></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p> Demo of the EasyBuild installation of GROMACS <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p>End of demo moment 2</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>There is a little problem though that you may run into. Sometimes the module does not show up immediately. This is because Lmod keeps a cache when it feels that Lmod searches become too slow and often fails to detect that the cache is outdated. The easy solution is then to simply remove the cache which is in <code>$HOME/.lmod.d/.cache</code>,  which you can do with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> And we have seen some very rare cases where even that did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r . </code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.0-cpeGNU-22.08.eb \u2013r . </code></pre></p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greatest before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/easybuild/easyconfigs</code>.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory, and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software.</p> <p>Moreover, EasyBuild also keeps copies of all installed easyconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#easybuild-tips-tricks","title":"EasyBuild tips &amp; tricks","text":"<p>Updating the version of a package often requires only trivial changes in the easyconfig file. However, we do tend to use checksums for the sources so that we can detect if the available sources have changed. This may point to files being tampered with, or other changes that might need us to be a bit more careful when installing software and check a bit more again.  Should the checksum sit in the way, you can always disable it by using  <code>--ignore-checksums</code> with the <code>eb</code> command.</p> <p>Updating an existing recipe to a new toolchain might be a bit more involving as you also have to make build recipes for all dependencies. When we update a toolchain on the system, we often bump the versions of all installed libraries to one of the latest versions to have most bug fixes and security patches in the software stack, so you need to check for those versions also to avoid installing yet another unneeded version of a library.</p> <p>We provide documentation on the available software that is either pre-installed or can be user-installed with EasyBuild in the  LUMI Software Library. For most packages this documentation does also contain information about the license. The user documentation for some packages gives more information about how to use the package on LUMI, or sometimes also about things that do not work. The documentation also shows all EasyBuild recipes, and for many packages there is  also some technical documentation that is more geared towards users who want to build or modify recipes. It sometimes also tells why we did things in a particular way.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>I also want to give some pointers to more information in case you want to learn a lot more about, e.g., developing support for your code in EasyBuild, or for support people who want to adapt our EasyConfigs for users requesting a specific configuration of a package.</p> <p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>There is also a later course developed by LUST for developers of EasyConfigs for LUMI that can be found on  lumi-supercomputer.github.io/easybuild-tutorial.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#containers-on-lumi","title":"Containers on LUMI","text":"<p>Let's now switch to using containers on LUMI.  This section is about using containers on the login nodes and compute nodes.  Some of you may have heard that there were plans to also have an OpenShift Kubernetes container cloud platform for running microservices but at this point it is not clear if and when this will materialize due to a lack of personpower to get this running and then to support this.</p> <p>In this section, we will </p> <ul> <li> <p>discuss what to expect from containers on LUMI: what can they do and what can't they do,</p> </li> <li> <p>discuss how to get a container on LUMI,</p> </li> <li> <p>discuss how to run a container on LUMI,</p> </li> <li> <p>and discuss some enhancements we made to the LUMI environment that are based on containers or help     you use containers.</p> </li> </ul> <p>Remember though that the compute nodes of LUMI are an HPC infrastructure and not a container cloud!</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#what-do-containers-not-provide","title":"What do containers not provide","text":"<p>What is being discussed in this subsection may be a bit surprising. Containers are often marketed as a way to provide reproducible science and as an easy way to transfer software from one machine to another machine. However, containers are neither of those and this becomes  very clear when using containers build on your typical Mellanox/NVIDIA InfiniBand based clusters with Intel processors and NVIDIA GPUs on LUMI.</p> <p>First, computational results are almost never 100% reproducible because of the very nature of how computers work. You can only expect reproducibility of sequential codes between equal hardware. As soon as you change the CPU type, some floating point computations may produce slightly different results, and as soon as you go parallel this may even be the case between two runs on exactly the same hardware and software.</p> <p>But full portability is a much greater myth. Containers are really only guaranteed to be portable between similar systems. They may be a little bit more portable than just a binary as you may be able to deal with missing or different libraries in the container, but that is where it stops. Containers are usually built for a particular CPU architecture and GPU architecture, two elements where everybody can easily see that if you change this, the container will not run. But  there is in fact more: containers talk to other hardware too, and on an HPC system the first piece of hardware that comes to mind is the interconnect. And they use the kernel of the host and the kernel modules and drivers provided by that kernel. Those can be a problem. A container that is not build to support the SlingShot interconnect, may fall back to TCP sockets in MPI, completely killing scalability. Containers that expect the knem kernel extension for good  intra-node MPI performance may not run as efficiently as LUMI uses xpmem instead.</p> <p>Even if a container is portable to LUMI, it may not yet be performance portable. E.g., without proper support for the interconnect it may still run but in a much slower mode. But one should also realise that speed gains in the x86 family over the years come to a large extent from adding new instructions to the CPU set, and that two processors with the same instructions set extensions may still benefit from different optimisations by the compilers.  Not using the proper instruction set extensions can have a lot of influence. At my local site we've seen GROMACS  doubling its speed by choosing proper options, and the difference can even be bigger.</p> <p>Many HPC sites try to build software as much as possible from sources to exploit the available hardware as much as  possible. You may not care much about 10% or 20% performance difference on your PC, but 20% on a 160 million EURO investment represents 32 million EURO and a lot of science can be done for that money...</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#but-what-can-they-then-do-on-lumi","title":"But what can they then do on LUMI?","text":"<ul> <li> <p>A very important reason to use containers on LUMI is reducing the pressure on the file system by software     that accesses many thousands of small files (Python and R users, you know who we are talking about).     That software kills the metadata servers of almost any parallel file system when used at scale.</p> <p>As a container on LUMI is a single file, the metadata servers of the parallel file system have far less  work to do, and all the file caching mechanisms can also work much better.</p> </li> <li> <p>When setting up very large software environments, e.g., some Python and R environments, they can still      be very helpful, even if you may have to change some elements in your build recipes from your regular     cluster or workstation. Some software may also be simply too hard to install from sources in the     typical HPC way of working.</p> </li> <li> <p>And related to the previous point is also that some software may not even be suited for installation in     a multi-user HPC system. HPC systems want a lightweight <code>/usr</code> etc. structure as that part of the system     software is often stored in a RAM disk, and to reduce boot times. Moreover, different users may need     different versions of a software library so it cannot be installed in its default location in the system     library. However, some software is ill-behaved and cannot be relocated to a different directory,     and in these cases containers help you to build a private installation that does not interfere with other     software on the system.</p> </li> </ul> <p>Remember though that whenever you use containers, you are the system administrator and not LUST. We can impossibly support all different software that users want to run in containers, and all possible Linux distributions they may want to run in those containers. We provide some advice on how to build a proper container, but if you chose to neglect it it is up to you to solve the problems that occur.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#managing-containers","title":"Managing containers","text":"<p>On LUMI, we currently support only one container runtime.</p> <p>Docker is not available, and will never be on the regular compute nodes as it requires elevated privileges to run the container which cannot be given safely to regular users of the system.</p> <p>Singularity is currently the only supported container runtime and is available on the login nodes and the compute nodes. It is a system command that is installed with the OS, so no module has to be loaded to enable it. We can also offer only a single version of singularity or its close cousin AppTainer  as singularity/AppTainer simply don't really like running multiple versions next to one another, and currently the version that we offer is determined by what is offered by the OS.</p> <p>To work with containers on LUMI you will either need to pull the container from a container registry, e.g., DockerHub, or bring in the container by copying the singularity <code>.sif</code> file.</p> <p>Singularity does offer a command to pull in a Docker container and to convert it to singularity format. E.g., to pull a container for the Julia language from DockerHub, you'd use</p> <pre><code>singularity pull docker://julia\n</code></pre> <p>Singularity uses a single flat sif file for storing containers. The <code>singularity pull</code> command does the  conversion from Docker format to the singularity format.</p> <p>Singularity caches files during pull operations and that may leave a mess of files in the <code>.singularity</code> cache directory or in <code>$XDG_RUNTIME_DIR</code> (works only on the login nodes).  The former can lead to exhaustion of your storage quota, so check and clean up from time to time. You may also want to clean up <code>$XDG_RUNTIME_DIR</code>, but this directory is also automatically cleaned when you log out from your last running session on that (login) node.</p> Demo singularity pull <p>Let's try the <code>singularity pull docker://julia</code> command:</p> <p> </p> <p>We do get a lot of warnings but usually this is perfectly normal and usually they can be safely ignored.</p> <p> </p> <p>The process ends with the creation of the file <code>jula_latest.sif</code>. </p> <p>Note however that the process has left a considerable number of files in <code>~/.singularity</code> also:</p> <p> </p> <p></p> <p>There is currently limited support for building containers on LUMI and I do not expect that to change quickly. Container build strategies that require elevated privileges, and even those that require fakeroot, cannot be supported for security reasons.  Enabling features that are known to have had several serious security vulnerabilities in the recent past, ot that themselves are unsecure by design and could allow users to do more on the system than a regular user should be able to do, will never be supported.</p> <p>So you should pull containers from a container repository, or build the container on your own workstation and then transfer it to LUMI.</p> <p>There is some support for building on top of an existing singularity container. We are also working on a number of base images to build upon, where the base images are tested with the OS kernel on LUMI.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#interacting-with-containers","title":"Interacting with containers","text":"<p>There are basically three ways to interact with containers.</p> <p>If you have the sif file already on the system you can enter the container with an interactive shell:</p> <pre><code>singularity shell container.sif\n</code></pre> Demo singularity shell <p> </p> <p>In this screenshot we checked the contents of the <code>/opt</code> directory before and after the <code>singularity shell julia_latest.sif</code> command. This shows that we are clearly in a different environment. Checking the <code>/etc/os-release</code> file only confirms this as LUMI runs SUSE Linux on the login nodes, not a version of Debian.</p> <p>The second way is to execute a command in the container with <code>singularity exec</code>. E.g., assuming the  container has the <code>uname</code> executable installed in it,</p> <pre><code>singularity exec container.sif uname -a\n</code></pre> Demo singularity exec <p> </p> <p>In this screenshot we execute the <code>uname -a</code> command before and with the <code>singularity exec julia_latest.sif</code> command. There are some slight differences in the output though the same kernel version is reported as the container uses the host kernel. Executing</p> <pre><code>singularity exec julia_latest.sif cat /etc/os-release\n</code></pre> <p>confirms though that the commands are executed in the container.</p> <p>The third option is often called running a container, which is done with singularity run:</p> <pre><code>singularity run container.sif\n</code></pre> <p>It does require the container to have a special script that tells singularity what  running a container means. You can check if it is present and what it does with <code>singularity inspect</code>: </p> <pre><code>singularity inspect --runscript container.sif\n</code></pre> Demo singularity run <p> </p> <p>In this screenshot we start the julia interface in the container using <code>singularity run</code>. The second command shows that the container indeed includes a script to tell singularity what <code>singularity run</code> should do.</p> <p>You want your container to be able to interact with the files in your account on the system. Singularity will automatically mount <code>$HOME</code>, <code>/tmp</code>, <code>/proc</code>, <code>/sys</code> and <code>dev</code> in the container, but this is not enough as your home directory on LUMI is small and only meant to be used for storing program settings, etc., and not as your main work directory. (And it is also not billed and therefore no extension is allowed.) Most of the time you want to be able to access files in your project directories in <code>/project</code>, <code>/scratch</code> or <code>/flash</code>, or maybe even in <code>/appl</code>. To do this you need to tell singularity to also mount these directories in the container, either using the  <code>--bind src1:dest1,src2:dest2</code>  flag or via the <code>SINGULARITY_BIND</code> or <code>SINGULARITY_BINDPATH</code> environment variables.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#running-containers-on-lumi","title":"Running containers on LUMI","text":"<p>Just as for other jobs, you need to use Slurm to run containers on the compute nodes.</p> <p>For MPI containers one should use <code>srun</code> to run the <code>singularity exec</code> command, e.g,,</p> <pre><code>srun singularity exec --bind ${BIND_ARGS} \\\n${CONTAINER_PATH} mp_mpi_binary ${APP_PARAMS}\n</code></pre> <p>(and replace the environment variables above with the proper bind arguments for <code>--bind</code>, container file and parameters for the command that you want to run in the container).</p> <p>On LUMI, the software that you run in the container should be compatible with Cray MPICH, i.e., use the MPICH ABI (currently Cray MPICH is based on MPICH 3.4). It is then possible to tell the container to use Cray MPICH (from outside the container) rather than the MPICH variant installed in the container, so that it can offer optimal performance on the LUMI SlingShot 11 interconnect.</p> <p>Open MPI containers are currently not well supported on LUMI and we do not recommend using them. We only have a partial solution for the CPU nodes that is not tested in all scenarios,  and on the GPU nodes Open MPI is very problematic at the moment. This is due to some design issues in the design of Open MPI, and also to some piece of software that recent versions of Open MPI require but that HPE only started supporting recently on Cray EX systems and that we haven't been able to fully test. Open MPI has a slight preference for the UCX communication library over the OFI libraries, and  currently full GPU support requires UCX. Moreover, binaries using Open MPI often use the so-called rpath linking process so that it becomes a lot harder to inject an Open MPI library that is installed elsewhere. The good news though is that the Open MPI developers of course also want Open MPI to work on biggest systems in the USA, and all three currently operating or planned exascale systems use the SlingShot 11 interconnect so work is going on for better support for OFI and for full GPU support on systems that rely on OFI and do not support UCX.</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#enhancements-to-the-environment","title":"Enhancements to the environment","text":"<p>To make life easier, LUST with the support of CSC did implement some modules that are either based on containers or help you run software with containers.</p> <p>The <code>singularity-bindings/system</code> module which can be installed via EasyBuild helps to set <code>SINGULARITY_BIND</code> and <code>SINGULARITY_LD_LIBRARY__PATH</code> to use  Cray MPICH. Figuring out those settings is tricky, and sometimes changes to the module are needed for a specific situation because of dependency conflicts between Cray MPICH and other software in the container, which is why we don't provide it in the standard software stacks but instead make it available as an EasyBuild recipe that you can adapt to your situation and install.</p> <p>As it needs to be installed through EasyBuild, it is really meant to be  used in the context of a LUMI software stack (so not in <code>CrayEnv</code>). To find the EasyConfig files, load the <code>EasyBuild-user</code> module and  run</p> <pre><code>eb --search singularity-bindings\n</code></pre> <p>You can also check the  page for the module in the LUMI Software Library.</p> <p>You may need to change the EasyConfig for your specific purpose though. E.g., the singularity command line option <code>--rocm</code> to import the ROCm installation from the system doesn't fully work (and in fact, as we have alternative ROCm versions on the system cannot work in all cases) but that can also be fixed by extending the <code>singularity-bindings</code> module (or by just manually setting the proper environment variables).</p> <p></p> <p>The second tool is a container that we provide with some bash functions to start a VNC server as temporary way to be able to use some GUI programs on LUMI until the final setup which will be based on Open OnDemand is ready. It can be used in <code>CrayEnv</code> or in the LUMI stacks. The container also contains a poor men's window manager (and yes, we know that there are sometimes some problems with fonts). It is possible to connect to the VNC server either through a regular VNC client on your PC or a web browser, but in both cases you'll have to create an ssh tunnel to access the server. Try</p> <pre><code>module help lumi-vnc\n</code></pre> <p>for more information on how to use <code>lumi-vnc</code>.</p> <p>The final tool is a container wrapper tool that users from Finland may also know as Tykky. It is a tool to wrap Python and conda installations in a limited number of files in a transparent way. On LUMI, it is provided by the <code>lumi-container-wrapper</code> module which is available in the <code>CrayEnv</code> environment and in the LUMI software stacks. It is also documented in the LUMI documentation.</p> <p>The basic idea is that you run a tool to either do a conda installation or an installation of Python packages from a file that defines the environment in either standard conda format (a Yaml file) or in the <code>requirements.txt</code> format used by <code>pip</code>. </p> <p>The container wrapper will then perform the installation in a work directory, create some wrapper commands in the <code>bin</code> subdirectory of the directory where you tell the container wrapper tool to do the installation, and it will use SquashFS to create as single file that contains the conda or Python installation.</p> <p>We do strongly recommend to use the container wrapper tool for larger conda and Python installation. We will not raise your file quota if it is to house such installation in your <code>/project</code> directory.</p> Demo lumi-container-wrapper <p>Create a subdirectory to experiment. In that subdirectory, create a file named <code>env.yml</code> with the content:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.8.8\n  - scipy\n  - nglview\n</code></pre> <p>and create an empty subdirectory <code>conda-cont-1</code>.</p> <p>|Now you can follow the commands on the slides below:</p> <p> </p> <p>On the slide above we prepared the environment.</p> <p>Now lets run the command </p> <pre><code>conda-containerize new --prefix ./conda-cont-1 env.yml\n</code></pre> <p>and look at the output that scrolls over the screen. The screenshots don't show the full output as some parts of the screen get overwritten during the process:</p> <p> </p> <p>The tool will first build the conda installation in a temprorary work directory and also uses a base container for that purpose.</p> <p> </p> <p>The conda installation itself though is stored in a SquashFS file that is then used by the container.</p> <p> </p> <p> </p> <p>In the slide above we see the installation contains both a singularity container and a SquashFS file. They work together to get a working conda installation.</p> <p>The <code>bin</code> directory seems to contain the commands, but these are in fact scripts  that run those commands in the container with the SquashFS file system mounted in it.</p> <p> </p> <p>So as you can see above, we can simply use the <code>python3</code> command without realising what goes on behind the screen...</p> <p>The wrapper module also offers a pip-based command to build upon the Cray Python modules already present on the system</p>"},{"location":"4day-20230530/notes_2_05_LUMI_Software_Stacks/#conclusion-container-limitations-on-lumi-c","title":"Conclusion: Container limitations on LUMI-C","text":"<p>To conclude the information on using singularity containers on LUMI, we want to repeat the limitations:</p> <ul> <li> <p>Containers use the host's operating system kernel which is likely different and     may have different drivers and kernel extensions than your regular system.     This may cause the container to fail or run with poor performance.</p> </li> <li> <p>The LUMI hardware is almost certainly different from that of the systems on which     you may have used the container before and that may also cause problems.</p> <p>In particular a generic container may not offer sufficiently good support for the  SlingShot 11 interconnect on LUMI which requires OFI (libfabric) with the right  network provider (the so-called Cassini provider) for optimal performance. The software in the container may fall back to TCP sockets resulting in poor  performance and scalability for communication-heavy programs.</p> <p>For containers with an MPI implementation that follows the MPICH ABI the solution is often to tell it to use the Cray MPICH libraries from the system instead.</p> </li> <li> <p>Building containers is currently not supported on LUMI due to security concerns.</p> </li> </ul>"},{"location":"4day-20230530/schedule/","title":"Course schedule","text":"<ul> <li>Day 1 <li>Day 2 <li>Day 3 <li>Day 4 DAY 1 - Tuesday 30/05              09:00 EEST             08:00 CEST Welcome and introduction Presenters: Emmanuel Ory (LUST), Harvey Richardson (HPE)(              09:15 EEST             08:15 CEST HPE Cray EX architecture Presenter: Harvey Richardson (HPE)              10:00 EEST             09:00 CEST Programming Environment and Modules Presenter: Harvey Richardson (HPE)              10:30 EEST             09:30 CEST Break (20 minutes)              10:50 EEST             09:40 CEST Running Applications <ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement (CPU/GPU/NIC)</li> </ul> Presenter: Harvey Richardson (HPE)              11:15 EEST             10:15 CEST Exercises (session #1)              12:00 EEST             11:00 CEST Lunch break (90 minutes)              13:30 EEST             12:30 CEST Compilers and Parallel Programming Models <ul> <li>An introduction to the compiler suites available, including examples of how to get additional information about the compilation process.</li> <li>Cray Compilation Environment (CCE) and options relevant to porting and performance. CCE classic to Clang transition.</li> <li>Description of the Parallel Programming models.</li> </ul> Presenter: Alfio Lazzaro (HPE)              14:40 EEST             13:40 CEST Exercises (session #2)              15:00 EEST             14:00 CEST Break (15 minutes)              15:15 EEST             14:15 CEST Cray Scientific Libraries <ul> <li>The Cray Scientific Libraries for CPU and GPU execution.</li> </ul> Presenter: Alfio Lazzaro (HPE)              15:45 EEST             14:45 CEST Exercises (session #3)              16:10 EEST             15:10 CEST CCE Offloading Models <ul> <li>Directive-based approach for GPU offloading execution with the Cray Compilation Environment.          Presenter: Alfio Lazzaro (HPE)              16:45 EEST             15:45 CEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 EEST             16:30 CEST End of the course day DAY 2 - Wednesday 31/05              09:00 EEST             08:00 CEST Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat Presenter: Thierry Braconnier (HPE)              09:45 EEST             08:45 CEST Exercises (session #4)              10:15 EEST             09:15 CEST Break (15 minutes)              10:30 EEST             09:30 CEST Advanced Placement <ul> <li>More detailed treatment of Slurm binding technology and OpenMP controls.</li> </ul> Presenter: Jean Pourroy (HPE)              11:30 EEST             10:30 CEST Exercises (session #5)              12:00 EEST             11:00 CEST Lunch break (90 minutes)              13:30 EEST             12:30 CEST LUMI Software Stacks <ul> <li>Software policy.</li> <li>Software environment on LUMI.</li> <li>Installing software with EasyBuild (concepts, contributed recipes)</li> <li>Containers for Python, R, VNC (container wrappers)</li> </ul> Presenter: Kurt Lust (LUST)              15:00 EEST             14:00 CEST Break (30 minutes)              15:30 EEST             14:30 CEST Introduction to HIP Programming <ul> <li></li> The AMD ROCmTM ecosystem             <li></li> HIP programming         </ul> Presenter: Samuel Ant\u00e3o (AMD)              16:30 EEST             15:30 CEST Exercises (session #6)              17:00 EEST             16:00 CEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 EEST             16:30 CEST End of the course day DAY 3 - Thursday 01/06              09:00 EEST             08:00 CEST Introduction to Perftools <ul> <li>Overview of the Cray Performance and Analysis toolkit for profiling applications.</li> <li>Demo: Visualization of performance data with Apprentice2 Presenter: Alfio Lazzaro (HPE)              09:40 EEST             08:40 CEST Exercises (session #7)              10:10 EEST             09:10 CEST Break              10:30 EEST             09:30 CEST Advanced Performance Analysis <ul> <li>Automatic performance analysis and loop work estimated with perftools</li> <li>Communication Imbalance, Hardware Counters, Perftools API, OpenMP</li> <li>Compiler feedback and variable scoping with Reveal</li> </ul> Presenter: Thierry Braconnier (HPE)              11:30 EEST             10:30 CEST Exercises (session #8)              12:00 EEST             11:00 CEST Lunch break              13:15 EEST             12:15 CEST MPI Topics on the HPE Cray EX Supercomputer <ul> <li>High level overview of Cray MPI on Slingshot</li> <li>Useful environment variable controls</li> <li>Rank reordering and MPMD application launch</li> </ul> Presenter: Harvey Richardson (HPE)              14:15 EEST             13:15 CEST Exercises (session #9)              14:45 EEST             13:45 CEST Break              15:00 EEST             14:00 CEST AMD Debugger: ROCgdb Presenter: Samuel Ant\u00e3o (AMD)              15:30 EEST             14:30 CEST Exercises (session #10)              15:45 EEST             14:45 CEST Introduction to ROC-Profiler (rocprof) Presenter: Samuel Ant\u00e3o (AMD)              16:25 EEST             15:25 CEST Exercises (session #11)              17:00 EEST             16:00 CEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.              17:30 EEST             16:30 CEST End of the course day DAY 4 - Friday June 2              09:00 EEST             08:00 CEST Performance Optimization: Improving Single-core Efficiency Presenter: Jean Pourroy (HPE)              09:50 EEST             08:50 CEST Python and Frameworks <ul> <li></li>Cray Python for the Cray EX         </ul> Presenter: Alfio Lazzaro (HPE)              10:00 EEST             09:00 CEST Exercises (session #12)              10:15 EEST             09:15 CEST Break              10:30 EEST             09:30 CEST Optimizing Large Scale I/O <ul> <li>Introduction into the structure of the Lustre Parallel file system. </li> <li>Tips for optimising parallel bandwidth for a variety of parallel I/O schemes. </li> <li>Examples of using MPI-IO to improve overall application performance.</li> <li>Advanced Parallel I/O considerations</li> <li>Further considerations of parallel I/O and other APIs.</li> <li>Being nice to Lustre</li> <li>Consideration of how to avoid certain situations in I/O usage that don\u2019t specifically relate to data movement.</li> </ul> Presenter: Harvey Richardson (HPE)              11:20 EEST             10:20 CEST Exercises (session #13)              12:00 EEST             11:00 CEST Lunch break (75 minutes)              13:15 EEST             12:15 CEST Introduction to OmniTrace Presenter: Samuel Ant\u00e3o (AMD)              13:45 EEST             12:45 CEST Exercises (session #14)              14:00 EEST             13:00 CEST Introduction to Omniperf Presenter: Samuel Ant\u00e3o (AMD)              14:30 EEST             13:30 CEST Exercises (session #15)              14:45 EEST             13:45 CEST Break              15:00 EEST             14:00 CEST Tools in Action - An Example with Pytorch Presenter: Samuel Ant\u00e3o (AMD)              16:30 EEST             15:30 CEST LUMI User Support <ul> <li>What can we help you with and what not? How to get help, how to write good support requests.</li> <li>Some typical/frequent support questions of users on LUMI?</li> </ul> Presenter: Anne Vomm (LUST)              17:00 EEST             16:00 CEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 EEST             16:30 CEST End of the course"},{"location":"4day-20231003/","title":"Comprehensive General LUMI Training, October 3-6, 2023","text":""},{"location":"4day-20231003/#course-organisation","title":"Course organisation","text":"<ul> <li> <p>Location: Centrum Konferencyjne IBIB PAN, Ks. Trojdena 4, 02-109 Warsaw, Poland     (Institute of Biocybernetics and Biomedical Engineering Polish Academy of Sciences).</p> <p>Public transportation in Warsaw</p> </li> <li> <p>Original schedule (PDF)</p> <p>Dynamic schedule (adapted as the course progresses)</p> <p>The dynamic schedule also contains links to pages with information about the course materials, but   those links are also available below on this page.</p> </li> </ul>"},{"location":"4day-20231003/#course-materials","title":"Course materials","text":"<p>Course materials include the Q&amp;A of each session, slides when available and notes when available.</p> <p>Due to copyright issues some of the materials are only available to current LUMI users and have to be downloaded from LUMI.</p> <p>Note: Some links in the table below are dead and will remain so until after the end of the course.</p> Presentation slides notes recording Appendix: Additional documentation / documentation /"},{"location":"4day-20231003/#links-to-documentation","title":"Links to documentation","text":"<p>The links to all documentation mentioned during the talks is on a separate page.</p>"},{"location":"4day-20231003/#external-material-for-exercises","title":"External material for exercises","text":"<p>Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:</p> <ul> <li>OSU benchmark</li> <li>Fortran OpenACC examples</li> <li>Fortran OpenMP examples</li> <li>Collections of examples in BabelStream</li> <li>hello_jobstep example</li> <li>Run OpenMP example in the HPE Suport Center</li> <li>ROCm HIP examples</li> </ul>"},{"location":"4day-20231003/A01_Documentation/","title":"Documentation links","text":"<p>Note that documentation, and especially web based documentation, is very fluid. Links change rapidly and were correct when this page was developed right after the course. However, there is no guarantee that they are still correct when you read this and will only be updated at the next course on the pages of that course.</p> <p>This documentation page is far from complete but bundles a lot of links mentioned during the presentations, and some more.</p>"},{"location":"4day-20231003/A01_Documentation/#web-documentation","title":"Web documentation","text":"<ul> <li> <p>Slurm version 22.05.8, on the system at the time of the course</p> </li> <li> <p>HPE Cray Programming Environment web documentation has only become available in      May 2023 and is a work-in-progress. It does contain a lot of HTML-processed man pages in an easier-to-browse      format than the man pages on the system.</p> <p>The presentations on debugging and profiling tools referred a lot to pages that can be found on this web site.  The manual pages mentioned in those presentations are also in the web documentation and are the easiest way  to access that documentation.</p> </li> <li> <p>Cray PE Github account with whitepapers and some documentation.</p> </li> <li> <p>Cray DSMML - Distributed Symmetric Memory Management Library</p> </li> <li> <p>Cray Library previously provides as TPSL build instructions</p> </li> <li> <p>Clang latest version documentation (Usually for the latest version)</p> <ul> <li> <p>Clang 13.0.0 version (basis for aocc/3.2.0)</p> </li> <li> <p>Clang 14.0.0 version (basis for rocm/5.2.3 and amd/5.2.3)</p> </li> <li> <p>Clang 15.0.0 version (cce/15.0.0 and cce/15.0.1 in 22.12/23.03)</p> </li> </ul> </li> <li> <p>AMD Developer Information</p> <ul> <li> <p>AOCC 4.0 Compiler Options Quick Reference Guide      (Version 4.0 compilers will come when the 23.05 or later CPE release gets installed on LUMI)</p> </li> <li> <p>AOCC 4.0 User Guide</p> </li> </ul> </li> <li> <p>ROCmTM documentation overview</p> <ul> <li> <p>rocminfo application for reporting system info.</p> </li> <li> <p>rocm-smi</p> </li> <li> <p>HIP porting guide</p> </li> <li> <p>ROCm Software Platform GitHub repository</p> </li> <li> <p>Libraries:</p> <ul> <li> <p>BLAS: rocBLAS and hipBLAS</p> </li> <li> <p>FFTs: rocFFT and hipFFT</p> </li> <li> <p>Random number generation: rocRAND</p> </li> <li> <p>Sparse linear algebra: rocSPARSE and hipSPARSE</p> </li> <li> <p>Iterative solvers: rocALUTION</p> </li> <li> <p>Parallel primitives: rocPRIM and hipCUB</p> </li> <li> <p>Machine Learning Libraries: MIOpen (similar to cuDNN),      Tensile (GEMM Autotuner),     RCCL (ROCm analogue of NCCL) and      Horovod (Distributed ML)</p> </li> <li> <p>Machine Learning Frameworks: Tensorflow,     Pytorch and     Caffe</p> </li> <li> <p>Machine Learning Benchmarks:     DeepBench and      MLPerf</p> </li> </ul> </li> <li> <p>Development tools:</p> <ul> <li> <p>rocgdb resources:</p> <ul> <li> <p>AMD documentation</p> </li> <li> <p>2021 presentation by Justin Chang</p> </li> <li> <p>2021 Linux Plumbers Conference presentation     with youTube video with a part of the presentation</p> </li> </ul> </li> <li> <p>rocprof profiler</p> </li> <li> <p>OmniTrace</p> </li> <li> <p>Omniperf</p> </li> </ul> </li> </ul> </li> <li> <p>HDF5 generic documentation</p> </li> <li> <p>Mentioned in the Lustre presentation: The      ExaIO project paper     \"Transparent Asynchronous Parallel I/O Using Background Threads\".</p> </li> </ul>"},{"location":"4day-20231003/A01_Documentation/#man-pages","title":"Man pages","text":"<p>A selection of man pages explicitly mentioned during the course:</p> <ul> <li> <p>Compilers</p> PrgEnv C C++ Fortran PrgEnv-cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> PrgEnv-gnu <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> PrgEnv-aocc/PrgEnv-amd - - - Compiler wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> </li> <li> <p>OpenMP in CCE</p> <ul> <li><code>man intro_openmp</code></li> </ul> </li> <li> <p>OpenACC in CCE</p> <ul> <li><code>man intro_openacc</code></li> </ul> </li> <li> <p>MPI:</p> <ul> <li> <p>MPI itself: <code>man intro_mpi</code> or <code>man mpi</code></p> </li> <li> <p>libfabric: <code>man fabric</code></p> </li> <li> <p>CXI: `man fi_cxi'</p> </li> </ul> </li> <li> <p>LibSci</p> <ul> <li> <p><code>man intro_libsci</code> and <code>man intro_libsci_acc</code></p> </li> <li> <p><code>man intro_blas1</code>,     <code>man intro_blas2</code>,     <code>man intro_blas3</code>,     <code>man intro_cblas</code></p> </li> <li> <p><code>man intro_lapack</code></p> </li> <li> <p><code>man intro_scalapack</code> and <code>man intro_blacs</code></p> </li> <li> <p><code>man intro_irt</code></p> </li> <li> <p><code>man intro_fftw3</code></p> </li> </ul> </li> <li> <p>DSMML - Distributed Symmetric Memory Management Library </p> <ul> <li><code>man intro_dsmml</code></li> </ul> </li> <li> <p>Slurm manual pages are also all on the web      and are easily found by Google, but are usually those for the latest version.</p> <ul> <li> <p><code>man sbatch</code></p> </li> <li> <p><code>man srun</code></p> </li> <li> <p><code>man salloc</code></p> </li> <li> <p><code>man squeue</code></p> </li> <li> <p><code>man scancel</code></p> </li> <li> <p><code>man sinfo</code></p> </li> <li> <p><code>man sstat</code></p> </li> <li> <p><code>man sacct</code></p> </li> <li> <p><code>man scontrol</code></p> </li> </ul> </li> </ul>"},{"location":"4day-20231003/A01_Documentation/#via-the-module-system","title":"Via the module system","text":"<p>Most HPE Cray PE modules contain links to further documentation. Try <code>module help cce</code> etc.</p>"},{"location":"4day-20231003/A01_Documentation/#from-the-commands-themselves","title":"From the commands themselves","text":"PrgEnv C C++ Fortran PrgEnv-cray <code>craycc --help</code> <code>crayCC --help</code> <code>crayftn --help</code> <code>craycc --craype-help</code> <code>crayCC --craype-help</code> <code>crayftn --craype-help</code> PrgEnv-gnu <code>gcc --help</code> <code>g++ --help</code> <code>gfortran --help</code> PrgEnv-aocc <code>clang --help</code> <code>clang++ --help</code> <code>flang --help</code> PrgEnv-amd <code>amdclang --help</code> <code>amdclang++ --help</code> <code>amdflang --help</code> Compiler wrappers <code>cc --help</code> <code>CC --help</code> <code>ftn --help</code> <p>For the PrgEnv-gnu compiler, the <code>--help</code> option only shows a little bit of help information, but mentions further options to get help about specific topics.</p> <p>Further commands that provide extensive help on the command line:</p> <ul> <li><code>rocm-smi --help</code>, even on the login nodes.</li> </ul>"},{"location":"4day-20231003/A01_Documentation/#documentation-of-other-cray-ex-systems","title":"Documentation of other Cray EX systems","text":"<p>Note that these systems may be configured differently, and this especially applies to the scheduler. So not all documentations of those systems applies to LUMI. Yet these web sites do contain a lot of useful information.</p> <ul> <li> <p>Archer2 documentation.      Archer2 is the national supercomputer of the UK, operated by EPCC. It is an AMD CPU-only cluster.     Two important differences with LUMI are that (a) the cluster uses AMD Rome CPUs with groups of 4 instead     of 8 cores sharing L3 cache and (b) the cluster uses Slingshot 10 instead of Slinshot 11 which has its     own bugs and workarounds.</p> <p>It includes a page on cray-python referred to during the course.</p> </li> <li> <p>ORNL Frontier User Guide and      ORNL Crusher Qucik-Start Guide.     Frontier is the first USA exascale cluster and is built up of nodes that are very similar to the     LUMI-G nodes (same CPA and GPUs but a different storage configuration) while Crusher is the     192-node early access system for Frontier. One important difference is the configuration of     the scheduler which has 1 core reserved in each CCD to have a more regular structure than LUMI.</p> </li> <li> <p>KTH Dardel documentation. Dardel is the Swedish \"baby-LUMI\" system.     Its CPU nodes use the AMD Rome CPU instead of AMD Milan, but its GPU nodes are the same as in LUMI.</p> </li> <li> <p>Setonix User Guide.     Setonix is a Cray EX system at Pawsey Supercomputing Centre in Australia. The CPU and GPU compute     nodes are the same as on LUMI.</p> </li> </ul>"},{"location":"4day-20231003/extra_1_00_Introduction/","title":"Introduction","text":"<p>Presenters: Emmanuel Ory (LUST), Harvey Richardson (HPE)</p> <p>No materials available</p>"},{"location":"4day-20231003/extra_1_01_HPE_Cray_EX_Architecture/","title":"HPE Cray EX Architecture","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_1_01_HPE_Cray_EX_Architecture/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_02_Programming_Environment_and_Modules/","title":"Programming Environment and Modules","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_1_02_Programming_Environment_and_Modules/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_03_Running_Applications/","title":"Running Applications","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_1_03_Running_Applications/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_04_Exercises_1/","title":"Exercise session 1","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_1_04_Exercises_1/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_05_Compilers_and_Parallel_Programming_Models/","title":"Compilers and Parallel Programming Models","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_1_05_Compilers_and_Parallel_Programming_Models/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_06_Exercises_2/","title":"Exercise session 2","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_1_06_Exercises_2/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_07_Cray_Scientific_Libraries/","title":"Cray Scientific Libraries","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_1_07_Cray_Scientific_Libraries/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_08_Exercises_3/","title":"Exercise session 3","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_1_08_Exercises_3/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_1_09_Offload_CCE/","title":"CCE Offloading Models","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_2_01_Advanced_Application_Placement/","title":"Advanced Placement","text":"<p>Presenter: Jean Pourroy (HPE)</p> <p>Course materials will be provided during and after the course.</p> <p>Remark</p> <p>The <code>lumi-CPEtools</code> module (in the LUMI software stacks, see this afternoon) contains alternatives for <code>xthi</code> and the <code>hello_jobstep</code> tool.</p>"},{"location":"4day-20231003/extra_2_01_Advanced_Application_Placement/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_02_Exercises_4/","title":"Exercise session 4","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_2_02_Exercises_4/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_03_Debugging_at_Scale/","title":"Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat","text":"<p>Presenter: Thierry Braconnier (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_2_03_Debugging_at_Scale/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_04_Exercises_5/","title":"Exercise session 5","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_2_04_Exercises_5/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_05_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>Presenter: Kurt Lust (LUST)</p> <ul> <li>Notes</li> <li>Slides (PDF)</li> </ul> <p>The information in this talk is also partly covered by the following talks from the 1-day courses:</p> <ul> <li>Modules on LUMI</li> <li>LUMI Software Stacks</li> </ul>"},{"location":"4day-20231003/extra_2_05_LUMI_Software_Stacks/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_06_Introduction_to_AMD_ROCm_Ecosystem/","title":"Introduction to HIP Programming","text":"<p>Presenter: Jakub Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_2_06_Introduction_to_AMD_ROCm_Ecosystem/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_2_07_Exercises_6/","title":"Exercise session 6","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_2_07_Exercises_6/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_01_Introduction_to_Perftools/","title":"Introduction to Perftools","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <p>Course materials will be provided during and after the course.</p> <p>Info</p> <p>You can find the downloads of Apprentice2 and Reveal on LUMI in <code>$CRAYPAT_ROOT/share/desktop_installers/</code>. This only works when the <code>perftools-base</code> module is loaded, but this is the case at login.</p>"},{"location":"4day-20231003/extra_3_01_Introduction_to_Perftools/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_02_Exercises_7/","title":"Exercise session 7","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_3_02_Exercises_7/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_03_Advanced_Performance_Analysis/","title":"Advanced Performance Analysis","text":"<p>Presenter: Thierry Braconnier (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_3_03_Advanced_Performance_Analysis/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_04_Exercises_8/","title":"Exercise session 8","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_3_04_Exercises_8/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_05_Cray_MPI_on_Slingshot/","title":"MPI Topics on the HPE Cray EX Supercomputer","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_3_05_Cray_MPI_on_Slingshot/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_06_Exercises_9/","title":"Exercise session 9","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_3_06_Exercises_9/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_07_AMD_ROCgdb_Debugger/","title":"AMD ROCgdb debugger","text":"<p>Presenter: Jakub Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_3_07_AMD_ROCgdb_Debugger/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_08_Exercises_10/","title":"Exercise session 10","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_3_08_Exercises_10/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_3_09_Introduction_to_Rocprof_Profiling_Tool/","title":"Introduction to ROC-Profiler (rocprof)","text":"<p>Presenter: Jakub Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p> <p>Note</p> <p>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but  a browser application. Some browsers nowadays offer the option to install it on your system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</p>"},{"location":"4day-20231003/extra_3_09_Introduction_to_Rocprof_Profiling_Tool/#qa","title":"Q&amp;A","text":""},{"location":"4day-20231003/extra_3_10_Exercises_11/","title":"Exercise session 11","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_3_10_Exercises_11/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_01_Performance_Optimization_Improving_Single_Core/","title":"Performance Optimization: Improving Single-core Efficiency","text":"<p>Presenter: Jean Pourroy (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_01_Performance_Optimization_Improving_Single_Core/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_02_Exercises_12/","title":"Exercise session 12","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_4_02_Exercises_12/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_03_Introduction_to_Python_on_Cray_EX/","title":"Introduction to Python on Cray EX","text":"<p>Presenter: Alfio Lazzaro (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_03_Introduction_to_Python_on_Cray_EX/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_04_IO_Optimization_Parallel_IO/","title":"I/O Optimization - Parallel I/O","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_04_IO_Optimization_Parallel_IO/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_05_Exercises_13/","title":"Exercise session 13","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_4_05_Exercises_13/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_06_AMD_Ominitrace/","title":"Introduction to OmniTrace","text":"<p>Presenter: Jakur Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_06_AMD_Ominitrace/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_07_Exercises_14/","title":"Exercise session 14","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_4_07_Exercises_14/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_08_AMD_Ominiperf/","title":"AMD Omniperf","text":"<p>Presenter: Jakub Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_08_AMD_Ominiperf/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_09_Exercises_15/","title":"Exercise session 15","text":"<p>No materials available at the moment.</p>"},{"location":"4day-20231003/extra_4_09_Exercises_15/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_10_Best_Practices_GPU_Optimization/","title":"Tools in Action - An Example with Pytorch","text":"<p>Presenter: Jakub Kurzak (AMD)</p> <p>Course materials will be provided during and after the course.</p>"},{"location":"4day-20231003/extra_4_10_Best_Practices_GPU_Optimization/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"4day-20231003/extra_4_11_LUMI_Support_and_Documentation/","title":"LUMI User Support","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Course materials will be provided during and after the course.</p> <p>The information in this talk is also covered by the following talk from the 1-day courses:</p> <ul> <li>LUMI User Support</li> </ul>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>In this part of the training, we cover:</p> <ul> <li>Software stacks on LUMI, where we discuss the organisation of the software stacks     that we offer and some of the policies surrounding it</li> <li>Advanced Lmod use to make the best out of the software stacks</li> <li>Creating your customised environment with EasyBuild, the tool that we use to install     most software.</li> <li>Some remarks about using containers on LUMI.</li> </ul>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: the option to use a partly coherent fully unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in Apple Silicon M-series but then without the NUMA character     (except maybe for the Ultra version that consists of two dies).</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a a talk in the     EasyBuild user meeting in 2022.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparent way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. Both have their own strengths and weaknesses. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be accustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. </p> <p>We do offer some help so set up Spack also but it is mostly offered \"as is\" and we will not do bug-fixing or development in Spack package files. Spack is very attractive for users who want to set up a personal environment with fully customised versions of the software rather than the rather fixed versions provided by EasyBuild for every version of the software stack. It is possible to specify versions for the main packages that you need and then let Spack figure out a minimal compatible set of dependencies to install  those packages.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionnaire sent out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, the so-called Cassini provider,      so any software compiled with an MPI library that     requires UCX, or any other distributed memory model built on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intra-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-Bus comes to mind.</li> </ul> <p>Also, the LUMI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that I did not yet mention is that software that accesses tens of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. On LUMI the tool is called lumi-container-wrapper but it may by some from CSC also be known as Tykky.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the minimal software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 3 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes and zen3 + MI250X for the LUMI-G partition. We were also planning to have a fourth version for the visualisation nodes with  zen2 CPUs combined with NVIDIA GPUs, but that may never materialise and we may manage those differently.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p> <p>We also have an extensible software stack based on Spack which has been pre-configured to use the compilers from the Cray PE. This stack is offered as-is for users who know how to use Spack, but we don't offer much support nor do we do any bugfixing in Spack.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It is also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. </p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/22.08, LUMI/22.12 and LUMI/23.03 modules.  Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules.  There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes and  partition/G for the AMD GPU nodes. There may be a separate partition for the visualisation nodes in the future  but that is not clear yet.</p> <p>There is also a hidden partition/common module in which software is installed that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#lmod-on-lumi","title":"Lmod on LUMI","text":""},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the few modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#module-spider-command","title":"Module spider command","text":"<p>Demo moment 1 (when infrastructure for a demo is available)</p> <p></p> <p>(The content of this slide is really meant to be shown in practice on a command line.)</p> <p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive. Let's try for instance <code>module spider gnuplot</code>. This     will show 17 versions of GNUplot. There are 12 installations of GNUplot 5.4.3 (of which 3 with Spack,     their name has a different structure) and five of 5.4.6. The      remainder of the name shows us with what compilers gnuplot was compiled. The reason to have      versions for two or three compilers is that no two compiler modules can be loaded simultaneously,     and this offers a solution to use multiple tools without having to rebuild your environment for     every tool, and hence also to combine tools. </p> <p>Now try <code>module spider CMake</code>. We see that there are four versions,3.22.2, 3.23.2, 3.24.0 and 3.25.2,  that are shown in blue with an \"E\" behind the name. That is because these are not provided  by a module called <code>CMake</code> on LUMI, but by another module that in this case contains a collection of popular build tools and that we will discover shortly.</p> <p>There are also a couple of regular modules called <code>cmake</code> that come from software installed differently.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module. Try for instance     <code>module spider gnuplot/5.4.6-cpeGNU-22.12</code>. This will now show full help information for     the specific module, including what should be done to make the module available. For      this GNUplot module we see that there are three ways to load the module: By loading <code>LUMI/22.12</code>      combined with <code>partition/C</code>, by loading <code>LUMI/22.12</code> combined with <code>partition/G</code>     or by loading <code>LUMI/22.12</code> combined with <code>partition/L</code>. So use only     a single line, but chose it in function of the other modules that you will also need. In this case     it means that that version of GNUplot is available in the <code>LUMI/22.12</code> stack which we could already     have guessed from its name, with binaries for the login and large memory nodes and the LUMI-C compute     partition. This does however not always work with the Cray Programming Environment modules.</p> <p>We can also use <code>module spider</code> with the name and version of an extension. So try <code>module spider CMake/3.25.2</code>. This will now show us that this tool is in the <code>buildtools/22.12</code> module (among others) and give us 4 different options to load that module as it is provided in the <code>CrayEnv</code> and the <code>LUMI/22.12</code> software stacks and for all partitions (basically because we don't do processor-specific optimisations for these tools).</p> </li> </ol> Demo module spider <p>Try the following commands:</p> <pre><code>module spider\nmodule spider gnuplot\nmodule spider cmake\nmodule spider gnuplot/5.4.6-cpeGNU-22.12\nmodule spider CMake/3.25.2\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#module-keyword-command","title":"Module keyword command","text":"<p>Lmod has a second way of searching for modules: <code>module keyword</code>, but unfortunately it does not yet work very well on LUMI as the version of Lmod is rather old and still has some bugs in the processing of the command. </p> <p>The <code>module keyword</code> command searches in some of the information included in module files for the given keyword, and shows in which modules the keyword was found.</p> <p>We do an effort to put enough information in the modules to make this a suitable additional way to discover software that is installed on the system.</p> Demo module keyword <p>Try the following command:</p> <pre><code>module keyword https\n</code></pre> <p> </p> <p>The bug in the Lmod 8.3 version on LUMI is that all extensions are shown in the output  while they are irrelevant. </p> <p> </p> <p>On the second screen though we see <code>cURL</code> which is a tool to download files over, among others, https.</p> <p> </p> <p> </p> <p>And the fourth screen <code>wget</code> which is also a tool to download files from the internet over an https connection.</p> <p> </p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#sticky-modules-and-module-purge","title":"Sticky modules and module purge","text":"<p>On some systems you will be taught to avoid <code>module purge</code> as many HPC systems do their default user configuration also through modules. This advice is often given on Cray systems as it is a common practice to preload a suitable set of target modules and a programming environment. On LUMI both are used. A default programming environment and set of target modules suitable for the login nodes is preloaded when you log in to the system, and next the <code>init-lumi</code> module is loaded which in turn makes the LUMI software stacks available that we will discuss in the next session.</p> <p>Lmod however has a trick that helps to avoid removing necessary modules and it is called sticky modules. When issuing the <code>module purge</code> command these modules are automatically reloaded. It is very important to realise that those modules will not just be kept \"as is\" but are in fact unloaded and loaded again as we shall see later that this may have consequences. It is still possible to force unload all these modules using <code>module --force purge</code> or selectively unload those using <code>module --force unload</code>.</p> <p>The sticky property is something that is defined in the module file and not used by the module files ot the HPE Cray Programming Environment, but we shall see that there is a partial workaround for this in some of the LUMI software stacks. The <code>init-lumi</code> module mentioned above though is a sticky module, as are the modules that activate a software stack so that you don't have to start from scratch if you have already chosen a software stack but want to clean up your environment.</p> Demo <p>Try the following command:</p> <pre><code>module av\n</code></pre> <p> </p> <p>Note the very descriptive titles in the above screenshot.</p> <p>The letter \"D\" next to a name denotes that this is the default version, the letter \"L\" denotes that the module is loaded, but we'll come back to  that later also.</p> <p> </p> <p>Note the two categories for the PE modules. The target modules get their own block. The screen below also shows <code>(D:5.0.2:5.2.0)</code> next to the <code>rocm</code> module.  The <code>D</code> means that this version of the module, <code>5.2.3</code>, is currently the default on the system. The two version numbers next to this module show that the module can also  be loaded as <code>rocm/5.0.2</code> and <code>rocm/5.2.0</code>. These are two modules that were removed from the system during the last update of the system, but version 5.2.3 can be loaded as a replacement of these modules so that software that used the removed modules may still work without recompiling.</p> <p> </p> <p>In the next screen we see the modules for the software stack that we have just discussed.</p> <p> </p> <p>And the screen below shows the extensions of modules (like the CMake tool we've tried to locate before)</p> <p> </p> <p> </p> <p>At the end of the output we also get some information about the meaning of the  letters used in the display.</p> <p>Try the following commands and carefully observe the output:</p> <pre><code>module load LUMI/22.08 buildtools\nmodule list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <p>The sticky property has to be declared in the module file so we cannot add it to for instance the Cray Programming Environment target modules, but we can and do use it in some modules that we control ourselves. We use it on LUMI for the software stacks themselves and for the modules that set the display style of the modules. </p> <ul> <li>In the <code>CrayEnv</code> environment, <code>module purge</code> will clear the target     modules also but as <code>CrayEnv</code> is not just left untouched but reloaded instead, the load of <code>CrayEnv</code>     will load a suitable set of target modules for the node you're on again. But any customisations that     you did for cross-compiling will be lost. </li> <li>Similarly in the LUMI stacks, as the <code>LUMI</code> module itself     is reloaded, it will also reload a partition module. However, that partition module might not be the      one that you had loaded but it will be the one that the LUMI module deems the best for the node you're     on, and you may see some confusing messages that look like an error message but are not.</li> </ul>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed already that by default you don't see the directories in which the module files reside as is the case on many other clusters. Instead we try to show labels that tell you what that group of modules actually is. And sometimes this also combines modules from multiple directories that have the same purpose. For instance, in the default view we collapse all modules from the Cray Programming Environment in two categories, the target modules and other programming environment modules. But you can customise this by loading one of the <code>ModuleLabel</code> modules. One version, the <code>label</code> version, is the default view. But we also have <code>PEhierarchy</code> which  still provides descriptive texts but unfolds the whole hierarchy in the Cray Programming  Environment. And the third style is called <code>system</code> which shows you again the module directories.</p> Demo <p>Try the following commands:</p> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>We're also very much aware that the default colour view is not good for everybody. So far we are not  aware of an easy way to provide various colour schemes as one that is OK for people who like a black  background on their monitor might not be OK for people who prefer a white background. But it is possible to turn colour off alltogether by loading the <code>ModuleColour/off</code> module, and you can always turn it on again with <code>ModuleColour/on</code>.</p> Demo <p>Try the following commands:</p> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment. For instance, when working in the <code>LUMI/22.12</code> stack we prefer that users use the Cray programming environment modules that come with release 22.12 of that environment, and cannot guarantee compatibility of other modules with already installed software, so we hide the other ones from view. You can still load them if you know they exist but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work or to use any module that was designed for us to maintain the system.</p> Demo <p>Try the following commands:</p> <pre><code>module load LUMI/22.12\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <p>Note that we see a lot more Cray PE modules with <code>ModulePowerUser</code>!</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system.  This is expected to happen especially with packages that require specific MPI versions or implementations. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And LUMI needs a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is the primary software installation tool.  EasyBuild was selected as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the build-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain there would be problems with MPI. EasyBuild uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures with some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     or the classic Intel compilers will simply optimize for a two decades old CPU.     The situation is better with the new LLVM-based compilers though, and it looks like     very recent versions of MKL are less AMD-hostile. Problems have also been reported     with Intel MPI running on LUMI.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system. </p> <p>We also have the LUMI Software Library which documents all software for which we have EasyBuild recipes available.  This includes both the pre-installed software and the software for which we provide recipes in the LUMI-EasyBuild-contrib GitHub repository, and even instructions for some software that is not suitable for installation through EasyBuild or Spack, e.g., because it likes to write in its own directories while running.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#easybuild-recipes-easyconfigs","title":"EasyBuild recipes - easyconfigs","text":"<p>EasyBuild uses a build recipe for each individual package, or better said, each individual module as it is possible to install more than one software package in the same module. That installation description relies on either a generic or a specific installation process provided by an easyblock. The build recipes are called easyconfig files or simply easyconfigs and are Python files with  the extension <code>.eb</code>. </p> <p>The typical steps in an installation process are:</p> <ol> <li>Downloading sources and patches. For licensed software you may have to provide the sources as     often they cannot be downloaded automatically.</li> <li>A typical configure - build - test - install process, where the test process is optional and     depends on the package providing useable pre-installation tests.</li> <li>An extension mechanism can be used to install perl/python/R extension packages</li> <li>Then EasyBuild will do some simple checks (some default ones or checks defined in the recipe)</li> <li>And finally it will generate the module file using lots of information specified in the      EasyBuild recipe.</li> </ol> <p>Most or all of these steps can be influenced by parameters in the easyconfig.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#the-toolchain-concept","title":"The toolchain concept","text":"<p>EasyBuild uses the toolchain concept. A toolchain consists of compilers, an MPI implementation and some basic mathematics libraries. The latter two are optional in a toolchain. All these  components have a level of exchangeability as there are language standards, as MPI is standardised, and the math libraries that are typically included are those that provide a standard API for which several implementations exist. All these components also have in common that it is risky to combine  pieces of code compiled with different sets of such libraries and compilers because there can be conflicts in names in the libraries.</p> <p>On LUMI we don't use the standard EasyBuild toolchains but our own toolchains specifically for Cray and these are precisely the <code>cpeCray</code>, <code>cpeGNU</code>, <code>cpeAOCC</code> and <code>cpeAMD</code> modules already mentioned  before.</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers (login nodes and LUMI-C only) <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p></p> <p>There is also a special toolchain called the SYSTEM toolchain that uses the compiler provided by the operating system. This toolchain does not fully function in the same way as the other toolchains when it comes to handling dependencies of a package and is therefore a bit harder to use. The EasyBuild designers had in mind that this compiler would only be used to bootstrap an EasyBuild-managed software stack, but we do use it for a bit more on LUMI as it offers us a relatively easy way to compile some packages also for the CrayEnv stack and do this in a way that they interact as little as possible with other software.</p> <p>It is not possible to load packages from different cpe toolchains at the same time. This is an EasyBuild restriction, because mixing libraries compiled with different compilers does not always work. This could happen, e.g., if a package compiled with the Cray Compiling Environment and one compiled with the GNU compiler collection would both use a particular  library, as these would have the same name and hence the last loaded one would be used by both executables (we don't use rpath or runpath linking in EasyBuild for those familiar with that technique).</p> <p>However, as we did not implement a hierarchy in the Lmod implementation of our software stack at the toolchain level, the module system will not protect you from these mistakes.  When we set up the software stack, most people in the support team considered it too misleading and difficult to ask users to first select the toolchain they want to use and then see the  software for that toolchain.</p> <p>It is however possible to combine packages compiled with one CPE-based toolchain with packages compiled with the system toolchain, but you should avoid mixing those when linking as that may cause problems. The reason that it works when running software is because static linking is used as much as possible in the SYSTEM toolchain so that these packages are as independent as possible.</p> <p>And with some tricks it might also be possible to combine packages from the LUMI software stack with packages compiled with Spack, but one should make sure that no Spack packages are available when building as mixing libraries could cause problems. Spack uses rpath linking which is why this may work.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#easyconfig-names-and-module-names","title":"EasyConfig names and module names","text":"<p>There is a convention for the naming of an EasyConfig as shown on the slide. This is not mandatory, but EasyBuild will fail to automatically locate easyconfigs for dependencies  of a package that are not yet installed if the easyconfigs don't follow the naming convention. Each part of the name also corresponds to a parameter in the easyconfig  file.</p> <p>Consider, e.g., the easyconfig file <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.</p> <ol> <li>The first part of the name, <code>GROMACS</code>, is the name of the package, specified by the     <code>name</code> parameter in the easyconfig, and is after installation also the name of the     module.</li> <li>The second part, <code>2021.4</code>, is the version of GROMACS and specified by the     <code>version</code> parameter in the easyconfig.</li> <li> <p>The next part, <code>cpeCray-22.08</code> is the name and version of the toolchain,     specified by the <code>toolchain</code> parameter in the easyconfig. The version of the     toolchain must always correspond to the version of the LUMI stack. So this is     an easyconfig for installation in <code>LUMI/22.08</code>.</p> <p>This part is not present for the SYSTEM toolchain</p> </li> <li> <p>The final part, <code>-PLUMED-2.8.0-CPU</code>, is the version suffix and used to provide     additional information and distinguish different builds with different options     of the same package. It is specified in the <code>versionsuffix</code> parameter of the     easyconfig.</p> <p>This part is optional.</p> </li> </ol> <p>The version, toolchain + toolchain version and versionsuffix together also combine to the version of the module that will be generated during the installation process. Hence this easyconfig file will generate the module  <code>GROMACS/2021.4-cpeCray-22.08-PLUMED-2.8.0-CPE</code>.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#installing-software","title":"Installing software","text":""},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>The next step is to configure your environment. First load the proper version of the LUMI stack for which you want to install software, and you may want to change to the proper partition also if you are cross-compiling.</p> <p>Once you have selected the software stack and partition, all you need to do to activate EasyBuild to install additional software is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition. </p> <p>Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p> <p>Note that the <code>EasyBuild-user</code> module is only needed for the installation process. For using the software that is installed that way it is sufficient to ensure that <code>EBU_USER_PREFIX</code> has the proper value before loading the <code>LUMI</code> module.</p> <p></p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Demo moment 2</p> <p></p> <p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes.</p> <p>First we need to figure out for which versions of GROMACS we already have support. The easy way is to check the LUMI Software Library which lists all software that we manage via EasyBuild and make available either pre-installed on the system or as an EasyBuild recipe for user installation. A command-line alternative is to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre></p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS there already is a GPU version for AMD GPUs in active development so even before LUMI-G was active we chose to ensure that we could distinguish between GPU and CPU-only versions. To install it, we first run  <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The installation of dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb\n</code></pre></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p> Demo of the EasyBuild installation of GROMACS <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p>End of demo moment 2</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work.</p> <p>Lmod does keep a user cache of modules. EasyBuild will try to erase that cache after a software installation to ensure that the newly installed module(s) show up immediately. We have seen some very rare cases where clearing the cache did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>In case you see strange behaviour using modules you can also try to manually remove the Lmod user cache which is in <code>$HOME/.lmod.d/.cache</code>. You can do this with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre></p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r . </code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.0-cpeGNU-22.08.eb \u2013r . </code></pre></p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greatest before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/UserRepo/easybuild/easyconfigs</code>.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory (unless the sources are already available elswhere where EasyBuild can find them, e.g., in the system EasyBuild sources directory),  and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software.</p> <p>Moreover, EasyBuild also keeps copies of all installed easyconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#easybuild-tips-tricks","title":"EasyBuild tips &amp; tricks","text":"<p>Updating the version of a package often requires only trivial changes in the easyconfig file. However, we do tend to use checksums for the sources so that we can detect if the available sources have changed. This may point to files being tampered with, or other changes that might need us to be a bit more careful when installing software and check a bit more again.  Should the checksum sit in the way, you can always disable it by using  <code>--ignore-checksums</code> with the <code>eb</code> command.</p> <p>Updating an existing recipe to a new toolchain might be a bit more involving as you also have to make build recipes for all dependencies. When we update a toolchain on the system, we often bump the versions of all installed libraries to one of the latest versions to have most bug fixes and security patches in the software stack, so you need to check for those versions also to avoid installing yet another unneeded version of a library.</p> <p>We provide documentation on the available software that is either pre-installed or can be user-installed with EasyBuild in the  LUMI Software Library. For most packages this documentation does also contain information about the license. The user documentation for some packages gives more information about how to use the package on LUMI, or sometimes also about things that do not work. The documentation also shows all EasyBuild recipes, and for many packages there is  also some technical documentation that is more geared towards users who want to build or modify recipes. It sometimes also tells why we did things in a particular way.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>I also want to give some pointers to more information in case you want to learn a lot more about, e.g., developing support for your code in EasyBuild, or for support people who want to adapt our EasyConfigs for users requesting a specific configuration of a package.</p> <p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>There is also a later course developed by LUST for developers of EasyConfigs for LUMI that can be found on  lumi-supercomputer.github.io/easybuild-tutorial.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#containers-on-lumi","title":"Containers on LUMI","text":"<p>Let's now switch to using containers on LUMI.  This section is about using containers on the login nodes and compute nodes.  Some of you may have heard that there were plans to also have an OpenShift Kubernetes container cloud platform for running microservices but at this point it is not clear if and when this will materialize due to a lack of personpower to get this running and then to support this.</p> <p>In this section, we will </p> <ul> <li> <p>discuss what to expect from containers on LUMI: what can they do and what can't they do,</p> </li> <li> <p>discuss how to get a container on LUMI,</p> </li> <li> <p>discuss how to run a container on LUMI,</p> </li> <li> <p>and discuss some enhancements we made to the LUMI environment that are based on containers or help     you use containers.</p> </li> </ul> <p>Remember though that the compute nodes of LUMI are an HPC infrastructure and not a container cloud!</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#what-do-containers-not-provide","title":"What do containers not provide","text":"<p>What is being discussed in this subsection may be a bit surprising. Containers are often marketed as a way to provide reproducible science and as an easy way to transfer software from one machine to another machine. However, containers are neither of those and this becomes  very clear when using containers build on your typical Mellanox/NVIDIA InfiniBand based clusters with Intel processors and NVIDIA GPUs on LUMI.</p> <p>First, computational results are almost never 100% reproducible because of the very nature of how computers work. You can only expect reproducibility of sequential codes between equal hardware. As soon as you change the CPU type, some floating point computations may produce slightly different results, and as soon as you go parallel this may even be the case between two runs on exactly the same hardware and software.</p> <p>But full portability is a much greater myth. Containers are really only guaranteed to be portable between similar systems. They may be a little bit more portable than just a binary as you may be able to deal with missing or different libraries in the container, but that is where it stops. Containers are usually built for a particular CPU architecture and GPU architecture, two elements where everybody can easily see that if you change this, the container will not run. But  there is in fact more: containers talk to other hardware too, and on an HPC system the first piece of hardware that comes to mind is the interconnect. And they use the kernel of the host and the kernel modules and drivers provided by that kernel. Those can be a problem. A container that is not build to support the SlingShot interconnect, may fall back to TCP sockets in MPI, completely killing scalability. Containers that expect the knem kernel extension for good  intra-node MPI performance may not run as efficiently as LUMI uses xpmem instead.</p> <p>Even if a container is portable to LUMI, it may not yet be performance portable. E.g., without proper support for the interconnect it may still run but in a much slower mode. But one should also realise that speed gains in the x86 family over the years come to a large extent from adding new instructions to the CPU set, and that two processors with the same instructions set extensions may still benefit from different optimisations by the compilers.  Not using the proper instruction set extensions can have a lot of influence. At my local site we've seen GROMACS  doubling its speed by choosing proper options, and the difference can even be bigger.</p> <p>Many HPC sites try to build software as much as possible from sources to exploit the available hardware as much as  possible. You may not care much about 10% or 20% performance difference on your PC, but 20% on a 160 million EURO investment represents 32 million EURO and a lot of science can be done for that money...</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#but-what-can-they-then-do-on-lumi","title":"But what can they then do on LUMI?","text":"<ul> <li> <p>A very important reason to use containers on LUMI is reducing the pressure on the file system by software     that accesses many thousands of small files (Python and R users, you know who we are talking about).     That software kills the metadata servers of almost any parallel file system when used at scale.</p> <p>As a container on LUMI is a single file, the metadata servers of the parallel file system have far less  work to do, and all the file caching mechanisms can also work much better.</p> </li> <li> <p>Software installations that would otherwise be impossible.      E.g., some software may not even be suited for installation in     a multi-user HPC system as it uses fixed paths that are not compatible with installation in \\     module-controlled software stacks.     HPC systems want a lightweight <code>/usr</code> etc. structure as that part of the system     software is often stored in a RAM disk, and to reduce boot times. Moreover, different users may need     different versions of a software library so it cannot be installed in its default location in the system     library. However, some software is ill-behaved and cannot be relocated to a different directory,     and in these cases containers help you to build a private installation that does not interfere with other     software on the system.</p> </li> <li> <p>As an example, Conda installations are not appreciated on the main Lustre file system.</p> <p>On one hand, Conda installations tend to generate lots of small files (and then even more due to a linking strategy that does not work on Lustre). So they need to be containerised just for storage manageability.</p> <p>They also re-install lots of libraries that may already be on the system in a different version.  The isolation offered by a container environment may be a good idea to ensure that all software picks up the right versions.</p> </li> <li> <p>Another example where containers have proven to be useful on LUMI is to experiment with newer versions     of ROCm than we can offer on the system. </p> <p>This often comes with limitations though, as (a) that ROCm version is still limited by the drivers on the  system and (b) we've seen incompatibilities between newer ROCm versions and the Cray MPICH libraries.</p> </li> </ul> <p>Remember though that whenever you use containers, you are the system administrator and not LUST. We can impossibly support all different software that users want to run in containers, and all possible Linux distributions they may want to run in those containers. We provide some advice on how to build a proper container, but if you chose to neglect it it is up to you to solve the problems that occur.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#managing-containers","title":"Managing containers","text":"<p>On LUMI, we currently support only one container runtime.</p> <p>Docker is not available, and will never be on the regular compute nodes as it requires elevated privileges to run the container which cannot be given safely to regular users of the system.</p> <p>Singularity is currently the only supported container runtime and is available on the login nodes and the compute nodes. It is a system command that is installed with the OS, so no module has to be loaded to enable it. We can also offer only a single version of singularity or its close cousin AppTainer  as singularity/AppTainer simply don't really like running multiple versions next to one another,  and currently the version that we offer is determined by what is offered by the OS.</p> <p>To work with containers on LUMI you will either need to pull the container from a container registry, e.g., DockerHub, or bring in the container by copying the singularity <code>.sif</code> file.</p> <p>Singularity does offer a command to pull in a Docker container and to convert it to singularity format. E.g., to pull a container for the Julia language from DockerHub, you'd use</p> <pre><code>singularity pull docker://julia\n</code></pre> <p>Singularity uses a single flat sif file for storing containers. The <code>singularity pull</code> command does the  conversion from Docker format to the singularity format.</p> <p>Singularity caches files during pull operations and that may leave a mess of files in the <code>.singularity</code> cache directory. This can lead to exhaustion of your disk quota for your home directory. So you may want to use the environment variable <code>SINGULARITY_CACHEDIR</code> to put the cache in, e.g,, your scratch space (but even then you want to clean up after the pull operation so save on your storage billing units).</p> Demo singularity pull <p>Let's try the <code>singularity pull docker://julia</code> command:</p> <p> </p> <p>We do get a lot of warnings but usually this is perfectly normal and usually they can be safely ignored.</p> <p> </p> <p>The process ends with the creation of the file <code>jula_latest.sif</code>. </p> <p>Note however that the process has left a considerable number of files in <code>~/.singularity</code> also:</p> <p> </p> <p></p> <p>There is currently limited support for building containers on LUMI and I do not expect that to change quickly. Container build strategies that require elevated privileges, and even those that require fakeroot, cannot be supported for security reasons.  Enabling features that are known to have had several serious security vulnerabilities in the recent past, ot that themselves are unsecure by design and could allow users to do more on the system than a regular user should be able to do, will never be supported.</p> <p>So you should pull containers from a container repository, or build the container on your own workstation and then transfer it to LUMI.</p> <p>There is some support for building on top of an existing singularity container. We are also working on a number of base images to build upon, where the base images are tested with the OS kernel on LUMI.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#interacting-with-containers","title":"Interacting with containers","text":"<p>There are basically three ways to interact with containers.</p> <p>If you have the sif file already on the system you can enter the container with an interactive shell:</p> <pre><code>singularity shell container.sif\n</code></pre> Demo singularity shell <p> </p> <p>In this screenshot we checked the contents of the <code>/opt</code> directory before and after the <code>singularity shell julia_latest.sif</code> command. This shows that we are clearly in a different environment. Checking the <code>/etc/os-release</code> file only confirms this as LUMI runs SUSE Linux on the login nodes, not a version of Debian.</p> <p>The second way is to execute a command in the container with <code>singularity exec</code>. E.g., assuming the  container has the <code>uname</code> executable installed in it,</p> <pre><code>singularity exec container.sif uname -a\n</code></pre> Demo singularity exec <p> </p> <p>In this screenshot we execute the <code>uname -a</code> command before and with the <code>singularity exec julia_latest.sif</code> command. There are some slight differences in the output though the same kernel version is reported as the container uses the host kernel. Executing</p> <pre><code>singularity exec julia_latest.sif cat /etc/os-release\n</code></pre> <p>confirms though that the commands are executed in the container.</p> <p>The third option is often called running a container, which is done with singularity run:</p> <pre><code>singularity run container.sif\n</code></pre> <p>It does require the container to have a special script that tells singularity what  running a container means. You can check if it is present and what it does with <code>singularity inspect</code>: </p> <pre><code>singularity inspect --runscript container.sif\n</code></pre> Demo singularity run <p> </p> <p>In this screenshot we start the julia interface in the container using <code>singularity run</code>. The second command shows that the container indeed includes a script to tell singularity what <code>singularity run</code> should do.</p> <p>You want your container to be able to interact with the files in your account on the system. Singularity will automatically mount <code>$HOME</code>, <code>/tmp</code>, <code>/proc</code>, <code>/sys</code> and <code>dev</code> in the container, but this is not enough as your home directory on LUMI is small and only meant to be used for storing program settings, etc., and not as your main work directory. (And it is also not billed and therefore no extension is allowed.) Most of the time you want to be able to access files in your project directories in <code>/project</code>, <code>/scratch</code> or <code>/flash</code>, or maybe even in <code>/appl</code>. To do this you need to tell singularity to also mount these directories in the container, either using the  <code>--bind src1:dest1,src2:dest2</code>  flag or via the <code>SINGULARITY_BIND</code> or <code>SINGULARITY_BINDPATH</code> environment variables.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#running-containers-on-lumi","title":"Running containers on LUMI","text":"<p>Just as for other jobs, you need to use Slurm to run containers on the compute nodes.</p> <p>For MPI containers one should use <code>srun</code> to run the <code>singularity exec</code> command, e.g,,</p> <pre><code>srun singularity exec --bind ${BIND_ARGS} \\\n${CONTAINER_PATH} mp_mpi_binary ${APP_PARAMS}\n</code></pre> <p>(and replace the environment variables above with the proper bind arguments for <code>--bind</code>, container file and parameters for the command that you want to run in the container).</p> <p>On LUMI, the software that you run in the container should be compatible with Cray MPICH, i.e., use the MPICH ABI (currently Cray MPICH is based on MPICH 3.4). It is then possible to tell the container to use Cray MPICH (from outside the container) rather than the MPICH variant installed in the container, so that it can offer optimal performance on the LUMI SlingShot 11 interconnect.</p> <p>Open MPI containers are currently not well supported on LUMI and we do not recommend using them. We only have a partial solution for the CPU nodes that is not tested in all scenarios,  and on the GPU nodes Open MPI is very problematic at the moment. This is due to some design issues in the design of Open MPI, and also to some piece of software that recent versions of Open MPI require but that HPE only started supporting recently on Cray EX systems and that we haven't been able to fully test. Open MPI has a slight preference for the UCX communication library over the OFI libraries, and  currently full GPU support requires UCX. Moreover, binaries using Open MPI often use the so-called rpath linking process so that it becomes a lot harder to inject an Open MPI library that is installed elsewhere. The good news though is that the Open MPI developers of course also want Open MPI to work on biggest systems in the USA, and all three currently operating or planned exascale systems use the SlingShot 11 interconnect so work is going on for better support for OFI and for full GPU support on systems that rely on OFI and do not support UCX.</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#enhancements-to-the-environment","title":"Enhancements to the environment","text":"<p>To make life easier, LUST with the support of CSC did implement some modules that are either based on containers or help you run software with containers.</p> <p>The <code>singularity-bindings/system</code> module which can be installed via EasyBuild helps to set <code>SINGULARITY_BIND</code> and <code>SINGULARITY_LD_LIBRARY__PATH</code> to use  Cray MPICH. Figuring out those settings is tricky, and sometimes changes to the module are needed for a specific situation because of dependency conflicts between Cray MPICH and other software in the container, which is why we don't provide it in the standard software stacks but instead make it available as an EasyBuild recipe that you can adapt to your situation and install.</p> <p>As it needs to be installed through EasyBuild, it is really meant to be  used in the context of a LUMI software stack (so not in <code>CrayEnv</code>). To find the EasyConfig files, load the <code>EasyBuild-user</code> module and  run</p> <pre><code>eb --search singularity-bindings\n</code></pre> <p>You can also check the  page for the module in the LUMI Software Library.</p> <p>You may need to change the EasyConfig for your specific purpose though. E.g., the singularity command line option <code>--rocm</code> to import the ROCm installation from the system doesn't fully work (and in fact, as we have alternative ROCm versions on the system cannot work in all cases) but that can also be fixed by extending the <code>singularity-bindings</code> module  (or by just manually setting the proper environment variables).</p> <p>The second tool is a container that we provide with some bash functions to start a VNC server as temporary way to be able to use some GUI programs on LUMI until the final setup which will be based on Open OnDemand is ready. It can be used in <code>CrayEnv</code> or in the LUMI stacks through the <code>lumi-vnc</code> module.  The container also contains a poor men's window manager (and yes, we know that there are sometimes some problems with fonts). It is possible to connect to the VNC server either through a regular VNC client on your PC or a web browser, but in both cases you'll have to create an ssh tunnel to access the server. Try</p> <pre><code>module help lumi-vnc\n</code></pre> <p>for more information on how to use <code>lumi-vnc</code>.</p> <p></p> <p>The third tool is a container wrapper tool that users from Finland may also know as Tykky. It is a tool to wrap Python and conda installations in a container and then create wrapper scripts for the commands in the bin subdirectory so that for most practical use cases the commands can be used without directly using singularity commands.  On LUMI, it is provided by the <code>lumi-container-wrapper</code> module which is available in the <code>CrayEnv</code> environment and in the LUMI software stacks. It is also documented in the LUMI documentation.</p> <p>The basic idea is that you run the tool to either do a conda installation or an installation of Python packages from a file that defines the environment in either standard conda format (a Yaml file) or in the <code>requirements.txt</code> format used by <code>pip</code>. </p> <p>The container wrapper will then perform the installation in a work directory, create some wrapper commands in the <code>bin</code> subdirectory of the directory where you tell the container wrapper tool to do the installation, and it will use SquashFS to create as single file that contains the conda or Python installation.</p> <p>We do strongly recommend to use the container wrapper tool for larger conda and Python installation. We will not raise your file quota if it is to house such installation in your <code>/project</code> directory.</p> Demo lumi-container-wrapper <p>Create a subdirectory to experiment. In that subdirectory, create a file named <code>env.yml</code> with the content:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.8.8\n  - scipy\n  - nglview\n</code></pre> <p>and create an empty subdirectory <code>conda-cont-1</code>.</p> <p>Now you can follow the commands on the slides below:</p> <p> </p> <p>On the slide above we prepared the environment.</p> <p>Now lets run the command </p> <pre><code>conda-containerize new --prefix ./conda-cont-1 env.yml\n</code></pre> <p>and look at the output that scrolls over the screen. The screenshots don't show the full output as some parts of the screen get overwritten during the process:</p> <p> </p> <p>The tool will first build the conda installation in a tempororary work directory and also uses a base container for that purpose.</p> <p> </p> <p>The conda installation itself though is stored in a SquashFS file that is then used by the container.</p> <p> </p> <p> </p> <p>In the slide above we see the installation contains both a singularity container and a SquashFS file. They work together to get a working conda installation.</p> <p>The <code>bin</code> directory seems to contain the commands, but these are in fact scripts  that run those commands in the container with the SquashFS file system mounted in it.</p> <p> </p> <p>So as you can see above, we can simply use the <code>python3</code> command without realising what goes on behind the screen...</p> <p>The wrapper module also offers a pip-based command to build upon the Cray Python modules already present on the system</p> <p>The final tool is <code>cotainr</code>,  a tool developed by DeIC, the Danish partner in the LUMI consortium. It is another tool to pack a Conda installation into a container, but it does so in a more container-like way (so no wrapper scripts). Just as <code>lumi-container-wrapper</code>, it runs entirely in user space and doesn't need any special rights. (For the container specialists: It is based on the container sandbox idea to build containers in user space.)</p>"},{"location":"4day-20231003/notes_2_05_LUMI_Software_Stacks/#conclusion-container-limitations-on-lumi-c","title":"Conclusion: Container limitations on LUMI-C","text":"<p>To conclude the information on using singularity containers on LUMI, we want to repeat the limitations:</p> <ul> <li> <p>Containers use the host's operating system kernel which is likely different and     may have different drivers and kernel extensions than your regular system.     This may cause the container to fail or run with poor performance.     Also, containers do not abstract the hardware unlike some virtual machine solutions.</p> </li> <li> <p>The LUMI hardware is almost certainly different from that of the systems on which     you may have used the container before and that may also cause problems.</p> <p>In particular a generic container may not offer sufficiently good support for the  SlingShot 11 interconnect on LUMI which requires OFI (libfabric) with the right  network provider (the so-called Cassini provider) for optimal performance. The software in the container may fall back to TCP sockets resulting in poor  performance and scalability for communication-heavy programs.</p> <p>For containers with an MPI implementation that follows the MPICH ABI the solution is often to tell it to use the Cray MPICH libraries from the system instead.</p> <p>Likewise, for containers for distributed AI, one may need to inject an appropriate RCCL plugin to fully use the SlingShot 11 interconnect.</p> </li> <li> <p>Building containers is currently not supported on LUMI due to security concerns.</p> </li> </ul>"},{"location":"4day-20231003/schedule/","title":"Course schedule","text":"<ul> <li>Day 1 <li>Day 2 <li>Day 3 <li>Day 4 DAY 1 - Tuesday 03/10              09:00 CEST             10:00 EEST Welcome and introduction Presenters: Emmanuel Ory (LUST), Harvey Richardson (HPE)              09:15 CEST             10:15 EEST HPE Cray EX architecture <ul> <li>Focus on the HPE Cray EX hardware architecture</li> </ul> Presenter: Harvey Richardson (HPE)              10:15 CEST             11:15 EEST Programming Environment and Modules <ul> <li>Focus on the HPE Cray EX software stack</li> <li>Turorial on the Cray module environment and compiler wrapper scripts</li> </ul> Presenter: Harvey Richardson (HPE)              10:45 CEST             11:45 EEST Break (15 minutes)              11:00 CEST             12:00 EEST Running Applications <ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement (CPU/GPU/NIC)</li> </ul> Presenter: Harvey Richardson (HPE)              11:20 CEST             12:20 EEST Exercises (session #1)              12:00 CEST             13:00 EEST Lunch break (90 minutes)              13:30 CEST             14:30 EEST Compilers and Parallel Programming Models <ul> <li>An introduction to the compiler suites available, including examples of how to get additional information about the compilation process.</li> <li>Cray Compilation Environment (CCE) and options relevant to porting and performance. CCE classic to Clang transition.</li> <li>Description of the Parallel Programming models.</li> </ul> Presenter: Alfio Lazzaro (HPE)              14:30 CEST             15:30 EEST Exercises (session #2)              15:00 CEST             16:00 EEST Break (15 minutes)              15:15 CEST             16:15 EEST Cray Scientific Libraries <ul> <li>The Cray Scientific Libraries for CPU and GPU execution.</li> </ul> Presenter: Alfio Lazzaro (HPE)              15:45 CEST             16:45 EEST Exercises (session #3)              16:15 EEST             15:15 EEST CCE Offloading Models <ul> <li>Directive-based approach for GPU offloading execution with the Cray Compilation Environment.          Presenter: Alfio Lazzaro (HPE)              17:00 CEST             18:00 EEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 CEST             18:30 EEST End of the course day DAY 2 - Wednesday 04/10              09:00 CEST             10:00 EEST Advanced Placement <ul> <li>More detailed treatment of Slurm binding technology and OpenMP controls.</li> </ul> Presenter: Jean Pourroy (HPE)              10:00 CEST             11:00 EEST Exercises (session #4)              10:30 CEST             11:30 EEST Break (15 minutes)              10:45 CEST             11:45 EEST Debugging at Scale \u2013 gdb4hpc, valgrind4hpc, ATP, stat Presenter: Thierry Braconnier (HPE)              11:30 CEST             12:30 EEST Exercises (session #5)              12:00 CEST             13:00 EEST Lunch break (90 minutes)              13:30 CEST             14:30 EEST LUMI Software Stacks <ul> <li>Software policy.</li> <li>Software environment on LUMI.</li> <li>Installing software with EasyBuild (concepts, contributed recipes)</li> <li>Containers for Python, R, VNC (container wrappers)</li> </ul> Presenter: Kurt Lust (LUST)              15:00 CEST             16:00 EEST Break (30 minutes)              15:30 CEST             16:30 EEST Introduction to HIP Programming <ul> <li></li> The AMD ROCmTM ecosystem             <li></li> HIP programming         </ul> Presenter: Jakub Kurzak (AMD)              16:30 CEST             17:30 EEST Exercises (session #6)              17:00 CEST             16:00 EEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 EEST             18:30 EEST End of the course day DAY 3 - Thursday 05/10              09:00 CEST             10:00 EEST Introduction to Perftools <ul> <li>Overview of the Cray Performance and Analysis toolkit for profiling applications.</li> <li>Demo: Visualization of performance data with Apprentice2 Presenter: Alfio Lazzaro (HPE)              09:40 CEST             10:40 EEST Exercises (session #7)              10:10 CEST             11:10 EEST Break              10:30 CEST             11:30 EEST Advanced Performance Analysis <ul> <li>Automatic performance analysis and loop work estimated with perftools</li> <li>Communication Imbalance, Hardware Counters, Perftools API, OpenMP</li> <li>Compiler feedback and variable scoping with Reveal</li> </ul> Presenter: Thierry Braconnier (HPE)              11:30 CEST             10:30 EEST Exercises (session #8)              12:00 EEST             13:00 EEST Lunch break              13:15 CEST             14:15 EEST MPI Topics on the HPE Cray EX Supercomputer <ul> <li>High level overview of Cray MPI on Slingshot</li> <li>Useful environment variable controls</li> <li>Rank reordering and MPMD application launch</li> </ul> Presenter: Harvey Richardson (HPE)              14:15 CEST             15:15 EEST Exercises (session #9)              14:45 CEST             15:45 EEST Break              15:00 CEST             16:00 EEST AMD Debugger: ROCgdb Presenter: Jakub Kurzak (AMD)              15:30 CEST             16:30 EEST Exercises (session #10)              16:00 CEST             17:00 EEST Introduction to ROC-Profiler (rocprof) Presenter: Jakub Kurzak (AMD)              16:30 CEST             17:30 EEST Exercises (session #11)              17:00 CEST             18:00 EEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.              17:30 CEST             18:30 EEST End of the course day DAY 4 - Friday 06/10              09:00 CEST             10:00 EEST Performance Optimization: Improving Single-core Efficiency Presenter: Jean Pourroy (HPE)              09:45 CEST             10:45 EEST Exercises (session #12)              10:00 CEST             11:00 EEST Python and Frameworks Presenter: Alfio Lazzaro (HPE)              10:15 CEST             11:15 EEST Break              10:30 CEST             11:30 EEST Optimizing Large Scale I/O <ul> <li>Introduction into the structure of the Lustre Parallel file system. </li> <li>Tips for optimising parallel bandwidth for a variety of parallel I/O schemes. </li> <li>Examples of using MPI-IO to improve overall application performance.</li> <li>Advanced Parallel I/O considerations: Further considerations of parallel I/O and other APIs.</li> <li>Being nice to Lustre: Consideration of how to avoid certain situations in I/O usage that don\u2019t specifically relate to data movement.</li> </ul> Presenter: Harvey Richardson (HPE)              11:30 CEST             12:30 EEST Exercises (session #13)              12:00 CEST             13:00 EEST Lunch break (75 minutes)              13:15 CEST             14:15 EEST Introduction to OmniTrace Presenter: Jakub Kurzak (AMD)              13:40 CEST             14:40 EEST Exercises (session #14)              14:00 CEST             15:00 EEST Introduction to Omniperf Presenter: Jakub Kurzak (AMD)              14:25 CEST             15:25 EEST Exercises (session #15)              14:45 CEST             15:45 EEST Break              15:00 CEST             16:00 EEST Tools in Action - An Example with Pytorch Presenter: Jakub Kurzak (AMD)              16:30 CEST             17:30 EEST LUMI User Support <ul> <li>What can we help you with and what not? How to get help, how to write good support requests.</li> <li>Some typical/frequent support questions of users on LUMI?</li> </ul> Presenter: J\u00f8rn Dietze (LUST)              17:00 CEST             18:00 EEST Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.                       17:30 CEST             18:30 EEST End of the course"},{"location":"EasyBuild-CSC-20220509/","title":"EasyBuild course for CSC and local organisations (9-11 May 2022)","text":""},{"location":"EasyBuild-CSC-20220509/#downloads","title":"Downloads","text":"<ul> <li>Slides (PDF, 5.6M)</li> </ul>"},{"location":"EasyBuild-CSC-20220509/#notes","title":"Notes","text":"<ul> <li>Course notes</li> </ul>"},{"location":"Hackathon-20230417/","title":"LUMI-G hackathon April 2023","text":""},{"location":"Hackathon-20230417/#projects","title":"Projects","text":"<ul> <li>ALARO ACRANEB2: Project in the framework of Destination Earth, but the code is not in the public domain.</li> <li>FEniCSx with a team from Cambride University and Edinburgh University / EPCC.</li> <li>ICON: Icosahedral Nonhydrostatic Weather and Climate Model,     with a team linked to DKRZ.</li> <li>TurboGAP data-driven atomistic simulation,      with a team from CSC and Aalto University.</li> <li>waLBerla, with a team from      Forschungszentrum J\u00fclich.</li> </ul>"},{"location":"Hackathon-20230417/#presentations","title":"Presentations","text":"<p>Overview of the team's presentations at the start and end of the hackathon week:</p> Team Opening presentation Closing presentation ALARO ACRANEB2 / / FEniCSx / PDF ICON PDF PDF TurboGAP PDF PDF waLBerla PDF PDF"},{"location":"LUMI-G-20220823/","title":"LUMI-G Pilot Training, August 23, 2022","text":""},{"location":"LUMI-G-20220823/#downloads","title":"Downloads","text":"<ul> <li>Introduction to the AMD ROCmTM Ecosystem (PDF, 6.3M)</li> <li>Exercises for \"Introduction to the AMD ROCmTM Ecosystem\" (tar file, 56k)</li> </ul>"},{"location":"LUMI-G-20220823/#notes","title":"Notes","text":"<ul> <li>Notes from the hackmd page</li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/","title":"LUMI-G Pilot Training","text":"<p>23.8.2022 9:00--17:30 (CEST)</p> <ul> <li>LUMI-G Pilot Training<ul> <li>General Information<ul> <li>Next public HPC coffee break</li> <li>Schedule</li> <li>Slides and other material (temporary location)</li> </ul> </li> <li>Q&amp;A<ul> <li>Ice breaker: What is the most important topic you want to learn about today?</li> <li>Introduction to the Cray EX Hardware and Programming Environment on LUMI-G</li> <li>First steps for running on LUMI-G<ul> <li>Remarks for this section</li> </ul> </li> <li>Introduction to the AMD ROCm(TM) Ecosystem</li> <li>AMD hands-on exercises</li> <li>General Q&amp;A</li> </ul> </li> </ul> </li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/#general-information","title":"General Information","text":""},{"location":"LUMI-G-20220823/hackmd_notes/#next-public-hpc-coffee-break","title":"Next public HPC coffee break","text":"<p>31.8.22, 13:00-13:45 (CEST), 14:00--14:45(EEST) Meet the LUMI user support team, discuss problems, give feedback or suggestions on how to improve services, and get advice for your projects.</p> <p>Every last Wednesday in a month. Join via Zoom</p>"},{"location":"LUMI-G-20220823/hackmd_notes/#schedule","title":"Schedule","text":"<ul> <li>9:00-9:10: Introduction<ul> <li>Course organisation</li> <li>Demonstration of how to use hackmd</li> </ul> </li> <li>9:10-10:15: Introduction to the Cray EX Hardware and Programming Environment on LUMI-G ([name=Harvey])<ul> <li>HPE Cray EX hardware architecture and software stack</li> <li>The Cray programming environment and compiler wrapper scripts</li> <li>An introduction to the compiler suites for GPUs</li> </ul> </li> <li>10:15-10:45: Break</li> <li>10:45-12:00: First steps for running on LUMI-G<ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement (CPU/GPU/NIC)</li> <li>MPI update for GPUs/SS11 (GPU-aware communications)</li> <li>Profiling tools</li> </ul> </li> <li>12:00-14:00: Lunch break</li> <li>14:00-15:45: AMD topics ([name=George] &amp; [name=Samuel])<ul> <li>GPU Hardware intro</li> <li>Introduction to ROCm and HIP</li> <li>Porting Applications to HIP</li> <li>ROCm libraries</li> <li>Profiling </li> <li>Debugging</li> </ul> </li> <li>15:30-16:00: Break</li> <li>16:00-16:45: Continuation of AMD topics + examples &amp; hands-on exercises</li> <li>16:45-17:30: General Questions &amp; Answers</li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/#slides-and-other-material-temporary-location","title":"Slides and other material (temporary location)","text":"<ul> <li>HPE slides and excercises on lumi at <code>/users/lazzaroa/hackathon</code> </li> <li>AMD slides: https://www.dropbox.com/s/umcjwr6hhn06ivl/LUMIG_training_AMD_ecosystem_23_08_2022.pdf?dl=0</li> <li>AMD excersises on lumi at <code>/users/gmarkoman/training</code> The README contains basic instructions</li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/#qa","title":"Q&amp;A","text":""},{"location":"LUMI-G-20220823/hackmd_notes/#ice-breaker-what-is-the-most-important-topic-you-want-to-learn-about-today","title":"Ice breaker: What is the most important topic you want to learn about today?","text":"<ul> <li>I want to learn how to bind GPUs to CPU cores</li> <li>Profiling and Debugging +6</li> <li>AMD GPU Unified Memory performance, Page Migration Mechanism, memory prefetching (eg. hipMemPrefetchAsync), comparison of differences between the newest AMD and NVIDIA archs with respect to Unified Memory</li> <li>General use of the system</li> <li>Any significant ROCm issues known? +1</li> <li>GPU aware MPI on LUMI. +2 </li> <li>How to compile my application for CPU/GPU execution</li> <li>How to build software in user's space under different software stacks?</li> <li> <p>What are the problems with LUMI-G that lead to the postponing of the pilot phase? Appart from hardware issues, can these issues impact users running in rocm containers?</p> </li> <li> <p>How to edit this document (without logging in)?</p> <ul> <li>You can click the \"Pencil\" button in the top left.</li> </ul> </li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/#introduction-to-the-cray-ex-hardware-and-programming-environment-on-lumi-g","title":"Introduction to the Cray EX Hardware and Programming Environment on LUMI-G","text":"<ol> <li> <p>Will pilots be restricted to a max of 100 nodes/run or is larger possible?</p> <ul> <li>For the CPU pilots there were special arrangements for very big runs towards the end of the pilot phase so I guess that could be arranged<ul> <li>Great, thanks, we (UTU) are very interested in very large runs</li> </ul> </li> </ul> </li> <li> <p>How are the MI250X seen in a program? 1 or 2 GPUs?</p> <ul> <li>2, more description in the next lecture<ul> <li>So a program will have to be multi-gpu to use it at maximum?<ul> <li>Not sure I understand the question, let's discuss this in the next lecture. There are 4 Mi250X on the node, a total of 8 GCDs. From the software point of view these are 8 GPUs. You can use ranks attached to each gpu or use multi-gpu within the same process.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Benchmarks vs NVIDIA (node vs node &amp; gpu vs gpu // fundamental ops &amp; application ie pytorch)</p> <ul> <li>One of the purposes of the pilot phase is actually that you establish such benchmarks. We do not have much numbers yet.  </li> </ul> </li> <li> <p>Is Simultaneous Multi-Threading enabled on CPU</p> <ul> <li>Yes, there are 128 hardware threads</li> <li>You need to use the slurm option `--threads-per-core=2</li> </ul> </li> <li> <p>Does slurm schedule multi-node jobs on nodes which have the lowest node to node latency in the dragonfly network?</p> <ul> <li>I doubt. It is not the case on the CPU nodes, so I doubt it will be the case on the GPUs. In fact, every dual GPU node blade connects to 4 switches but it is not clear to me if every node already connects to 4 swithces or if both nodes each connect to two switches. SLURM does try to give nodes that are close in the numbering which means that they are in one so-called group (within a rack). There are still other problems with the Slurm configuration though.</li> <li>You can configure Slurm to try to keep workloads to 'switches' (a Slurm concept). So you can associate a switch to a group of physical switches.</li> </ul> </li> <li> <p>debugger: what's the maximum job size of ddt's license ?</p> <ul> <li>256 MPI ranks (each rank can use 1 GPU), i.e. max 32 nodes. There is also the gdb4hpc debugger from HPE Cray, which has no limit</li> <li>We don't have a version that is ready for AMD GPUs though at the moment.</li> </ul> </li> <li> <p>Known issues with ROCm / HIP complex numbers? What version of ROCm?</p> <ul> <li>Any issue in particular that you are referring to here?</li> </ul> </li> <li> <p>What version of ROCm? </p> <ul> <li>Currently 5.0.2 but it changes all the time. We're still figuring out why 5.1 did not get installed as that should be supported on the version of the OS that we have.  </li> </ul> </li> <li> <p>Does the GPU-aware MPI do packing and unpacking for derived datatypes on the GPU? Does it support Unified Memory (passing pointers to UM)?</p> <ul> <li>The system has an unified memory pool - GPU memory pointer can not only be used in MPI but also in your CPU code.</li> <li>HPE is beeter position to answer how that packing/unpacking is implemented - not sure if that is offloaded to the GPU.<ul> <li>(HPE) I will ask to MPI experts..</li> <li>Thanks! My experience is that for example with OpenMPI and MVAPCIH2-GDR with NVIDIA archs, the packing and unpacking for derived data types is not done on the GPUs. This means that with Unified Memory, recurring page faults occur (because packing/unpacking is done on the CPU, and requires CPU accessing the data from the GPU). This can make derived MPI datatypes very slow, and we actually had to move back to continuous MPI datatypes (eg. MPI_BYTE), this gave a huge performance increase (3x whole program performance) with CUDA and NVIDIA cards. But it would be good to know whether things are different with AMD cards and cray MPI implementation?</li> <li>[HPE] Can you provide a little more detail about the datatypes involved, are they vector constructions for example.</li> <li>MPI_Type_create_struct and MPI_Type_create_hvector are used at least I think, I don't remember the exact details anymore, the code is here: https://github.com/parflow/parflow/blob/master/pfsimulator/amps/mpi1/amps_pack.c<ul> <li>(HPE) MPI expert reply: we currently do not offload datatype pack/unpact to the GPU. Users can allocate memory via hipMallocManaged or cudaMallocManaged and pass those pointers to MPI.  Users need to set MPICH_GPU_MANAGED_MEMORY_SUPPORT_ENABLED=1  for such codes (check <code>man mpi</code> for details).<ul> <li>Thanks, Will there be page faults, or is the data prefetched to the CPU without page faults for packing/unpacking? Does it crash if hipMalloc is used instead of hipMallocManaged when using those derived datatypes?<ul> <li>Sorry, you have to try, we don't have performance numbers...</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Maybe I mis - what is the difference between cray-python and python?</p> <ul> <li>cray-python is a just an installation that is linked to the cray libsci library for numpy/scipy/pandas</li> <li>System python should never be used, it comes with a miminum of packages and is not meant to be build upon.</li> <li>cray-python can be loaded with the module system</li> </ul> </li> <li> <p>Will there be multiple rocm modules available? </p> <ul> <li>Likely through different versions of the programming environment, the Cray compilers and Cray MPICH require specific versions. </li> <li>(Kurt for LUST) I checked what the current rocm/5.0.2 module does and it actually does not even support multiple versions of ROCm on the system as it uses <code>/opt/rocm</code> rather <code>/opt/rocm-5.0.2</code> which in turn may have to do with a ROCm problem, i..e., hard-coded paths in the ROCm code that don't support installing in other directories. Now if tomorrow the sysadmins would install ROCm 5.2.0 and then use <code>/etc/alternatives</code> to make that version the default, the 5.0.2 module would actually be loading 5.2.0 instead...</li> </ul> </li> <li> <p>What is the preferred way to monitor GPU usage and memory across multiple nodes?</p> <ul> <li>See later sessions, this is more a question for the end</li> <li>Usually <code>rocm-smi</code> is how you go about this, or you can instrument your application to collect stats. I used to do monitoring by SSHing to the allocated nodes but that is not available on LUMI. A possibility is to create a script such as (rocm-monitor) :   <pre><code>#!/bin/bash\n\nwhile true ; do\n   date &gt; ~/rocm-smi-$(hostname)\n rocm-smi &gt;&gt; ~/rocm-smi-$(hostname)\n sleep 1\ndone\n</code></pre>   then you can use in your submission script:   <pre><code>mpids=''\nif [ $SLURM_LOCALID -eq 0 ] ; then\n  rocm-monitor &amp;\n  mpids=$!\nfi\n\n... do your thing\n\nfor p in $mpids ; do\n  kill $p\ndone\n</code></pre>   And in a login node you can <code>watch -n1 cat ~/rocm-smi-*</code></li> </ul> </li> <li> <p>Is there a difference between <code>hipMalloc</code> and <code>hipMallocManaged</code> for LUMI environment?      If I remember right, the pointer to hipMalloc'd memory can be used in host code as well      with AMD GPUs (this is different from NVIDIA archs).</p> <ul> <li>One difference is that with hipMallocManaged the migration happens with the declaration while      with hipMalloc the migration will happen on demand. On the dev, the first access could be      slighlty slower than the next ones.</li> </ul> <p>Follow-up question: Can you confirm that with <code>hipMalloc</code> the migration happens only when the data is needed?  This would be the opposite of how it works with NVIDIA archs.</p> <ul> <li>Yes, not every time, just the first time, then no need to migrate again</li> </ul> <p>Insisting:  Are you 100% sure you did not mix the hipMalloc and hipMallocManaged functions?  With NVIDIA archs they work the other way around.</p> <ul> <li> <p>Trying to clarify:</p> <ul> <li><code>hipmalloc</code> - page lives in the GPU and is migrated to main memory on demand</li> <li><code>hiphostalloc</code> - page lives in main memory and is migrated to the GPU on demand</li> <li><code>hipmallocmanaged</code> - page is migrated when it is touch and then resides in the destination memory</li> </ul> </li> <li> <p>I think what is meant is that the first time you touch memory allocated in the GPU in the GPU,      you have a small hit in BW to have the shared memory system to workout the consistency logic. </p> </li> <li> <p>Just for completion - unified memory is on by default on the nodes. If you disable it (HSA_XNACK=0)     then a page fault will result in segfault in the first two cases. That could be useful if you want      to make sure you are not relying on the unified memory by mistake, i.e you are not using a main memory      pointer on the GPU or vice-versa. </p> </li> </ul> </li> <li> <p><code>craype-x86-rome</code>: are the cpus of the cn zen3/milan cpus ? would you recommend to load <code>craype-x86-milan</code> instead ?</p> <ul> <li>Actually, there is <code>craype-x86-trento</code>. More in the next slides</li> </ul> </li> <li> <p>Will complete start to finish tutorials be available (i.e. MNIST JAX example including loading modules / installing packages / running)? </p> <ul> <li>Likely not, except probably for very specific packages. It is impossible to maintain such documentation      with a small team as we are a small team and with the rapid rate of compiler updates that we can expect      in the next year. We do try to develop EasyBuild recipes for software though, and offer Spack for those      who know how to use it (but do not intend to implement packages in Spack ourselves). The reality is that      given the very new technology on LUMI, it will be a rapidly changing system initially and not one for      those who expect an environment that is stable for a longer period of time. </li> </ul> </li> </ol>"},{"location":"LUMI-G-20220823/hackmd_notes/#first-steps-for-running-on-lumi-g","title":"First steps for running on LUMI-G","text":"<ol> <li> <p>How to profile python programs?</p> <ul> <li>(HPE) I'm not sure about this, <code>pat_run</code> might tell you something, we plan to have a discussion about Python      support in the CoE/LUST team so I will keep this in mind.</li> </ul> </li> <li> <p>How to do MPI allreduce on pure GPUs and hybrid case?</p> <ul> <li>Copy data to GPU, then allreduce will be handled on GPU, also in hybrid case       (if some data is in main memory)</li> </ul> </li> <li> <p>About gpu_bind.sh: is there a reason why gpus are not attached to the numa nodes in a friendler way (gpu0 to numa0, etc...) ? because of the nic ?</p> <ul> <li>I guess hardware design and routing issues may have created this mess...</li> </ul> </li> <li> <p>When I run the following simple test found in https://github.com/csc-training/summerschool/blob/master/gpu-hip/memory-prefetch/solution/prefetch.cpp      on the NVIDIA-based system, I always get more or less the following kind of timings:     <pre><code>Mahti timings (NVIDIA A100)\nThe results are OK! (0.990s - ExplicitMemCopy)\nThe results are OK! (0.744s - ExplicitMemPinnedCopy)\nThe results are OK! (0.040s - ExplicitMemNoCopy)\nThe results are OK! (2.418s - UnifiedMemNoPrefetch)\nThe results are OK! (1.557s - UnifiedMemPrefetch)\nThe results are OK! (0.052s - UnifiedMemNoCopy)\n</code></pre>     However, on the LUMI with AMD GPUs, everything else looks good, but I don't understand why the      latter two cases are so slow. For example, putting a <code>hipMemPrefetchAsync</code> (that should speed up things),      looks to make it much slower in the second last case. In the last case, using <code>hipMemset</code> for a pointer to      a Unified Memory appears extremely slow:     <pre><code>LUMI timings\nThe results are OK! (0.748s - ExplicitMemCopy)\nThe results are OK! (0.537s - ExplicitMemPinnedCopy)\nThe results are OK! (0.044s - ExplicitMemNoCopy)\nThe results are OK! (0.609s - UnifiedMemNoPrefetch)\nThe results are OK! (3.561s - UnifiedMemPrefetch)\nThe results are OK! (18.889s - UnifiedMemNoCopy)\n</code></pre>     Any explanation?</p> <ul> <li> <p>(AMD) I'm looking into it - not have an explanation ready to go as of now.</p> </li> <li> <p>(LUST) could an environment variable such as <code>HSA_XNACK=1</code> be needed here?</p> <ul> <li>Setting <code>HSA_XNACK=1</code> makes things worse:     <pre><code>The results are OK! (3.357s - ExplicitMemCopy)\nThe results are OK! (0.547s - ExplicitMemPinnedCopy)\nThe results are OK! (0.070s - ExplicitMemNoCopy)\nThe results are OK! (3.373s - UnifiedMemNoPrefetch)\nThe results are OK! (3.950s - UnifiedMemPrefetch)\nThe results are OK! (21.824s - UnifiedMemNoCopy)\n</code></pre></li> </ul> </li> </ul> </li> <li> <p>Do any modules need to be loaded to run <code>rocm-smi</code>? I get the following error:     <pre><code>ERROR:root:Driver not initialized (amdgpu not found in modules)\n</code></pre></p> <ul> <li> <p>(HPE) Are you running on the compute node?</p> <ul> <li>R: Yes, but I think it should also run on the login node. I used to be able to run this both on compute nodes and login nodes. </li> </ul> </li> <li> <p>(HPE) Login do not have GPUs and drivers. I'm running this (use your project ID):     <pre><code>srun --nodes=1 --ntasks-per-node=1 -p pilot -A project_462000031 -t \"00:10:00\" --ntasks=1 --gres=gpu:8 rocm-smi\n</code></pre>     On the login you can get the help though.</p> </li> </ul> <p>Ok thank you. But why do I need to run this with <code>srun</code>? </p> <ul> <li>The <code>srun</code> command gets you to the compute node.</li> </ul> <p>Ok sorry for the confusion. My question is why doesn't this work with <code>salloc</code>?  I ask for an interactive session, then cannot run rocm-smi there.</p> <ul> <li>So, <code>salloc</code> does reserves nodes for you, but you are still on the login node.      You need <code>srun</code> to \"access\" the compute nodes. Example:     <pre><code>[13:21:26] \u2248\u2248XXXXXX@uan04:~ &gt; salloc --nodes=1 --ntasks-per-node=1 -p pilot -A project_XXXXXXXX -t \"00:10:00\" --ntasks=1 --gres=gpu:8 \nsalloc: Pending job allocation 1442086\nsalloc: job 1442086 queued and waiting for resources\nsalloc: job 1442086 has been allocated resources\nsalloc: Granted job allocation 1442086\nho[13:21:29] XXXXXXXX@uan04:~ &gt; hostname\nuan04\n[13:21:30] XXXXXXXX@uan04:~ &gt; srun hostname\nnid005015    \n</code></pre>     Does it make clear? Uan is the login node, nodes with nidXXX are compute nodes.</li> </ul> <p>Yes that is clear, thank you. On other clusters, salloc usually gives a shell on a compute node in my  experience. But I assume this is not the case here because ssh is not enabled.</p> <ul> <li> <p>You can connect via srun shell, just in case... I think the difference in salloc is because the      login nodes are shared between LUMI-C and LUMI-G...</p> </li> <li> <p>(Someone from LUST) <code>salloc</code> on LUMI behaves as I am used from other clusters and a SLURM training      we got from SchedMD at my home university so I am not that surprised. It has nothing to do with ssh.      On the contrary, the reason why ssh is not enabled is that it does not necessarily take to the right      CPU set and the resources that are controlled by SLURM.</p> </li> <li> <p>(HPE) I think the salloc behaviour is site configurable.</p> </li> </ul> </li> <li> <p>I am wondering if the GPUDirect RDMA is supported on LUMI-G?</p> <ul> <li>I think the osu device to device copy that Alfio showed indicates this is the case.</li> <li>(HPE) Yes, it is supported.</li> </ul> </li> <li> <p>Are containers supported on lumi-g? With rdma ?</p> <ul> <li>[HPE] this is something we are looking at, but I don't think we have checked on the current software stack.</li> </ul> </li> </ol>"},{"location":"LUMI-G-20220823/hackmd_notes/#remarks-for-this-section","title":"Remarks for this section","text":"<ul> <li>There are xthi-like programs in the <code>lumi-CPEtools</code> modules. Load the module and check <code>man lumi-CPEtools</code> for more information.</li> </ul>"},{"location":"LUMI-G-20220823/hackmd_notes/#introduction-to-the-amd-rocmtm-ecosystem","title":"Introduction to the AMD ROCm(TM) Ecosystem","text":"<ol> <li> <p>(Q): Is there a GPU memory pool allocator (that uses either hipMalloc or hipMallocManaged) for AMD GPUs?</p> <p>(A): Can you clarify what exactly you are looking for - you mean an allocator for a given language or runtime?            </p> <p>(Q): The point of pool allocator is to allocate a large memory pool which is reused.  So that recurrent alloc and free-calls do not recurrently allocate and free memory at  the system level, but instead just reuse the memory pool. I think CUDA recently added  memory pools (cf. cudaDeviceSetMemPool and cudaMallocAsync), but I have not used these yet.  Previously I have used Rapids Memory Manager with NVIDIA cards. This is really important  with applications which do recurring allocations and deallocations in a loop. For example  in the paper \"Leveraging HPC accelerator architectures with modern techniques - huydrologic modeling on  GPUs with ParFlow\",  simply using GPU memory pool allocator gave additional 5x speed-up for the whole program  performance (instead of allocating and freeing things recurringly with cudaMallocManaged and cudaFree).</p> <p>(Q): I see, you have hipDeviceSetMemPool but that is in  rocm 5.2.0,  unfortunately that is not the version on LUMI but it is possible to install in user space  and have it to work with the existing driver. Apart from that there are many runtimes that  do similar things, I don't have an exaustive list. There are many libraries and portability  layers that come up with their own memory management - if there is one in particular you think  is worth us to look at I (Sam) am happy to do so.</p> <p>(Q): Is that rocm5.2 also supporting memory pools for AMD GPUs, or only for NVIDIA GPUs?  The whole point is really to avoid having to write your own memory manager and using an  existing one, preferably one that is directly offered by HIP.</p> <p>(A): Didn't try it but if it goes in HIP should be supported on AMD Instinct GPUs.</p> <p>(Q): Do you know any libraries which would provide hipMallocManaged pool allocator for  AMD GPUs? I am not sure if the CUDA/HIP pools in rocm5.2 support Unified Memory.</p> <p>(A):Just found Umpire (https://computing.llnl.gov/projects/umpire) which appears to support HIP+Unified Memory pool allocation</p> </li> <li> <p>Will tools like GPUFORT be available on LUMI?</p> <ul> <li>We strive to provide many development tools on LUMI-G, but in the beginning,      during the pilot phase, you are expected to install some of the tools that you need      by yourself. GPUFORT seems like a research project, so might not want to \"officially\"      support itif it is difficult to use. Regarding OpenACC in general (the use case for      GPUFORT?), Cray's Fortran compiler does support OpenACC offloading to the AMD GPUs,      so this might be a better approach.</li> </ul> </li> <li> <p>If there performance difference hipforrtran vs fortran + hip ?</p> <ul> <li>There should not - hipfortran is awrapper exactly for fortran + hip.</li> </ul> </li> <li> <p>Question for HPE: Does the gcc that comes with the PE support OpenMP offload on AMD?</p> <ul> <li>No, the first version with Mi250X will be GCC 13. I do expect support in the PE when GNU will support the GPU.</li> </ul> </li> <li> <p>(Q): Is there JAX support / tests? </p> <p>(A): I'm not familiar with this or the XLA dependencies,  else might be able to answer.</p> <p>(Q): There is a known issue on AMD, seems to be unstable.</p> </li> <li> <p>Does any AMD profiling app give backtrace for Unified Memory page fault locations?</p> <ul> <li>Unfortunatly, I am not aware of a way for one to do that with the profile. You can      try disabling unified memory (<code>export HSA_XNACK=0</code>) and see where code crashes and get the backtrace then.</li> </ul> </li> <li> <p>Is Perfetto available as a desktop application? Or can I look at AMD profiles offline somehow?</p> <ul> <li>Even though Perfetto runs on the browser, it does run locally. If you want to have your instance      served locally you can use a docker container, this is the image I use:     <pre><code>FROM eu.gcr.io/perfetto-ci/sandbox\n\nRUN set -eux ; \\\ncd /opt ; \\\ngit clone -b v20.1 https://github.com/google/perfetto\n\nWORKDIR /opt/perfetto\nRUN set -eux ; \\\ntools/install-build-deps --ui\n\nRUN set -eux ; \\\nui/build\n\nRUN set -eux ; \\\nsed -i 's/127\\.0\\.0\\.1/0.0.0.0/g' ui/build.js\n\nEXPOSE 10000\nENTRYPOINT []\nCMD [\"./ui/run-dev-server\", \"-n\"]\n</code></pre>     build with     <pre><code>#!/bin/bash\n\ndocker network rm \\\nlan-restricted\n\ndocker network create \\\n-o \"com.docker.network.bridge.enable_ip_masquerade\"=\"false\" \\\nlan-restricted\n\ndocker run -p 10000:10000 --name myperfetto --network  lan-restricted myperfetto\n</code></pre>     This will create a local server for Perfetto</li> </ul> </li> <li> <p>Is the following warning expected when running rocm-smi?     <pre><code>======================= ROCm System Management Interface =======================\n================================= Concise Info =================================\nGPU  Temp   AvgPwr  SCLK    MCLK     Fan  Perf  PwrCap  VRAM%  GPU%  \n0    39.0c  88.0W   800Mhz  1600Mhz  0%   auto  560.0W    0%   0%    \n1    45.0c  N/A     800Mhz  1600Mhz  0%   auto  0.0W      0%   0%    \n2    43.0c  85.0W   800Mhz  1600Mhz  0%   auto  560.0W    0%   0%    \n3    41.0c  N/A     800Mhz  1600Mhz  0%   auto  0.0W      0%   0%    \n4    44.0c  82.0W   800Mhz  1600Mhz  0%   auto  560.0W    0%   0%    \n5    41.0c  N/A     800Mhz  1600Mhz  0%   auto  0.0W      0%   0%    \n6    41.0c  83.0W   800Mhz  1600Mhz  0%   auto  560.0W    0%   0%    \n7    40.0c  N/A     800Mhz  1600Mhz  0%   auto  0.0W      0%   0%    \n================================================================================\nWARNING:                 One or more commands failed\n============================= End of ROCm SMI Log ==============================\n</code></pre></p> <ul> <li>The warning likely comes from SLURM because <code>rocm-smi</code> returns non-zero exit codes?</li> </ul> </li> <li> <p>What is the timeline of the pilot phase? When exactly does it start and when does it end?</p> <ul> <li>It will start on September 26th and last for a month.</li> </ul> </li> </ol>"},{"location":"LUMI-G-20220823/hackmd_notes/#amd-hands-on-exercises","title":"AMD hands-on exercises","text":"<p>Files for  excersises on lumi are available for download (tar file, 56k). The README contains basic instructions</p>"},{"location":"LUMI-G-20220823/hackmd_notes/#general-qa","title":"General Q&amp;A","text":"<ol> <li> <p>How to bind correctly mpi-rank &lt;-&gt; gpu-id?     select_gpu.sh     <pre><code>#!/bin/bash\n\nGPUSID=\"4 5 2 3 6 7 0 1\"\nGPUSID=(${GPUSID})\nif [ ${#GPUSID[@]} -gt 0 -a -n \"${SLURM_NTASKS_PER_NODE}\" ]; then\n    export ROCR_VISIBLE_DEVICES=${GPUSID[$((SLURM_LOCALID / ($SLURM_NTASKS_PER_NODE / ${#GPUSID[@]})))]}\nfi\n\nexec $*\n</code></pre></p> <pre><code>#SBATCH --job-name=NAME          # &lt;--- SET \n#SBATCH --output=\"NAME.%J.out\"   # &lt;--- SET\n#SBATCH --error=\"NAME.%J.err\"    # &lt;--- SET\n#SBATCH --nodes=2                # &lt;--- SET: Number of nodes, each noode has 8 GPUs\n#SBATCH --ntasks=16              # &lt;--- SET: Number of processes you want to use, MUST be nodes*8 !!!\n#SBATCH --gpus=16                # &lt;--- SET: MUST be the same as ntasks !!!\n#SBATCH --time=15:00             # &lt;--- SET: Walltime HH:MM:SS\n#SBATCH --mail-type=ALL\n#SBATCH --mail-user=your@email   # &lt;--- SET: if you want to get e-mail notification\n#SBATCH --partition=eap \n#SBATCH --account=project_465000150 \n#SBATCH --cpus-per-task=1        # Do not modify\n#SBATCH --ntasks-per-node=8      # Do not modify\n\n# Set environment\nexport MPICH_GPU_SUPPORT_ENABLED=1 \n\n# the simple call\nsrun -n 16 ./td-wslda-3d input.txt\n\n# I mapping provided above.\n\n--------------------------------------------------------------------\n# START OF THE MAIN FUNCTION\n# CODE: TD-WSLDA-3D\n# PROCESS ip=6 RUNNING ON NODE nid005100 USES device-id=6\n# PROCESS ip=1 RUNNING ON NODE nid005100 USES device-id=1\n# PROCESS ip=7 RUNNING ON NODE nid005100 USES device-id=7\n# PROCESS ip=5 RUNNING ON NODE nid005100 USES device-id=5\n# PROCESS ip=4 RUNNING ON NODE nid005100 USES device-id=4\n# PROCESS ip=3 RUNNING ON NODE nid005100 USES device-id=3\n# PROCESS ip=2 RUNNING ON NODE nid005100 USES device-id=2\n# PROCESS ip=12 RUNNING ON NODE nid005104 USES device-id=4\n# PROCESS ip=13 RUNNING ON NODE nid005104 USES device-id=5\n# PROCESS ip=15 RUNNING ON NODE nid005104 USES device-id=7\n# PROCESS ip=8 RUNNING ON NODE nid005104 USES device-id=0\n# PROCESS ip=14 RUNNING ON NODE nid005104 USES device-id=6\n# PROCESS ip=10 RUNNING ON NODE nid005104 USES device-id=2\n# PROCESS ip=11 RUNNING ON NODE nid005104 USES device-id=3\n# PROCESS ip=9 RUNNING ON NODE nid005104 USES device-id=1\n# PROCESS ip=0 RUNNING ON NODE nid005100 USES device-id=0\n...\n</code></pre> </li> <li> <p>What has changed over the past 2 weeks (software and or hardware) ? I was running PyTorch code      using this container more or less reliably at the beginning of the pre pilot phase using rccl backend. I haven't touched it since and tried again today and I seem to have network issues:</p> <pre><code>nid005000:30599:30731 [0] /long_pathname_so_that_rpms_can_package_the_debug_info/data/driver/rccl/src/include/socket.h:415 NCCL WARN Net : Connect to 10.120.24.10&lt;52061&gt; failed : No route to host\n</code></pre> <p>Any ideas?</p> <ul> <li>(AMD): Try <code>export NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3</code> let RCCL focus on the right      network interfaces. Also <code>export NCCL_DEBUG=INFO</code> to get more info. <code>export NCCL_DEBUG_SUBSYS=INIT,COLL</code>.</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/","title":"LUMI-G Training, January 11, 2023","text":""},{"location":"LUMI-G-20230111/#course-overview","title":"Course overview","text":"<ul> <li>Course schedule</li> </ul>"},{"location":"LUMI-G-20230111/#downloads","title":"Downloads","text":"<ul> <li>Slides Introduction to the AMD ROCmTM Ecosystem (PDF, 10M)</li> <li>Additional notes and exercises from the AMD session</li> <li>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but      a browser application. Some browsers nowadays offer the option to install it on your     system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</li> </ul>"},{"location":"LUMI-G-20230111/#other-material-only-available-on-lumi","title":"Other material only available on LUMI","text":"<p>The following materials can only be found on LUMI and are only accessible to members of project_465000320:</p> <ul> <li>Introduction to the Cray EX Hardware and Programming Environment on LUMI-G<ul> <li>Slides: <code>/project/project_465000320/slides/HPE/01_Intro_EX_Architecture_and_PE.pdf</code></li> <li>Recording: <code>/project/project_465000320/recordings/01_Intro_EX_Architecture_and_PE.mp4</code> </li> </ul> </li> <li>Running Applications on LUMI-G<ul> <li>Slides: <code>/project/project_465000320/slides/HPE/02_Running_Applications_and_Tools.pdf</code></li> <li>Recording: <code>/project/project_465000320/recordings/02_Running_Applications_and_Tools.mp4</code></li> </ul> </li> <li>Introduction to AMD ROCmTM Ecosystem<ul> <li>Recording: <code>/project/project_465000320/recordings/03_Introduction_to_the_AMD_ROCmTM_ecosystem.mp4</code></li> </ul> </li> <li>Exercises are in <code>/project/project_465000320/exercises</code></li> </ul>"},{"location":"LUMI-G-20230111/#notes","title":"Notes","text":"<ul> <li>Notes from the HedgeDOC page</li> </ul>"},{"location":"LUMI-G-20230111/#exercises","title":"Exercises","text":"<p>Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:</p> <ul> <li>OSU benchmark</li> <li>Fortran OpenACC examples</li> <li>Fortran OpenMP examples</li> <li>Collections of examples in BabelStream</li> <li>hello_jobstep example</li> <li>Run OpenMP example in the HPE Suport Center</li> <li>ROCm HIP examples</li> </ul>"},{"location":"LUMI-G-20230111/hedgedoc_notes/","title":"Notes from the HedgeDoc page","text":"<p>These are the notes from the LUMI-G training, 11.01.2023, 9:00--17:00 (CET) on Zoom.</p> <ul> <li>Notes from the HedgeDoc page<ul> <li>General information<ul> <li>Exercises</li> <li>LUMI user coffee break</li> </ul> </li> <li>Slides and other material</li> <li>Q&amp;A of the sessions<ul> <li>Questions regarding organisation or LUMI in general</li> <li>Introduction to the Cray EX Hardware and Programming Environment on LUMI-G</li> <li>First steps for running on LUMI-G</li> <li>Exercises morning sessions</li> <li>GPU Hardware &amp; Introduction to ROCm and HIP</li> <li>General Q&amp;A</li> </ul> </li> </ul> </li> </ul>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#general-information","title":"General information","text":""},{"location":"LUMI-G-20230111/hedgedoc_notes/#exercises","title":"Exercises","text":"<p>The exercise files are on lumi at <code>project/project_465000320/exercises</code>.Copy the files into your home directory and work from there.</p>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#lumi-user-coffee-break","title":"LUMI user coffee break","text":"<p>25.1.23, 13:00-13:45 (CET), 14:00--14:45(EET) Meet the LUMI user support team, discuss problems, give feedback or suggestions on how to improve services, and get advice for your projects.</p> <p>Every last Wednesday in a month. Join via Zoom</p>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#slides-and-other-material","title":"Slides and other material","text":"<p>Slides from HPE are available on LUMI at <code>project/project_465000320/slides</code> You need to join the training project via the link you received in the email on Monday. Slides from the LUST talks are available on these pages</p>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#qa-of-the-sessions","title":"Q&amp;A of the sessions","text":""},{"location":"LUMI-G-20230111/hedgedoc_notes/#questions-regarding-organisation-or-lumi-in-general","title":"Questions regarding organisation or LUMI in general","text":"<ol> <li> <p>I was on the waiting list for the training, and didn't seen to recieve the invitation link to the project. Any way to get the slides? (I have access to LUMI)</p> <p>Answer</p> <ul> <li>This training was heavily overbooked, so it wasn't possible for everyone to get access.</li> <li>We will share the AMD slides on https://lumi-supercomputer.github.io/LUMI-training-materials/</li> <li>We are still debating on how to share the HPE slides with all LUMI users (everyone who joined the training project can access the slides on LUMI at <code>/project/project_465000320/slides</code>.</li> <li>I tried to see the slides at /project/project_465000320/slides, but permission denied.</li> <li>I managed to <code>cp</code> the presentation slides to my ~/user/slides and then <code>scp</code> to my base PC with no problem.</li> <li>Still can not access: cp: cannot stat '/project/project_465000320/slides': Permission denied<ul> <li>same for me \"permission denied\"</li> </ul> </li> </ul> </li> <li> <p>Will the recorded training available after? I did not get the link and could join after 20 minutes.</p> <p>Answer</p> <ul> <li>We are still debating on how to best share but we will definitely upload them to LUMI at <code>/project/project_465000320/recordings</code>.<ul> <li>it will be unavailable for people with \"permission denied\"</li> </ul> </li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#introduction-to-the-cray-ex-hardware-and-programming-environment-on-lumi-g","title":"Introduction to the Cray EX Hardware and Programming Environment on LUMI-G","text":"<p>Presenter: Harvey Richardson (HPE)</p> <p>Info</p> <p>The slides for this session are available on LUMI at <code>01_Intro_EX_Architecture_and_PE.pdf</code>. There are also optional exercises on LUMI at <code>/project/project_465000320/exercises/HPE</code></p> <ol> <li> <p>What's the topology of Slingshot in Lumi?</p> <p>Answer</p> <ul> <li>Dragonfly, more later</li> </ul> <p>Question</p> <ul> <li>Do we have about 50 GPUs per switch?</li> </ul> <p>Answer</p> <ul> <li>It's a bit more difficult than this as every board (with two nodes per board) is connected to multiple switches on the first level of switches, and I believe this actually results in multiple switches per node also. But the number is much less than 50 per switch. I'm not sure but I believe it is 16 at the first level, the other connections on those switches are used to build the dragonfly with some ports for in-group connections and others for connections between the groups.</li> <li>(Harvey) I will try to address this in future training, I still need to understand this myself as it varies by system and node type.</li> </ul> <p>Question</p> <ul> <li>Is Slurm aware? Will it but tasks in one job to the same electric group?</li> </ul> <p>Answer</p> <ul> <li>Not always as this would dramatically raise waiting times for jobs in the queue. Network groups are available as a Slurm feature of the compute node: <code>scontrol show node nid00XXXX</code> -&gt; \"ActiveFeatures=AMD_EPYC_7A53,x1101. In this example, <code>x1101</code> is the identifier of the network group. User can request that a job use a particular group by using the Slurm <code>--constraint=&lt;feature&gt;</code> option.</li> <li>(Harvey) You can configure slurm to be aware of the switch topology, I just checked and I don't think this is currently enabled but this is something we should consider.</li> </ul> </li> <li> <p>How does SHMEM work with GPU memory? is there something similar to NVSHMEM?</p> <p>Answer</p> <ul> <li>I don't think so, I don't think there is a GPU support. Good question for AMD people though... </li> <li>See ROC_SHMEM.    It requires UCX so, it may not work on LUMI that relies on libfabric for   communication.</li> </ul> </li> <li> <p>What is the module name for the Cray Scientific and Math Libraries     I can't find out how to load LAPACK and BLAS on LUMI</p> <p>Answer</p> <ul> <li><code>module load cray-libsci</code>. This might be discussed later in the course and is part of our introductory courses. It is linked automatically when cray-libsci is loaded but there is more to it that is discussed in our \"big\" course like the one we had in November in Brussels or the online one we will have in February. All those modules also come with manual pages. In this case it is <code>man intro_libsci</code> (after <code>module load cray-libsci</code>) that is a good starting point.</li> </ul> <p>Question</p> <ul> <li>Thank you! And then I can probably use <code>module show cray-libsci</code> to locate the header files.</li> </ul> <p>Answer</p> <ul> <li>The compiler wrappers should add the necessary <code>-I</code> options automatically. But the mdoule does define    a number of environment variables that point to the installation directory of the libraries, so you can   develop Makefiles etc. that adapt to new releases on the system</li> </ul> </li> <li> <p>Where can I get more information about GPU accelerated Sci libraries?</p> <p>Answer</p> <ul> <li>Need to load the module first (cray-libsci_acc) and then you have a man page: <code>man -l /opt/cray/pe/libsci_acc/default/man/man3/intro_libsci_acc.3s</code></li> </ul> </li> <li> <p>how can I check my project ID (I have two projects)?</p> <p>Answer</p> <ul> <li><code>groups</code> command will tell your projects</li> <li><code>lumi-workspaces</code> with <code>module load lumi-workspaces</code> will print all your projects with their directories. </li> </ul> </li> <li> <p>Does LUMI support installation of software via Anaconda/conda?</p> <p>Answer</p> <ul> <li>Yes but not directly. You can create conda environments in a container: https://docs.lumi-supercomputer.eu/software/installing/container-wrapper/ </li> <li>It is not supported in the sense that we also solve problems with Conda. We have no control whatsoever over the binaries that Conda installs nor how they are build, so we cannot solve problems with those either. And just as with regular containers, as is discussed in the full courses, you can expect problems with, e.g., MPI which may not recognize the SlingShot network correctly and use it in the appropriate way.</li> </ul> </li> <li> <p>I have a Finnish/CSC based Lumi account, and now also the myaccessid/puhuri based one. Is there way to combine or something?</p> <p>Answer</p> <ul> <li>A solution is being rolled out (but still somewhat in a test phase). It is a direct result of the choice to use the myCSC system that is familiar to Finnish users to manage Finnish project on LUMI without integrating it with Puhuuri and use the authentication mechanisms that Puhuuri uses.</li> <li>I have managed to (No guarantees that you will be able to): https://docs.csc.fi/accounts/how-to-manage-user-information/. in myCSC you can link your myCSC account to myAccessID. So my access to the LUMI-G course is attached to myCSC account.<ul> <li>I don't dare to push that before end of course to not to break anything with the existing dual accounts :-)<ul> <li>Yes. No guarantees it works! </li> <li>Linking in My CSC worked for me nicely, can access the training directory with me regular CSC account.</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Is mpi4py available in python? if so, which python module has mpi4py available?</p> <p>Answer</p> <ul> <li>cray-python</li> </ul> </li> <li> <p>Can I use cray compilers outside of LUMI? </p> <p>Answer</p> <ul> <li>Cray compiler (CCE) is part of the HPE Cray Environment, so it is available only on HPE Cray systems</li> <li>If you are using the Cray C/C++ compiler it is very similar to Clang, which is freely available. The Fortran compiler, though, is HPE/Cray-specific.</li> </ul> <p>Question</p> <ul> <li>Are there online docs to view cray specific compile flags and options? Or is it safe to assume that they are very similar to clang and that cray compiler are simply optimized versions</li> </ul> <p>Answer</p> <ul> <li>There are online PDF documents which are very hard to find and not very enlighting. The Cray PE is mostly documented through man pages accessible via the man command on the system. That is also why man pages are mentioned throughout the talk of Harvey.</li> <li>The man pages to use are actually mentioned in our documentation at https://docs.lumi-supercomputer.eu in the relevant pages (though I note that those for the GPU compiler of AMD should still be added).</li> <li>(Harvey) We cover compilers in a lot of detailed in the longer training courses. There is a Fortran manual but for clang the manpage is just showing the additions, there is comprehensive clang documentation online.</li> </ul> </li> <li> <p>Why do I have to export following to get the ROCm-aware MPI support not to error? I am running on AMD GPUs and MPI via Julia and need to explicitly export the following if I use ROCm-aware MPI features in the code. Thus I load following:     <pre><code>export LD_PRELOAD=${CRAY_MPICH_ROOTDIR}/gtl/lib/libmpi_gtl_hsa.so\n</code></pre> <pre><code>module load CrayEnv\nmodule load craype-accel-amd-gfx90a # MI250x\nmodule load cray-mpich\nmodule load rocm\n</code></pre></p> <p>Answer</p> <ul> <li>Could you give more details? GTL is the GPU-Transfer-Library used by cray-mpich for GPU to GPU communications. MPI links with this library whenever the module <code>craype-accel-amd-gfx90a</code> is loaded.</li> <li>OK, so you are not using the compiler wrappers, therefore you have link with the GTL library to get MPI GPU-aware. </li> </ul> <p>User answer</p> <ul> <li>Thanks for the info. Indeed, I am not using the wrapper indeed, as just launching Julia via <code>srun julia my_prog.jl</code></li> </ul> </li> <li> <p>What do I need to load in order to get working OpenCL support?</p> <p>Answer</p> <ul> <li>I have no tried it, but I would assume the standard modules just like any GPU compilation. eg.   <pre><code>module load craype-accel-amd-gfx90a\nmodule load rocm\n</code></pre></li> </ul> <p>User remark</p> <ul> <li>This makes libOpenCL.so and include files available (so things compile), but OpenCL depends on dynamically loading drivers that are normally listed in /etc/OpenCL/vendors.  This dir does not exist on the GPU nodes.  I can create my own in my home directory and set OCL_ICD_VENDORS environment variable to point at it (which libOpenCL picks up), but this seems rather hacky.  Note that all this \"vendors\" directory contains is a file \"amdocl64_50002.icd\" containing the string \"libamdocl64.so\".</li> </ul> </li> <li> <p>The compute nodes have rocm 5.1,while the log in nodes 5.0. This makes some problems with some compilations. Is there a plan to have the 5.1 available on the log in nodes as well?</p> <p>Answer</p> <ul> <li>The official ROCm versions are actually 5.0 on login and 5.1 on compute nodes, and this is a configuration error of the system so it should be solved at some point. But currently the GPU nodes are still in the hands of HPE so we cannot yet do whatever we like. This is also why the current phase is called \"extended beta\". The 5.1 is a module that we build ourselves and that may not fully integrate with the HPE Cray PE.</li> </ul> <p>Question</p> <ul> <li>Follow up: can/should the 5.1 module be used with hipcc? (Trying to build Jax..., I got a container for my app already, this was just an attempt to get a native build flying)</li> </ul> <p>Answer</p> <ul> <li> <p>I'm not sure building Jax on LUMI is a good idea at the moment since the more recent versions require ROCm 5.3 or newer and the code for AMD in the older versions of Jax is even more immature. Some users use a container with ROCm 5.3 and a prebuilt Jax in it. ROCm 5.3 should still work fine on the driver version that we have on LUMI. And in any case I would build on a compute node and use 5.1 instead. </p> </li> <li> <p>You can try to use prebuild wheels of jax:</p> </li> </ul> <pre><code>wget https://a3s.fi/swift/v1/AUTH_ac5838fe86f043458516efa4b8235d7a/lumi-wheels/jaxlib-0.3.25-cp39-cp39-manylinux2014_x86_64.whl\nwget https://a3s.fi/swift/v1/AUTH_ac5838fe86f043458516efa4b8235d7a/lumi-wheels/jax-0.3.25-py3-none-any.whl\nmodule load cray-python\nmodule load rocm\npython -m venv --system-site-packages jaxenv\nsource jaxenv/bin/activate\npip install absl-py etils opt_einsum wheel typing_extensions\npip install --no-deps jax*.whl\n</code></pre> <p>Question</p> <ul> <li>Thanx, that receipe worked, as far as building and loading libraries. However, it doesn't seem to see the GPUs (I'm on dev-g):</li> </ul> <pre><code>Python 3.9.12 (main, Apr 18 2022, 21:29:31)\n[GCC 9.3.0 20200312 (Cray Inc.)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; import jax\n&gt;&gt;&gt; import jaxlib\n&gt;&gt;&gt; jax.device_count()\n2023-01-11 11:50:57.816391: E  external/org_tensorflow/tensorflow/compiler/xla/stream_executor/rocm/rocm_driver.cc:302] failed call to hipInit: HIP_ERROR_InvalidDevice\nWARNING:jax._src.lib.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n1           \n</code></pre> <p>Answer</p> <ul> <li>The only way I can reproduce your result is by not requesting a GPU. Did you request a GPU when you submitted your job? Here is what I get:</li> </ul> <pre><code>$ srun -pdev-g --gres=gpu:1 --pty -t30:00 $SHELL\nsrun: job 2420138 queued and waiting for resources\nsrun: job 2420138 has been allocated resources\n\u2744\ufe0f (12:32) nid007565 [~/sandbox] $ source jaxenv/bin/activate\n(jaxenv) \u2744\ufe0f (12:32) nid007565 [~/sandbox] $ python\nPython 3.9.12 (main, Apr 18 2022, 21:29:31)\n[GCC 9.3.0 20200312 (Cray Inc.)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more    information.\n&gt;&gt;&gt; import jax\n&gt;&gt;&gt; jax.device_count()\n1\n&gt;&gt;&gt; jax.devices('gpu')\n[StreamExecutorGpuDevice(id=0, process_index=0, slice_index=0)]\n</code></pre> <ul> <li>We also have a container with a JAX installation: https://a3s.fi/swift/v1/AUTH_ac5838fe86f043458516efa4b8235d7a/lumi-experimental-containers/jax/jax-0.3.25-rocm-5.3.sif</li> </ul> </li> <li> <p>In the MI250x EAP phase the compiler names were not yet wrapped with \"CC\" etc, yet? Right? I've not been using wrong commands, have I? (Say, september 2022) (OpenMP)</p> <p>Answer</p> <ul> <li>If you mean the MI100 EAP phase: the wrappers where there also but not OK.</li> <li>Once users where allowed on the MI250X everything was there. In September the wrappers where there already, and in fact this is also what HPE was using for the acceptance tests. The wrappers were actually explained in the course for Pilot users in August.</li> </ul> <p>User remark</p> <ul> <li>I was just reading the web pages. I have \"amdclang\" as a compiler in my Makefile with <code>-fopenmp-targets=amdgcn-amd-amdhsa</code>  etc.</li> </ul> <p>Answer</p> <ul> <li>Using the compilers without wrappers is possible but you have to know better what to do then to, e.g., ensure that MPI works properly (as shown in one of the questions above). The wrappers are just a convenience, not an absolute requirement. With older versions of some of the PE compilers the compiles sometimes had trouble finding their own include files though. </li> </ul> </li> <li> <p>Does cray-libsci_acc work transparently with GPU pointers?</p> <p>Answer</p> <ul> <li>Yes, in that case it will push the computation on the GPU. With CPU pointers, the library will apply some heuristics to check if it worth to move data to the GPU and do the computation there. Check the man page for more info.</li> </ul> </li> <li> <p>Is it allowed to use Jupyter notebooks on Lumi GPUs? and if yes, how to log in to the allocated node and forward the port?</p> <p>Answer</p> <ul> <li>In the (hopefully not too distant) future this will be possible with OpenOnDemand (see question 23)</li> <li>The prefered scenario, also with OpenOnDemand, will be though that the Jupyter notebooks are used to launch jobs and process what they return on resources reserved for interactive use, and that they are not used to block access to regular nodes for interactive work for a long time as having those expensive nodes idle waiting for user input is not what you want, and as you never can be sure that your allocation will actually start at a time that you will be available to use it. LUMI does have nodes that are set apart for interactive use and will be used by Open On Demand, but these are not the AMD GPU nodes.</li> </ul> </li> <li> <p>Is there a prebuilt tensorflow &amp; pytorch available that's optimized for the GPU architecture?</p> <p>Answer</p> <ul> <li>AMD has optimized versions in containers that seem to work well but it is nearly impossible to build these packages from scratch ourselves as they have build environments that are developed for a totally different environment than an HPC cluster (even more so for TensorFlow than for PyTorch) and as build procedures and dependencies are not well documented, so expect that pre-built containers and/or wheels will be the way to go for a very long time.</li> </ul> </li> <li> <p>Is there anything similar to PyCuda available?</p> <p>Answer</p> <ul> <li>CuPY has some AMD GPU support. https://docs.cupy.dev/en/stable/install.html?highlight=AMD#using-cupy-on-amd-gpu-experimental</li> </ul> </li> <li> <p>This may be linked to question #20 above: Harvey mentioned at the begining (interactive?) nodes for vizualisation, are these in production and where can we find more information?</p> <p>Answer</p> <ul> <li>No, they are not in production yet. </li> <li>(Harvey) Sorry for any confusion but I was talking in general terms at that point and not being specific about node types on LUMI.</li> <li>CSC is working a OpenOnDemand solution to allow quick and easy access to LUMI-D (visualisation partition with Nvidia GPUs). We are hoping for a production phase in Q2 2023. This would also allow direct in browser Jupyter and R notebook access.</li> </ul> <p>User remark</p> <ul> <li>Ok, thanks, so no interactive nodes with Radeon GPUs then?</li> </ul> <p>Answer</p> <ul> <li>Maybe. As far as I know OpenOnDemand should also allow access to LUMI-G for calculations.</li> <li>(Kurt): As far as I know it will allow to launch jobs on all partitions, but there is no partition on LUMI-G with a job policy optimised for interactive work.</li> </ul> </li> <li> <p>I used to have access to the eap partition. How can I see all partitions that I am allowed to use?</p> <p>Answer</p> <ul> <li>All users of lumi have now access to the new partitions (standard-g, small-g, dev-g) but you will need allocated GPU hours</li> <li>Talk to your allocator to get GPU resources</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#first-steps-for-running-on-lumi-g","title":"First steps for running on LUMI-G","text":"<p>Info</p> <p>The slides for this session are available on LUMI at <code>/project/project_465000320/slides/HPE/02_Running_Applications_and_Tools.pdf</code>. There are also optional exercises on LUMI at <code>/project/project_465000320/exercises/HPE</code></p> <ol> <li> <p>Is the famous <code>slurm</code> command available on Lumi?</p> <p>Answer</p> <ul> <li>It is! A wrapper for e.g. sinfo.</li> </ul> </li> <li> <p>In all theses examples the exact format of the \"project\" is omitted. Is it just the number or with \"project_nnnn\" format?</p> <p>Answer</p> <ul> <li>project_XXXXXXX</li> <li>You can quickly see your projects by running the <code>groups</code> command. It is the names as used in SLURM.</li> </ul> </li> <li> <p>Is there any guarantee that the GPUs land on the same node?</p> <p>Answer</p> <ul> <li>With <code>--gres</code> yes. Using <code>--gpus=&lt;n&gt;</code> on the <code>dev-g</code> and <code>small-g</code> partitions no.</li> </ul> </li> <li> <p>If I have an sbatch job running on a node e.g. nid012, is it possible to log in to that node and check e.g. rocm-smi status? It seems that slurm somehow isolates the GPUs of other jobs (e.g. via srun, requesting nid012) that land on the same node, so I can't check the status of the GPUs allocated to the first job. </p> <p>Answer</p> <ul> <li>This would allow you to go into a given node but no GPU visibility: <code>srun --pty --jobid &lt;your job id&gt; -w &lt;your node&gt; --mem=0 --oversubscribe --gpus-per-task=0 -N 1 -n 1 -c 16  /usr/bin/bash -l</code></li> <li>This would allow you to go to the first node of a given allocation with GPU visibility: <code>srun --jobid &lt;your job id&gt; --interactive --pty /bin/bash</code></li> <li>Unfortunately the previous version ignores -w option to specify any node. There is a ticket on that.</li> <li>Our sysadmins are also working on allowing ssh access to allocated nodes. But this is still in the future.</li> </ul> </li> <li> <p>What is the difference between <code>--gres=gpu:N</code> and e.g. <code>--gpus=N</code>. When should either be used</p> <p>Answer</p> <ul> <li>The outcome will be similar. Also, using --gpus should instruct SLURM to allocate the specified number of GPUs. E.g. <code>-N $N --gpus $((N*8))</code></li> </ul> </li> <li> <p><code>seff</code> isn't on LUMI AFAIK. Why?</p> <p>Answer</p> <ul> <li>This is not a standard Slurm command but something that has to be installed separately, and also requires certain rights to certain data in Slurm. We currently use a Slurm instance as pre-configured by HPE Cray that does not contain <code>seff</code>. It is likely that it will be installed in the future as many people are requesting it.</li> <li>Note also that <code>seff</code> is no replacement for a decent profiler when you want to assess the efficiency of your job/code. E.g., so-called busy waiting is common in MPI implementations and OpemMP runtimes and <code>seff</code> would still give the impression that those jobs are efficient.</li> </ul> </li> <li> <p>Why is SMT not enabled by default in Slurm?</p> <p>Answer</p> <ul> <li>SMT is typically not faster for most HPC workloads.</li> </ul> </li> <li> <p>Are the GPU interrupts something not bound to the computation? I just wonder because CPU0 is reserverd for system AND gpu interrupts of </p> <p>Answer</p> <ul> <li>(Harvey) I'm not an expert on this but I think the interrupts relate to the driver and are in kernel space so not clear to me how this interacts with the 'computation'. You could ask this again later today as I think hardware will be covered again.</li> </ul> </li> <li> <p>Is it possible to disable the low-noise mode?</p> <p>Answer</p> <ul> <li>(Peter) No, not as a user.</li> <li>(Harvey) I expect we might see future developments here as we learn more and implement more features.  I think that disabling 0 was a pretty recent change felt to be of benefit based on experience of running applications. It would be useful to get feedback on this.</li> <li>(Kurt) My guess is that it is probably needed for applications that scale over many nodes as any kind of OS jitter can them completely break scalability, but it is an annoyance for single node jobs. But since LUMI is build as a pre-exascale system that should accomodate huge jobs, it is a reasonable thing to have.</li> <li>(Kurt) If AMD is reading this: I know what you are doing for MI300 from the hints at the investor's day and CES, but for MI400 please give as yet another CPU die to run those processes, with quick access to some on-package LPDDR5 memory so that all OS code can be in a different part of memory from the user GPU application. An \"accelerator\" to run the OS code without interfering with user applications... Cloud companies can then use these cores to run the hypervisor.</li> </ul> </li> <li> <p>Can I run examples/exercises using the LUMI-G training project? </p> <p>Answer</p> <ul> <li>You can use it for the exercises this afternoon but not for other purposes as the amount of resources allocated to the project is very minimal.</li> <li>I just want to run the <code>xthi</code> example :). I copied the files to my <code>$HOME</code> dir. </li> <li><code>xthi</code> hardly consumes any resources. I believe you can actually try the program first on the login nodes.</li> <li>And if you do <code>module spider lumi-CPEtools</code> it will actually tell you about a module that contains a similar program that gives even a bit more information. I'm not sure it is there already for the GPU nodes though.</li> </ul> </li> <li> <p>Shouldn't SLURM be doing this NUMA-GPU-CPU-NIC binding for us? At least for the default case? </p> <p>Answer</p> <ul> <li>(Peter) Yes, ideally... Hopefully, it will be added to SLURM eventually.</li> <li>(Harvey) I'm not sure that there is a generic capability to discover all the hardware (maybe hwloc, or at least it was not there for AMD GPus to enable this to be developed in time.)</li> </ul> </li> <li> <p>Could you please provide us with the handy script to select the proper GPU id with <code>ROCR_VISIBLE_DEVICES</code>?</p> <p>Answer</p> <ul> <li>Do you mean the script in the slides?</li> <li>There is something similar in the LUMI user documentation on the page with GPU examples: https://docs.lumi-supercomputer.eu/runjobs/scheduled-jobs/lumig-job/</li> <li>The <code>xthi</code> example talked about in the presentation is available: <code>/projappl/project_465000320/exercises/HPE/xthi</code> </li> </ul> </li> <li> <p>Is it faster to MPI transfer data from GPU memory than host memory?</p> <p>Answer</p> <ul> <li>Answered in slides. (a bit faster, not really significant.)</li> </ul> </li> <li> <p>Does the programmer need to handle manually the communications between gpus on the same nodes or in different node? I mean if the suitable technology is automatically selected.(RDMA vs. peer2peer)</p> <p>Answer</p> <ul> <li>The MPI implementation will handle that for you (MPICH_GPU_SUPPORT_ENABLED=1 needs to be set). Other libraries like RCCL will also detect topology and use the best approach for communication between GPUs. Having said that, if you are not planning on using these libs you need to manage the topology yourself.</li> <li>You may wish to take care on which ranks are on each node of course as you would for any MPI application to balance on or off- node traffic.</li> </ul> </li> <li> <p>I tried running a simple NCCL example ported to HIP using the RCCL library within rocm. Compilation worked well but I had trouble running it when submitting it to the GPU queue. The first call to a library function, ncclCommInitRank(), returned an error reading \"unhandled system error\". I suspect something is wrong with my batch script, might be related to some MPI environment variable. Have you got any ideas what the problem could be?</p> <p>Answer</p> <ul> <li>RCCL is using the wrong network interface. Please <code>export NCCL_SOCKET_IFNAME=hsn</code> to select the slingshot NICs.</li> </ul> </li> <li> <p>Can you also profile the energy consumption of GPU jobs? I assumed what was just shown is only for CPU?</p> <p>Answer</p> <ul> <li>(Harvey) I have not checked this but the basic information for whole-job GPU energy consumption should be available. I'm not sure if either Slurm or perftools reports that and would have to check.</li> </ul> <p>User remark</p> <ul> <li>OK, we have a research project where we want to look at the energy consumption of GPU jobs, so this would be very useful. I know with <code>rocm-smi</code> we can see the current (at that specific point in time) GPU utilization and consumption, but might be hard to get for the whole job?</li> </ul> <p>Answer</p> <ul> <li>The files are in <code>/sys/cray/pm_counters</code> (on compute nodes). They update at 10Hz. See accel0_energy etc. for example</li> </ul> </li> <li> <p>Is it possible to get memory peak on the GPU ?</p> <p>Answer</p> <ul> <li>this is something CrayPAT can do for you. (This is actually a question for AMD, you can ask it in the afternoon).</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#exercises-morning-sessions","title":"Exercises morning sessions","text":"<p>Info</p> <p>The exercises can be found on LUMI at <code>/project/project_465000320/exercises/HPE</code></p> <ol> <li> <p>Is there a way to get access to the exercices when not on the training project? (This is basically question 1)</p> <p>Answer</p> <ul> <li>No, unfortunately at the moment not. We will reevaluate how to publish slides and exercises for future courses.</li> <li>If you have gotten all the emails in the last few days about the course, you should be able tojoin the project and then get access to the project folder on LUMI.</li> </ul> <p>User remark</p> <ul> <li>I was on the waiting list and apparently didn't recieve a link to get the access. Should I open a ticket like suggested in the next question?</li> </ul> <p>Answer</p> <ul> <li>It will take a few minutes (~15-30) after you joined for the synchronization to LUMI.</li> </ul> </li> <li> <p>What should we do if we get permission denied when trying to access <code>/project/project_465000320/</code>? </p> <p>Answer</p> <ul> <li>Check that you are using the right account (the Puhuri one)</li> </ul> <p>User remark</p> <ul> <li>I see the project listed under the Puhuru portal. Should I sign in with another username than normally?</li> </ul> <p>Answer</p> <ul> <li>Otherwise join the project or if you have problems with joining the project, please open a ticket at https://lumi-supercomputer.eu/user-support/need-help/generic/</li> </ul> </li> <li> <p>Are there some instructions for the exercises? In what order should they be run?</p> <p>Answer</p> <ul> <li>No instructions are provided, there are there only to reproduce what we showed in the slides. </li> <li>We are running ahead of expectation as last time I think we had way more discussion during the morning. Because we are switching to AMD presenters this afternoon I didn't want to suggest moving everything forward.</li> </ul> </li> <li> <p>What is the recommended way of running Java code on LUMI? Can the Java Fork/Join framework be used directly or does one need to use something like aparapi?</p> <p>Answer</p> <ul> <li>Question remained unanswered due to the lack of Java experts. After all, this is not a popular HPC tool...</li> </ul> </li> <li> <p>I am trying to compile the implementation of BabelStream (\"ocl\").  After doing <code>module load craype-accel-amd-gfx90a</code> and <code>module load rocm</code> I try <code>cmake -Bbuild -H. -DMODEL=ocl</code>, but this fails with <code>Could NOT find OpenCL (missing: OpenCL_LIBRARY) (found version \"2.2\")</code>.  The OpenCL libraries are certainly somewhere in /opt/rocm, but apparently not made available to cmake.  What am I missing?</p> <p>Answer</p> <ul> <li>This seem to work: <code>cmake -DMODEL=ocl -DOpenCL_LIBRARY=/opt/rocm-5.1.0/opencl/lib/libOpenCL.so ../</code>. Built in the compute node. However the resulting binary fails with:   <pre><code>&gt;  ./ocl-stream                      \nBabelStream                                                                                                \nVersion: 4.0                                                                                               \nImplementation: OpenCL  \nRunning kernels 100 times                                                                                  \nPrecision: double                                                                                          \nArray size: 268.4 MB (=0.3 GB)\nTotal size: 805.3 MB (=0.8 GB)                                                                             \nterminate called after throwing an instance of    'cl::Error'                                                                                                                                                            \n  what():  clGetPlatformIDs\nAborted (core dumped)\n</code></pre>   This may require further investigation.</li> <li>(Alfio) There was a discussion about missing OpenCL files on the compute nodes (see a question above), namely the files under <code>/etc/OpenCL/vendors</code>. I'm not an expert, but it appears that the suggested solution is to copy those files in the home to make them available on the compute nodes too.</li> </ul> </li> <li> <p>Any news on hipSYCL on Lumi?</p> <p>Answer</p> <ul> <li>We have an EasyConfig for it, see the link to the LUMI software Library in the LUMI documentation: https://docs.lumi-supercomputer.eu/software/#the-lumi-software-library</li> </ul> </li> <li> <p>Do we need to load modules in slurm batch script or set variables ? hello_jobstep after compilation (modified Makefile to use flags like frontier) during execution - error while loading shared libraries: libomp.so cannot open shared object file: No such file or directory</p> <p>Answer</p> <ul> <li>If you use anyting other then default modules at build time then it is best to load those modules in the batch script (or check if the environment at the point you submit the job has been exported to the job (that is a site dependent configuration))</li> <li>On a fresh connection to LUMI, I set:   <pre><code>module load rocm\nmodule load craype-accel-amd-gfx90a\n\nCC -std=c++11 -fopenmp  -x hip -c hello_jobstep.cpp\nCC -fopenmp hello_jobstep.o -o hello_jobstep\n</code></pre>   Then I run on sbatch (using a script used in the slides).</li> <li>The various scenarios for using the Cray PE on LUMI is a part of the introductory courses e.g., the full 4-day course on GPU computing in February or the course we had in November). As this was a LUST talk, some of the material is available on https://lumi-supercomputer.github.io/LUMI-training-materials/</li> <li>There is a problem with the installation fo PrgEnv-amd (which may in fact be an HPE packaging error in 22.08). Is that what you were using? It does cause certain libraries not to be found at runtime.</li> </ul> <p>User remark</p> <ul> <li>Problem solved- do not change PrgEnv-cray during compilation to PrgEnv-amd for hello_jobstep. Only modification is in Makefile - there is no lumi, but flags from frontier worked</li> </ul> <p>Answer</p> <ul> <li>Well, the problem is that libomp is under <code>/opt/rocm/llvm/lib</code>, while the PrgEnv-amd module (5.0.2) is using <code>/opt/rocm-5.0.2/llvm/lib</code> and the 5.0.2 is not available on the compute nodes (only 5.1.0). You can do <code>export LD_LIBRARY_PATH=/opt/rocm/llvm/lib:$LD_LIBRARY_PATH</code>.</li> </ul> </li> <li> <p>What exercises can I make public and which ones can I not? For example in a public repo on Github</p> <p>Answer</p> <ul> <li>Those from HPE cannot be made public in any way. In fact, they can only be spread to users of LUMI.</li> <li>(Harvey) In some cases those exercises came from elsewhere in which case there is no problem and I migh have been a bit strong in my comments earlier based on examples used in other courses, We will check.</li> <li>I remember seeing an AMD repo in one of their accounts for ROCm that had exercises very similar to those of this afternoon, so I guess you can look up the license that covers that repository. The AMD people will only be around this afternoon.</li> <li>Check the slides, we basically took the slides from the repos, namely:</li> <li>OSU benchmark https://mvapich.cse.ohio-state.edu/download/mvapich/osu-micro-benchmarks-5.9.tar.gz</li> <li>Fortran OpenACC examples https://github.com/RonRahaman/openacc-mpi-demos</li> <li>Fortran OpenMP examples https://github.com/ye-luo/openmp-target</li> <li>Collections of examples in BabelStream https://github.com/UoB-HPC/BabelStream</li> <li>https://code.ornl.gov/olcf/hello_jobstep</li> <li>https://support.hpe.com/hpesc/public/docDisplay?docId=a00114008en_us&amp;docLocale=en_US&amp;page=Run_an_OpenMP_Application.html</li> </ul> </li> <li> <p>except PrgEnv-xxx, Cray introduced also cpe module (Cray Programming environment). when is the cpe module used for compiling? </p> <p>Answer</p> <ul> <li>(Alfio) cpe is a collection, for instance LUMI has 22.08 (year.month version). You can load the cpe, which will load PrgEnv-XXX versions (and all other modules)...</li> </ul> <p>User remark</p> <ul> <li>but e.g PrgEnv-cray is loaded by default, if then load cpe, there is not any changed. </li> </ul> <p>Answer</p> <ul> <li>Because by default CPE 22.08 is the default   <pre><code>&gt; module av cpe\ncpe-cuda/22.06    cpe-cuda/22.08 (D)    cpe/21.12    cpe/22.06    cpe/22.08 (D)\n</code></pre>   Therefore, loading 22.08 will not change the default modules. </li> <li>(Kurt) cpe is really a module that changes the default versions of the packages and then tries to reload the already modules to switch to the new default versions. With the emphasis on \"tries to\", sometimes it fails. Also, due to the way LMOD works it should always be loaded in a separate <code>module load cpe</code> command. And a workaround for some of the problems is to do that <code>module load</code> twice.</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#gpu-hardware-introduction-to-rocm-and-hip","title":"GPU Hardware &amp; Introduction to ROCm and HIP","text":"<p>Info</p> <p>The slides for this session are available on LUMI at <code>/project/project_465000320/slides/AMD/</code>.</p> <ol> <li> <p>It seems that whenever I try to run a slurm job, I get the sbatch error AssocMaxSubmitJobLimit - \"Batch job submission failed: Job violates accounting/QOS policy (job submit limit, user's size and/or time limits)\". I assume this means I need to be allocated more time and resources on LUMI.</p> <p>Answer</p> <ul> <li>Are you submitting with your own project or the training one? (<code>--account=&lt;project_XXXXXXXXXX&gt; option</code>)</li> </ul> <p>User remark</p> <ul> <li> <p>Thanks. I get the same error whether I use my own project or the trainig project. I am submitting to partition \"small\" - perhaps I should be submitting to a different partition? Here's the batch file I'n trying to run:</p> <pre><code>#!/bin/bash \n#SBATCH -p small\n#SBATCH -A project_465000320\n#SBATCH --time=00:02:00\n#SBATCH --nodes=1\n#SBATCH --gres=gpu:1\n#SBATCH --exclusive\nsrun -n 1 rocm-smi\n</code></pre> </li> </ul> <p>Answer</p> <ul> <li> <p>You should use <code>small-g</code> but the error message you should get is <code>sbatch: error: Batch job submission failed: Requested node configuration is not available</code>. What is your username?</p> </li> <li> <p>You should be able to submit with <code>project_465000320</code> and using the <code>small-g</code> partition. Your other project has no billing units. Maybe you have the <code>SBATCH_ACCOUNT</code> or <code>SLURM_ACCOUNT</code> environment variables set to this project as this is something we recommend in the documentation?</p> </li> </ul> <p>User remark</p> <ul> <li>Thank you. The problem was that my <code>SBATCH_ACCOUNT</code> variable was set to my other project. Thanks for the help!</li> </ul> </li> <li> <p>Are these advanced features like Matrix cores and packed FP32 already ported to libraries like PyTorch and TensorFlow (as they already have official ROCm ports)? </p> <p>Answer</p> <ul> <li>Yes, these libs/frameworks leverage BLAS and MiOpen libs that comprise support for matrix ops.</li> </ul> </li> <li> <p>When running multi-GPU (but single node, so up to 8 logical GPUs) batch ML training jobs using basic Keras/Tensorflow with ROCm, I'm noticing that it's quite unstable, often but not always the training crashes after a few steps. This does not occur (or occurs much more rarely) when using a single (logical) GPU. There are no useful messages in the log. Any ideas how to debug this?</p> <p>Answer</p> <ul> <li>Any backtrace dumped when the crash happens? Several users have managed to run training on multiple GPUs and multiple nodes each using multiple GPUs. </li> </ul> </li> <li> <p>If I need to synchronize only a subset of my threads, similar to what I'd do with a <code>__syncwarp</code>, should I abandon the optimization and do a <code>__syncthreads</code>, or is there an implicit wavefront-wide synchronisation?</p> <p>Answer</p> <ul> <li>Cooperative groups are supported in recent ROCm versions. However on Instinct GPUs all threads in a wave front always execute in lock step. So cooperative groups is mostly a portability feature as on instinct GPUs threads do not diverge. </li> </ul> </li> <li> <p>Why isn't there a HIP equivalent to CUDA fortran? (Out of curiosity)</p> <p>Answer</p> <ul> <li>There is not, you have to call the HIP runtime through the C interface and launch kernels separately. There is a library with wrappers to facilitate this: https://github.com/ROCmSoftwarePlatform/hipfort</li> </ul> </li> <li> <p>What are some good resources for running python code (torch/CUDA) on LUMI GPUs? The documentation does not have anything on it.</p> <p>Answer</p> <ul> <li>https://docs.csc.fi/apps/pytorch/ has some comments on using pytorch on LUMI. </li> </ul> <p>User remark</p> <ul> <li>Ok, so the package is available, but if changes in the code regarding running it on AMD GPUs are needed I cannot find that in the docs, right?</li> </ul> <p>Answer</p> <ul> <li>You can run the same Python/PyTorch code on AMD.</li> <li>There are some AI/ML modules on LUMI (for AMD GPUs) created by CSC: <code>module use /appl/local/csc/soft/ai/modulefiles/</code>, if you have any questions about this you can send a ticket to csc service desk (email: servicedesk@csc.fi).</li> </ul> </li> <li> <p>There was at some point a HIP implementation that runs on the CPU (https://github.com/ROCm-Developer-Tools/HIP-CPU), which would be useful for portability, but it doesn't seem maintained. Is the project dead?</p> <p>Answer</p> <ul> <li>Being a header only project I'd expect it to work in most cases as HIP standard didn't shift much. However, this is maintained on best effort and not officially supported. Having said that, we encourage users to file tickets if they are facing issues using it. </li> </ul> </li> <li> <p>Can you obtain the information provided by rocminfo (CUs etc.) from an API simply useable in an OpenMP offload program?</p> <p>Answer</p> <ul> <li>Yes, there is library which provides the <code>rocm-smi</code> information: https://github.com/RadeonOpenCompute/rocm_smi_lib</li> <li>Actually, if you look at the source of rocminfo, it's quite a small utility (~1K LoC). You can have a look and extract the part that you are interested in and include it in your application.</li> </ul> </li> <li> <p>When I run Alfio's example on slide 8 of his slides, I get an output similar to that on his slide 9, but this is followed by the following errors:</p> <pre><code>srun: error: nid007244: task 0: Exited with exit code 2\nsrun: launch/slurm: _step_signal: Terminating StepId=2422727.0\n</code></pre> <p>Does anyone know what this is due to?</p> <p>Answer</p> <ul> <li> <p>rocm-smi is exiting with a return code of 2 which slurm interprets as a failure.</p> <pre><code>harveyri@nid007307:~/workshop/2023_01&gt; rocm-smi\n\n\n======================= ROCm System Management Interface     =======================\n================================= Concise Info =================================\nGPU  Temp   AvgPwr  SCLK    MCLK     Fan  Perf  PwrCap  VRAM%  GPU%\n0    40.0c  91.0W   800Mhz  1600Mhz  0%   auto  560.0W    0%   0%\n================================================================================\n============================= End of ROCm SMI Log ==============================\nharveyri@nid007307:~/workshop/2023_01&gt; echo $?\n2\n</code></pre> </li> </ul> <p>User remark</p> <ul> <li>OK. Thanks. I assume rocm-smi is supposed to exit with code 2. At least, not something I need to worry about!</li> </ul> <p>Answer</p> <ul> <li>(Harvey) I don't know but there is an issue reported on the return code in github for an invocation with -a so I expect this is not expected. It is not something to worry about in any case.</li> </ul> </li> <li> <p>I am interested in running distributed trainings using pytorch, as we have a very large dataset. I am using the official Docker container for Pytorch with ROCm support. The communication between nodes/GPUs works at this moment. But, I get this error <code>MIOpen Error: /long_pathname_so_that_rpms_can_package_the_debug_info/data/driver/MLOpen/src/sqlite_db.cpp:220: Internal error while accessing SQLite database: locking protocol</code> for the trainings. I can set <code>MIOPEN_DEBUG_DISABLE_FIND_DB=1</code>, <code>MIOPEN_DISABLE_CACHE=1</code>, and <code>MIOPEN_FIND_ENFORCE=5</code> to eliminate this issue. Any comments would be great.</p> <p>Answer</p> <ul> <li> <p>This can be fixed if you add to each process instance something like:     <pre><code>export MIOPEN_USER_DB_PATH=\"/tmp/sam-miopen-cache-$SLURM_PROCID\"\nexport MIOPEN_CUSTOM_CACHE_DIR=$MIOPEN_USER_DB_PATH\n\nrm -rf $MIOPEN_USER_DB_PATH\nmkdir -p $MIOPEN_USER_DB_PATH\n</code></pre></p> <p>the FS doesn't cope with the locks, so moving the DB to /tmp fixes the problem.</p> </li> <li> <p>Please do some cleanup at the end of your job if you use this solution, i.e., remove the files <code>rm -rf $MIOPEN_USER_DB_PATH</code> as <code>/tmp</code> is a RAM disk and, at the moment, is not cleaned at the end of the job execution. As a consequence, leftover files may endup consuming the entire node memory.</p> </li> <li> <p>Not sure which ROCm users space you use but you might be interested in enabling the libfabric plugin. Here's a module I maintain that provides that - not sure if there a generally available build:</p> <pre><code>module use /pfs/lustrep2/projappl/project_462000125/samantao-public/mymodules\nmodule load aws-ofi-rccl/sam-rocm-5.3.3.lua\n</code></pre> <p>this will boost your internode BW.</p> </li> </ul> <p>Question</p> <ul> <li>Thank you for this answer. I get another error <code>nid007564:5809:6364 [6] /long_pathname_so_that_rpms_can_package_the_debug_info/data/driver/rccl/src/misc/rocm_smi_wrap.cc:38 NCCL WARN ROCm SMI init failure An error occurred during initialization, during monitor discovery or when when initializing internal data structures</code> if <code>MIOPEN_FIND_ENFORCE=5</code> is not set. Is this also related? </li> </ul> <p>Answer</p> <ul> <li>Does it help if you set <code>export NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3</code>?</li> </ul> <p>User remark</p> <ul> <li>Unfortunately not -- <code>NCCL_SOCKET_IFNAME=hsn</code> is already set. Only thing seems to help is the enforce level 5, which seems to be related to this DB. </li> </ul> <p>Answer</p> <ul> <li>RCCL attempts to initilaize all interfaces but the ones other than slingshot can't be initialized properly.</li> </ul> </li> <li> <p>Is there a mechanism to profile shared libraries that use the GPUs? (My application is a python package, so everything is in a <code>.so</code>)</p> <p>Answer</p> <ul> <li>rocprof will follow linked libraries, so the profiling method is not different than a regular map. <code>rocprof python ...</code> is what you should be running.</li> <li>for omnitrace with instrumentation you'd have to instrument the libraries you care about.</li> </ul> </li> <li> <p>Using omniperf with Grafana is definitely interesting! So could we take this debugging and profiling information back locally and analyse on our own Grafana servers? Granted this is more advanced due to having your own Grafana server. </p> <p>Answer</p> <ul> <li>Copying the information locally: According to AMD, yes.</li> <li>(Kurt from LUST) But no hope that LUST will offer omniperf in one way or another for now. I just heard from a colleague that there is a serious security problem which has to do with the basic concepts that omniperf uses, making it not suitable for a shared infrastructure as LUMI. We cannot stop you from installing yourself but be aware that you put your data at risk. We are working on omnitrace though.</li> </ul> </li> <li> <p>If you had a working program (\"black box\"), how would you start profiling the program and what metrics would you first focus on to see if the program utilizes the GPUs correctly?</p> <p>Answer</p> <ul> <li>Using plain <code>rocprof</code> with your app is a good starting point - that will produce a list of the kernels ran on the GPU and that could give one hints if that is what one would expect. While running you can also monitor rocm-smi and see what PIDs use which GPUs and have an overview of the activity: memory being used and compute (which correlates to the GPU drawn power - up to 560W).</li> </ul> </li> <li> <p>This is very heavy with lots of info. Is there a \"poor man\" way to use it. Like getting start it with something simple?</p> <p>Answer</p> <ul> <li>Our more introductory 4-day course...</li> </ul> </li> <li> <p>As an excercise I'm running rocgdb for my openMP offload code. Could someone interpret the general lines:     <pre><code>(gdb) run\nThe program being debugged has been started already.\nStart it from the beginning? (y or n) y\nStarting program: /pfs/lustrep2/users/---/prw/parallel_random_walk\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\nOMP: Warning #234: OMP_NUM_THREADS: Invalid symbols found. Check the value \"\".\n[New Thread 0x1554aae22700 (LWP 61357)]\nMarkers 1000000 Steps 320000 Gridsize 10240.\n[New Thread 0x1554a37ff700 (LWP 61358)]\n[GPU Memory Error] Addr: 0x155673c00000 Reason: No Idea!\nMemory access fault by GPU node-4 (Agent handle: 0x3d4160) on address 0x155673c00000. Reason: Unknown.\n</code></pre>     Specifically </p> <ul> <li><code>[GPU Memory Error] Addr: 0x155673c00000 Reason: No Idea!</code></li> <li><code>Memory access fault by GPU node-4 (Agent handle: 0x3d4160) on address 0x155673c00000. Reason: Unknown.</code></li> </ul> <p>Answer</p> <ul> <li>This is a memory access problem - some data not being accessed properly. Are you assuming unified memory?</li> </ul> <p>User remark/question</p> <ul> <li>openMP...so no. The same code works with other compliler versions in Lumi. </li> <li>What's this: <code>OMP: Warning #234: OMP_NUM_THREADS: Invalid symbols found. Check the value \"\".</code>?</li> </ul> <p>Answer</p> <ul> <li>Have you tried OMP_NUM_THREADS=1? How do you declare it btw?</li> </ul> <p>User remark/question</p> <ul> <li>That was a good question. Forgot to remove it from the script to bring the code to the debugger.</li> </ul> <p>Answer</p> <ul> <li>Here's an example from Babelstream that runs to completion:     <pre><code>module purge\nmodule load CrayEnv\nmodule load PrgEnv-cray/8.3.3\nmodule load craype-accel-amd-gfx90a\nmodule load amd/5.1.0\ncmake -DMODEL=omp ../\nmake\nrocgdb ./omp-stream \n</code></pre></li> </ul> </li> <li> <p>Can I submit tickets regarding what George discussed to LUST? In-depth questions about profiling, debugging etc in case I would like some support on roctrace, omniperf etc?</p> <p>Answer</p> <ul> <li>Yes you can. When you submit a ticket it's also visible to AMD and HPE LUMI center of excellence members. So, either LUST or the vendors can answer depending on the complexity of your question</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/hedgedoc_notes/#general-qa","title":"General Q&amp;A","text":"<ol> <li> <p>What is the status of LUMI? has it now being handed over to CSC/EuroHPC?</p> <p>Answer</p> <ul> <li>LUMI-G is still owned by HPE and hasn't been handed over.    That's also the reason why we are not in full production but in an extended beta phase.</li> </ul> </li> <li> <p>What software will be first hand supported?</p> <p>Answer</p> <ul> <li>We don't know yet. SW has to be quite stable for us to be supportable</li> <li>LUST is a very small team so we don't have much resources except for providing SW installation (easybuild) recipes.</li> <li>Medium term goal to produce some guide lines for most used SW packages.</li> <li>Long term goal to involve local consortium countries (centers and universities) to help support and tune    software packages and write application guidelines.</li> </ul> </li> </ol>"},{"location":"LUMI-G-20230111/schedule/","title":"Course schedule","text":"<p>All times CET.</p> 09:00\u00a0\u00a0 Introduction Presenter: J\u00f8rn Dietze (LUST) 09:10 Introduction to the Cray EX Hardware and Programming Environment on LUMI-G     <ul> <li>The HPE Cray EX hardware architecture and software stack <li>The Cray module environment and compiler wrapper scripts</li> <li>An introduction to the compiler suites for GPUs      Presenter: Harvey Richardson (HPE) Slide files: <code>/project/project_465000320/slides/HPE/01_Intro_EX_Architecture_and_PE.pdf</code> on LUMI only. Recording: <code>/project/project_465000320/recordings/01_Intro_EX_Architecture_and_PE.mp4</code> on LUMI only. 10:15 break (30 minutes) 10:45 Running Applications on LUMI-G     <ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement (CPU/GPU/NIC)</li> <li>MPI update for GPUs and SlingShot 11 (GPU-aware communications)</li> <li>Profiling tools </li> </ul> Presenter: Alfio Lazzaro (HPE) Slide file: <code>/project/project_465000320/slides/HPE/02_Running_Applications_and_Tools.pdf</code> on LUMI only. Recording: <code>/project/project_465000320/recordings/02_Running_Applications_and_Tools.mp4</code> on LUMI only. 12:00 lunch break (60 minutes) 13:00 Introduction to AMD ROCmTM Ecosystem     <ul> <li>GPU Hardware intro </li> <li>Introduction to ROCm and HIP</li> <li>Porting Applications to HIP </li> <li>ROCm libraries </li> </ul> Slides and      additional notes and exercises Recording: <code>/project/project_465000320/recordings/03_Introduction_to_the_AMD_ROCmTM_ecosystem.mp4</code> on LUMI only. 14:30 break (30 minutes) 15:00 Introduction to AMD ROCmTM Ecosystem (Ctd)     <ul> <li>Profiling (Ctd)</li> <li>Debugging</li> </ul> Presenter: George Markomanolis (AMD) 16:30 General Questions &amp; Answers       17:00 End of the course"},{"location":"PEAP-Q-20220427/","title":"Detailed introduction to the LUMI-C environment and architecture (April 27/28, 2022)","text":""},{"location":"PEAP-Q-20220427/#downloads","title":"Downloads","text":"<ul> <li>LUMI Software Stacks slides (PDF, 667k)</li> <li>Containers on LUMI (PDF, 243k)</li> <li>The LUMI documentation and help desk (PDF, 1.8M)</li> <li>Frequently asked support questions (PDF, 907 k)</li> </ul>"},{"location":"PEAP-Q-20220427/#notes","title":"Notes","text":"<ul> <li>Notes from the hackmd page</li> <li>LUMI Software Stacks</li> </ul>"},{"location":"PEAP-Q-20220427/demo_software_stakcs_mdp/","title":"Demo software stakcs mdp","text":"<p>%title: LUMI Software Stacks (demos) %author: Kurt Lust %date: 2022-04-28</p> <p>-&gt; # module spider &lt;-</p> <pre><code>module spider\n</code></pre> <ul> <li>Long list of all installed software with short description<ul> <li>Will also look into modules for \u201cextensions\u201d and show those   also, marked with an \\\u201cE\\\u201d</li> </ul> </li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the (suspected) name of a package</li> </ul> <pre><code>module spider gnuplot\n</code></pre> <ul> <li>Shows all versions of gnuplot on the system</li> <li>Case-insensitive</li> </ul> <pre><code>module spider GNUplot\n</code></pre> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the (suspected) name of a package</li> </ul> <pre><code>module spider cmake\n</code></pre> <ul> <li><code>CMake</code> turns out to be an extension but <code>module spider</code>   still manages to tell which versions exist.</li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the full module name of a package</li> </ul> <pre><code>module spider gnuplot/5.4.3-cpeGNU-21.12 \n</code></pre> <ul> <li>Shows help information for the specific module, including    what should be done to make the module available</li> <li>But this does not completely work with the Cray PE modules</li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the name and version of an extension</li> </ul> <pre><code>module spider CMake/3.22.2 \n</code></pre> <ul> <li>Will tell you which module contains CMake and how to load   it</li> </ul> <pre><code>module spider buildtools/21.12\n</code></pre> <p>-&gt; # module keyword &lt;-</p> <ul> <li>Currently not yet very useful due to a bug in Cray Lmod</li> <li>It searches in the module short description and help for    the keyword.</li> </ul> <pre><code>module keyword https\n</code></pre> <ul> <li>We do try to put enough information in the modules to make   this a suitable additional way to discover software that is   already installed on the system</li> </ul> <p>-&gt; # sticky modules and module purge &lt;-</p> <ul> <li>On some systems, you will be taught to avoid module purge   (which unloads all modules)</li> <li>Sticky modules are modules that are not unloaded by    <code>module purge</code>, but reloaded.<ul> <li>They can be force-unloaded with <code>module \u2013-force purge</code>   and <code>module \u2013-force unload</code></li> </ul> </li> </ul> <pre><code>module list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <ul> <li>Used on LUMI for the software stacks and modules that set    the display style of the modules<ul> <li>But keep in mind that the modules are reloaded, which    implies that the target modules and partition module    will be switched (back) to those for the current node.</li> </ul> </li> </ul> <pre><code>module load init-lumi\nmodule list\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>You may have noticed that you don\u2019t see directories in the    module view but descriptive texts</li> <li>This can be changed by loading a module<ul> <li><code>ModuleLabel/label</code>: The default view</li> <li><code>ModuleLabel/PEhierarchy</code>: Descriptive texts, but the    PE hierarchy is unfolded</li> <li><code>ModuleLabel/system</code>: Module directories</li> </ul> </li> </ul> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>Turn colour on or off using ModuleColour/on or    ModuleColour/off</li> </ul> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>Show some hidden modules with ModulePowerUser/LUMI   This will also show undocumented/unsupported modules!</li> </ul> <pre><code>module load LUMI/21.12\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <ul> <li>Note that we see a lot more Cray PE modules with   ModulePowerUser!</li> </ul> <p>-&gt; # Demo moment 2 &lt;-</p> <p>-&gt; # Install GROMACS &lt;-</p> <ul> <li>Search for a GROMACS build recipe</li> </ul> <pre><code>module load LUMI/21.12 partition/C EasyBuild-user\neb --search GROMACS\neb -S GROMACS\n</code></pre> <ul> <li>Let\u2019s take <code>GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb</code></li> </ul> <pre><code>eb -r GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb -D\neb -r GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb\n</code></pre> <ul> <li>Now the module should be available</li> </ul> <pre><code>module avail GROMACS\n</code></pre>"},{"location":"PEAP-Q-20220427/hackmd_notes/","title":"Copy of the shared notes for course \"Detailed introduction to LUMI-C architecture and environment (April 27/28)\"","text":"<ul> <li>Copy of the shared notes for course \"Detailed introduction to LUMI-C architecture and environment (April 27/28)\"</li> <li>Useful info<ul> <li>Zoom</li> <li>Slides and Exercises</li> </ul> </li> <li>Notes, questions &amp; answers per session<ul> <li>April 27 (all times CEST)<ul> <li>09:00   Welcome, introduction to the course</li> <li>09:10   How the LUMI User Support Team works</li> <li>09:20   Introduction to the HPE Cray Hardware and Programming Environment<ul> <li>HPE Cray EX hardware talk</li> <li>Programming environment talk</li> </ul> </li> <li>10:30  break (30 minutes)</li> <li>11:00   First steps to running on Cray EX Hardware</li> <li>12:10  lunch break (80 minutes)</li> <li>13:30   Overview of compilers and libraries</li> <li>15:00  break (30 minutes)</li> <li>15:30   Advanced Application Placement</li> <li>16:30   Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)</li> <li>17:00  End of first course day</li> </ul> </li> <li>April 28 (all times CEST)<ul> <li>09:00   Performance and Debugging Tools incl exercises and a break<ul> <li>09:00 Introduction to Perftools -- Perftools-lite module and demo</li> <li>09:55 Advanced Performance Analysis I/II \u2014 Perftools, variable scoping and compiler</li> <li>10:45 Advanced Performance Analysis II/II \u2014 Communication Imbalance, Apprentice2, Hardware Counters, Perftools API, Feedback with Reveal, OpenMP, demo</li> <li>11:30 Debugging at Scale -- gdb4hpc, valgrind4hpc, ATP, stat, demo</li> </ul> </li> <li>12:00  lunch break (60 minutes)</li> <li>13:00   Understanding Cray MPI on Slingshot, rank reordering and MPMD launch</li> <li>14:00   I/O Optimisation \u2014 Parallel I/O</li> <li>14:45  break (30 minutes)</li> <li>15:15   Additional software on LUMI-C</li> <li>16:15   LUMI documentation, how to get help, how to write good support requests</li> <li>16:20   What are typical/frequent support questions of users on LUMI-C?</li> <li>16:35   Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)</li> <li>17:00  End of second course day</li> </ul> </li> </ul> </li> <li>Any other notes<ul> <li>Course page</li> <li>Misc</li> </ul> </li> <li>Questions</li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#useful-info","title":"Useful info","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#zoom","title":"Zoom","text":"<ul> <li>Link distributed via email</li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#slides-and-exercises","title":"Slides and Exercises","text":"<ul> <li> <p>Links, info on how to access them will be provided directly to participants</p> </li> <li> <p>Slides from the LUST presentations are on lumi-supercomputer.github.io/LUMI-training-materials, and in particular on this page.</p> </li> </ul> <p>During the course some materials were temprorarily available but do expect those to have become inaccessible when reading this:</p> <ul> <li>Slides appeared at: <code>/users/richards/workshop/slides</code></li> <li>Exercise materials were available at  <code>/users/richards/workshop/exercises</code> and for the performance tools sessions at     <code>/users/anielloesp/exercises</code></li> </ul> <p>The following instruction was only valid during the course. If you want to do this after the course you can no longer use the reservation and you have to submit regular jobs on a project you are member of in the regular partitions and queues:</p> <ul> <li>In the jobscripts please add <code>#SBATCH --reservation=lumi_course</code> and use one of your project accounts,      e.g., <code>project_46{2,5}0000xx</code> (<code>#SBATCH -A project_46{2,5}000xyz</code>). Remove/comment out      <code>#SBATCH -p standard</code> and <code>#SBATCH -q standard</code>).</li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#notes-questions-answers-per-session","title":"Notes, questions &amp; answers per session","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#april-27-all-times-cest","title":"April 27 (all times CEST)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#0900-welcome-introduction-to-the-course","title":"09:00   Welcome, introduction to the course","text":"<p>Q&amp;A</p> <ul> <li>Q: 1.5h in a row is rather long (both morning and afternoon sessions) in one go. Will there be some excercises or other breaks in between? Just 5mins or so to stretch a bit.<ul> <li>A: not planned, sorry (we will take this into account for a future course)</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#0910-how-the-lumi-user-support-team-works","title":"09:10   How the LUMI User Support Team works","text":"<p>Q&amp;A</p> <ul> <li>Q: who are the dedicated Experts in Sweden? <ul> <li>A: Peter Larsson at KTH, Stockholm, is the LUST member for Sweden; but the idea behind LUST is not that the person from your country should answer your questions, but the person who has most experience with the topic.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#0920-introduction-to-the-hpe-cray-hardware-and-programming-environment","title":"09:20   Introduction to the HPE Cray Hardware and Programming Environment","text":"<p>Session info: Focus on the HPE Cray EX hardware architecture and software stack. Tutorial on the Cray module environment and compiler wrapper scripts.</p>"},{"location":"PEAP-Q-20220427/hackmd_notes/#hpe-cray-ex-hardware-talk","title":"HPE Cray EX hardware talk","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: are you supporting or will you support interactive notebooks on compute nodes? (moving question to software session tomorrow)</p> <ul> <li>A: It is not yet supported now but part of the planned Open OnDemand service that will be rolled out after the summer.      It may use just a few nodes meant specifically for data analysis and visualisation (LUMI-D), with the option to launch regular jobs from your notebooks. </li> </ul> </li> <li> <p>Q: Is the AMD CPU on LUMI-G nodes the same as the one on LUMI-C nodes?</p> <ul> <li>A: no, GPU nodes have AMD Trento CPUs (more details at https://www.lumi-supercomputer.eu/lumis-full-system-architecture-revealed/ ...     also https://docs.olcf.ornl.gov/systems/crusher_quick_start_guide.html#crusher-quick-start-guide may provide some insights about GPU nodes,     but final design remains to be seen). Both CPUs are zen3 though, but with a special I/O die for the one on LUMI-G to provide the     InfinityFabric connection to the GPUs for the unified cache coherent memory architecture.</li> </ul> </li> <li> <p>Q: on the AMD GPUs, how will you handle the situation of commercial software extensively used MATLAB for instance (just one example)      that don't have a version for that?</p> <ul> <li>A: As every machine in the world, not all software is compatible with all hardware and that is why EuroHPC has multiple clusters.       There is in fact more than just the GPU that could cause compatibility problems with MATLAB. LUMI has specific requirements for MPI       also that may not be met by software only available as binaries.  </li> </ul> </li> <li> <p>Q: Do you know what other EuroHPC cluster offers NVIDIA GPUs?</p> <ul> <li>A: Leonardo (pre-exascale), Meluxina (petascale), Vega (petascale), Karolina (petascale),      Deucalion (when ready, petascale). An overview is on      the EuroHPC JU web site, \"Discover EuroHPC JU\" page.</li> </ul> </li> <li> <p>Q: Does the slingshot network handle IPMI (iLO and OOB management) as well?</p> <ul> <li>A: There is a separate network for system management as far as I know.</li> <li>A(Harvey, HPE): This is the answer I got from a colleague, don't shoot the messenger:      Slides \"IPMI is dead, long live RedFish</li> </ul> </li> <li> <p>Q: How is the boost of CPU's configured at Lumi-c by default.</p> <ul> <li>A: Slurm has the <code>--cpu-freq</code> flag to control   the CPU frequency (see here (<code>--cpu-freq</code>).      In general you can expect boosting to be enabled on compute nodes but core boost policy is quite complex.  </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#programming-environment-talk","title":"Programming environment talk","text":"<ul> <li> <p>Remark 1: There is not only the CMake integration, but pkg-config is also Cray-specific. If you try to replace it with your own version the compiler wrappers may fail.</p> </li> <li> <p>Remark 2: On licenses, LUMI has a license for ARM Forge but we are still struggling with the installation, so some patience required.</p> </li> <li> <p>Remark 3: The AMD compiler modules on the system do not all work. AOCC 2.2 that came with the 21.05 version of the system works      but will be removed at one of the next maintenance intervals. 3.0 has a module on the system but no binaries, and the      module of 3.1.0 is broken. That can be dealt with by instead using the LUMI/21.12 software stack and then the cpeAOCC      module (see a presentation on the second day about the LUMI software stacks).</p> <ul> <li>A (Alfio, HPE): I have tried the <code>PrgEnv-aocc/8.2.0</code> module (<code>module swap PrgEnv-cray PrgEnv-aocc</code>) and indeed      it doesn't load the corresponding <code>cray-mpich</code> module. To solve this problem, I have to set the variable     <pre><code>export MODULEPATH=/opt/cray/pe/lmod/modulefiles/comnet/aocc/3.0/ofi/1.0:$MODULEPATH\n</code></pre>     and then I can run <code>module load cray-mpich</code>. I've tested with a Fortran application and it runs.</li> <li>A (Kurt, LUST): The solution above solves only part of the problem. There are other modules you might need that     will also fail to load. The <code>LUMI/21.12</code> software stack contains a more robust workaround in the <code>cpeAOCC/21.12</code> toolchain.</li> </ul> </li> </ul> <p>Q&amp;A</p> <ul> <li> <p>Q: Question about the Cray Developer Environment: Do the 3rd party packages have a different support deal that the ones developed by Cray?</p> <ul> <li>A: Unclear to LUST, we have not seen the contracts. But the installation files do come via HPE and we did notice      that some builds are definitely HPE Cray-specific (choice of options and supported technologies, names of binaries to      avoid conflicts with other tools, ...). But basically we cannot expect HPE to debug the GNU compiler while we can expect      them to do bug fixes for the CCE compiler. And since AMD is also involved in the project, we can go to them with compiler      bugs in the AMD compilers. ARM Forge is a different story, it is obtained from ARM directly and not via HPE.</li> <li>A(Harvey, HPE): The developers will forward bugs for some of the components not developed internally,      it depends. For AMD we have a special relationship with them that we can use for LUMI. All of the integration      pieces (modules) are supported.</li> </ul> </li> <li> <p>Q: what about h5py?</p> <ul> <li>A: It is not included in the Cray branded module.      <pre><code>module load cray-python/3.9.4.2\npython -c 'import h5py'\npip3 list\n</code></pre></li> <li>A: It may be one that needs to be compiled from sources, and may also depend on which of the HDF5 configurations      you need for the software that you may want your Python code to talk to.</li> </ul> </li> <li> <p>Q: how about Julia, Rust, golang?</p> <ul> <li>A: <ul> <li>We had Rust but removed it again from the software stack due to problems with installing Rust.      The whole Rust installation process is very HPC-unfreiendly (and we are not the only one suffering with this,      I know this from the meetings about the software management/installation tool that we use). </li> <li>Golang due to its poor memory use is not even an HPC language. </li> <li>Julia would be interesting, but for now it looks best to do this via containers as the installation process      from sources is complicated.      </li> </ul> </li> <li>Comment: I guess one could place binaries of Julia in the work directory?</li> <li>Answer: I don't know, Julia binaries may require other libraries to be installed that are not installed on      the Cray system. It does special things to link to some mathematical libraries and to MPI.</li> </ul> </li> <li> <p>Q: There was a brief mention of singularity containers and using MPI with containers. Will HPE provide a basic      singularity recipe for using MPI on LUMI? This would be a useful starting point for building containers for various      application (e.g. machine learning with Horovod support). Experience shows it can be quite tricky to get this working,      having right versions etc.</p> <ul> <li>A: We're working on that. Basically, currently Open MPI is a big problem and we have failed to get it to work      reliably with our network and SLURM. For containers that support MPICH 3 we already have a (currently still undocumented)      module available that users can adapt and then install to set some environment variables to tell the container      to use the Cray MPICH library instaed (relying on ABI compatibility with plain MPICH). After the course, try      <code>eb --search singularity-bindings</code> (tomorrow we will explain what this means). You may even adapt this EasyConfig yourself     before installing to include additional bindings that you may need before installing it with EasyBuild.</li> </ul> </li> <li> <p>Q: Have you also considered conda environments, especially when it comes to complex Python dependencies?</p> <ul> <li>A: We are providing dedicated wrapper for containerized conda and pip based environments.      It will be mentioned tomorrow afternoon. But again, not everything installed via Conda might work as Conda      may try to use libraries that are not compatible with LUMI. More info in the     LUMI documentation, lumi-container-wrapper page.</li> </ul> </li> <li> <p>Q: Singularity is available but Docker does not seem to be available?</p> <ul> <li>A: Docker was mentioned from administration perspective. From the user perspective singularity is the choice.      For most docker containers simple <code>singularity pull</code> command should be enough for conversion.      For instance <code>singularity pull docker://julia</code></li> </ul> </li> <li> <p>Q: Regarding MPI : is there any native OpenMPI implementation available?</p> <ul> <li>A: Not really. We have some workarounds but in large scale it is expected to fail.</li> </ul> </li> <li> <p>Q: What with Intel compilers, MKL Intel and Julia language?</p> <ul> <li>A: Harvey will describe current status on the Intel development tools in the compilers talk.</li> <li>A: We have no support for Intel in our contract with HPE and Intel will also not support it on      AMD processors. If the reason why you want Intel is the classic Fortran compiler, you should really      consider modifying the code as their classic compiler is end-of-line anyway and the new one has a      completely different front-end so different compatibility problems. </li> <li>A: MKL is known to produce wrong results on the AMD processors and there are performance problems      that need hacks that are not user-friendly to force it to take an AVX2 code path rather than one for      the Pentium 4 from 15 years ago. At the University of Antwerp, where I work, most DFT packages for      instance produce wrong results with Intel on AMD Rome CPUs that we could correct by using FFTW instead      of MKL for FFT.      JuliA: see above, the question has already been asked, we'd like to support this but the installation      procedure is a bit complicated and we cannot do everything in the first year.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1030-break-30-minutes","title":"10:30  break (30 minutes)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1100-first-steps-to-running-on-cray-ex-hardware","title":"11:00   First steps to running on Cray EX Hardware","text":"<p>Session info: Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement. Exercises: about 40 minutes</p> <p>Q&amp;A</p> <ul> <li> <p>Q: you don't need to specify the number of tasks for this script? just the number of nodes?</p> <ul> <li>A: Just checked and the slide is indeed wrong. The #SBATCH lines will create only 2 task slots I think      so srun will fail to then use 256. (Harvey: Which slide was this?) (Kurt: One of the first but I don't remember      the page number, in the July version of the course it was slide 6 and the first example of a job script) Harvey:      The jobs are specifying nodes (--nodes/N). We will check at end of talk.</li> </ul> </li> <li> <p>Q: Does Gromacs get some benefits from the hardware threads (--hint)?</p> <ul> <li>A: Can you be a bit clearer? Turning threads on or off? My expectation is that it would be case dependend,      but I doubt as GROMACS already puts a very high stress on the CPU. (And we know that some GROMACS jobs trigger a      hardware problem in some nodes that HPE is still working on because of the high load they put on the CPU.) </li> </ul> </li> <li> <p>Q: Using --exclusive on small/eap partitions would always reserve full nodes, right?</p> <ul> <li>A: For binding exercises/jobs this flag is needed.</li> <li>A: Using <code>--exclusive</code> on small defeats the whole purpose of the small partition which is all about having      resources available for programs that cannot use a whole node. Also note that you will be billed for the whole      node of course. On the EAP it is very asocial behaviour as we have only few such nodes available so it should only      be done for short jobs if there is really no other option available. Note also that the EAP is not really a      benchmarking platform.</li> </ul> </li> <li> <p>Q: Will <code>--cpus-per-task</code> set the <code>OMP_NUM_THREADS</code> variable?</p> <ul> <li>A: It does not. And while on some systems the Open MP runtime recognizes from the CPU sets how much threads      should be created, this does not always work on LUMI as that mechanism cannot recognize between <code>--hint=multithread</code>      and <code>--hint=nomultithread</code> so you may get twice the number of threads you want. We'll put a program in the software      stack that shows you what srun would do by running a quick program not requiring many billing units, but it is not yet      there as I am waiting for some other software to go into the same module that is not finished yet.</li> <li>A: SLURM does set <code>SLURM_THREADS_PER_CORE</code> and <code>SLURM_CPUS_PER_TASK</code> environment variables that you can use to      set <code>OMP_NUM_THREADS</code>.</li> </ul> </li> <li> <p>Q: Is there \"seff\" command (exist in Puhti) to check resources used by batch job?</p> <ul> <li>A: No, it is something we've looked into but it turns out that that script needs a SLURM setup that we do not      have on LUMI and that it is not something we could install without sysadmin support. And currently the LUMI      sysadmins install the system the way HPE tells them to, which means that there are some SLURM plugins that      are on puhti or mahti but not on LUMI. I guess we'll see the sacct command later in the course and that can      tell you what the total and average CPU time consumed by a job is so that you can get some idea about efficiency. </li> </ul> </li> <li> <p>Q: can we use mpprun instead of srun?</p> <ul> <li>A: No. <code>srun</code> is the only parallel executor supported.</li> </ul> </li> <li> <p>Q: Why is SMT not turned off by default if it is not beneficial in most cases?</p> <ul> <li>A: I would say it is turned off by default (for both <code>small</code> and <code>standard</code> partitions). </li> <li>A: SMT tends to be most beneficial for code that runs at a low \"instructions per clock\", so branchy      code (like databases) or code that has very bad memory access patterns, and hence creates pipeline stalls.      For well written scientific codes that do proper streaming of data it tends to make matters worse rather      than better as you effectively half the amount of cache available per thread and as a single thread per      core already keeps the memory units busy.</li> </ul> </li> <li> <p>Q: Compiling the pi/C example gives <code>warning: Cray does not optimize for target 'znver3' [-Wunsupported-target-opt]</code>      Is this something to worry about? Does it mean it will not optimize for AMD at all?</p> <ul> <li>A: I think you are using the wrong CCE module? The latest one (cce/13.0.0) that came with the 21.12 programming      environment can optimise for zen3, but older versions didn't. Indeed, I had some other modules loaded.      Just loading <code>PrgEnv-cray/8.1.0</code> makes the warning disappear.</li> </ul> </li> <li> <p>Q: Bash completion for Slurm      does not seem to be setup on Lumi? Are there plans to install it?</p> <ul> <li>A: No idea. This is something that has to be done at the sysadmin level, not at the level that the support team can do.      Given the security constraints for a machine like LUMI and the desire to have a setup at the system level which is      fully supported by HPE, there is a very strict border between what is possible at the user interface level and what sysadmins      should do, and are willing to do as some features are turned off explicitly for security reasons. This, e.g., explains      some of the restrictions there are on LUMI working with containers. But if you really really want it I guess you could install      it in your account and activate from your .bashrc. Just sourcing the file seems to work. </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1210-lunch-break-80-minutes","title":"12:10  lunch break (80 minutes)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1330-overview-of-compilers-and-libraries","title":"13:30   Overview of compilers and libraries","text":"<p>Session info: An introduction to the compiler suites available. Including examples of how to get additional information  about the compilation process. Special attention is given the Cray Compilation Environment (CCE) noting options  relevant to porting and performance. CCE classic to Clang transition Exercises: about 20 minutes</p> <p>Remark 1: Slide 7 (3 ways of dynamic linking) is a really important one. It implies that you will sometimes  be using a different version of a library at run time than you think unless you use the third approach. It also  implies the behaviour of a code may change when the default programming environment on the system is changed if  you use the first apporach.</p> <p>Remark 2: The Cray Fortran compiler is actually one of the most strict compilers around when it comes to  standard compliance. Many codes that don't fully follow the standards fail to compile.</p> <p>Q&amp;A</p> <ul> <li> <p>Q: would one expect a more performant code with dynamic vs. static linking?</p> <ul> <li>A: I think on modern CPUs the main difference will be the performance during loading (static is faster      as you have only one file to open and read). There are differences in the code generated (e.g., you have      to use position independent code for a shared library) but I would expect that the performance impact      of that will be very low or none on modern architectures as CPUs have simply been optimised to work well      with the memory models for shared libraries. I haven't benchmarked it though. </li> </ul> </li> <li> <p>Q: I am trying to compile my library on LUMI. According the recommendation, I have loaded PrgEnv-cray/8.2.0.      Since I am using waf compiler tool, that does not recognise cc/CC wrappers, so I have specified clang++ to be c++ compiler.     <pre><code>onvysock@uan02:~/meric&gt; CC --version\nCray clang version 13.0.0  (24b043d62639ddb4320c86db0b131600fdbc6ec6)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /opt/cray/pe/cce/13.0.0/cce-clang/x86_64/share/../bin\n\nonvysock@uan02:~/meric&gt; clang++ --version\nCray clang version 13.0.0  (24b043d62639ddb4320c86db0b131600fdbc6ec6)\nTarget: x86_64-unknown-linux-gnu\nThread model: posix\nInstalledDir: /opt/cray/pe/cce/13.0.0/cce-clang/x86_64/bin\n</code></pre>     Despite using the clang++ the compilation fails that it does not find C++ header file. It seems to me, that C compiler is used instead of C++.     <pre><code>[ 2/82] Compiling src/meric/meric.cpp\n14:57:01 runner ['clang++', '-O0', '-g', '-std=c++11', '-fPIC', '-fopenmp', '-I/pfs/lustrep2/users/onvysock/meric/include/', '-DMERIC_PATH=\"/pfs/lustrep2/users/onvysock/meric\"', '-DVERBOSE', '../src/meric/meric.cpp', '-c', '-o/pfs/lustrep2/users/onvysock/meric/build/src/meric/meric.cpp.1.o']\n\nIn file included from ../src/meric/meric.cpp:2:\n../src/meric/meric.h:5:10: fatal error: 'iostream' file not found\n#include &lt;iostream&gt;\n         ^~~~~~~~~~\n1 error generated.\n</code></pre>     Do you have any idea what can be wrong?</p> <ul> <li>A: I was expecting this problem would be solved by now, but the Cray compilers need additional options      to find their own include files. These are added automatically by the wrappers. I'm not sure if I have compiled      programs with waf already on LUMI (I hate all those alternative tools that are incomplete) but most install      utilities have a way to tell them which compiler to use. <code>cc</code> can show the commands that it would generate      using the <code>-craype-verbose</code> flag so you could see which libraries and include files it tries to use but from      what I remember this is cumbersome. I checked the tool that we use to manage software installations and I do      not that it seems to support Waf which means that there must be a way to set environmen variables or command      line options to select the compiler.</li> <li>A (Alfio): the flag is actually <code>-craype-verbose</code>, e.g.     <pre><code>$ CC -craype-verbose test.cc \nclang++ -march=znver2 -dynamic -D__CRAY_X86_ROME -D__CRAYXT_COMPUTE_LINUX_TARGET --gcc-toolchain=/opt/cray/pe/gcc/8.1.0/snos -isystem /opt/cray/pe/cce/13.0.0/cce-clang/x86_64/lib/clang/13.0.0/include -isystem /opt/cray/pe/cce/13.0.0/cce/x86_64/include/craylibs -Wl,-rpath=/opt/cray/pe/cce/13.0.0/cce/x86_64/lib -Wl,-rpath=/opt/cray/pe/gcc-libs test.cc -I/opt/cray/pe/libsci/21.08.1.2/CRAY/9.0/x86_64/include -I/opt/cray/pe/mpich/8.1.12/ofi/cray/10.0/include -I/opt/cray/pe/dsmml/0.2.2/dsmml//include -I/opt/cray/xpmem/2.2.40-2.1_3.9__g3cf3325.shasta/include -L/opt/cray/pe/libsci/21.08.1.2/CRAY/9.0/x86_64/lib -L/opt/cray/pe/mpich/8.1.12/ofi/cray/10.0/lib -L/opt/cray/pe/dsmml/0.2.2/dsmml//lib -L/opt/cray/pe/cce/13.0.0/cce/x86_64/lib/pkgconfig/../ -L/opt/cray/xpmem/2.2.40-2.1_3.9__g3cf3325.shasta/lib64 -Wl,--as-needed,-lsci_cray_mpi,--no-as-needed -Wl,--as-needed,-lsci_cray,--no-as-needed -ldl -Wl,--as-needed,-lmpi_cray,--no-as-needed -Wl,--as-needed,-ldsmml,--no-as-needed -lxpmem -Wl,--as-needed,-lstdc++,--no-as-needed -Wl,--as-needed,-lpgas-shmem,--no-as-needed -lquadmath -lmodules -lfi -lcraymath -lf -lu -lcsup -Wl,--as-needed,-lpthread,-latomic,--no-as-needed -Wl,--as-needed,-lm,--no-as-needed -Wl,--disable-new-dtags \n</code></pre></li> <li>RE1: To be honest I am not sure, what is your advice. Should I add the include paths when compiling with clang++      (I did a fast browse and did not find the standard c++ headers in the paths mentioned in the Alfio's answer)?      Should I wait for someone to fix the clang++ utility? Should I load a compiler module instead of PrgEnv module?</li> <li>A: (Alfio): I'm not really familiar with the tool, apologize in advance for any naive suggestion...      Could you try <code>CXX=CC ../../waf configure build</code>? I tried it with a simple C++ example in the waf repository      and it correctly reports <code>Checking for 'clang++' (C++ compiler)    : CC</code></li> <li>RE1.1: This is not a problem of waf. Try the following:     <pre><code>$ module load PrgEnv-cray/8.2.0\n$ vim hello.cpp\n    #include &lt;iostream&gt;\n    int main()\n    {\n        std::cout &lt;&lt; \"Hello LUMI\\n\";\n        return 0;\n    }\n$ clang++ -std=c++11 hello.cpp\n    hello.cpp:1:10: fatal error: 'iostream' file not found\n    #include &lt;iostream&gt;\n            ^~~~~~~\n    1 error generated.\n$ CC -std=c++11 hello.cpp\n$ ./a.out\nHello LUMI\n$\n</code></pre> What solution do you suggest to use, if I do not want to use <code>CC</code> but directly <code>clang++</code>?     If you prefer, we may use another channel for communication.</li> <li>A: So, if you want directly use clang++, you should be aware that it comes from the Cray compiler, so you really need the wrappers. For instance:     <pre><code>$ which clang\n/opt/cray/pe/cce/13.0.0/cce-clang/x86_64/bin/clang\n</code></pre>     If you need a plain clang, then I suggest to use the AOCC clang:     <pre><code>$ module load aocc-mixed\n</code></pre>     and then you can compile with <code>clang++</code>  the example above.</li> <li>RE2: I did not do a deep research, so it could be possible, that waf support Cray compiler wrapper,      however as an easy solution I did just specify the <code>clang++</code>, which equals to <code>CC</code>.</li> <li>A (Alfio): Have you seen this?</li> <li>RE2.1: My library compilation process supports clang++, but the CC wrapper is not working for me.      I know how to tell waf, which compiler to use based on what the CC wrapper returns. The source of the      problem is not in the waf, see RE1.1.</li> <li>A: I've checked what EasyBuild does, tested myself and also searched a bit on the web and it looks like Waf      indeed simply uses the environment variables in the way that <code>configure</code> does to specify the compilers so it      should be possible to use statements like <code>export CC='cc'</code> and <code>export CXX='CC'</code> to tell Waf to use the wrappers.     Using the <code>waf</code> command line options (if that is what you are doing) is NOT enough to say      With this on a C++ demo program the output does show     <pre><code>Checking for 'g++' (C++ compiler)        : not found\nChecking for 'clang++' (C++ compiler)    : CC\n</code></pre>     Whis is exactly what I want to see, and continuing this with <code>waf configure build -vvv</code> clearly shows once      more that Waf is using the <code>CC</code> wrapper. In general, I'd say never trust autodetection of compilers when      running configure/build tools because you'll often end up using the worst one on your system. Any decent      tool has a way to specify the name of the compiler and compiler flags, at least when used in the proper      way by the developers creating the build recipe. All the software we have at the moment on LUMI is build      using the Cray wrappers except for software where I explicitly wanted the system gcc to be able to run      completely independent of the Cray PE.</li> <li>A: And <code>clang++</code> does not equal to <code>CC</code>. <code>CC</code> does a lot more.</li> <li>RE2.2: Can you please share your wscript? The part that checks for the CXX.</li> <li>A: I simply ran some examples from the Waf examples, e.g.,     the C++ one with the current version     of Waf (2.0.23) and telling it via the <code>CXX</code> environment variable to use <code>CC</code> as I described above. I'm not    a Waf specialist, but I guess it is the    <pre><code>opt.load('compiler_cxx')\n</code></pre>    or    <pre><code>conf.load('compiler_cxx')\n</code></pre>    lines that activate the routines that do the magic.</li> </ul> </li> <li> <p>Q: Is the BLIS library available?</p> <ul> <li>A: We have a recipe so that a user can install it but we don't want to make it available by default      in the central stack as it would conflict with libraries already build with Cray LibSci.      A look at the symbols in Cray LibSci shows that is uses a mix of OpenBLAS and BLIS. </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1500-break-30-minutes","title":"15:00  break (30 minutes)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1530-advanced-application-placement","title":"15:30   Advanced Application Placement","text":"<p>Session info: More detailed treatment of Slurm binding technology and OpenMP controls. Exercises: about 30 minutes</p> <p>Q&amp;A</p> <ul> <li> <p>Q: If it is only \"marginally slower\" that suggest that very little extra perfomance can be obtained by      doing the explicit binding? Ok, now he is saying something else. Suggest to ask at end of presentation.</p> <ul> <li>A: crossing socket boundaries may lead to significantly lower performance</li> <li>A: depends on the particular case</li> </ul> </li> <li> <p>Q: (slide 16) Are you assuming --exclusive or other kind of full-node-access here?</p> <ul> <li>A: yes.</li> </ul> </li> <li> <p>Q: which binding mechanism has a higher priority OpenMP or SLURM?</p> <ul> <li>A: Slurm will set a cgroup, you can't escape that. But also depends on which plugins are enabled.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1630-open-questions-answers-participants-are-encouraged-to-continue-with-exercises-in-case-there-should-be-no-questions","title":"16:30   Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: Is there a mechanism for requesting packages such as MUMPS?</p> <ul> <li>A: should be addressed tomorrow.</li> <li>A: Checked for MUMPS. The likely reasons why we don't have that yet ready (besides that it has not yet      been requested) is that we have given priority to packages for which a friendly site with a similar system      provides build instructions in a way that we can easily adapt to LUMI, and a frightening element on the web      site that actually asks you to specify some information about how MUMPS will be used before downloading      which we as support people rather than users obviously cannot answer with any accuracy.      Though it looks like the download isn't really protected.</li> </ul> </li> <li> <p>Q: would you provide tools such as Extrae as modules? Or maybe users would install them?</p> <ul> <li>A: likely answered in tomorrows talk on additional software</li> <li>A: if someone struggles to build/install a software package LUST+CoE can help, for example,      by asking around (what experiences on other systems have been made)</li> <li>A: The reality is also that the support team of 9 FTE is way too small to do all software      installations for all projects as the expected number is very high given that many countries assign      lots of small projects. We have to do more than just software installations, and we are only a fraction      of the size of the software support team of larger centres as, e.g., J\u00fclich. So we have to rely a lot on      users doing their own installations, possibly with the help of local support teams from the countries they      come from, and hopefully then contributing their experiences so that we can make them available to others.</li> </ul> </li> <li> <p>Q: I want to build/compile CP2K 9.1, may be need assistance for that</p> <ul> <li>A: we already have a recipe (easyconfig) for that, should be more clear after tomorrows talk on additional software</li> <li>A (Alfio, HPE): CoE has expertise with CP2K too.         That's they way I use to install CP2K v9.1 on LUMI:         +   <code>module swap PrgEnv-cray PrgEnv-gnu</code> (GNU is supported by CP2K)         +   <code>module load cray-fftw</code>         +   <code>git clone --recursive --branch  v9.1.0 https://github.com/cp2k/cp2k.git</code>         +   <code>cd cp2k/tools/toolchain</code>         +   <code>./install_cp2k_toolchain.sh --enable-cray</code> (use <code>./install_cp2k_toolchain.sh --help</code> to get more help on what to install). Note that this takes a while to complete.         +   <code>cp install/arch/local.psmp ../../arch/</code>         +   <code>cd ../../</code>         +   Change the <code>arch/local.psmp</code> file by adding <code>-fallow-argument-mismatch</code> flag to <code>FCDEBFLAGS</code> variable         +   <code>make ARCH=local VERSION=psmp</code></li> <li>A: LUST may have had a support request for CP2K 9.1 recently</li> </ul> </li> <li> <p>Q: will programs like LAMMPS, ABINIT, SIESTA be available as modules?</p> <ul> <li>A: Status for these applications:<ul> <li>Limited support for LAMMPS, only few plugins, configuration based on input we got from CSCS who have a system      similar to LUMI-C. Some of the plugins are supported by neither EasyBuild nor Spack, the two frameworks for HPC      software installation that we use or consult for installation procedures. </li> <li>ABINIT is available as easyconfig and discussions are going on with the ABINIT authors to improve the installation.      The developers have already got access via the Belgian share on LUMI.</li> <li>SIESTA: Kind of problematic. I've seen it fail on user tests even though the compile succeeded without any      terrifying warning. They also had the brilliant idea to change the build process to one that is harder to support      in tools such as Spack and EasyBuild. Therefore Spack for now stopped supporting Siesta at version 4.0.2 which      is 4 years old. EasyBuild kind of supports newer versions but only in combination with some libraries that are      different from what we use on the system, and do to the nature of the new build process it is difficult to adapt      the EasyBuild code in a generic way but also to write a robust automated build process specifically for the Cray PE.      We'd need working manual installation procedures before even looking at how we can automate the procedure and maintain it.      There are some instructions to compile Siesta with PrgEnv-gnu on the Archer2 GitHub      but we'd need a Siesta expert to see if this is just the most basic build or includes options that Siesta      might provide. At first sight it does not include METIS, ELAP, MUMPS, PEXSI or flook that are mentioned in      the 4.1.5 manual as libraries that provide additional functionality.</li> </ul> </li> </ul> </li> <li> <p>Q: Are there Easybuild recipes to install the Cray PE/tools?</p> <ul> <li>A: No. This is no free software and installed in a very different way. EasyBuild can use the the Cray PE as external software though. </li> </ul> </li> <li> <p>Q: I think for Lammps and other softwares alike would be better to have a short guide suggesting the best      combination of compilers, libraries and slurm options that would give the best performance in a general way</p> <ul> <li>A: not easy to provide general answers. The right combination of compilers and libraries and the right Slurm      options will often depend on the particular test case. E.g., due to different vectorisation and loop unrolling      strategies one compiler may be better on one problem that leads to shorter loops and another may be better on      another problem with the same code that leads to longer loops. The amount of parallelism and certainly how to      tune a hybrid run combining MPI with threads will depend a lot on the test case.</li> <li>A: maybe better to provide guidance on how to determine these options on a case by case basis</li> </ul> </li> <li> <p>Q: is there a supercomputer similar to LUMI in the world?</p> <ul> <li>A: to some extend yes, Frontier (ORNL, US), Dardel (KTH, SE), Setonix (Pawsey, Australia),      Adastra (CINES, Montpellier, France). For LUMI-C there is Archer2 (EPCC, UK) and Eiger (CSCS, Switzerland).      The software stack for LUMI was originally developed on Eiger as otherwise it would have taken half a year or      so from the start of the pilot to have something that is properly designed and working.</li> </ul> </li> <li> <p>Q: What is important to participants in terms of applications (standard applications or own applications)?</p> <ul> <li>A: Looking at the proposals submitted in the latest round in Belgium, it was about 50-50. </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1700-end-of-first-course-day","title":"17:00  End of first course day","text":"<p>See you tomorrow at 07:00 UTC, 08:00 EPCC, 09:00 CEST or 10:00 EEST.</p>"},{"location":"PEAP-Q-20220427/hackmd_notes/#april-28-all-times-cest","title":"April 28 (all times CEST)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#0900-performance-and-debugging-tools-incl-exercises-and-a-break","title":"09:00   Performance and Debugging Tools incl exercises and a break","text":"<p>Session info: Includes following content broken up with Exercises/Demos and a break + Introduction to perftools + Pertfools lite modules + Loop work estimates + Reveal for performance data display, compiler feedback and automatedscoping + Debugging tools at scale</p>"},{"location":"PEAP-Q-20220427/hackmd_notes/#0900-introduction-to-perftools-perftools-lite-module-and-demo","title":"09:00 Introduction to Perftools -- Perftools-lite module and demo","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: I would be really interested in some comments about HIP and OpenMP offload profiling as long as power      consumption tracking with the tools</p> <ul> <li>A: Noted but this course is not about LUMI-G.</li> <li>A: Sure, we have EAP though</li> <li>A: These tools can be used with the AMD GPUs but we don't plan to cover that in this course.</li> <li>A: routine-level power consumption available, not sure about data transfers</li> </ul> </li> <li> <p>Q: When do the GPU partition will be available? For early access and then production?</p> <ul> <li>A: LUMI-G: not before August (pilot), general availability fall 2022. The Early Access Platform, EAP,      (MI100, available already, any existing project on LUMI-C has access). The EAP is designed for porting code,      not for production runs or benchmarking. Especially inter-node communication is very poor at the moment which      makes benchmarking this completely irrelevant, and the GPUs in the EAP are sufficiently different that much      benchmarking and really fine-tuning on them may also prove to be irrelevant on the MI250X.</li> </ul> </li> <li> <p>Q: Is there a tool to track specific I/O events (like volume of data written or read along the run) ?</p> <ul> <li>A: perftools reports include a table addressing I/O, this will be shown later.</li> </ul> </li> <li> <p>Q: Do you also advise to compare the performance of the exec generated with perftools-lite (only sampling)      with the original executable without any monitoring? In other words, can there be a significant overhead with just application sampling?</p> <ul> <li>A: always good to have one reference run</li> </ul> </li> <li> <p>Q: Can the perftools-lite tools also be used with MPMD execution?</p> <ul> <li>A: yes, has been done in the past</li> </ul> </li> <li> <p>Q: What should you do if you notice that perftools-lite introduces a significant overhead compared to an executable      without any profiling hooks?</p> <ul> <li>A: More likely if you trace very small, frequently called functions, you can specify not to profile certain functions.</li> <li>Q2: Can this be done with perftools-lite?</li> <li>A: perftools is needed to select/exclude certain functions , however this applies to tracing, it is less likely      that a lite sampling experiment will skew the performance.</li> </ul> </li> <li> <p>Q: What is the purpose of the perftools-base module that is loaded by default?</p> <ul> <li>A: <code>man perftools-base</code> (HPE Cray really likes man pages rather than web-based documentation). One of the functions      is to make the other perftools modules available in the Lmod hierarchy. It is a rather common practice on Cray systems      to load it by default, so we follow this \"convention\" so that people who are familiar with the Cray Programming Environment      find more or less what they expect. </li> <li>A: It provides the command-line tools but unlike the full perftools module it does not affect any compilations.</li> </ul> </li> <li> <p>Q: Is it possible to install <code>perftools-*</code> in our machine so that we can get the interactive output?      (I mean this \"Apprentice\" program)</p> <ul> <li>A: /opt/cray/pe/perftools/default/share/desktop_installers contains Apprentice2 for Windows and macOS      and Reveal for macOS. Some remote connect capability of these does not work with ssh keys at the moment but you      can run apprentice2 on .ap2 files you copy to your desktop/laptop.</li> <li>A: We also have the lumi-vnc module to run graphical programs on LUMI via a VNC client or web browser      (try <code>module help lumi-vnc</code>), and later this year (hopefully) there should also be Open OnDemand to offer      a frontend to LUMI to run GUI programs without too much trouble. </li> <li>Q2: but not a Linux version, it seems (I guess this would require the full Cray stack to be installed, though)</li> <li>A: This comes up from time to time but it is not clear how large the community is of people who want this      and at the moment there is no commitment to provide Linux clients. We will feed this back.</li> <li>A: The problem may also be that release engineering for Linux can be very hard for GUI packages that are not      spread through RPM or other repositories as you can never be sure which libraries are present on a Linux machine      due to all the distributions and all the installation options. One of the reasons we are so slow in setting up      GUI-based applications on LUMI and to get the visualisation nodes available to users is precisely that we run      into these problems all the time. You may have to use one of the modern containerised solutions for that.</li> <li>C: The first argument is a bit surprizing, given that I would expect the HPC community to be a bit more      Linux-oriented than the average public. But I totally agree that getting a GUI to run on Linux is a hell of a job, so thank you for your answers :)</li> <li>C: The reality is that macOS is very popular in the HPC community because it offers you a UNIX-like environment,      good development tools, but also good office tools that you also need in your work, and that Windows is on the rise      since it has become rather good for development on Linux also thanks to WSL and WSL2. ComputeCanada makes their      HPC software stack that they serve via CernVM FS also available to their users in Canada on Windows simply via WSL2...</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#0955-advanced-performance-analysis-iii-perftools-variable-scoping-and-compiler","title":"09:55 Advanced Performance Analysis I/II \u2014 Perftools, variable scoping and compiler","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1045-advanced-performance-analysis-iiii-communication-imbalance-apprentice2-hardware-counters-perftools-api-feedback-with-reveal-openmp-demo","title":"10:45 Advanced Performance Analysis II/II \u2014 Communication Imbalance, Apprentice2, Hardware Counters, Perftools API, Feedback with Reveal, OpenMP, demo","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: Is there a way to \"customize\" the profiling : for example if the runtime is n sec, start the profiling      at t0 and stop it at t1 with 0&lt;t0&lt;t1&lt;n, i. e. produce a profiling from t0 to t0+t1? it may be usefull for      tracing for example a small number of it\u00e9rations (rather than all it\u00e9rations) and also for avoiding to generate too much data to proceed later with GUI.</p> <ul> <li>A: You can use an API to control which parts of an application are profiled (between begin/end calls).      This is covered in the talk and one of the exercise directories. The two aspects of this are first that you      can collection off and on, secondly wrapping particular parts of an application between begin/end calls such that this will appear separately in the report.</li> <li>A: Using specific time stamps is not directly possible with the API.</li> </ul> </li> <li> <p>Q: Regarding the himeno example; What is the importance of distributing processes over NUMA domains?</p> <ul> <li>A: By default, processes are not cyclically distributed over NUMA domains. Might use <code>--cpu-bind=verbose</code>      as srun option to obtain binding information. </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1130-debugging-at-scale-gdb4hpc-valgrind4hpc-atp-stat-demo","title":"11:30 Debugging at Scale -- gdb4hpc, valgrind4hpc, ATP, stat, demo","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: Is there any reason not to setup ATP by default so that it can capture any unexpected crash?</p> <ul> <li>A: ATP has a low overhead, but it has some. So, it's up to the user to make the decision to include it or not.</li> <li>A: It adds a signal handler. That might interfere with the application.</li> </ul> </li> <li> <p>Q: Will DDT be available on LUMI?</p> <ul> <li>A: Yes ARM forge will be available on LUMI. No ETA for the installation at the moment.</li> </ul> </li> <li> <p>Q: Will totalview be also treated in the same way as DDT? Will the user have to bring its own license to use it on      Lumi if I understood well?</p> <ul> <li>A: DDT will be available as a part of the ARM Forge. I do not believe TotalView would be available.</li> <li>A: No, we've looked at TotalView also but we cannot buy every debugger/profiler and in fact     at that time there were not even realistic plans for support for the architecture that we have     (didn't check if this has changed though).</li> </ul> </li> <li> <p>Q: Is it possible/advised to enable by default both ATP and perftools-lite?</p> <ul> <li>A: ATP could be enabled by default, there might be the odd interaction with application signal handlers to watch out for.</li> <li>A: I (Harvey) don't recommend having profiling enabled by default as this affects how applications      are built and run and generates extra data that people might not want. </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1200-lunch-break-60-minutes","title":"12:00  lunch break (60 minutes)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1300-understanding-cray-mpi-on-slingshot-rank-reordering-and-mpmd-launch","title":"13:00   Understanding Cray MPI on Slingshot, rank reordering and MPMD launch","text":"<p>Session info: High level overview of Cray MPI on Slingshot, useful environment variable controls. Rank reordering and MPMD application launch. Exercises: about 20 minutes</p> <p>Q&amp;A</p> <ul> <li> <p>Q: When will the Slingshot upgrade take place?</p> <ul> <li>A: ~ end of May, from then UCX won't be available</li> </ul> </li> <li> <p>Q: Can <code>MPICH_RANK_REORDER</code> environment variables also be used to control binding inside a node, for example spreading across sockets?</p> <ul> <li>A: don't think so</li> <li>Q2: I phrased my question wrong. Suppose in a single node you bind processes to cores 0,32,64,96.      Can you then use <code>MPICH_RANK_REORDER</code> to control mapping of ranks to those processes? Admittedly, this will      have a smaller impact compared to inter-node communication, but it is possible that communication      between 0-64 is slower than between 0-32.</li> <li>A: This is a very good question and I have been thinking we should start looking at this from the perspective      of node structure in addtion to on/off node considerations.</li> </ul> </li> <li> <p>Q: What is the difference between <code>MPICH_RANK_REORDER_METHOD</code> and <code>srun --distribution</code>?      Apparently the former takes precedence over the latter.</p> <ul> <li>A: I'd say: srun will map Slurm tasks on the resources of the job, and <code>MPICH_RANK_REORDER_METHOD</code>      will then influence the mapping of MPI ranks on Slurm tasks with the default being rank i on task i.</li> <li>A: (Harvey) I really need to test this as I could imagine that distribution to nodes could be      done from scratch but the custom mapping might be done from SLURM-set mapping already there.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1400-io-optimisation-parallel-io","title":"14:00   I/O Optimisation \u2014 Parallel I/O","text":"<p>Session info: Introduction into the structure of the Lustre Parallel file system. Tips for optimising parallel bandwidth for a variety of parallel I/O schemes. Examples of using MPI-IO to improve overall application performance.</p> <p>Advanced Parallel I/O considerations + Further considerations of parallel I/O and other APIs.</p> <p>Being nice to Lustre</p> <ul> <li>Consideration of how to avoid certain situations in I/O usage that don\u2019t specifically relate to data movement.</li> </ul> <p>Q&amp;A</p> <ul> <li> <p>Q: What is the ratio between IO node to compute nodes on Lumi?</p> <ul> <li>What do you mean by IO node?</li> <li>IO nodes is probably not the right terminologiy here indeed. I used the terminology from the decommissioned BGQ system.</li> <li>I/O node == some node that is only used for I/O transfers???</li> <li>A: don't think that there are such special nodes on LUMI-C, however some other partition, for example,      LUMI-K (?) might be used (don't know if these partitions have better network connections for I/O)</li> <li>A: The I/O servers on one of the slides where it said that you only do I/O from some processes are      not hardware I/O servers, but your processes of which some take care of the I/O. Is that the source of the confusion?</li> <li>Probably. If I request a collective IO with MPIIO, which fraction of my processes will then be in charge of communicating with the file server?</li> <li>A: maybe depends on the implementation of MPI-IO (and stripe_size, stripe_count) --&gt; in other words: \"don't know\"</li> </ul> </li> <li> <p>Q: What is the optimize number of files per compute nodes for MPIIO?</p> <ul> <li>A: maybe one file per process? </li> <li>Q2: This would overflow the meta data server if for instance 100 000 processes write 100 000 files at      the same time. The other extreme would be 100 000 files wrting collectively in one single shared file. Is there an optimum where a subset of processes would write to their own share file?</li> <li>A: probably there is an optimum, but difficult to provide one answer to all possible scenarios</li> </ul> </li> <li> <p>Q: It seems there is no metadata striping: <code>lfs getdirstripe .</code> gives <code>lmv_stripe_count: 0 lmv_stripe_offset: 0 lmv_hash_type: none</code>      Is this a deliberate choice? How do you ensure load balancing across MDTs? I see generally MDT0000 already is used more than MDT0001.</p> <ul> <li>A: second MDT seems to be there for redundancy only</li> </ul> </li> <li> <p>Q: What is performance for writing small files to MDTs (https://doc.lustre.org/lustre_manual.xhtml#dataonmdt)?</p> <ul> <li>A: It is probably a non-issue on LUMI as the file policies are such that the use of small files is strongly      discouraged due to bad experiences on other CSC systems. You will be forced to use different strategies than putting      10M small files on the system.</li> </ul> </li> <li> <p>Q: Do you use PFL (Progressive File Layouts - https://doc.lustre.org/lustre_manual.xhtml#pfl)? If so when do you recomend it?</p> <ul> <li>A: With <code>lfs getstripe -d .</code> you can see the current settings; I see <code>stripe_count=1</code> and no PFL.</li> <li>A: (Harvey) I don't have the answer but we can ask about this. I would expect some delay in any case      for features to be enabled in the Lustre that HPE provides even if they have been available for some time.</li> <li>A: I tried <code>lfs setstripe -E 4M -c 1 -E 64M -c 4 -E -1 -c -1 -i 4 /my/dir</code> and it seems to work.      So I think PFLs are possible, but the default striping settings do not use it.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1445-break-30-minutes","title":"14:45  break (30 minutes)","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1515-additional-software-on-lumi-c","title":"15:15   Additional software on LUMI-C","text":"<p>Session info:</p> <ul> <li>Software stacks and policies</li> <li>Advanced Lmod use</li> <li>Installing software with EasyBuild (concepts, contributed recipes)</li> <li>Containers for Python, R, VNC (container wrappers)</li> </ul> <p>Q&amp;A</p> <ul> <li>Q: Are the EasyBlocks adapted for LUMI? Do you expect users will need to modify those as well?<ul> <li>A1: some easyblocks have been adapted for LUMI, see https://github.com/Lumi-supercomputer/LUMI-SoftwareStack/tree/main/easybuild/easyblocks </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1615-lumi-documentation-how-to-get-help-how-to-write-good-support-requests","title":"16:15   LUMI documentation, how to get help, how to write good support requests","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1620-what-are-typicalfrequent-support-questions-of-users-on-lumi-c","title":"16:20   What are typical/frequent support questions of users on LUMI-C?","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#1635-open-questions-answers-participants-are-encouraged-to-continue-with-exercises-in-case-there-should-be-no-questions","title":"16:35   Open Questions &amp; Answers (participants are encouraged to continue with exercises in case there should be no questions)","text":"<p>Q&amp;A</p> <ul> <li> <p>Q: Would LUST be interested in EB recipes contributed from users?</p> <ul> <li>A: definitely yes</li> </ul> </li> <li> <p>Q: Will mail server for slurm be installed on LUMI? so, when the calculation finish will notify by email (#SBATCH --mail-type=END)</p> <ul> <li>A: need to ask system admins</li> </ul> </li> <li> <p>Q: A question about the material from yesterday: When is it safe to use the mixed compiler modules and when it is not?      I would expect it to be safe for C, but can see problems combining C++ code from different compilers      (name mangling issues?) or Fortran code. Can you give any advice?</p> <ul> <li>A: The real use case here is that you normally have a programming environment loaded and are using the wrappers      but want to use another compiler to build something directly without the wrappers, typically PrgEnv-cray for the      former and a newer-than-system gcc for the latter. For example you might want to build cmake with gcc but don't      need to swap the whole environemnt to gnu and use the wrappers.</li> </ul> </li> <li> <p>Q: Any plans for LUMI Users Group or something similar?</p> <ul> <li>A: Exchange of solutions, experiences, etc. I was thinking online.</li> </ul> </li> <li> <p>Q: Quick question: to compile a code which targets Lumi-C, I suppose the modules <code>LUMI/21.08 partition/C</code> should be the right ones</p> <ul> <li>A: yes, but better start using <code>LUMI/21.12</code></li> </ul> </li> <li> <p>Q: In my experience, EasyBuild is not necessarily the best tool to fix compilation problems.      Do you have tips for when an existing easyblock does not work on LUMI? For example try a manual build first,      and afterwards add it to EasyBuild for reproducibility?</p> <ul> <li>A: (Answered in person)</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/hackmd_notes/#1700-end-of-second-course-day","title":"17:00  End of second course day","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#any-other-notes","title":"Any other notes","text":""},{"location":"PEAP-Q-20220427/hackmd_notes/#course-page","title":"Course page","text":"<p>https://www.lumi-supercomputer.eu/events/detailed-introduction-to-lumi-c-april-2022/</p>"},{"location":"PEAP-Q-20220427/hackmd_notes/#misc","title":"Misc","text":"<p>Download the LUST slides</p>"},{"location":"PEAP-Q-20220427/hackmd_notes/#questions","title":"Questions","text":"<ul> <li> <p>Q: How to get login to LUMI? (for users with a Finnish allocation)</p> <ul> <li>A: See https://www.lumi-supercomputer.eu/get-started-2021/users-in-finland/ </li> </ul> </li> <li> <p>Q: I have registerd my public key to mycsc.fi page few days back, but I still not recived the username.      Can I use my csc username (the one i use for puhti and mahti) to get login into lumi?</p> <ul> <li>A: Best option is to send a support request for this. If you let us know the username for puhti/mahti      we might check if it is created on LUMI already.</li> </ul> </li> </ul>"},{"location":"PEAP-Q-20220427/software_stacks/","title":"LUMI Software Stacks","text":"<p>In this part of the training, we cover:</p> <ul> <li>Software stacks on LUMI, where we discuss the organisation of the software stacks     that we offer and some of the policies surrounding it</li> <li>Advanced Lmod use to make the best out of the software stacks</li> <li>Creating your customised environment with EasyBuild, the tool that we use to install     most software.</li> </ul>"},{"location":"PEAP-Q-20220427/software_stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"PEAP-Q-20220427/software_stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: a fully cache-coherent unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in the Apple M1 but then without the NUMA character.</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a recent talk in an     EasyBuild user meeting.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"PEAP-Q-20220427/software_stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparant way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be acustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an increasing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place. We do offer some help so set up Spack also but activating Spack for installation is your project directory is not yet automated.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionaire send out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The final LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, so any software compiled with an MPI library that     requires UCX, or any other distributed memory model build on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intro-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-bus comes to mind.</li> </ul> <p>Also, the LUNI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that I did not yet mention is that software that accesses hundreds of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. The link to the documentation of the tool that we call lumi-container-wrapper but may by some from CSC also be known as Tykky is in the handout of the slides that you can get after the course.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using the that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 4 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes, zen 2 combined with NVIDIA GPUs for the visualisation nodes and zen3 + MI250X for the LUMI-G partition. There is also some support for the early access platform which has zen2 CPUs combined with MI100 GPUs but we don't pre-install software in there at the moment except for some build tools and some necessary tools for ROCm as these nodes are not meant to run codes on and as due to installation  restrictions we cannot yet use the GPU compilers with EasyBuild the way we should do that on the final system.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"PEAP-Q-20220427/software_stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It ia also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. E.g., the <code>PRgEnv-aocc/21.12</code> module can successfully use the <code>aocc/3.1.0</code> compilers.</p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/21.08 and LUMI/21.12 modules. Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules. There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes, partition/EAP for the early access platform and in the future we will have partition/D for the visualisation nodes and partition/G for the AMD GPU nodes.</p> <p>There is also a hidden partition/common module in which we install software that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#lmod-on-lumi","title":"Lmod on LUMI","text":""},{"location":"PEAP-Q-20220427/software_stacks/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the few modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"PEAP-Q-20220427/software_stacks/#module-spider-command","title":"Module spider command","text":"<p>Demo moment 1</p> <p></p> <p>(The content of this slide is really meant to be shown in practice on a command line.)</p> <p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive. Let's try for instance <code>module spider gnuplot</code>. This     will show 5 versions of GNUplot. There are two installations of GNUplot 5.4.2 and three of 5.4.3. The      remainder of the name shows us with what compilers gnuplot was compiled. The reason to have      versions for two or three compilers is that no two compiler modules can be loaded simultaneously,     and this offers a solution to use multiple tools without having to rebuild your environment for     every tool, and hence also to combine tools. </p> <p>Now try <code>module spider CMake</code>. We see that there are two versions, 3.21.2 and 3.22.2, but now they are shown in blue with an \"E\" behind the name. That is because there is no module called <code>CMake</code> on LUMI. Instead the tool is provided by another module that in this case contains a collection of popular build tools and that we will discover shortly.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module. Try for instance     <code>module spider gnuplot/5.4.3-cpeGNU-21.12</code>. This will now show full help information for     the specific module, including what should be done to make the module available. For      this GNUplot module we see that there are two ways to load the module: By loading <code>LUMI/21.12</code>      combined with <code>partition/C</code> or by loading <code>LUMI/21.12</code> combined with <code>partition/L</code>. So use only     a single line, but chose it in function of the other modules that you will also need. In this case     it means that that version of GNUplot is available in the <code>LUMI/21.12</code> stack which we could already     have guessed from its name, with binaries for the login and large memory nodes and the LUMI-C compute     partition. This does however not always work with the Cray Programming Environment modules.</p> <p>We can also use <code>module spider</code> with the name and version of an extension. So try <code>module spider CMake/3.22.2</code>. This will now show us that this tool is in the <code>buildtools/21.12</code> module and give us 6 different options to load that module as it is provided in the <code>CrayEnv</code> and the <code>LUMI/211.12</code> software stacks and for all partitions (basically because we don't do processor-specific optimisations for these tools).</p> </li> </ol>"},{"location":"PEAP-Q-20220427/software_stacks/#module-keyword-command","title":"Module keyword command","text":"<p><code>module keyword</code> will search for a module using a keyword but it is currently not very useful on LUMI because of a bug in the current version of Cray Lmod which is solved in the more recent versions. Currently the output contains a lot of irrelevant modules, basically all extensions of modules on the system.</p> <p>What <code>module keyword</code> really does is search in the module description and help for the word that  you give as an argument. Try for instance <code>module keyword https</code> and you'll see two relevant tools, <code>cURL</code> and <code>wget</code>, two tools that can be used to download files to LUMI via several protocols in use on the internet.</p> <p>On LUMI we do try to put enough information in the module files to make this a suitable additional way to discover software that is already installed on the system, more so than in regular EasyBuild installations.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#sticky-modules-and-module-purge","title":"Sticky modules and module purge","text":"<p>You may have been taught that <code>module purge</code> is a command that unloads all modules and on some systems they might tell you in trainings not to use it because it may also remove some basic  modules that you need to use the system. On LUMI for instance there is an <code>init-lumi</code> module that does some of the setup of the module system and should be reloaded after a normal <code>module purge</code>. On Cray systems <code>module purge</code> will also unload the target modules while those are typically not loaded by the <code>PrgEnv</code> modules so you'd need to reload them by hand before the <code>PrgEnv</code> modules would work.</p> <p>Lmod however does have the concept of \"sticky modules\". These are not unloaded by <code>module purge</code> but are re-loaded, so unloaded and almost immediately loaded again, though you can always force-unload them with <code>module --force purge</code> or <code>module --force unload</code> for individual modules.</p> <p>The sticky property has to be declared in the module file so we cannot add it to for instance the Cray Programming Environment target modules, but we can and do use it in some modules that we control ourselves. We use it on LUMI for the software stacks themselves and for the modules that set the display style of the modules. </p> <ul> <li>In the <code>CrayEnv</code> environment, <code>module purge</code> will clear the target     modules also but as <code>CrayEnv</code> is not just left untouched but reloaded instead, the load of <code>CrayEnv</code>     will load a suitable set of target modules for the node you're on again. But any customisations that     you did for cross-compiling will be lost. </li> <li>Similary in the LUMI stacks, as the <code>LUMI</code> module itself     is reloaded, it will also reload a partition module. However, that partition module might not be the      one that you had loaded but it will be the one that the LUMI module deems the best for the node you're     on, and you may see some confusing messages that look like an error message but are not.</li> </ul>"},{"location":"PEAP-Q-20220427/software_stacks/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed already that by default you don't see the directories in which the module files reside as is the case on many other clusters. Instead we try to show labels that tell you what that group of modules actually is. And sometimes this also combines modules from multiple directories that have the same purpose. For instance, in the default view we collapse all modules from the Cray Programming Environment in two categories, the target modules and other programming environment modules. But you can customise this by loading one of the <code>ModuleLabel</code> modules. One version, the <code>label</code> version, is the default view. But we also have <code>PEhierarchy</code> which  still provides descriptive texts but unfolds the whole hierarchy in the Cray Programming  Environment. And the third style is calle <code>system</code> which shows you again the module directories.</p> <p>We're also very much aware that the default colour view is not good for everybody. So far I don't know an easy way to provide various colour schemes as one that is OK for people who like a black  background on their monitor might not be OK for people who prefer a white background. But it is possible to turn colour off alltogether by loading the <code>ModuleColour/off</code> module, and you can always turn it on again with <code>ModuleColour/on</code>.</p> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment. For instance, when working in the <code>LUMI/21.12</code> stack we prefer that users use the Cray programming environment modules that come with release 21.12 of that environment, and cannot guarantee compatibility of other modules with already installed software, so we hide the other ones from view. You can still load them if you know they exist but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work or to use any module that was designed for us to maintain the system.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"PEAP-Q-20220427/software_stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system. We expect this to happen especially with packages that  require specific MPI versions. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And we need a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is our primary software installation tool. We selected this as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the build-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain we would have problems with MPI. EasyBuild there uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     or the Intel compiler will simply optimize for a two decades old CPU.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system.  We're also working on presenting a list of supported software in the documentation.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.bash_profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p> <p>Once that environment variable is set, all you need to do to activate EasyBuild is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition.  Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#step-2-install-the-software","title":"Step 2: Install the software.","text":"<p>Demo moment 2</p> <p></p> <p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS we already have support. At the moment we have to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre> This process is not optimal and will be improved in the future. We are developing a system that will instead give an overview of available EasyBuild recipes on the documentation web site.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/21.12</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS we do expect that GPU builds for LUMI will become available early on in the deployment of LUMI-G so we've already added a so-called version suffix to distinguish between CPU and GPU versions. To install it, we first run  <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The search for dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb \u2013r GROMACS-2021.4-cpeCray-21.12-PLUMED-2.8.0-CPU.eb\n</code></pre></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p> <p>End of demo moment 2</p>"},{"location":"PEAP-Q-20220427/software_stacks/#step-2-install-the-software-note","title":"Step 2: Install the software - Note","text":"<p>There is a little problem though that you may run into. Sometimes the module does not show up immediately. This is because Lmod keeps a cache when it feels that Lmod searches become too slow and often fails to detect that the cache is outdated. The easy solution is then to simply remove the cache which is in <code>$HOME/.lmod.d/.cache</code>,  which you can do with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> And we have seen some very rare cases where even that did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb -r . my_recipe.eb\n</code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb \u2013r . VASP-6.3.0-cpeGNU-21.12.eb\n</code></pre></p>"},{"location":"PEAP-Q-20220427/software_stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greates before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/easybuild/easyconfigs</code>.</p>"},{"location":"PEAP-Q-20220427/software_stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory, and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software.</p> <p>Moreover, EasyBuild also keeps copies of all installed easconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is also a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"PEAP-Q-20220427/software_stacks/#easybuild-training-for-support-team-members","title":"EasyBuild training for support team members","text":"<p>Since there were a lot of registrations from local support team members, I want to dedicate one slide to them also.</p> <p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>Lastly we are organising a training for CSC staff also open to other local support organisations on May 9 and 11, from 12:30 to 15:30 CEST. Notes from that training will likely also become available on the EasyBuilders training web site, or we will post them via a separate GitHub pages web site or so. If you want to join, contact LUMI support.</p>"},{"location":"PEAP-Q-20221123/","title":"Detailed introduction to the LUMI-C environment and architecture (November 23/24, 2022)","text":""},{"location":"PEAP-Q-20221123/#during-the-course","title":"During the course","text":"<ul> <li>Course schedule</li> <li>HedgeDoc collaborative document for questions</li> <li>Where to eat?</li> </ul>"},{"location":"PEAP-Q-20221123/#course-materials","title":"Course materials","text":"<p>Resources in italics on the list below are only available on LUMI and not via web download.</p> Presentation title slides notes recording Introduction slides / recording HPE Cray EX Architecture slides / recording Programming Environment and Modules slides / recording Running Applications slides / recording Compilers and Libraries slides / recording Advanced Placement slides / recording Introduction to Perftools slides / recording Advanced Performance Analysis part 1 slides / recording Advanced Performance Analysis part 2 slides / recording Debugging at Scale slides / recording MPI Topics on the HPE Cray EX Supercomputer slides / recording Optimizing Large Scale I/O slides / recording LUMI Software Stacks slides notes recording LUMI User Support slides / recording Day 2 General Q&amp;A / / /"},{"location":"PEAP-Q-20221123/demo_software_stacks_mdp/","title":"Demo software stacks mdp","text":"<p>%title: LUMI Software Stacks (demos) %author: Kurt Lust %date: 2022-11-24</p> <p>-&gt; # module spider &lt;-</p> <pre><code>module spider\n</code></pre> <ul> <li>Long list of all installed software with short description<ul> <li>Will also look into modules for \u201cextensions\u201d and show those   also, marked with an \\\u201cE\\\u201d</li> </ul> </li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the (suspected) name of a package</li> </ul> <pre><code>module spider gnuplot\n</code></pre> <ul> <li>Shows all versions of gnuplot on the system</li> <li>Case-insensitive</li> </ul> <pre><code>module spider GNUplot\n</code></pre> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the (suspected) name of a package</li> </ul> <pre><code>module spider cmake\n</code></pre> <ul> <li><code>CMake</code> turns out to be an extension but <code>module spider</code>   still manages to tell which versions exist.</li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the full module name of a package</li> </ul> <pre><code>module spider gnuplot/5.4.3-cpeGNU-22.08 \n</code></pre> <ul> <li>Shows help information for the specific module, including    what should be done to make the module available</li> <li>But this does not completely work with the Cray PE modules</li> </ul> <p>-&gt; # module spider &lt;-</p> <ul> <li>With the name and version of an extension</li> </ul> <pre><code>module spider CMake/3.24.0 \n</code></pre> <ul> <li>Will tell you which module contains CMake and how to load   it</li> </ul> <pre><code>module spider buildtools/21.08\n</code></pre> <p>-&gt; # module keyword &lt;-</p> <ul> <li>Currently not yet very useful due to a bug in Cray Lmod</li> <li>It searches in the module short description and help for    the keyword.</li> </ul> <pre><code>module keyword https\n</code></pre> <ul> <li>We do try to put enough information in the modules to make   this a suitable additional way to discover software that is   already installed on the system</li> </ul> <p>-&gt; # sticky modules and module purge &lt;-</p> <ul> <li>On some systems, you will be taught to avoid module purge   (which unloads all modules)</li> <li>Sticky modules are modules that are not unloaded by    <code>module purge</code>, but reloaded.<ul> <li>They can be force-unloaded with <code>module \u2013-force purge</code>   and <code>module \u2013-force unload</code></li> </ul> </li> </ul> <pre><code>module list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <ul> <li>Used on LUMI for the software stacks and modules that set    the display style of the modules<ul> <li>But keep in mind that the modules are reloaded, which    implies that the target modules and partition module    will be switched (back) to those for the current node.</li> </ul> </li> </ul> <pre><code>module load init-lumi\nmodule list\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>You may have noticed that you don\u2019t see directories in the    module view but descriptive texts</li> <li>This can be changed by loading a module<ul> <li><code>ModuleLabel/label</code>: The default view</li> <li><code>ModuleLabel/PEhierarchy</code>: Descriptive texts, but the    PE hierarchy is unfolded</li> <li><code>ModuleLabel/system</code>: Module directories</li> </ul> </li> </ul> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>Turn colour on or off using ModuleColour/on or    ModuleColour/off</li> </ul> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>-&gt; # Changing the module list display &lt;-</p> <ul> <li>Show some hidden modules with ModulePowerUser/LUMI   This will also show undocumented/unsupported modules!</li> </ul> <pre><code>module load LUMI/22.08\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <ul> <li>Note that we see a lot more Cray PE modules with   ModulePowerUser!</li> </ul> <p>-&gt; # Demo moment 2 &lt;-</p> <p>-&gt; # Install GROMACS &lt;-</p> <ul> <li>Search for a GROMACS build recipe</li> </ul> <pre><code>module load LUMI/22.08 partition/C EasyBuild-user\neb --search GROMACS\neb -S GROMACS\n</code></pre> <ul> <li>Let\u2019s take <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code></li> </ul> <pre><code>eb -r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb -D\neb -r GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb\n</code></pre> <ul> <li>Now the module should be available</li> </ul> <pre><code>module avail GROMACS\n</code></pre>"},{"location":"PEAP-Q-20221123/extra_00_Introduction/","title":"Welcome and introduction","text":"<p>Presenters: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li> <p>Slides (PDF)</p> <p>Also on LUMI in <code>/appl/local/training/peap-q-20221123/files/00_LUST_Course_intro.pdf</code>.</p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_00_Introduction/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Do you know the current allocation per country ? (I wonder how much Belgium contributes to LUMI)</p> <ul> <li>Belgium: 7.4% of the total budget.</li> <li>Information about how to contact the Belgian team is https://www.enccb.be/LUMI</li> </ul> </li> <li> <p>What do you mean the training project? like ssh to lumi? or the puhuri portal?</p> <ul> <li>Yes, there is a small allocation on LUMI associated with the course (i.e. yo can log in with SSH and run jobs). We send out an email on Monday with the puhuri link to join the training project. This is a different project from the one you may have from a project from EuroHPC or your national allocation. Please use this project only for the exercises, not to run your own code or we will run out of our allocation for the course.</li> <li>The information on how to join was sent out a few days before the course. We will mention the project number and slurm reservation before we start the exercises.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_01_HPE_Cray_EX_Architecture/","title":"HPE Cray EX Architecture","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/01_EX_Architecture.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/01_EX_Architecture.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_01_HPE_Cray_EX_Architecture/#qa","title":"Q&amp;A","text":"<ol> <li> <p>What's the expected CPU clock for a heavy all-core job?</p> <ul> <li>2.45 GHz base clock rate (https://www.amd.com/en/product/10906)</li> <li>Don't expect any boost for a really heavy load. The effective clock is determined dynamically by the system depending on the heating/cooling situation. It can be complex, because heavy network/MPI traffic will also affect this, and the node tries to distribute power between the CPU cores, the IO die on the CPU, (the GPUs for LUMI-G), and the network cards on-the-fly to optimize for the best performance.</li> </ul> </li> <li> <p>Regarding the CPU cores and threads : you said that the threads are hardware : should we run large runs on the number of threads, rather than the number of nodes ?</p> <ul> <li>Could you elaborate a bit more? </li> <li>My understanding is : a cpu that has 64 cores, shows 128 threads by multithreading, therefore cases that use the cpu 100% load during 100% of the time will be better tu run on 64 core, rather than the 128 threads to eliminate the overhead of the operating system due to scheduling the software threads to the hardware core.</li> <li>There are two sessions about SLURM in the course where it will be explained how to use hyperthreading etc. </li> <li>In general, hyperthreading doesn't offer much benefits on a good code, rather the contrary. It's really more lack of cache and memory bandwidth stat stops you from using hyperthreading. Hyperthreading is basically a way to hide latency in very branchy code such as databases. In fact there are codes that run faster using a given number of nodes and 75% of the cores than the same number of nodes and all cores per socket, without hyperthreading.</li> <li>OK I will wait for the next parts of the course. Thank you</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_02_Programming_Environment_and_Modules/","title":"Programming Environment and Modules","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/02_PE_and_Modules.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/02_PE_and_Modules.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_02_Programming_Environment_and_Modules/#qa","title":"Q&amp;A","text":"<ol> <li> <p>At the ExaFoam summer school I was told that HDF5 parallel I/O does not scale to exa scale applications. Ist that correct Instead the exafoam project is working on an ADIOS-2 based system for parallel I/O in OpenFOAM. Feel free to answer this question at the most appropriate time in the course</p> <ul> <li>This is the current understanding, so I would say \"yes\" (even if I'm not a 100% expert).</li> <li>The HDF5 group had a BOF at SC22 about their future plans</li> <li>I would not rule out HDF5 parallel I/O at large scale on LUMI-C for runs of say 500 nodes or similar. The best approach would be to try to benchmark it first for your particular use case.</li> <li>It depends on what you would exactly need to do. If you need to write to file, I am not sure there are real alternatives. ADIOS would be great for in-situ processing.</li> <li>[Harvey] I have heard of some good experience about ADIOS-2 but have not tried it yet myself, on my list of things to do.</li> <li>One of the engines that ADIOS-2 can use is HDF5 so it is not necessarily more scalable. Just as for HDF5, it will depend much on how it is used and tuned for the particular simulation.</li> </ul> </li> <li> <p>Will there be, for the exercises, shown on-screen (in the zoom session) terminal session which will show how to use all the commands, how to successfully complete the exercises, or will we be void of visual guide and will we only have to rely on the voice of the person presenting the exercises? What I mean - can we please have the presenter show interactively the commands and their usage and output?</p> <ul> <li>You can find exercises at <code>/project/project_465000297/exercises/</code> with Readme's. You can copy the directory in your area. Just follow them and let us know if you have questions. We will cover it during the next sessions.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_03_Running_Applications_Slurm/","title":"Running Applications","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/03_Running_Applications_Slurm.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/03_Running_Applications_Slurm.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_03_Running_Applications_Slurm/#qa","title":"Q&amp;A","text":"<ol> <li> <p>I would like to know whether it is possible to run FEM simulation software (e.g., COMSOL Multiphysics) on LUMI?</p> <ul> <li>As long as it is installed correctly then I see no reason why not. It has been run on other Cray EX systems. The only complication here will be the commerical license.  LUMI does not have its own license, you would have to provide your own. There might be some complications right now, because the compute nodes do not have internet access, which would block access to the license server. We hope that internet access will be enabled on the compute nodes soon.</li> </ul> </li> <li> <p>Is it something like MC (Midnight Commander) installed?</p> </li> <li>No, and midnight commander specifically has some annoying dependencies so it will not come quickly in a way that integrates properly with all the other software on LUMI.</li> <li>You can see your files and transfer to and from LUMI using tools like filezilla and the host <code>sftp://lumi.csc.fi</code></li> <li>And for people on a connection with sufficiently low latency Visual Studio Code also works. The client-server connection seems to fail easily though on connections with a higher latency. It is also more for editing remotely in a user friendly way than browsing files or running commands. But we do understand that mc is awesome for some people.</li> <li>In the future there will also be an Open OnDemand interface to LUMI.</li> <li> <p>MC is ok but Krusader is better</p> </li> <li> <p>and WinSCP?</p> <ul> <li>That is client software to run on your PC. It should work. </li> <li>In general, until we have Open OnDemand, the support for running GUI software on LUMI is very limited. And after that it will not be brilliant either, as an interface such as GNOME is not ideal to run on multiuser login nodes due to the resources it needs but also due to how it works internally.</li> </ul> </li> <li> <p>Would it be alright to test the building of licensed software such as VASP during the course and the EasyBuild system you have in place? (and benchmark with very small test run of course)</p> <ul> <li>Please don't run benchmarks of your own software on the project account. If you already have another project, use that one instead.</li> <li>You can install and run VASP but need to bring your own license file. See also here or the future page in the LUMI Software Library.</li> </ul> </li> </ol> <p>Exercise</p> <p>Exercises are available at <code>/project/project_465000297/exercises/ProgrammingModels/</code> Copy the files to your home folder before unpacking them.</p>"},{"location":"PEAP-Q-20221123/extra_03_Running_Applications_Slurm/#exercises","title":"Exercises","text":"<p>A tar file with exercises is available as <code>/appl/local/training/peap-q-20221123/files/exercises-1day-20221123.tar.gz</code>. </p>"},{"location":"PEAP-Q-20221123/extra_04_Compilers_and_Libraries/","title":"Compilers and Libraries","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/04_Compilers_and_Libraries.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/04_Compilers_and_Libraries.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_04_Compilers_and_Libraries/#qa","title":"Q&amp;A","text":"<ol> <li> <p>By default the libraries are shared (dynamic), so isn't it good practice to but the compiling part of the application in the slurm script job ?</p> <ul> <li>In general, no. The libraries on the system will not change that often, only after service breaks / upgrades of the Cray Programming Environment. It would also be inefficient to compile using compute node allocation if you have e.g. a wide parallel job with 100 compute nodes.</li> <li>You must also consider that it uses your allocated resources (from your project)</li> </ul> </li> <li> <p>Question about the cray fortran compiler: I've been trying to use it now on some private code, and it crashes when it encounters preprocesseor statements like <code>#ifdef</code> which gfortran is happy about. Is this expected? Is there a way to handle this?</p> <ul> <li>What error does the compiler give?<ul> <li><code>ftn-100: This statement must begin with a label, a keyword or identifier</code>, so it just seems to take the statement literally</li> </ul> </li> <li>Did you use the right filename extension to activate the preprocessor or the -ep/-ez options shown in the presentation?</li> <li>That is probably the problem, I think I missed that comment, I will go back to the slides to look</li> <li>After loading PrgEnv-cray you can also get extensive help about all the command line options using man crayftn</li> <li>Source file extension needs to start with F and not f to automatically trigger the preprocessor.</li> <li>The other cause might be that sometimes there are subtle differences between wat a C and Fortran preprocessor allows but I believe there is an option for that also. I remember having such a ticket long ago.</li> <li>Thanks, the filename was actually the problem, I wasn't expecting that</li> <li>I may have another advice, just in case: the CCE produces modules with capital letters names (FOO.mod), you can use <code>-emf</code> to get lowercase (like gfortran).</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_04_Compilers_and_Libraries/#exercises","title":"Exercises","text":"<p>A tar file with exercises is available as <code>/appl/local/training/peap-q-20221123/files/exercises-1day-20221123.tar.gz</code>. </p> <p>Try the compiler exercises in <code>perftools/compiler_listings</code> and try recompiling the exercises from earlier. You don't need to run any jobs.</p>"},{"location":"PEAP-Q-20221123/extra_05_Advanced_Placement/","title":"Advanced Placement","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/05_Advanced_Placement.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/05_Advanced_Placement.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_05_Advanced_Placement/#qa","title":"Q&amp;A","text":"<ol> <li>I have a question regarding <code>srun</code>: does it forward options to the underlying MPI implementation? with OpenMPI you can get a report of the binding using \u2014report-bindings <ul> <li>Yes, it forwards the options to pmi</li> <li>It is possible to get a report and we will mention tomorrow how to do that. But it can be done by option or environmental variable.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_05_Advanced_Placement/#exercises","title":"Exercises","text":"<p>A tar file with exercises is available as <code>/appl/local/training/peap-q-20221123/files/exercises-1day-20221123.tar.gz</code>. </p> <p>Try the exercides in the <code>Binding</code> subdirectory.</p>"},{"location":"PEAP-Q-20221123/extra_06_introduction_to_perftools/","title":"Introduction to Perftools","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/06_introduction_to_perftools.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/06_introduction_to_perftools.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_06_introduction_to_perftools/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Can <code>perftools-lite</code> also be used with the gcc compilers?</p> <ul> <li>yes, there is support for all the compilers offered on the machine. </li> <li>the 'loops' variant only works with CCE as it needs extra information from the compiler.</li> </ul> </li> <li> <p>Can <code>perftools</code> also output per-MPI-rank timings or only (as shown in the presentation) averaged over all processes?</p> <pre><code>* you can get per rank timings in the text output with appropriate options to pat_reoprt. Conversely, you can have a look at apprentice2 which has a nice way of showing per-rank timings.\n</code></pre> <ul> <li>there is an option pe=ALL that will show timings per rank/PE</li> </ul> </li> <li> <p>The output of the statistics will tell you the name of the subroutine, line number, will it also tell you the name of the file where this is from ?</p> <ul> <li>with the <code>-O ca+src</code> option to <code>pat_report</code> you can get the source information.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_06_introduction_to_perftools/#exercises","title":"Exercises","text":"<p>The exercises for this session are in the <code>perftools/perftools-lite</code> subdirectory.</p> <p>Apprentice2 and Reveal downloads</p> <p>With <code>perftools-base</code> loaded (and it is loaded by default), you can also find the Apprentice2 downloads in <code>$CRAYPAT_ROOT/share/desktop_installers</code> or  <code>$CRAY_PERFTOOLS_PREFIX/share/desktop_installers</code>. Copy them to your local machine and install them there.</p>"},{"location":"PEAP-Q-20221123/extra_07_advanced_performance_analysis_part1/","title":"Advanced Performance Analysis part 1","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/07_advanced_performance_analysis_part1.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/07_advanced_performance_analysis_part1.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_07_advanced_performance_analysis_part1/#qa","title":"Q&amp;A","text":"<ol> <li> <p>I downloaded and installed \"Apprentice2\" under Windows. Even if I am able to connect to LUMI via SSH, I am not able to open a remote folder with Apprentice2 (connection failed). Is it something special to configure (I added the ssh keys to pageagent and also added a LUMI section in my ~/.ssh/config)?</p> <ul> <li>I think you will have to copy the files to the laptop as Windows has no concept of a generic ssh setup for a user as far as I know.</li> <li>Kurt I'd have to check when I can get access to a Windows machine (as my work machine is macOS), but Windows 10 and 11 come with OpenSSH and can use a regular config file in the .ssh subdirectory. And that could allow to define an alias with a parameter that points to the keu file. Windows 10 and 11 also have a built-in ssh agent equivalent that Windows Open?SSH can use. </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_08_advanced_performance_analysis_part2/","title":"Advanced Performance Analysis part 2","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/08_advanced_performance_analysis_part2.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/08_advanced_performance_analysis_part2.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_08_advanced_performance_analysis_part2/#qa","title":"Q&amp;A","text":"<ol> <li> <p>If perftools runs on CLE/Mac/windows where can we get it/ find install instructions? </p> <ul> <li>Only apprentice2 and reveal are available as clients on mac/windows (basically the user interface components to interpret the collected data). These should be self-installing executables. Like <code>*.dmg</code> on a MAC.</li> <li>You can download the apprentice install files from LUMI (look at the info box above question 23)</li> </ul> </li> <li> <p>I managed to install apprentice2 on my MAC. How can I connect to Lumi? I need to provide a password, but when connecting to Lumi via the terminal I just pass the local ssh key...</p> <ul> <li>There is no password access enabled, you have to setup ssh in a way that it is being picked up by apprentice</li> <li>It should work if you have a ssh config file with the hostname, username and identity file for lumi. Can you connect to lumi with just <code>ssh lumi</code>?<ul> <li>Yes, I can connect to lumi with just <code>ssh lumi</code>. However: apprentice2, open remote with host <code>username@lumi.csc.fi</code> prompts for a password</li> </ul> </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_08_advanced_performance_analysis_part2/#exercises","title":"Exercises","text":"<p>The exercises are in the <code>perftools</code> subdirectory.</p>"},{"location":"PEAP-Q-20221123/extra_09_debugging_at_scale/","title":"Debugging at Scale","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/09_debugging_at_scale.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/09_debugging_at_scale.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_09_debugging_at_scale/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"PEAP-Q-20221123/extra_11_cray_mpi_MPMD_short/","title":"MPI Topics on the HPE Cray EX Supercomputer","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/11_cray_mpi_MPMD_short.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/11_cray_mpi_MPMD_short.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_11_cray_mpi_MPMD_short/#qa","title":"Q&amp;A","text":"<p>/</p>"},{"location":"PEAP-Q-20221123/extra_12_IO_short_LUMI/","title":"Optimizing Large Scale I/O","text":"<ul> <li> <p>Slide file in  <code>/appl/local/training/peap-q-20221123/files/12_IO_short_LUMI.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/peap-q-20221123/recordings/12_IO_short_LUMI.mp4</code></p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_12_IO_short_LUMI/#qa","title":"Q&amp;A","text":"<ol> <li> <p>You mentioned that you are using a RAID array to have redundancy of storage (and I read RAID-6 in the slides), have you considered using the ZFS file system ? I don't know too much, but i read it could be more reliable and better performance.</p> <ul> <li>in ZFS you also chose a RAID level. I'm not sure what is used on LUMI, and it might be different for metadata and the storage targets. You will not solve the metadata problem with ZFS though. I know H?PE supports two backend file systems for Lustre but I'm not sure which one is used on LUMI.</li> </ul> </li> <li> <p>This is really a question about the earlier session on performance tools, but I hope it's still OK to post it: I've tried using <code>perftools-lite</code>on my own code, but doing so it does not compile (it does without the modules). The linking seems to fail with      <code>WARNING: cannot acquire file status information for '-L/usr/lib64/libdl.so' [No such file or directory]</code>     Is this something that has been seen before? Any tips/hints on what is going on?</p> <ul> <li>without checking the code is hard to understand what it the problem. Do you really link with libdl.so in your compilation?</li> <li>Yes, doing ldd on a successful compile gives <code>libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f228c3b0000)</code> The other dl library symlinks to that one.</li> <li>OK, the question is the line <code>-L/usr/lib64/libdl.so</code>, I wonder if you are using somewhere in the makefile</li> <li>Yes, this is a large cmake set-up though, but cmake has <code>CMakeCache.txt:LIBDL_LIBRARY:FILEPATH=/usr/lib64/libdl.so</code></li> <li>Then we are hitting a situation where perftools-lite doesn't work... Try perftools, restricting to <code>-g</code></li> <li>OK, thanks! Will try that.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_13_LUMI_Software_Stacks/","title":"Additional software on LUMI","text":"<p>Presenter: Kurt Lust (LUST)</p> <p>Additional materials</p> <ul> <li> <p>Slides (PDF)</p> <p>Also on LUMI in <code>/appl/local/training/peap-q-20221123/files/13_LUST_LUMI_Software.pdf</code>.</p> </li> <li> <p>Notes</p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_13_LUMI_Software_Stacks/#qa","title":"Q&amp;A","text":"<ol> <li> <p><code>Error: ~/exercises/VH1-io/VH1-io/run&gt; sbatch run_vh1-io.slurm sbatch: error: Invalid directive found in batch script: e.g</code> Do I need to change something in run_vh1-io.slurm before submitting?</p> <ul> <li>Yes, you have to at least adapt the account, partition and reservation. qos has to be deleted (reservation is also optional). </li> <li>The readme has some quick build instructions. It worked for me :) </li> <li>Okay, thank you.</li> </ul> </li> <li> <p>More information about the python container wrapper can be found in the documentation.</p> </li> <li> <p>Is easybuild with AMD compilers on the roadmap for EB? </p> <ul> <li>The AMD AOCC compiler is already available in the Cray and LUMI software stack. Either <code>PrgEnv-aocc</code> or <code>cpeAOCC/22.08</code>. Additionally the AMD LLVM compiler is available via <code>PrgEnv-amd</code>.</li> <li>Ok thanks! I thought one of Kurt's slides showed that EB currently only works with GNU or Intel</li> <li>No, it works with Cray, GNU and AOCC but intel is tricky and not recommended.</li> <li>Thanks!</li> <li>[Kurt] Clarification: Standard EasyBuild has a lot of toolchains for different compilers, but only build recipes \\9the EasyConfig files) for some specific toolchains, called the common toolchains. And they are based on GNU+OpenMPI+FlexiBLAS with OpenBLAS+FFTW and a few other libraries, or Intel (currently the classic compilers but that will change) with MKL and Intel MPI. This is what I pointed to with GNU and Intel in EasyBuild. For LUMI we build our own toolchain definitions which are an improved version of those used at CSCS and similar toolchains for an older version of the Cray PE included in EasyBuild.</li> <li>[Kurt] It is not on the roadmap of the EasyBuilders. They have toolchains for AMD compilers but doe not build specific EasyBuild recipes and don't do much specific testing. I am trying to push them to support at least default clang, but then the Fortran mess will have to be cleaned up first. Regular clang support would at least imply that a number of clang-specific configuration problems would get solved so that changing to the AMD toolchain would be a relatively small effort (and could work with <code>--try-toolchain</code>). </li> <li>Ok thanks again! :D </li> </ul> </li> <li> <p>Julia (language) is installed?</p> <ul> <li>No, not in the central software stack available for everyone. It is quite easy to just download the Julia binaries in your home directory and just run it, though. Julia uses OpenBLAS by default, which is quite OK on AMD CPUs. If you want, you can also try to somewhat \"hidden\" Julia module installed with Spack. <code>module load spack/22.08; module load julia/1.7.2-gcc-vv</code>. No guarantees on that one, though (unsupported/untested).</li> <li>Another easy approach is to use existing containers. Unless GPU is used, generic container from DockerHub should work fine.</li> <li>It is not clear though if the communication across nodes is anywhere near optimal on LUMI at the moment. The problem is that Julia comes with very incomplete installation instructions. Both the Spack and EasyBuild teams are struggling with a proper installation from sources and neither seem to have enough resources to also fully test and benchmark to see if Julia is properly tuned. </li> </ul> </li> <li> <p>Paraview is a data postprocessing software that employs a graphical user interface. Is it possible to use it with LUMI?     Also, as explained in https://www.paraview.org/Wiki/PvPython_and_PvBatch,\u00a0Paraview functions may be accessed without using the GUI and just using python scripts. Is it feasible to use pvBatch and pvPython in LUMI to postprocess data with Paraview?</p> <ul> <li>Yes, you can use Paraview on LUMI. We have an EasyBuild recipe that is not yet present on the system but is available via the LUMI \"contrib\" Github repository. This easyconfig build the server components only and does CPU rendering via MESA. You need to run a client of the same version of the server on your local machine in order to interact with the server.</li> <li>Actually, the Paraview recipe is still missing in the repository but we will take care of that.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_14_LUMI_User_Support/","title":"LUMI support and LUMI documentation","text":"<p>Presenter: J\u00f8rn Dietze (LUST)</p> <p>Additional materials</p> <ul> <li> <p>Slides (PDF)</p> <p>Also on LUMI in <code>/appl/local/training/peap-q-20221123/files/13_LUST_User_Supprt.pdf</code>.</p> </li> </ul>"},{"location":"PEAP-Q-20221123/extra_14_LUMI_User_Support/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Will porting calls be available just for academic users? What about (potential) industrial users?</p> <ul> <li>There are other EuroHPC inititiaves that specifically aim to support industrial users (like the national competence centres). An industrial project for the LUMI porting program could be considered if it is open research and the software is then publicly available for all (and I think without a big license cost). </li> <li>Good to know. Thanks for answering. I guess industrial users can always pay for porting if they wish to keep their software private.</li> <li>Indeed, but then the problem on our side would still be personpower. The payment could of course be used to hire additional people on our side, but that is also not always easy. I also don't know how much AMD and/or HPE would charge for their part in the support.</li> </ul> </li> <li> <p>If I think I may need level-3 support is it still recommended to go through LUMI service desk? </p> <ul> <li>Hard to tell. At the moment we ourselves have no clear view on all the instances giving Level-3 support. If a ticket would end up with us we would do an effort to refer to the right instance, but the reality is that we hope there is already a lot more than we see. I am pretty sure that some centres are already offering some support to some of the users of their country without much contact with us.</li> <li>I guess to be clearer. Would LUST like to be kept 'in the loop' regarding these problems or is it more effort than necessary for LUST to forward these tickets to local centres?</li> <li>It would be nice for us to be in the loop as we can learn from it, but the reality is that it turned out to be difficult to integrate ticketing systems to make that easy and that the communication with some local teams is decent but is totally absent with others so we cannot efficiently pass things to the local centres. That is a communication problem that LUST and the LUMI project management needs to solve though.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/extra_15_Day_2_QandA/","title":"Day 2 General Q&amp;A","text":"<ol> <li> <p>What is the <code>libfabric</code> module that is loaded by default upon login?</p> <ul> <li>It is the library necessary for the node interconnect (slingshot) to work. It will be automatically loaded if you load <code>craype-network-ofi</code> module which is standard if you login or use one of the described Software stacks.</li> </ul> </li> <li> <p>I know it is not the object of today course, but may I still ask how launch I a job on LUMI-G ?     As Kurt said, first:     reload LUMI/22.08 partition/G     and then do I have to specify a specific --partition with the sbatch command ?</p> <ul> <li>Yes, you have to use <code>--partition=pilot</code> but this only works at the moment if you are member of a GPU-pilot project. Alternatively you can use the <code>eap</code> partition which is available for everyone on LUMI and consists of the same GPU nodes, but has shorter walltime limits. <code>eap</code> is intended for testing only, not for production runs.</li> <li>partition <code>gpu</code> is shown but currently not available (it is for the HPE benchmarking) instead <code>pilot</code> and <code>eap</code> have to be used.</li> <li>Thank you for the precision. My project is mostly GPU oriented, so we did not ask for CPU as we thought a minimum amount of CPU would be included. Will it be possible to launch jobs on LUMI-G without any CPU resources or should I ask for additional CPU resources ?</li> <li>[Kurt] In regular operation you will only need GPU billing units to run on the GPUs. However, at the moment, during the pilot, the situation is different:<ul> <li>The Early Access Platform (partition <code>eap</code>) does not require GPU billing units. It is also not charged, but usage is monitored and should remain reasonable, i.e., development and first benchmarking only. However, to get access to the queue, a minimal CPU allocation is needed.</li> <li>The <code>pilot</code> partition is for pilot users only and this one requires GPU billing units but no CPU allocation.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/","title":"Notes from the HedgeDoc page","text":"<p>These are the notes from the LUMI-C training, 23.--24.11.2022, 9:30--17:30 (CET) Hybrid on Zoom and in person HOEK 38, Leuvenseweg 38, 1000 Brussels</p> <ul> <li>Notes from the HedgeDoc page<ul> <li>General information<ul> <li>Exercises</li> <li>LUMI user coffee break</li> </ul> </li> <li>Slides and other material</li> <li>Q&amp;A of the sessions on day 1<ul> <li>Course introduction</li> <li>Introduction to the HPE Cray Hardware and Programming Environment</li> <li>First steps to running on Cray EX Hardware</li> <li>Overview of compilers and libraries</li> <li>Advanced Application Placement</li> </ul> </li> <li>Q&amp;A of the sessions on day 2<ul> <li>Introduction to Perftools</li> <li>Advanced Performance Analysis I/II</li> <li>Advanced Performance Analysis II/II</li> <li>Debugging</li> <li>MPI Topics on the HPE Cray EX supercomputer</li> <li>Optimizing Large Scale I/O</li> <li>Lust presentation: LUMI software stack</li> <li>LUST presentation: LUMI support</li> <li>General Q&amp;A</li> </ul> </li> </ul> </li> </ul>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#general-information","title":"General information","text":""},{"location":"PEAP-Q-20221123/hedgedoc_notes/#exercises","title":"Exercises","text":"<p>The exercise files are on lumi at <code>/project/project_465000297/exercises</code>.Copy the files into your home directory and work from there.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#lumi-user-coffee-break","title":"LUMI user coffee break","text":"<p>30.11.22, 13:00-13:45 (CET), 14:00--14:45(EET) Meet the LUMI user support team, discuss problems, give feedback or suggestions on how to improve services, and get advice for your projects.</p> <p>Every last Wednesday in a month. Join via Zoom</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#slides-and-other-material","title":"Slides and other material","text":"<p>Slides from HPE are available on LUMI at <code>/project/project_465000297/slides</code> You need to join the training project via the link you received in the email on Monday. Slides from the LUST talks are available on these pages</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#qa-of-the-sessions-on-day-1","title":"Q&amp;A of the sessions on day 1","text":""},{"location":"PEAP-Q-20221123/hedgedoc_notes/#course-introduction","title":"Course introduction","text":"<p>Presenter: Kurt Lust Slides</p> <ol> <li> <p>Do you know the current allocation per country ? (I wonder how much Belgium contributes to LUMI)</p> <ul> <li>Belgium: 7.4% of the total budget.</li> <li>Information about how to contact the Belgian team is https://www.enccb.be/LUMI</li> </ul> </li> <li> <p>What do you mean the training project? like ssh to lumi? or the puhuri portal?</p> <ul> <li>Yes, there is a small allocation on LUMI associated with the course (i.e. yo can log in with SSH and run jobs). We send out an email on Monday with the puhuri link to join the training project. This is a different project from the one you may have from a project from EuroHPC or your national allocation. Please use this project only for the exercises, not to run your own code or we will run out of our allocation for the course.</li> <li>The information on how to join was sent out a few days before the course. We will mention the project number and slurm reservation before we start the exercises.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#introduction-to-the-hpe-cray-hardware-and-programming-environment","title":"Introduction to the HPE Cray Hardware and Programming Environment","text":"<p>Presenter: Harvey Richardson (HPE) Slide files: <code>/project/project_465000297/slides/01_EX_Architecture.pdf</code> and <code>/project/project_465000297/slides/02_PE_and_Modules.pdf</code></p> <ol> <li> <p>What's the expected CPU clock for a heavy all-core job?</p> <ul> <li>2.45 GHz base clock rate (https://www.amd.com/en/product/10906)</li> <li>Don't expect any boost for a really heavy load. The effective clock is determined dynamically by the system depending on the heating/cooling situation. It can be complex, because heavy network/MPI traffic will also affect this, and the node tries to distribute power between the CPU cores, the IO die on the CPU, (the GPUs for LUMI-G), and the network cards on-the-fly to optimize for the best performance.</li> </ul> </li> <li> <p>Regarding the CPU cores and threads : you said that the threads are hardware : should we run large runs on the number of threads, rather than the number of nodes ?</p> <ul> <li>Could you elaborate a bit more? </li> <li>My understanding is : a cpu that has 64 cores, shows 128 threads by multithreading, therefore cases that use the cpu 100% load during 100% of the time will be better tu run on 64 core, rather than the 128 threads to eliminate the overhead of the operating system due to scheduling the software threads to the hardware core.</li> <li>There are two sessions about SLURM in the course where it will be explained how to use hyperthreading etc. </li> <li>In general, hyperthreading doesn't offer much benefits on a good code, rather the contrary. It's really more lack of cache and memory bandwidth stat stops you from using hyperthreading. Hyperthreading is basically a way to hide latency in very branchy code such as databases. In fact there are codes that run faster using a given number of nodes and 75% of the cores than the same number of nodes and all cores per socket, without hyperthreading.</li> <li>OK I will wait for the next parts of the course. Thank you</li> </ul> </li> <li> <p>At the ExaFoam summer school I was told that HDF5 parallel I/O does not scale to exa scale applications. Ist that correct Instead the exafoam project is working on an ADIOS-2 based system for parallel I/O in OpenFOAM. Feel free to answer this question at the most appropriate time in the course</p> <ul> <li>This is the current understanding, so I would say \"yes\" (even if I'm not a 100% expert).</li> <li>The HDF5 group had a BOF at SC22 about their future plans</li> <li>I would not rule out HDF5 parallel I/O at large scale on LUMI-C for runs of say 500 nodes or similar. The best approach would be to try to benchmark it first for your particular use case.</li> <li>It depends on what you would exactly need to do. If you need to write to file, I am not sure there are real alternatives. ADIOS would be great for in-situ processing.</li> <li>[Harvey] I have heard of some good experience about ADIOS-2 but have not tried it yet myself, on my list of things to do.</li> <li>One of the engines that ADIOS-2 can use is HDF5 so it is not necessarily more scalable. Just as for HDF5, it will depend much on how it is used and tuned for the particular simulation.</li> </ul> </li> <li> <p>Will there be, for the exercises, shown on-screen (in the zoom session) terminal session which will show how to use all the commands, how to successfully complete the exercises, or will we be void of visual guide and will we only have to rely on the voice of the person presenting the exercises? What I mean - can we please have the presenter show interactively the commands and their usage and output?</p> <ul> <li>You can find exercises at <code>/project/project_465000297/exercises/</code> with Readme's. You can copy the directory in your area. Just follow them and let us know if you have questions. We will cover it during the next sessions.</li> </ul> </li> <li> <p>Julia (language) is installed?</p> <ul> <li>No, not in the central software stack available for everyone. It is quite easy to just download the Julia binaries in your home directory and just run it, though. Julia uses OpenBLAS by default, which is quite OK on AMD CPUs. If you want, you can also try to somewhat \"hidden\" Julia module installed with Spack. <code>module load spack/22.08; module load julia/1.7.2-gcc-vv</code>. No guarantees on that one, though (unsupported/untested).</li> <li>Another easy approach is to use existing containers. Unless GPU is used, generic container from DockerHub should work fine.</li> <li>It is not clear though if the communication across nodes is anywhere near optimal on LUMI at the moment. The problem is that Julia comes with very incomplete installation instructions. Both the Spack and EasyBuild teams are struggling with a proper installation from sources and neither seem to have enough resources to also fully test and benchmark to see if Julia is properly tuned. </li> </ul> </li> <li> <p>Paraview is a data postprocessing software that employs a graphical user interface. Is it possible to use it with LUMI?     Also, as explained in https://www.paraview.org/Wiki/PvPython_and_PvBatch,\u00a0Paraview functions may be accessed without using the GUI and just using python scripts. Is it feasible to use pvBatch and pvPython in LUMI to postprocess data with Paraview?</p> <ul> <li>Yes, you can use Paraview on LUMI. We have an EasyBuild recipe that is not yet present on the system but is available via the LUMI \"contrib\" Github repository. This easyconfig build the server components only and does CPU rendering via MESA. You need to run a client of the same version of the server on your local machine in order to interact with the server.</li> <li>Actually, the Paraview recipe is still missing in the repository but we will take care of that.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#first-steps-to-running-on-cray-ex-hardware","title":"First steps to running on Cray EX Hardware","text":"<p>Slide file: <code>/project/project_465000297/slides/03_Running_Applications_Slurm.pdf</code></p> <ol> <li> <p>I would like to know whether it is possible to run FEM simulation software (e.g., COMSOL Multiphysics) on LUMI?</p> <ul> <li>As long as it is installed correctly then I see no reason why not. It has been run on other Cray EX systems. The only complication here will be the commerical license.  LUMI does not have its own license, you would have to provide your own. There might be some complications right now, because the compute nodes do not have internet access, which would block access to the license server. We hope that internet access will be enabled on the compute nodes soon.</li> </ul> </li> <li> <p>Is it something like MC (Midnight Commander) installed?</p> </li> <li>No, and midnight commander specifically has some annoying dependencies so it will not come quickly in a way that integrates properly with all the other software on LUMI.</li> <li>You can see your files and transfer to and from LUMI using tools like filezilla and the host <code>sftp://lumi.csc.fi</code></li> <li>And for people on a connection with sufficiently low latency Visual Studio Code also works. The client-server connection seems to fail easily though on connections with a higher latency. It is also more for editing remotely in a user friendly way than browsing files or running commands. But we do understand that mc is awesome for some people.</li> <li>In the future there will also be an Open OnDemand interface to LUMI.</li> <li> <p>MC is ok but Krusader is better</p> </li> <li> <p>and WinSCP?</p> <ul> <li>That is client software to run on your PC. It should work. </li> <li>In general, until we have Open OnDemand, the support for running GUI software on LUMI is very limited. And after that it will not be brilliant either, as an interface such as GNOME is not ideal to run on multiuser login nodes due to the resources it needs but also due to how it works internally.</li> </ul> </li> <li> <p>Would it be alright to test the building of licensed software such as VASP during the course and the EasyBuild system you have in place? (and benchmark with very small test run of course)</p> <ul> <li>Please don't run benchmarks of your own software on the project account. If you already have another project, use that one instead.</li> <li>You can install and run VASP but need to bring your own license file. See also here or the future page in the LUMI Software Library.</li> </ul> </li> </ol> <p>Exercise</p> <p>Exercises are available at <code>/project/project_465000297/exercises/ProgrammingModels/</code> Copy the files to your home folder before unpacking them.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#overview-of-compilers-and-libraries","title":"Overview of compilers and libraries","text":"<p>Slide file: <code>/project/project_465000297/slides/04_Compilers_and_Libraries.pdf</code></p> <ol> <li> <p>By default the libraries are shared (dynamic), so isn't it good practice to but the compiling part of the application in the slurm script job ?</p> <ul> <li>In general, no. The libraries on the system will not change that often, only after service breaks / upgrades of the Cray Programming Environment. It would also be inefficient to compile using compute node allocation if you have e.g. a wide parallel job with 100 compute nodes.</li> <li>You must also consider that it uses your allocated resources (from your project)</li> </ul> </li> <li> <p>Question about the cray fortran compiler: I've been trying to use it now on some private code, and it crashes when it encounters preprocesseor statements like <code>#ifdef</code> which gfortran is happy about. Is this expected? Is there a way to handle this?</p> <ul> <li>What error does the compiler give?<ul> <li><code>ftn-100: This statement must begin with a label, a keyword or identifier</code>, so it just seems to take the statement literally</li> </ul> </li> <li>Did you use the right filename extension to activate the preprocessor or the -ep/-ez options shown in the presentation?</li> <li>That is probably the problem, I think I missed that comment, I will go back to the slides to look</li> <li>After loading PrgEnv-cray you can also get extensive help about all the command line options using man crayftn</li> <li>Source file extension needs to start with F and not f to automatically trigger the preprocessor.</li> <li>The other cause might be that sometimes there are subtle differences between wat a C and Fortran preprocessor allows but I believe there is an option for that also. I remember having such a ticket long ago.</li> <li>Thanks, the filename was actually the problem, I wasn't expecting that</li> <li>I may have another advice, just in case: the CCE produces modules with capital letters names (FOO.mod), you can use <code>-emf</code> to get lowercase (like gfortran).</li> </ul> </li> </ol> <p>Exercise</p> <p>Try the compiler exercises at <code>/project/project_465000297/exercises/perftools/compiler_listings</code> and recompiling the exercises from earlier. You don't need to run any jobs.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#advanced-application-placement","title":"Advanced Application Placement","text":"<p>Presenter: Jean Pourroy (HPE) Slide file: <code>/project/project_465000297/slides/05_Advanced_Placement.pdf</code></p> <ol> <li>I have a question regarding <code>srun</code>: does it forward options to the underlying MPI implementation? with OpenMPI you can get a report of the binding using \u2014report-bindings <ul> <li>Yes, it forwards the options to pmi</li> <li>It is possible to get a report and we will mention tomorrow how to do that. But it can be done by option or environmental variable.</li> </ul> </li> </ol> <p>Exercise</p> <p>Try out the exercises found under <code>/project/project_465000297/exercises/Binding</code> and ask questions here. All exercises are described in the pdf document there.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#qa-of-the-sessions-on-day-2","title":"Q&amp;A of the sessions on day 2","text":""},{"location":"PEAP-Q-20221123/hedgedoc_notes/#introduction-to-perftools","title":"Introduction to Perftools","text":"<p>Presenter: Alfio Lazarro Slide file: <code>/project/project_465000297/slides/06_introduction_to_perftools.pdf</code></p> <ol> <li> <p>Can <code>perftools-lite</code> also be used with the gcc compilers?</p> <ul> <li>yes, there is support for all the compilers offered on the machine. </li> <li>the 'loops' variant only works with CCE as it needs extra information from the compiler.</li> </ul> </li> <li> <p>Can <code>perftools</code> also output per-MPI-rank timings or only (as shown in the presentation) averaged over all processes?</p> <pre><code>* you can get per rank timings in the text output with appropriate options to pat_reoprt. Conversely, you can have a look at apprentice2 which has a nice way of showing per-rank timings.\n</code></pre> <ul> <li>there is an option pe=ALL that will show timings per rank/PE</li> </ul> </li> <li> <p>The output of the statistics will tell you the name of the subroutine, line number, will it also tell you the name of the file where this is from ?</p> <ul> <li>with the <code>-O ca+src</code> option to <code>pat_report</code> you can get the source information.</li> </ul> </li> </ol> <p>Exercise</p> <p>The exercise files are on lumi at <code>/project/project_465000297/exercises/perftools/perftools-lite</code>. Copy the files into your home directory and work from there.</p> <p>Apprentice2 and Reveal downloads</p> <p>With <code>perftools-base</code> loaded (and it is loaded by default), you can also find the Apprentice2 downloads in <code>$CRAYPAT_ROOT/share/desktop_installers</code> or </p> <p><code>$CRAY_PERFTOOLS_PREFIX/share/desktop_installers</code>.     Copy them to your local machine and install them there.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#advanced-performance-analysis-iii","title":"Advanced Performance Analysis I/II","text":"<p>Presenter: Thierry Braconnier (HPE) Slide file: <code>/project/project_465000297/slides/07_advanced_performance_analysis_part1.pdf</code></p> <ol> <li> <p>I downloaded and installed \"Apprentice2\" under Windows. Even if I am able to connect to LUMI via SSH, I am not able to open a remote folder with Apprentice2 (connection failed). Is it something special to configure (I added the ssh keys to pageagent and also added a LUMI section in my ~/.ssh/config)?</p> <ul> <li>I think you will have to copy the files to the laptop as Windows has no concept of a generic ssh setup for a user as far as I know.</li> <li>[name=Kurt] I'd have to check when I can get access to a Windows machine (as my work machine is macOS), but Windows 10 and 11 come with OpenSSH and can use a regular config file in the .ssh subdirectory. And that could allow to define an alias with a parameter that points to the keu file. Windows 10 and 11 also have a built-in ssh agent equivalent that Windows Open?SSH can use. </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#advanced-performance-analysis-iiii","title":"Advanced Performance Analysis II/II","text":"<p>Presenter: Thierry Braconnier (HPE) Slide file: <code>/project/project_465000297/slides/08_advanced_performance_analysis_part2.pdf</code></p> <ol> <li> <p>If perftools runs on CLE/Mac/windows where can we get it/ find install instructions? </p> <ul> <li>Only apprentice2 and reveal are available as clients on mac/windows (basically the user interface components to interpret the collected data). These should be self-installing executables. Like <code>*.dmg</code> on a MAC.</li> <li>You can download the apprentice install files from LUMI (look at the info box above question 23)</li> </ul> </li> <li> <p>I managed to install apprentice2 on my MAC. How can I connect to Lumi? I need to provide a password, but when connecting to Lumi via the terminal I just pass the local ssh key...</p> <ul> <li>There is no password access enabled, you have to setup ssh in a way that it is being picked up by apprentice</li> <li>It should work if you have a ssh config file with the hostname, username and identity file for lumi. Can you connect to lumi with just <code>ssh lumi</code>?<ul> <li>Yes, I can connect to lumi with just <code>ssh lumi</code>. However: apprentice2, open remote with host <code>username@lumi.csc.fi</code> prompts for a password</li> </ul> </li> </ul> </li> </ol> <p>Exercise</p> <p>The exercise files are on lumi at <code>/project/project_465000297/exercises/perftools/</code>.Copy the files into your home directory and work from there.</p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#debugging","title":"Debugging","text":"<p>Presenter: Alfio Lazarro (HPE) Slide file: <code>/project/project_465000297/slides/09_debugging_at_scale.pdf</code></p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#mpi-topics-on-the-hpe-cray-ex-supercomputer","title":"MPI Topics on the HPE Cray EX supercomputer","text":"<p>Presenter: Harvey Richardson (HPE) Slide file: <code>/project/project_465000297/slides/11_cray_mpi_MPMD_short.pdf</code></p>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#optimizing-large-scale-io","title":"Optimizing Large Scale I/O","text":"<p>Presenter: Harvey Richardson (HPE) Slide file: <code>/project/project_465000297/slides/12_IO_short_LUMI.pdf</code></p> <ol> <li> <p>You mentioned that you are using a RAID array to have redundancy of storage (and I read RAID-6 in the slides), have you considered using the ZFS file system ? I don't know too much, but i read it could be more reliable and better performance.</p> <ul> <li>in ZFS you also chose a RAID level. I'm not sure what is used on LUMI, and it might be different for metadata and the storage targets. You will not solve the metadata problem with ZFS though. I know H?PE supports two backend file systems for Lustre but I'm not sure which one is used on LUMI.</li> </ul> </li> <li> <p>This is really a question about the earlier session on performance tools, but I hope it's still OK to post it: I've tried using <code>perftools-lite</code>on my own code, but doing so it does not compile (it does without the modules). The linking seems to fail with      <code>WARNING: cannot acquire file status information for '-L/usr/lib64/libdl.so' [No such file or directory]</code>     Is this something that has been seen before? Any tips/hints on what is going on?</p> <ul> <li>without checking the code is hard to understand what it the problem. Do you really link with libdl.so in your compilation?</li> <li>Yes, doing ldd on a successful compile gives <code>libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f228c3b0000)</code> The other dl library symlinks to that one.</li> <li>OK, the question is the line <code>-L/usr/lib64/libdl.so</code>, I wonder if you are using somewhere in the makefile</li> <li>Yes, this is a large cmake set-up though, but cmake has <code>CMakeCache.txt:LIBDL_LIBRARY:FILEPATH=/usr/lib64/libdl.so</code></li> <li>Then we are hitting a situation where perftools-lite doesn't work... Try perftools, restricting to <code>-g</code></li> <li>OK, thanks! Will try that.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#lust-presentation-lumi-software-stack","title":"Lust presentation: LUMI software stack","text":"<p>Presenter: Kurt Lust Slides and notes</p> <ol> <li> <p><code>Error: ~/exercises/VH1-io/VH1-io/run&gt; sbatch run_vh1-io.slurm sbatch: error: Invalid directive found in batch script: e.g</code> Do I need to change something in run_vh1-io.slurm before submitting?</p> <ul> <li>Yes, you have to at least adapt the account, partition and reservation. qos has to be deleted (reservation is also optional). </li> <li>The readme has some quick build instructions. It worked for me :) </li> <li>Okay, thank you.</li> </ul> </li> <li> <p>More information about the python container wrapper can be found in the documentation.</p> </li> <li> <p>Is easybuild with AMD compilers on the roadmap for EB? </p> <ul> <li>The AMD AOCC compiler is already available in the Cray and LUMI software stack. Either <code>PrgEnv-aocc</code> or <code>cpeAOCC/22.08</code>. Additionally the AMD LLVM compiler is available via <code>PrgEnv-amd</code>.</li> <li>Ok thanks! I thought one of Kurt's slides showed that EB currently only works with GNU or Intel</li> <li>No, it works with Cray, GNU and AOCC but intel is tricky and not recommended.</li> <li>Thanks!</li> <li>[Kurt] Clarification: Standard EasyBuild has a lot of toolchains for different compilers, but only build recipes \\9the EasyConfig files) for some specific toolchains, called the common toolchains. And they are based on GNU+OpenMPI+FlexiBLAS with OpenBLAS+FFTW and a few other libraries, or Intel (currently the classic compilers but that will change) with MKL and Intel MPI. This is what I pointed to with GNU and Intel in EasyBuild. For LUMI we build our own toolchain definitions which are an improved version of those used at CSCS and similar toolchains for an older version of the Cray PE included in EasyBuild.</li> <li>[Kurt] It is not on the roadmap of the EasyBuilders. They have toolchains for AMD compilers but doe not build specific EasyBuild recipes and don't do much specific testing. I am trying to push them to support at least default clang, but then the Fortran mess will have to be cleaned up first. Regular clang support would at least imply that a number of clang-specific configuration problems would get solved so that changing to the AMD toolchain would be a relatively small effort (and could work with <code>--try-toolchain</code>). </li> <li>Ok thanks again! :D </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#lust-presentation-lumi-support","title":"LUST presentation: LUMI support","text":"<p>Presenter: Jorn Dietze Slides</p> <ol> <li> <p>Will porting calls be available just for academic users? What about (potential) industrial users?</p> <ul> <li>There are other EuroHPC inititiaves that specifically aim to support industrial users (like the national competence centres). An industrial project for the LUMI porting program could be considered if it is open research and the software is then publicly available for all (and I think without a big license cost). </li> <li>Good to know. Thanks for answering. I guess industrial users can always pay for porting if they wish to keep their software private.</li> <li>Indeed, but then the problem on our side would still be personpower. The payment could of course be used to hire additional people on our side, but that is also not always easy. I also don't know how much AMD and/or HPE would charge for their part in the support.</li> </ul> </li> <li> <p>If I think I may need level-3 support is it still recommended to go through LUMI service desk? </p> <ul> <li>Hard to tell. At the moment we ourselves have no clear view on all the instances giving Level-3 support. If a ticket would end up with us we would do an effort to refer to the right instance, but the reality is that we hope there is already a lot more than we see. I am pretty sure that some centres are already offering some support to some of the users of their country without much contact with us.</li> <li>I guess to be clearer. Would LUST like to be kept 'in the loop' regarding these problems or is it more effort than necessary for LUST to forward these tickets to local centres?</li> <li>It would be nice for us to be in the loop as we can learn from it, but the reality is that it turned out to be difficult to integrate ticketing systems to make that easy and that the communication with some local teams is decent but is totally absent with others so we cannot efficiently pass things to the local centres. That is a communication problem that LUST and the LUMI project management needs to solve though.</li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/hedgedoc_notes/#general-qa","title":"General Q&amp;A","text":"<ol> <li> <p>What is the <code>libfabric</code> module that is loaded by default upon login?</p> <ul> <li>It is the library necessary for the node interconnect (slingshot) to work. It will be automatically loaded if you load <code>craype-network-ofi</code> module which is standard if you login or use one of the described Software stacks.</li> </ul> </li> <li> <p>I know it is not the object of today course, but may I still ask how launch I a job on LUMI-G ?     As Kurt said, first:     reload LUMI/22.08 partition/G     and then do I have to specify a specific --partition with the sbatch command ?</p> <ul> <li>Yes, you have to use <code>--partition=pilot</code> but this only works at the moment if you are member of a GPU-pilot project. Alternatively you can use the <code>eap</code> partition which is available for everyone on LUMI and consists of the same GPU nodes, but has shorter walltime limits. <code>eap</code> is intended for testing only, not for production runs.</li> <li>partition <code>gpu</code> is shown but currently not available (it is for the HPE benchmarking) instead <code>pilot</code> and <code>eap</code> have to be used.</li> <li>Thank you for the precision. My project is mostly GPU oriented, so we did not ask for CPU as we thought a minimum amount of CPU would be included. Will it be possible to launch jobs on LUMI-G without any CPU resources or should I ask for additional CPU resources ?</li> <li>[Kurt] In regular operation you will only need GPU billing units to run on the GPUs. However, at the moment, during the pilot, the situation is different:<ul> <li>The Early Access Platform (partition <code>eap</code>) does not require GPU billing units. It is also not charged, but usage is monitored and should remain reasonable, i.e., development and first benchmarking only. However, to get access to the queue, a minimal CPU allocation is needed.</li> <li>The <code>pilot</code> partition is for pilot users only and this one requires GPU billing units but no CPU allocation.  </li> </ul> </li> </ul> </li> </ol>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/","title":"LUMI Software Stacks","text":"<p>In this part of the training, we cover:</p> <ul> <li>Software stacks on LUMI, where we discuss the organisation of the software stacks     that we offer and some of the policies surrounding it</li> <li>Advanced Lmod use to make the best out of the software stacks</li> <li>Creating your customised environment with EasyBuild, the tool that we use to install     most software.</li> </ul>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#the-software-stacks-on-lumi","title":"The software stacks on LUMI","text":""},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#design-considerations","title":"Design considerations","text":"<ul> <li> <p>LUMI is a very leading edge and also an inhomogeneous machine. Leading edge often implies     teething problems and inhomogeneous doesn't make life easier either.</p> <ol> <li>It uses a novel interconnect which is an extension of Ethernet rather than being based on InfiniBand,      and that interconnect has a different software stack of your typical Mellanox InfiniBand cluster. </li> <li>It also uses a relatively new GPU architecture, AMD CDNA2, with an immature software ecosystem.      The GPU nodes are really GPU-first, with the interconnect cards connected directly to the GPU packages      and only one CPU socket, and another feature which is relatively new: a fully cache-coherent unified memory     space between the CPU and GPUs, though of course very NUMA. This is a feature that has previously     only been seen in some clusters with NVIDIA P100 and V100 GPUs and IBM Power 8 and 9 CPUs used     for some USA pre-exascale systems, and of course in the Apple M1 but then without the NUMA character.</li> <li>LUMI is also inhomogeneous because some nodes have zen2 processors while the two main compute partitions     have zen3-based CPUs, and the compute GPU nodes have AMD GPUs while the visualisation nodes have     NVIDIA GPUs. </li> </ol> <p>Given the novel interconnect and GPU we do expect that both system and application software will be immature at first and evolve quickly, hence we needed a setup that enables us to remain very agile, which leads to different compromises compared to a software stack for a more conventional and mature system as an x86 cluster with NVIDIA GPUs and Mellanox InfiniBand.</p> </li> <li> <p>Users also come to LUMI from 11 different channels, not counting subchannels as some countries have     multiple organisations managing allocations, and those channels all have different expectations about     what LUMI should be and what kind of users should be served. For our major stakeholder, the EuroHPC JU,     LUMI is a pre-exascale system meant to prepare users and applications to make use of future even large     systems, while some of the LUMI consortium countries see LUMI more as an extension of their tier-1 or     even tier-2 machines.</p> </li> <li> <p>The central support team of LUMI is also relatively small compared to the nature of LUMI with its     many different partitions and storage services and the expected number of projects and users.      Support from users coming in via the national channels will rely a lot on efforts from local organisations     also. So we must set up a system so that they can support their users without breaking things on     LUMI, and to work with restricted rights. And in fact, LUMI User Support team members also have very limited additional     rights on the machine compared to regular users or support people from the local organisations.     LUST is currently 9 FTE. Compare this to 41 people in the J\u00fclich Supercomputer Centre for software     installation and support only... (I give this number because it was mentioned in a recent talk in an     EasyBuild user meeting.)</p> </li> <li> <p>The Cray Programming Environment is also a key part of LUMI and the environment for which we get     support from HPE Cray. It is however different from more traditional environments such as a typical     Intel oneAPI installation of a typical installation build around the GNU Compiler Collection and Open MPI     or MPICH. The programming environment is installed with the operating system rather than through the     user application software stack hence not managed through the tools used for the application software     stack, and it also works differently with its universal compiler wrappers that are typically configured     through modules. </p> </li> <li> <p>We also see an increasing need for customised setups. Everybody wants a central stack as long as their     software is in there but not much more as otherwise it is hard to find, and as long as software is      configured in the way they are used to. And everybody would like LUMI to look as much as possible      as their home system. But this is of course impossible. Moreover, there are more and more conflicts     between software packages and modules are only a partial solution to this problem. The success of     containers, conda and Python virtual environments is certainly to some extent explained by the      need for more customised setups and the need for multiple setups as it has become nearly impossible     to combine everything in a single setup due to conflicts between packages and the dependencies they need.</p> </li> </ul>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#the-lumi-solution","title":"The LUMI solution","text":"<p>We tried to take all these considerations into account and came up with a solution that may look a little unconventional to many users.</p> <p>In principle there should be a high degree of compatibility between releases of the HPE Cray Programming Environment but we decided not to take the risk and build our software for a specific release of the  programming environment, which is also a better fit with the typical tools used to manage a scientific  software stack such as EasyBuild and Spack as they also prefer precise versions for all dependencies and compilers etc. We also made the stack very easy to extend. So we have many base libraries and some packages already pre-installed but also provide an easy and very transparant way to install additional packages in your project space in exactly the same way as we do for the central stack, with the same performance but the benefit that the installation can be customised more easily to the needs of your project. Not everybody needs the same configuration of GROMACS or LAMMPS or other big packages, and in fact a one-configuration-that-works-for-everybody may even be completely impossible due to conflicting options that cannot be used together.</p> <p>For the module system we could chose between two systems supported by HPE Cray. They support  Environment Modules with module files based on the TCL scripting language, but only the old version that is no longer really developed and not the newer versions 4 and 5 developed in France, and Lmod, a module system based on the LUA scripting language that also support many TCL module files through a translation layer. We chose to go with Lmod as LUA is an easier and more modern language to work with and as Lmod is much more powerful than Environment Modules 3, certainly for searching modules.</p> <p>To manage the software installations we could chose between EasyBuild, which is mostly developed in Europe and hence a good match with a EuroHPC project as EuroHPC wants to develop a European HPC technology stack from hardware to application software, and Spack, a package developed in the USA national labs. We chose to go with EasyBuild as our primary tool for which we also do some development.  However, as we shall see, our EasyBuild installation is not your typical EasyBuild installation that you may be acustomed with from clusters at your home institution. It uses toolchains specifically for the HPE Cray programming environment so recipes need to be adapted. We do offer an growing library of Cray-specific installation recipes though. The whole setup of EasyBuild is done such that you can build on top of the central software stack and such that your modules appear in your module view without having to add directories by hand to environment variables etc. You only need to point to the place where you want to install software for your project as we cannot automatically determine a suitable place.  We have a pre-configured Spack installation also but do not do any package development in Spack ourselves. The setup is meant for users familiar with Spack who can also solve problems that occur on the road, but we already did the work of ensuring that Spack is correctly configured for the HPE Cray compilers.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#software-policies","title":"Software policies","text":"<p>As any site, we also have a number of policies about software installation, and we're still further developing them as we gain experience in what we can do with the amount of people we have and what we cannot do.</p> <p>LUMI uses a bring-your-on-license model except for a selection of tools that are useful to a larger community. </p> <ul> <li>This is partly caused by the distributed user management as we do not even have the necessary     information to determine if a particular user can use a particular license, so we must shift that      responsibility to people who have that information, which is often the PI of your project.</li> <li>You also have to take into account that up to 20% of LUMI is reserved for industry use which makes      negotiations with software vendors rather difficult as they will want to push us onto the industrial     rather than academic pricing as they have no guarantee that we will obey to the academic license     restrictions. </li> <li>And lastly, we don't have an infinite budget. There was a questionaire send out to      some groups even before the support team was assembled and that contained a number of packages that     by themselves would likely consume our whole software budget for a single package if I look at the      size of the company that produces the package and the potential size of their industrial market.      So we'd have to make choices and with any choice for a very specialised package you favour a few      groups. And there is also a political problem as without doubt the EuroHPC JU would prefer that we     invest in packages that are developed by European companies or at least have large development     teams in Europe.</li> </ul> <p>The LUMI User Support Team tries to help with installations of recent software but porting or bug correction in software is not our task. As a user, you have to realise that not all Linux or even supercomputer software will work on LUMI. This holds even more for software that comes only as a binary. The biggest problems are the GPU and anything that uses distributed memory and requires high performance from the interconnect. For example,</p> <ul> <li>software that use NVIDIA proprietary programming models and     libraries needs to be ported. </li> <li>Binaries that do only contain NVIDIA code paths, even if the programming     model is supported on AMD GPUs, will not run on LUMI. </li> <li>The final LUMI interconnect requires libfabric     using a specific provider for the NIC used on LUMI, so any software compiled with an MPI library that     requires UCX, or any other distributed memory model build on top of UCX, will not work on LUMI, or at     least not work efficiently as there might be a fallback path to TCP communications. </li> <li>Even intro-node interprocess communication can already cause problems as there are three different kernel extensions     that provide more efficient interprocess messaging than the standard Linux mechanism. Many clusters     use knem for that but on LUMI xpmem is used. So software that is not build to support xpmem will     also fall back to the default mechanism or fail. </li> <li>Also, the MPI implementation needs to collaborate     with certain modules in our Slurm installation to start correctly and experience has shown that this     can also be a source of trouble as the fallback mechanisms that are often used do not work on LUMI. </li> <li>Containers solve none of these problems. There can be more subtle compatibility problems also.      As has been discussed earlier in the course, LUMI runs SUSE Linux and not Ubuntu which is popular on      workstations or a Red Hat-derived Linux popular on many clusters. Subtle differences between Linux      versions can cause compatibility problems that in some cases can be solved with containers. But containers     won't help you if they are build for different kernel extensions, driver versions and hardware interfaces.</li> <li>The compute nodes also lack some Linux daemons that may be present on smaller clusters. HPE Cray use an     optimised Linux version called COS or Cray Operating System on the compute nodes. It is optimised to     reduce OS jitter and hence to enhance scalability of applications as that is after all the primary     goal of a pre-exascale machine. But that implies that certain Linux daemons that your software may      expect to find are not present on the compute nodes. D-bus comes to mind.</li> </ul> <p>Also, the LUNI user support team is too small to do all software installations which is why we currently state in our policy that a LUMI user should be capable of installing their software themselves or have another support channel. We cannot install every single piece of often badly documented research-quality code that was never meant to be used by people who don't understand the code.</p> <p>Another soft compatibility problem that has not yet been mentioned is that software that accesses hundreds of thousands of small files and abuses the file system as a database rather than using structured data formats designed to organise data on supercomputers is not welcome on LUMI. For that reason we also require to containerize conda and Python installations. We do offer a container-based wrapper that offers a way to install conda packages or to install Python packages with pip on top of  the Python provided by the <code>cray-python</code> module. The link to the documentation of the tool that we call lumi-container-wrapper but may by some from CSC also be known as Tykky is in the handout of the slides that you can get after the course.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#organisation-of-the-software-in-software-stacks","title":"Organisation of the software in software stacks","text":"<p>On LUMI we have several software stacks.</p> <p>CrayEnv is the software stack for users who only need the Cray Programming Environment but want a more recent set of build tools etc than the OS provides. We also take care of a few issues that we will discuss on the next slide that are present right after login on LUMI.</p> <p>Next we have the stacks called \"LUMI\". Each one corresponds to a particular release of the HPE Cray Programming Environment. It is the stack in which we install software using the that programming environment and mostly EasyBuild. The Cray Programming Environment modules are still used, but they are accessed through a replacement for the PrgEnv modules that is managed by EasyBuild. We have tuned versions for the 4 types of hardware in the regular LUMI system: zen2 CPUs in the login nodes and large memory nodes, zen3 for the  LUMI-C compute nodes, zen 2 combined with NVIDIA GPUs for the visualisation nodes and zen3 + MI250X for the LUMI-G partition. There is also some support for the early access platform which has zen2 CPUs combined with MI100 GPUs but we don't pre-install software in there at the moment except for some build tools and some necessary tools for ROCm as these nodes are not meant to run codes on and as due to installation  restrictions we cannot yet use the GPU compilers with EasyBuild the way we should do that on the final system.</p> <p>We also provide the spack modules which provide some support to install software with Spack. This stack is  meant for users who are very familiar with Spack and can deal with the problems Spack may throw at you. We have no intent to debug or modify Spack package files ourselves, but did an effort to configure Spack to use the compilers provided by the HPE Cray PE.</p> <p>In the far future we will also look at a stack based on the common EasyBuild toolchains as-is, but we do expect problems with MPI that will make this difficult to implement, and the common toolchains also do not yet support the AMD GPU ecosystem, so we make no promises whatsoever about a time frame for this development.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#3-ways-to-access-the-cray-programming-environment-on-lumi","title":"3 ways to access the Cray Programming environment on LUMI.","text":""},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#bare-environment-and-crayenv","title":"Bare environment and CrayEnv","text":"<p>Right after login you have a very bare environment available with the Cray Programming Environment with the PrgEnv-cray module loaded. It gives you basically what you can expect on a typical Cray system. There aren't many tools available, basically mostly only the tools in the base OS image and some tools that we are sure will not impact software installed in one of the software stacks. The set of target modules loaded is the one for the login nodes and not tuned to any particular node type. As a user you're fully responsible for managing the target modules, reloading them when needed or loading the appropriate set for the hardware you're using or want to cross-compile for.</p> <p>The second way to access the Cray Programming Environment is through the CrayEnv software stack. This stack offers an \"enriched\" version of the Cray environment. It takes care of the target modules: Loading or reloading CrayEnv will reload an optimal set of target modules for the node you're on. It also provides some additional  tools like newer build tools than provided with the OS. They are offered here and not in the bare environment to be sure that those tools don't create conflicts with software in other stacks. But otherwise the Cray Programming  Environment works exactly as you'd expect from this course.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#lumi-stack","title":"LUMI stack","text":"<p>The third way to access the Cray Programming Environment is through the LUMI software stacks, where each stack is based on a particular release of the HPE Cray Programming Environment. We advise against mixing with modules that came with other versions of the Cray PE, but they remain accessible although they are hidden from the default view for regular users. It ia also better to not use the PrgEnv modules, but the equivalent LUMI EasyBuild  toolchains instead as indicated by the following table:</p> HPE Cray PE LUMI toolchain What? <code>PrgEnv-cray</code> <code>cpeCray</code> Cray Compiler Environment <code>PrgEnv-gnu</code> <code>cpeGNU</code> GNU C/C++ and Fortran <code>PrgEnv-aocc</code> <code>cpeAOCC</code> AMD CPU compilers <code>PrgEnv-amd</code> <code>cpeAMD</code> AMD ROCm GPU compilers (LUMI-G only) <p>The cpeCray etc modules also load the MPI libraries and Cray LibSci just as the PrgEnv modules do. And we sometimes use this to work around problems in Cray-provided modules that we cannot change. E.g., the <code>PrgEnv-aocc/21.12</code> module can successfully use the <code>aocc/3.1.0</code> compilers.</p> <p>This is also the environment in which we install most software, and from the name of the modules you can see which compilers we used.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#lumi-stack-module-organisation","title":"LUMI stack module organisation","text":"<p>To manage the heterogeneity in the hardware, the LUMI software stack uses two levels of modules</p> <p>First there are the LUMI/21.12 and LUMI/22.08 modules. Each of the LUMI modules loads a particular version of the LUMI stack.</p> <p>The second level consists of partition modules. There is partition/L for the login and large memory nodes, partition/C for the regular compute nodes, partition/G for the GPU nodes and in the future we may have partition/D for the visualisation nodes.</p> <p>There is also a hidden partition/common module in which we install software that is available everywhere,  but we advise you to be careful to install software in there in your own installs as it is risky to rely on software in one of the regular partitions, and impossible in our EasyBuild setup.</p> <p>The LUMI module will automatically load the best partition module for the current hardware whenever it is loaded or reloaded. So if you want to cross-compile, you can do so by loading a different partition  module after loading the LUMI module, but you'll have to reload every time you reload the LUMI module.</p> <p>Hence you should also be very careful in your job scripts. On LUMI the environment from the login nodes is used when your job starts, so unless you switched to the suitable partition for the compute nodes, your job will start with the software stack for the login nodes. If in your job script you reload the  LUMI module it will instead switch to the software stack that corresponds to the type of compute node you're using and more optimised binaries can be available. If for some reason you'd like to use the same software on LUMI-C and on the login or large memory nodes and don't want two copies of locally installed software, you'll have to make sure that after reloading the LUMI module in your job script you explicitly load the partition/L module.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#lmod-on-lumi","title":"Lmod on LUMI","text":""},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#exploring-modules-with-lmod","title":"Exploring modules with Lmod","text":"<p>Contrary to some other module systems, or even some other Lmod installations, not all modules are immediately available for loading. So don't be disappointed by the small number of modules you will see with <code>module available</code> right after login. Lmod has a so-called hierarchical setup that tries to protect you from being confronted with all modules at the same time, even those that may conflict with  each other, and we use that to some extent on LUMI. Lmod distinguishes between installed modules and available modules. Installed modules are all modules on the system that can be loaded one way or another, sometimes through loading other modules first. Available modules are all those modules that can be loaded at a given point in time without first loading other modules.</p> <p>The HPE Cray Programming Environment also uses a hierarchy though it is not fully implemented in the way the Lmod developer intended so that some features do not function as they should.</p> <ul> <li>For example, the <code>cray-mpich</code> module can only be loaded if both a network target module and a     compiler module are loaded (and that is already the example that is implemented differently from     what the Lmod developer had in mind). </li> <li>Another example is the performance monitoring tools. Many of those     tools only become available after loading the <code>perftools-base</code> module. </li> <li>Another example is the     <code>cray-fftw</code> module which requires a processor target module to be loaded first.</li> </ul> <p>Lmod has several tools to search for modules. </p> <ul> <li>The <code>module avail</code> command is one that is also     present in the various Environment Modules implementations and is the command to search in the     available modules. </li> <li>But Lmod also has other commands, <code>module spider</code> and <code>module keyword</code>, to      search in the list of installed modules.</li> </ul>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#module-spider-command","title":"Module spider command","text":"<p>Demo moment 1 (when infrastructure for a demo is available)</p> <p></p> <p>(The content of this slide is really meant to be shown in practice on a command line.)</p> <p>There are three ways to use <code>module spider</code>, discovering software in more and more detail.</p> <ol> <li> <p><code>module spider</code> by itself will show a list of all installed software with a short description.     Software is bundled by name of the module, and it shows the description taken from the default     version. <code>module spider</code> will also look for \"extensions\" defined in a module and show those also     and mark them with an \"E\". Extensions are a useful Lmod feature to make clear that a module offers     features that one would not expect from its name. E.g., in a Python module the extensions could be     a list of major Python packages installed in the module which would allow you to find <code>NumPy</code> if     it were hidden in a module with a different name. This is also a very useful feature to make     tools that are bundled in one module to reduce the module clutter findable.</p> </li> <li> <p><code>module spider</code> with the name of a package will show all versions of that package installed on     the system. This is also case-insensitive. Let's try for instance <code>module spider gnuplot</code>. This     will show 10 versions of GNUplot. There are two installations of GNUplot 5.4.2 and eight of 5.4.3. The      remainder of the name shows us with what compilers gnuplot was compiled. The reason to have      versions for two or three compilers is that no two compiler modules can be loaded simultaneously,     and this offers a solution to use multiple tools without having to rebuild your environment for     every tool, and hence also to combine tools. </p> <p>Now try <code>module spider CMake</code>. We see that there are four versions, 3.21.2, 3.22.2, 3.23.2 and 3.24.0, but now they are shown in blue with an \"E\" behind the name. That is because there is no module called <code>CMake</code> on LUMI. Instead the tool is provided by another module that in this case contains a collection of popular build tools and that we will discover shortly.</p> </li> <li> <p>The third use of <code>module spider</code> is with the full name of a module. Try for instance     <code>module spider gnuplot/5.4.3-cpeGNU-22.08</code>. This will now show full help information for     the specific module, including what should be done to make the module available. For      this GNUplot module we see that there are two ways to load the module: By loading <code>LUMI/22.08</code>      combined with <code>partition/C</code> or by loading <code>LUMI/22.08</code> combined with <code>partition/L</code>. So use only     a single line, but chose it in function of the other modules that you will also need. In this case     it means that that version of GNUplot is available in the <code>LUMI/22.08</code> stack which we could already     have guessed from its name, with binaries for the login and large memory nodes and the LUMI-C compute     partition. This does however not always work with the Cray Programming Environment modules.</p> <p>We can also use <code>module spider</code> with the name and version of an extension. So try <code>module spider CMake/3.24.0</code>. This will now show us that this tool is in the <code>buildtools/22.08</code> module (among others) and give us 6 different options to load that module as it is provided in the <code>CrayEnv</code> and the <code>LUMI/22.08</code> software stacks and for all partitions (basically because we don't do processor-specific optimisations for these tools).</p> </li> </ol> Demo module spider <p>Try the following commands:</p> <pre><code>module spider\nmodule spider gnuplot\nmodule spider cmake\nmodule spider gnuplot/5.4.3-cpeGNU-22.08\nmodule spider CMake/3.24.0\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#module-keyword-command","title":"Module keyword command","text":"<p><code>module keyword</code> will search for a module using a keyword but it is currently not very useful on LUMI because of a bug in the current version of Cray Lmod which is solved in the more recent versions. Currently the output contains a lot of irrelevant modules, basically all extensions of modules on the system.</p> <p>What <code>module keyword</code> really does is search in the module description and help for the word that  you give as an argument. Try for instance <code>module keyword https</code> and you'll see two relevant tools, <code>cURL</code> and <code>wget</code>, two tools that can be used to download files to LUMI via several protocols in use on the internet.</p> <p>On LUMI we do try to put enough information in the module files to make this a suitable additional way to discover software that is already installed on the system, more so than in regular EasyBuild installations.</p> Demo module keyword <p>Try the following command:</p> <pre><code>module keyword https\n</code></pre> <p> </p> <p> </p> <p> </p> <p> </p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#sticky-modules-and-module-purge","title":"Sticky modules and module purge","text":"<p>You may have been taught that <code>module purge</code> is a command that unloads all modules and on some systems they might tell you in trainings not to use it because it may also remove some basic  modules that you need to use the system. On LUMI for instance there is an <code>init-lumi</code> module that does some of the setup of the module system and should be reloaded after a normal <code>module purge</code>. On Cray systems <code>module purge</code> will also unload the target modules while those are typically not loaded by the <code>PrgEnv</code> modules so you'd need to reload them by hand before the <code>PrgEnv</code> modules would work.</p> <p>Lmod however does have the concept of \"sticky modules\". These are not unloaded by <code>module purge</code> but are re-loaded, so unloaded and almost immediately loaded again, though you can always force-unload them with <code>module --force purge</code> or <code>module --force unload</code> for individual modules.</p> Demo <p>Try the following command:</p> <pre><code>module av\n</code></pre> <p> </p> <p>Note the very descriptive titles in the above screenshot.</p> <p> </p> <p> </p> <p> </p> <p>The letter \"D\" next to a name denotes that this is the default version, the letter \"L\" denotes that the module is loaded.</p> <p>Try the following commands and carefully observe the output:</p> <pre><code>module load LUMI/22.08 buildtools\nmodule list\nmodule purge\nmodule list\nmodule --force unload ModuleLabel/label\nmodule list\n</code></pre> <p>The sticky property has to be declared in the module file so we cannot add it to for instance the Cray Programming Environment target modules, but we can and do use it in some modules that we control ourselves. We use it on LUMI for the software stacks themselves and for the modules that set the display style of the modules. </p> <ul> <li>In the <code>CrayEnv</code> environment, <code>module purge</code> will clear the target     modules also but as <code>CrayEnv</code> is not just left untouched but reloaded instead, the load of <code>CrayEnv</code>     will load a suitable set of target modules for the node you're on again. But any customisations that     you did for cross-compiling will be lost. </li> <li>Similary in the LUMI stacks, as the <code>LUMI</code> module itself     is reloaded, it will also reload a partition module. However, that partition module might not be the      one that you had loaded but it will be the one that the LUMI module deems the best for the node you're     on, and you may see some confusing messages that look like an error message but are not.</li> </ul>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#changing-how-the-module-list-is-displayed","title":"Changing how the module list is displayed","text":"<p>You may have noticed already that by default you don't see the directories in which the module files reside as is the case on many other clusters. Instead we try to show labels that tell you what that group of modules actually is. And sometimes this also combines modules from multiple directories that have the same purpose. For instance, in the default view we collapse all modules from the Cray Programming Environment in two categories, the target modules and other programming environment modules. But you can customise this by loading one of the <code>ModuleLabel</code> modules. One version, the <code>label</code> version, is the default view. But we also have <code>PEhierarchy</code> which  still provides descriptive texts but unfolds the whole hierarchy in the Cray Programming  Environment. And the third style is called <code>system</code> which shows you again the module directories.</p> Demo <p>Try the following commands:</p> <pre><code>module list\nmodule avail\nmodule load ModuleLabel/PEhiererachy\nmodule avail\nmodule load ModuleLabel/system\nmodule avail\nmodule load ModuleLabel/label\n</code></pre> <p>We're also very much aware that the default colour view is not good for everybody. So far we are not  aware of an easy way to provide various colour schemes as one that is OK for people who like a black  background on their monitor might not be OK for people who prefer a white background. But it is possible to turn colour off alltogether by loading the <code>ModuleColour/off</code> module, and you can always turn it on again with <code>ModuleColour/on</code>.</p> Demo <p>Try the following commands:</p> <pre><code>module avail\nmodule load ModuleColour/off\nmodule avail\nmodule list\nmodule load ModuleColour/on\n</code></pre> <p>We also hide some modules from regular users because we think they are not useful at all for regular users or not useful in the context you're in at the moment. For instance, when working in the <code>LUMI/22.08</code> stack we prefer that users use the Cray programming environment modules that come with release 22.08 of that environment, and cannot guarantee compatibility of other modules with already installed software, so we hide the other ones from view. You can still load them if you know they exist but  you cannot see them with <code>module available</code>. It is possible though to still show most if not all of  them by loading <code>ModulePowerUser/LUMI</code>. Use this at your own risk however, we will not help you to make things work or to use any module that was designed for us to maintain the system.</p> Demo <p>Try the following commands:</p> <pre><code>module load LUMI/22.08\nmodule avail\nmodule load ModulePowerUser\nmodule avail\n</code></pre> <p>Note that we see a lot more Cray PE modules with <code>ModulePowerUser</code>!</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#easybuild-to-extend-the-lumi-software-stack","title":"EasyBuild to extend the LUMI software stack","text":""},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#installing-software-on-hpc-systems","title":"Installing software on HPC systems","text":"<p>Software on HPC systems is rarely installed from RPMs for various reasons. Generic RPMs are rarely optimised for the specific CPU of the system as they have to work on a range of systems and as including optimised code paths in a single executable for multiple architectures is hard to even impossible.  Secondly generic RPMs might not even work with the specific LUMI environment. They may not fully support the SlingShot interconnect and hence run at reduced speed, or they may need particular kernel modules or daemons that are not present on the system or they may not work well with the resource manager on the system. We expect this to happen especially with packages that  require specific MPI versions. Moreover, LUMI is a multi-user system so there is usually no \"one version fits all\". And we need a small system image as nodes are diskless which means that RPMs need to be relocatable so that they can be installed elsewhere.</p> <p>Spack and EasyBuild are the two most popular HPC-specific software build and installation frameworks.  These two systems usually install packages from sources so that the software can be adapted to the underlying hardware and operating system. They do offer a mean to communicate and execute installation instructions easily so that in practice once a package is well supported by these tools a regular user can install them also. Both packages make software available via modules so that you can customise your environment and select appropriate versions for your work.  And they do take care of dependency handling in a way that is compatible with modules.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#extending-the-lumi-stack-with-easybuild","title":"Extending the LUMI stack with EasyBuild","text":"<p>On LUMI EasyBuild is our primary software installation tool. We selected this as there is already a lot of experience with EasyBuild in several LUMI consortium countries and as it is also a tool developed in Europe which makes it a nice fit with EuroHPC's goal of creating a fully European HPC ecosystem.</p> <p>EasyBuild is fully integrated in the LUMI software stack. Loading the LUMI module will not only make centrally installed packages available, but also packages installed in your personal or project stack. Installing packages in that space is done by loading the EasyBuild-user module that will load a suitable version of EasyBuild and configure it for installation in a way that is compatible with the LUMI stack. EasyBuild will then use existing modules for dependencies if those are already on the system or in your personal or project stack.</p> <p>Note however that the built-in easyconfig files that come with EasyBuild do not work on LUMI at the moment.</p> <ul> <li>For the GNU toolchain we would have problems with MPI. EasyBuild there uses Open MPI and that     needs to be configured differently to work well on LUMI, and there are also still issues with     getting it to collaborate with the resource manager as it is installed on LUMI.</li> <li>The Intel-based toolchains have their problems also. At the moment, the Intel compilers with the     AMD CPUs are a problematic cocktail. There have recently been performance and correctness problems      with the MKL math library and also failures some versions of Intel MPI,      and you need to be careful selecting compiler options and not use <code>-xHost</code>     with the classic compilers or the Intel compiler will simply optimize for a two decades old CPU.</li> </ul> <p>Instead we make our own EasyBuild build recipes that we also make available in the  LUMI-EasyBuild-contrib GitHub repository. The EasyBuild configuration done by the EasyBuild-user module will find a copy of that repository on the system or in your own install directory. The latter is useful if you always want the very latest, before we deploy it on the system.  We also maintain a list of all EasyBuild recipes installed in the central stack maintained by LUST or available in the main EasyConfig repository LUMI-EasyBuild-contrib in  the LUMI Software Library.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#step-1-where-to-install","title":"Step 1: Where to install","text":"<p>Let's now discuss how you can extend the central LUMI software stack with packages that you need for your project.</p> <p>The default location for the EasyBuild user modules and software is in <code>$HOME/EasyBuild</code>. This is not the ideal place though as then the software is not available for other users in your project, and as the size of your home directory is also limited and cannot be expanded. The home file system on LUMI  is simply not meant to install software. However, as LUMI users can have multiple projects there is no easy way to figure out automatically where else to install software.</p> <p>The best place to install software is in your project directory so that it also becomes available for the whole project. After all, a project is meant to be a collaboration between all participants on a scientific problem. You'll need to point LUMI to the right location though and that has to be done by setting the environment variable <code>EBU_USER_PREFIX</code> to point to the location where you want to have your custom installation. Also don't forget to export that variable as otherwise the module system and EasyBuild will not find it when they need it. So a good choice would be  something like  <code>export EBU_USER_PREFIX=/project/project_465000000/EasyBuild</code>.  You have to do this before loading the <code>LUMI</code> module as it is then already used to ensure that user modules are included in the module search path. You can do this in your <code>.bash_profile</code> or <code>.bashrc</code>.  This variable is not only used by EasyBuild-user to know where to install software, but also  by the <code>LUMI</code> - or actually the <code>partition</code> - module to find software so all users in your project who want to use the software should set that variable.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#step-2-configure-the-environment","title":"Step 2: Configure the environment","text":"<p>Once that environment variable is set, all you need to do to activate EasyBuild is to load the <code>LUMI</code> module, load a partition module if you want a different one from the default, and  then load the <code>EasyBuild-user</code> module. In fact, if you switch to a different <code>partition</code>  or <code>LUMI</code> module after loading <code>EasyBuild-user</code> EasyBuild will still be correctly reconfigured  for the new stack and new partition.  Cross-compilation which is installing software for a different partition than the one you're working on does not always work since there is so much software around with installation scripts that don't follow good practices, but when it works it is easy to do on LUMI by simply loading a different partition module than the one that is auto-loaded by the <code>LUMI</code> module.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#step-3-install-the-software","title":"Step 3: Install the software.","text":"<p>Demo moment 2</p> <p></p> <p>Let's look at GROMACS as an example. I will not try to do this completely live though as the  installation takes 15 or 20 minutes. First we need to figure out for which versions of GROMACS we already have support. At the moment we have to use <code>eb -S</code> or <code>eb --search</code> for that. So in our example this is <pre><code>eb --search GROMACS\n</code></pre> This process is not optimal and will be improved in the future. We are developing a system that will instead give an overview of available EasyBuild recipes on the documentation web site.</p> <p>Now let's take the variant <code>GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb</code>.  This is GROMACS 2021.4 with the PLUMED 2.8.0 plugin, build with the Cray compilers from <code>LUMI/22.08</code>, and a build meant for CPU-only systems. The <code>-CPU</code> extension is not always added for CPU-only system, but in case of GROMACS we do expect that GPU builds for LUMI will become available early on in the deployment of LUMI-G so we've already added a so-called version suffix to distinguish between CPU and GPU versions. To install it, we first run  <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb \u2013D\n</code></pre> The <code>-D</code> flag tells EasyBuild to just perform a check for the dependencies that are needed when installing this package, while the <code>-r</code> argument is needed to tell EasyBuild to also  look for dependencies in a preset search path. The search for dependencies is not automatic since there are scenarios where this is not desired and it cannot be turned off as easily as it can be turned on.</p> <p>Looking at the output we see that EasyBuild will also need to install <code>PLUMED</code> for us. But it will do so automatically when we run <pre><code>eb GROMACS-2021.4-cpeCray-22.08-PLUMED-2.8.0-CPU.eb -r\n</code></pre></p> <p>This takes too long to wait for, but once it finished the software should be available and you should be able to see the module in the output of <pre><code>module avail\n</code></pre></p> Demo of the EasyBuild installation of GROMACS <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p> </p> <p>End of demo moment 2</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#step-3-install-the-software-note","title":"Step 3: Install the software - Note","text":"<p>There is a little problem though that you may run into. Sometimes the module does not show up immediately. This is because Lmod keeps a cache when it feels that Lmod searches become too slow and often fails to detect that the cache is outdated. The easy solution is then to simply remove the cache which is in <code>$HOME/.lmod.d/.cache</code>,  which you can do with  <pre><code>rm -rf $HOME/.lmod.d/.cache\n</code></pre> And we have seen some very rare cases where even that did not help likely because some internal data structures in Lmod where corrupt. The easiest way to solve this is to simply log out and log in again and rebuild your environment.</p> <p>Installing software this way is 100% equivalent to an installation in the central software tree. The application is compiled in exactly the same way as we would do and served from the same file systems. But it helps keep the output of <code>module avail</code> reasonably short and focused on your projects, and it puts you in control of installing updates. For instance, we may find out that something in a module does not work for some users and that it needs to be re-installed.  Do this in the central stack and either you have to chose a different name or risk breaking running jobs as the software would become unavailable during the re-installation and also jobs may get confused if they all of a sudden find different binaries. However, have this in your own stack extension and you can update whenever it suits your project best or even not update at all if  you figure out that the problem we discovered has no influence on your work. OFten you also don't need to be an EasyBuild expert to adapt the build recipe to install, e.g., a slgithly different version of the package that better suits your needs.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#more-advanced-work","title":"More advanced work","text":"<p>You can also install some EasyBuild recipes that you got from support. For this it is best to create a subdirectory where you put those files, then go into that directory and run  something like <pre><code>eb my_recipe.eb -r .\n</code></pre> The dot after the <code>-r</code> is very important here as it does tell EasyBuild to also look for  dependencies in the current directory, the directory where you have put the recipes you got from support, but also in its subdirectories so for speed reasons you should not do this just in your home directory but in a subdirectory that only contains those files.</p> <p>In some cases you will have to download sources by hand as packages don't allow to download  software unless you sign in to their web site first. This is the case for a lot of licensed software, for instance, for VASP. We'd likely be in violation of the license if we would put the download somewhere where EasyBuild can find it, and it is also a way for us to ensure that you have a license for VASP. For instance,  <pre><code>eb --search VASP\n</code></pre> will tell you for which versions of VASP we already have build instructions, but you will still have to download the file that the EasyBuild recipe expects. Put it somewhere in a directory, and then from that directory run EasyBuild, for instance for VASP 6.3.0 with the GNU compilers: <pre><code>eb VASP-6.3.2-cpeGNU-22.08.eb -r .\n</code></pre></p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#more-advanced-work-2-repositories","title":"More advanced work (2): Repositories","text":"<p>It is also possible to have your own clone of the <code>LUMI-EasyBuild-contrib</code> GitHub repository in your <code>$EBU_USER_PREFIX</code> subdirectory if you want the latest and greates before it is in the centrally maintained clone of the repository. All you need to do is <pre><code>cd $EBU_USER_PREFIX\ngit clone https://github.com/Lumi-supercomputer/LUMI-EasyBuild-contrib.git\n</code></pre> and then of course keep the repository up to date.</p> <p>And it is even possible to maintain your own GitHub repository. The only restrictions are that it should also be in <code>$EBU_USER_PREFIX</code> and that the subdirectory should be called <code>UserRepo</code>, but that doesn't stop you from using a different name for the repository on GitHub. After cloning your GitHub version you can always change the name of the directory. The structure should also be compatible with the structure that EasyBuild uses, so easyconfig files go in <code>$EBU_USER_PREFIX/easybuild/easyconfigs</code>.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#more-advanced-work-3-reproducibility","title":"More advanced work (3): Reproducibility","text":"<p>EasyBuild also takes care of a high level of reproducibility of installations.</p> <p>It will keep a copy of all the downloaded sources in the <code>$EBU_USER_PREFIX/sources</code> subdirectory, and use that source file again rather than downloading it again. Of course in some cases those \"sources\" could be downloaded tar files with binaries instead as EasyBuild can install downloaded binaries or relocatable RPMs. And if you know the structure of those directories, this is also a place where you could manually put the downloaded installation files for licensed software. Also, there are rare cases in which EasyBuild cannot save the sources because they are automatically downloaded during the installation procedure outside the control of EasyBuild with no way to teach EasyBuild where to download those files and place them to avoid them to be downloaded automatically. This is, e.g., often te case for software written in Rust.</p> <p>Moreover, EasyBuild also keeps copies of all installed easconfig files in two locations.</p> <ol> <li>There is a copy in <code>$EBU_USER_PREFIX/ebrepo_files</code>. And in fact, EasyBuild will use this version     first if you try to re-install and did not delete this version first. This is also a policy     we set on LUMI which has both its advantages and disadvantages. The advantage is that it ensures     that the information that EasyBuild has about the installed application is compatible with what is     in the module files. But the disadvantage of course is that if you install an EasyConfig file     without being in the subdirectory that contains that file, it is easily overlooked that it     is installing based on the EasyConfig in the <code>ebrepo_files</code> subdirectory and not based on the     version of the recipe that you likely changed and is in your user repository or one of the      other repositories that EasyBuild uses.</li> <li>The second copy is with the installed software in <code>$EBU_USER_PREFIX/SW</code> in a subdirectory     called <code>easybuild</code>. This subdirectory is meant to have all information about how EasyBuild     installed the application, also some other files that play a role in the installation process, and hence     to help in reproducing an installation or checking what's in an existing installation. It is     also the directory where you will find the extensive log file with all commands executed during     the installation and their output.</li> </ol>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#easybuild-training-for-advanced-users-and-developers","title":"EasyBuild training for advanced users and developers","text":"<p>Since there were a lot of registrations from local support team members, I want to dedicate one slide to them also.</p> <p>Pointers to all information about EasyBuild can be found on the EasyBuild web site  easybuild.io. This page also includes links to training materials, both written and as recordings on YouTube, and the EasyBuild documentation.</p> <p>Generic EasyBuild training materials are available on  easybuilders.github.io/easybuild-tutorial. The site also contains a LUST-specific tutorial oriented towards Cray systems.</p> <p>In the past we also organised a training for CSC staff and staff from other local support  organisations. The latest version of the training materials is currently available on klust.github.io/easybuild-tutorial.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#containers-on-lumi","title":"Containers on LUMI","text":"<p>Let's now switch to using containers on LUMI.  This section is about using containers on the login nodes and compute nodes.  Some of you may have heard that there were plans to also have an OpenShift Kubernetes container cloud platform for running microservices but at this point it is not clear if and when this will materialize due to a lack of manpower to get this running and then to support this.</p> <p>In this section, we will </p> <ul> <li> <p>discuss what to expect from containers on LUMI: what can they do and what can't they do,</p> </li> <li> <p>discuss how to get a container on LUMI,</p> </li> <li> <p>discuss how to run a container on LUMI,</p> </li> <li> <p>and discuss some enhancements we made to the LUMI environment that are based on containers or help     you use containers.</p> </li> </ul> <p>Remember though that the compute nodes of LUMI are an HPC infrastructure and not a container cloud!</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#what-do-containers-not-provide","title":"What do containers not provide","text":"<p>What is being discussed in this subsection may be a bit surprising. Containers are often marketed as a way to provide reproducible science and as an easy way to transfer software from one machine to another machine. However, containers are neither of those and this becomes  very clear when using containers build on your typical Mellanox/NVIDIA InfiniBand based clusters with Intel processors and NVIDIA GPUs on LUMI.</p> <p>First, computational results are almost never 100% reproducible because of the very nature of how computers work. You can only expect reproducibility of sequential codes between equal hardware. As soon as you change the CPU type, some floating point computations may produce slightly different results, and as soon as you go parallel this may even be the case between two runs on exactly the same hardware and software.</p> <p>But full portability is a much greater myth. Containers are really only guaranteed to be portable between similar systems. They may be a little bit more portable than just a binary as you may be able to deal with missing or different libraries in the container, but that is where it stops. Containers are usually build for a particular CPU architecture and GPU architecture, two elements where everybody can easily see that if you change this, the container will not run. But  there is in fact more: containers talk to other hardware to, and on an HPC system the first piece of hardware that comes to mind is the interconnect. And they use the kernel of the host and the kernel modules and drivers provided by that kernel. Those can be a problem. A container that is not build to support the SlingShot interconnect, may fall back to TCP sockets in MPI, completely killing scalability. Containers that expect the knem kernel extension for good  intra-node MPI performance may not run as efficiently as LUMI uses xpmem instead.</p> <p>Even if a container is portable to LUMI, it may not yet be performance portable. E.g., without proper support for the interconnect it may still run but in a much slower mode. But one should also realise that speed gains in the x86 family over the years come to a large extent from adding new instructions to the CPU set, and that two processors with the same instructions set extensions may still benefit from different optimisations by the compilers.  Not using the proper instruction set extensions can have a lot of influence. At my local site we've seen GROMACS  doubling its speed by choosing proper options, and the difference can even be bigger.</p> <p>Many HPC sites try to build software as much as possible from sources to exploit the available hardware as much as  possible. You may not care much about 10% or 20% performance difference on your PC, but 20% on a 160 million EURO investment represents 32 million EURO and a lot of science can be done for that money...</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#but-what-can-they-then-do-on-lumi","title":"But what can they then do on LUMI?","text":"<ul> <li> <p>A very important reason to use containers on LUMI is reducing the pressure on the file system by software     that accesses many thousands of small files (Python and R users, you know who we are talking about).     That software kills the metadata servers of almost any parallel file system when used at scale.</p> <p>As a container on LUMI is a single file, the metadata servers of the parallel file system have far less  work to do, and all the file caching mechanisms can also work much better.</p> </li> <li> <p>When setting up very large software environments, e.g., some Python and R environments, they can still      be very helpful, even if you may have to change some elements in your build recipes from your regular     cluster or workstation. Some software may also be simply too hard to install from sources in the     typical HPC way of working.</p> </li> <li> <p>And related to the previous point is also that some software may not even be suited for installation in     a multi-user HPC system. HPC systems want a lightweight <code>/usr</code> etc. structure as that part of the system     software is often stored in a RAM disk, and to reduce boot times. Moreover, different users may need     different versions of a software library so it cannot be installed in its default location in the system     library. However, some software is ill-behaved and doesn't allowed to be relocated to a different directory,     and in these cases containers help you to build a private installation that does not interfere with other     software on the system.</p> </li> </ul> <p>Remember though that whenever you use containers, you are the system administrator and not LUST. We can impossibly support all different software that users want to run in containers, and all possible Linux distributions they may want to run in those containers. We provide some advice on how to build a proper container, but if you chose to neglect it it is up to you to solve the problems that occur.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#managing-containers","title":"Managing containers","text":"<p>On LUMI, we currently support only one container runtime.</p> <p>Docker is not available, and will never be on the regular compute nodes as it requires elevated privileges to run the container which cannot be given safely to regular users of the system.</p> <p>Singularity is currently the only supported container runtime and is available on the login nodes and the compute nodes. It is a system command that is installed with the OS, so no module has to be loaded to enable it. We can also offer only a single version of singularity or its close cousin AppTainer  as singularity/AppTainer simply don't support running multiple versions, and currently the version that we offer is determined by what is offered by the OS.</p> <p>To work with containers on LUMI you will either need to pull the container from a container registry, e.g., DockerHub, or bring in the container by copying the singularity <code>.sif</code> file.</p> <p>Singularity does offer a command to pull in a Docker container and to convert it to singularity format. E.g., to pull a container for the Julia language from DockerHub, you'd use</p> <pre><code>singularity pull docker://julia\n</code></pre> <p>Singularity uses a single flat sif file for storing containers. The <code>singularity pull</code> command does the  conversion from Docker format to the singularity format.</p> <p>Singularity caches files during pull operations and that may leave a mess of files in the <code>.singularity</code> cache directory or in <code>$XDG_RUNTIME_DIR</code> (works only on the login nodes).  The former can lead to exhaustion of your storage quota, so check and clean up from time to time. You may also want to clean up <code>$XDG_RUNTIME_DIR</code>, but this directory is also automatically cleaned when you log out from your last running session on that (login) node.</p> Demo singularity pull <p>Let's try the <code>singularity pull docker://julia</code> command:</p> <p> </p> <p>We do get a lot of warnings but usually this is perfectly normal and usually they can be safely ignored.</p> <p> </p> <p>The process ends with the creation of the file <code>jula_latest.sif</code>. </p> <p>Note however that the process has left a considerable number of files in <code>~/.singularity</code> also:</p> <p> </p> <p></p> <p>There is currently no support for building containers on LUMI and I do not expect that to change quickly. It would require enabling some features in the Linux kernel that have seen some very serious security vulnerabilities in recent years.</p> <p>So you should pull containers from a container repository, or build the container on your own workstation and then transfer it to LUMI.</p> <p>We are also working on a number of base images to build upon, where the base images are tested with the OS kernel on LUMI.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#interacting-with-containers","title":"Interacting with containers","text":"<p>There are basically three ways to interact with containers.</p> <p>If you have the sif file already on the system you can enter the container with an interactive shell:</p> <pre><code>singularity shell container.sif\n</code></pre> Demo singularity shell <p> </p> <p>In this screenshot we checked the contents of the <code>/opt</code> directory before and after the <code>singularity shell julia_latest.sif</code> command. This shows that we are clearly in a different environment. Checking the <code>/etc/os-release</code> file only confirms this as LUMI runs SUSE Linux on the login nodes, not a version of Debian.</p> <p>The second way is to execute a command in the container with <code>singularity exec</code>. E.g., assuming the  container has the <code>uname</code> executable installed in it,</p> <pre><code>singularity exec container.sif uname -a\n</code></pre> Demo singularity exec <p> </p> <p>In this screenshot we execute the <code>uname -a</code> command before and with the <code>singularity exec julia_latest.sif</code> command. There are some slight differences in the output though the same kernel version is reported as the container uses the host kernel. Executing</p> <pre><code>singularity exec julia_latest.sif cat /etc/os-release\n</code></pre> <p>confirms though that the commands are executed in the container.</p> <p>The third option is often called running a container, which is done with singularity run:</p> <pre><code>singularity run container.sif\n</code></pre> <p>It does require the container to have a special script that tells singularity what  running a container means. You can check if it is present and what it does with <code>singularity inspect</code>: </p> <pre><code>singularity inspect --runscript container.sif\n</code></pre> Demo singularity run <p> </p> <p>In this screenshot we start the julia interface in the container using <code>singularity run</code>. The second command shows that the contianer indeed includes a script to tell singularity what <code>singularity run</code> should do.</p> <p>You want your container to be able to interact with the files in your account on the system. Singularity will automatically mount <code>$HOME</code>, <code>/tmp</code>, <code>/proc</code>, <code>/sys</code> and <code>dev</code> in the container, but this is not enough as your home directory on LUMI is small and only meant to be used for storing program settings, etc., and not as your main work directory. (And it is also not billed and therefore no extension is allowed.) Most of the time you want to be able to access files in your project directories in <code>/project</code>, <code>/scratch</code> or <code>/flash</code>, or maybe even in <code>/appl</code>. To do this you need to tell singularity to also mount these directories in the container, either using the  <code>--bind src1:dest1,src2:dest2</code>  flag or via the <code>SINGULARITY_BIND</code> or <code>SINGULARITY_BINDPATH</code> environment variables.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#running-containers-on-lumi","title":"Running containers on LUMI","text":"<p>Just as for other jobs, you need to use Slurm to run containers on the compute nodes.</p> <p>For MPI containers one should use <code>srun</code> to run the <code>singularity exec</code> command, e.g,,</p> <pre><code>srun singularity exec --bind ${BIND_ARGS} \\\n${CONTAINER_PATH} mp_mpi_binary ${APP_PARAMS}\n</code></pre> <p>(and replace the environment variables above with the proper bind arguments for <code>--bind</code>, container file and parameters for the command that you want to run in the container).</p> <p>On LUMI, the software that you run in the container should be compatible with Cray MPICH, ie.e, use the MPICH ABI (currently Cray MPICH is based on MPICH 3.4). It is then possible to tell the container to use Cray MPICH (from outside the container) rather than the MPICH variant installed in the container, so that it can offer optimal performance on the LUMI SlingShot 11 interconnect.</p> <p>Open MPI containers are currently not well supported on LUMI and we do not recommend using them. We have no good solutions at the moment to run them with good performance. We only have a partial  solution for the CPU nodes, and on the GPU nodes Open MPI is very problematic at the moment. This is both due to some design issues in the design of Open MPI, and also to some piece of software that recent versions of Open MPI require but that HPE does not yet support on Cray EX systems. Open MPI has a slight preference for the UCX communication library over the OFI libraries, and  currently full GPU support requires UCX. Moreover, binaries using Open MPI often use the so-called rpath linking process so that it becomes a lot harder to inject an Open MPI library that is installed elsewhere. The good news though is that the Open MPI developers of course also want Open MPI to work on biggest systems in the USA, and all three currently operating or planned exascale systems use the SlingShot 11 interconnect so work is going on for better support for OFI and for full GPU support on systems that rely on OFI and do not support UCX.</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#enhancements-to-the-environment","title":"Enhancements to the environment","text":"<p>To make life easier, LUST with the support of CSC did implement some modules that are either based on containers or help you run software with containers.</p> <p>The <code>singularity-bindings/system</code> module which can be installed via EasyBuild helps to set <code>SINGULARITY_BIND</code> and <code>SINGULARITY_LD_LIBRARY__PATH</code> to use  Cray MPICH. Figuring out those settings is tricky, and sometimes changes to the module are needed for a specific situation because of dependency conflicts between Cray MPICH and other software in the container, which is why we don't provide it in the standard software stacks but instead make it available as an EasyBuild recipe that you can adapt to your situation and install.</p> <p>As it needs to be installed through EasyBuild, it is really meant to be  used in the context of a LUMI software stack (so not in <code>CrayEnv</code>). To find the EasyConfig files, load the <code>EasyBuild-user</code> module and  run</p> <pre><code>eb --search singularity-bindings\n</code></pre> <p>Soon you'll also be able to find more information on the design of this module and the contents of the EasyConfig files in the software library documentation that we are developing and that will be made available via the \"Software\" section in the LUMI documentation.</p> <p></p> <p>The second tool is a container that we provide with some bash functions to start a VNC server as temporary way to be able to use some GUI programs on LUMI until the final setup which will be based on Open OnDemand is ready. It can be used in <code>CrayEnv</code> or in the LUMI stacks. The container also contains a poor men's window manager (and yes, we know that there are sometimes some problems with fonts). It is possible to connect to the VNC server either through a regular VNC client on your PC or a web browser, but in both cases you'll have to create an ssh tunnel to access the server. Try</p> <pre><code>module help lumi-vnc\n</code></pre> <p>for more information on how to use <code>lumi-vnc</code>.</p> <p>The final tool is a container wrapper tool that users from Finland may also know as Tykky. It is a tool to wrap Python and conda installations in a limited number of files in a transparent way. On LUMI, it is provided by the <code>lumi-container-wrapper</code> module which is available in the <code>CrayEnv</code> environment and in the LUMI software stacks. It is also documented in the LUMI documentation.</p> <p>The basic idea is that you run a tool to either do a conda installation or an installation of Python packages from a file that defines the environment in either standard conda format (a Yaml file) or in the <code>requirements.txt</code> format used by <code>pip</code>. </p> <p>The container wrapper will then perform the installation in a work directory, create some wrapper commands in the <code>bin</code> subdirectory of the directory where you tell the container wrapper tool to do the installation, and it will use SquashFS to create as single file that contains the conda or Python installation.</p> <p>We do strongly recommend to use the container wrapper tool for larger conda and Python installation. We will not raise your file quota if it is to house such installation in your <code>/project</code> directory.</p> Demo lumi-container-wrapper <p>Create a subdirectory to experiment. In that subdirectory, create a file named <code>env.yml</code> with the content:</p> <pre><code>channels:\n  - conda-forge\ndependencies:\n  - python=3.8.8\n  - scipy\n  - nglview\n</code></pre> <p>and create an empty subdirectory <code>conda-cont-1</code>.</p> <p>|Now you can follow the commands on the slides below:</p> <p> </p> <p>On the slide above we prepared the environment.</p> <p>Now lets run the command </p> <pre><code>conda-containerize new --prefix ./conda-cont-1 env.yml\n</code></pre> <p>and look at the output that scrolls over the screen. The screenshots don't show the full output as some parts of the screen get overwritten during the process:</p> <p> </p> <p>The tool will first build the conda installation in a temprorary work directory and also uses a base container for that purpose.</p> <p> </p> <p> </p> <p>The conda installation itself though is stored in a SquashFS file that is then used by the container.</p> <p> </p> <p> </p> <p>In the slide above we see the installation contains both a singularity container and a SquashFS file. They work together to get a working conda installation.</p> <p>The <code>bin</code> directory seems to contain the commands, but these are in fact scripts  that run those commands in the container with the SquashFS file system mounted in it.</p> <p> </p> <p>So as you can see above, we can simply use the <code>python3</code> command without realising what goes on behind the screen...</p> <p>The wrapper module also offers a pip-based command to build upon the Cray Python modules already present on the system</p>"},{"location":"PEAP-Q-20221123/notes_13_LUMI_Software_Stacks/#conclusion-container-limitations-on-lumi-c","title":"Conclusion: Container limitations on LUMI-C","text":"<p>To conclude the information on using singularity containers on LUMI, we want to repeat the limitations:</p> <ul> <li> <p>Containers use the host's operating system kernel which is likely different and     may have different drivers and kernel extensions than your regular system.     This may cause the container to fail or run with poor performance.</p> </li> <li> <p>The LUMI hardware is almost certainly different from that of the systems on which     you may have used the container before and that may also cause problems.</p> <p>In particular a generic container may not offer sufficiently good support for the  SlingShot 11 interconnect on LUMI which requires OFI (libfabric) with the right  network provider (the so-called Cassini provider) for optimal performance. The software in teh container may fall back to TCP sockets resulting in poor  performance and scalability for communication-heavy programs.</p> <p>For containers with an MPI implementation that follows the MPICH aBI the solution is often to tell it to use the Cray MPICH libraries fro the system instead.</p> </li> <li> <p>Building containers is currently not supported on LUMI due to security concerns.</p> </li> </ul>"},{"location":"PEAP-Q-20221123/schedule/","title":"Course schedule","text":""},{"location":"PEAP-Q-20221123/schedule/#wednesday-november-23","title":"Wednesday November 23","text":"<p>All times CET.</p> 09:30\u00a0\u00a0 Welcome, introduction to the course Presenter: Kurt Lust (LUST) 09:45 Introduction to the HPE Cray Hardware and Programming Environment <ul> <li>The HPE Cray EX hardware architecture and software stack <li>The Cray module environment and compiler wrapper scripts</li> Presenter: Harvey Richardson (HPE) 10:55 break (25 minutes) 11:20 Running Applications <ul> <li>Examples of using the Slurm Batch system, launching jobs on the front end and basic controls for job placement</li> <li>Exercises: about 45 minutes</li> </ul> 12:40 lunch break (80 minutes) 14:00 Compilers and Libraries <ul> <li>An introduction to the compiler suites available</li> <li>How to get additional information about the compilation process</li> <li>Special attention is given the Cray Compilation Environment (CCE) noting options relevant to porting and performance. CCE classic to Clang transition</li> <li>Exercises: about 20 minutes</li> </ul> 15:30 break (30 minutes) 16:00 Advanced Placement <ul> <li>More detailed treatment of Slurm binding technology and OpenMP controls</li> <li>Exercises: about 30 minutes</li> </ul> Presenter: Jean Pourroy 17:00 Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.      17:30 End of first course day"},{"location":"PEAP-Q-20221123/schedule/#thursday-november-24","title":"Thursday November 24","text":"<p>All times CET.</p> 09:30\u00a0\u00a0 Introduction to Perftools,          Performance Analysis Part 1 and Part 2, and          Debugging at Scale <ul> <li>Introduction to perftools</li> <li>Pertfools lite modules</li> <li>Loop work estimates</li> <li>Reveal for performance data display, compiler feedback and automatedscoping</li> <li>Debugging tools at scale</li> </ul> Presenters: Alfio Lazarro and Thierry Braconnier (HPE) 12:15 lunch break (60 minutes) 13:15 MPI Topics on the HPE Cray EX Supercomputer <ul> <li>High level overview of Cray MPI on Slingshot, useful environment variable controls.</li> <li>Rank reordering and MPMD application launch.</li> <li>Exercises: about 20 minutes</li> </ul> Presenter: Harvey Richardson 14:15 Optimizing Large Scale I/O <ul> <li>Introduction into the structure of the Lustre Parallel file system</li> <li>Tips for optimising parallel bandwidth for a variety of parallel I/O schemes</li> <li>Examples of using MPI-IO to improve overall application performance.</li> <li>Advanced Parallel I/O considerations</li> <li>Further considerations of parallel I/O and other APIs.</li> <li>Being nice to Lustre</li> <li>Consideration of how to avoid certain situations in I/O usage that don\u2019t specifically relate to data movement.</li> </ul> Presenter: Harvey Richardson Slide file: <code>/project/project_465000297/slides/12_IO_short_LUMI.pdf</code> on LUMI only. 15:00 break (20 minutes) 15:20 LUMI Software Stacks <ul> <li>Software policy</li> <li>Software environment on LUMI</li> <li>Installing software with EasyBuild (concepts, contributed recipes)</li> <li>Containers for Python, R, VNC (container wrappers)</li> </ul> Presenter: Kurt Lust (LuST) 16:40 LUMI User Support <ul> <li>LUMI documentation</li> <li>What can we help you with and what not? How to get help, how to write good support requests</li> <li>Some typical/frequent support questions of users on LUMI-C?</li> </ul> Presenter: J\u00f8rn Dietze (LUST) 17:10 Open Questions &amp; Answers Participants are encouraged to continue with exercises in case there should be no questions.      17:30 End of second course day"},{"location":"PEAP-Q-20221123/where_to_eat/","title":"Where to eat?","text":"<p>Just some suggestions. There are many more decent restaurants in Brussels especially if you are alone or only with a small group. In general most places that score a 4 or more on Google Maps are decent places. Just some suggestions:</p> <ul> <li>Brasserie des Alexiens (Rue des Alexiens/Cellebroersstraat 63)<ul> <li>Opens only at 7pm</li> <li>The bar La Porte Noir next door is a good option for a beer before or afterwards.</li> </ul> </li> <li>Fin de Sci\u00e8cle (Rue des Chartreux/Kartuizersstraat 9)<ul> <li>The interior may not look nice at all but has character, and the food is good</li> </ul> </li> <li>La porteuse d'eau (Avenue JEan Volders/Jean Voldersslaan 48)<ul> <li>Interesting Art Deco building and interior, and the food is very much OK. It is a bit further away      but still interesting for its architecture. There are more Art Deco restaurants in Brussels,      but this one has the best reputation for the food.</li> <li>Tip: Combine with the nearby bar L'Ermitage Saint-Gilles       (Rue de Moscou/Moskoustraat 34) for a local beer,      or simply have some pub food in the bar.      This bar is from a brewery in Brussels that started the bar elsewhere as the location had become too small.</li> </ul> </li> <li>Moeder Lambic Fontainas (Place Fontainas/Fontainasplein 8) is a good choice for decent food     with a good Belgian beer. They have more than just the stuff from the large breweries.</li> <li>The Rue du March\u00e9 au Charbon/Kolenmarkt is the gay street in Brussels, but it also has some nice places to eat     where nobody has to feel uncomfortable. Brasserie du Lombard on the     corner with the Rue du Lombard/Lombardstraat has nice food. Order at the bar with your drinks.     Le Plattesteen on the opposite corner     has also a decent reputation. Caf\u00e9 Charbon (Rue du March\u00e9 au Charbon/Kolenmarkt 90)     serves good food also, and the daily specials are definitely recommended.</li> <li>Restaurants in the neighbourhood of HOEK 38 that should be OK:<ul> <li>La Tana (Rue de l'Enseignement/Onderrichtsstraat 27)</li> <li>Per Bacco (Rue de l'Enseignement/Onderrichtsstraat 31)</li> <li>La Bottega (Rue de l'Enseignement/Onderrichtsstraat )</li> </ul> </li> <li>Aux Armes de Bruxelles (Rue des Bouchers/Beenhouwersstraat 13)      and Chez L\u00e9on (Rue des Bouchers/Beenhouwersstraat 13) <ul> <li>A very touristic street and with a bad reputation as many of the restaurants are true tourist     traps. But if you want to eat there for the atmosphere of the street, these are two decent     options, each with their own character.</li> </ul> </li> <li>Mozart (Petit Rue des Bouchers/Korte Beenhouwersstraat 18)     Specialises in ribs, and has a good reputation</li> <li>Rue du March\u00e9 aux Fromages/Kaasmarkt is another street with restaurants very much oriented towards     tourists. Contrary to the Rue des Bouchers, even some of the cheap places there serve very decent     food if you're travelling on a budget, e.g., Plaka, Hellas, Saffron and The Blue, and the Italians     in that street also seem to be decent. Baladi, a Syrian restaurant in the nearby Rue des Chapeliers/Hoedenmakerstraat 16,     is definitely worth a visit.</li> </ul>"},{"location":"Profiling-20230413/","title":"HPE and AMD profiling tools (April 13, 2023)","text":""},{"location":"Profiling-20230413/#course-organisation","title":"Course organisation","text":"<ul> <li> <p>Course schedule</p> <p>The full filename for the slides and the video recording of each presentation is also mentioned in that table,  if that file is only available on LUMI.</p> </li> <li> <p>HedgeDoc for questions (during the course only)</p> </li> </ul>"},{"location":"Profiling-20230413/#course-materials","title":"Course materials","text":"Presenatation slides recording Introduction / / Preparing an Application for Hybrid Supercomputing slides recording Introduction to ROC-Profiler (rocprof) slides recording Introduction to OmniTrace slides recording Introduction to Omniperf slides recording Exercises / /"},{"location":"Profiling-20230413/#extras","title":"Extras","text":"<p>Extra downloads:</p> <ul> <li>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but      a browser application. Some browsers nowadays offer the option to install it on your     system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</li> </ul> <p>Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:</p> <ul> <li>vcopy.cpp example from the Omniperf presentation</li> <li>mini-nbody from the rocporf exercise</li> </ul>"},{"location":"Profiling-20230413/00_Introduction/","title":"Introduction","text":"<ul> <li>The video is also available as <code>/appl/local/training/profiling-20230413/recordings/00_Introduction.mp4</code></li> </ul>"},{"location":"Profiling-20230413/00_Introduction/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Can I ask for incresing the home directory capacity?</p> <p>Answer: No. The home directory cannot be extended, not in capacity and not in number of files as it is also the only directory that is not billed. The home directory is only for stricly personal files and typically the type of stuff that Linux software tends to put in home directories such as caches. The project directory is the directory to install software, work on code, etc., and the scratch and flash directory are for temporary data. You can always create a subdirectory for yourself in your project directory and take away the group read rights if you need more personal space.</p> </li> <li> <p><code>/project/project_465000502/slides</code> is empty now, right? Thanks.</p> <p>Answer Yes. HPE tends to upload the slides only at the end of the presentation.            PDF file is now copied.</p> </li> <li> <p>How one can see <code>/project/project_465000502/</code> on LUMI?     When I do <code>ls</code> in the terminal, I do not see this folder.</p> <p>Answer Did you accept the project invite you got earlier this week? And if you have a Finnish user account you will now have a second userid and that is the one you have to use.</p> <p>Did you try to <code>cd</code> into <code>/project/project_465000502</code>? That directory is not a subdirectory of your home directory!</p> <pre><code>cd /project/project_465000502\n</code></pre> </li> </ol>"},{"location":"Profiling-20230413/01_Preparing_an_Application_for_Hybrid_Supercomputing/","title":"Preparing an Application for Hybrid Supercomputing","text":"<ul> <li> <p>Slides in <code>/appl/local/training/profiling-20230413/files/01_Preparing_an_Application_for_Hybrid_Supercomputing.pdf</code></p> </li> <li> <p>Recording in <code>/appl/local/training/profiling-20230413/recordings/00_Introduction.mp4</code></p> </li> </ul>"},{"location":"Profiling-20230413/01_Preparing_an_Application_for_Hybrid_Supercomputing/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Can the tools be used for profiling GPU code which is not directive-based, but written in CUDA/HIP?</p> <p>Answer: Yes, we provide examples in perftools/perftools-for-hip (and clearly CUDA is supported too) and perftools-lite-gpu. Perftools-lite can give output like this for HIP code: <pre><code>Table 2:  Profile by Function Group and Function\n\n  Time% |     Time | Imb. |  Imb. | Team |    Calls | Group\n        |          | Time | Time% | Size |          |  Function=[MAX10]\n        |          |      |       |      |          |   Thread=HIDE\n        |          |      |       |      |          |    PE=HIDE\n\n 100.0% | 0.593195 |   -- |    -- |   -- | 14,960.0 | Total\n|---------------------------------------------------------------------------\n|  57.5% | 0.341232 |   -- |    -- |   -- |     18.0 | HIP\n||--------------------------------------------------------------------------\n||  39.5% | 0.234131 |   -- |    -- |    1 |      3.0 | hipMemcpy\n||  10.2% | 0.060392 |   -- |    -- |    1 |      2.0 | hipMalloc\n||   7.2% | 0.042665 |   -- |    -- |    1 |      1.0 | hipKernel.saxpy_kernel\n||==========================================================================\n</code></pre></p> </li> <li> <p>Completely unrelated to this course, but, is it possible to use all 128GB of GPU memory on the chip from a single GCD? i.e. have processes running on one GCD access memory on the other GCD.</p> <p>Answer Not sure if this is allowed. We never investigated since the performance will be really, really bad. The inter-die bandwidth is low compared to the memory bandwidth. BAsically 200 GB/s read and write (theoretical peak) while the theoretical memory bandwidth of a single die is 1.6 TB/s. </p> <p>Follow up Yes, I appreciate it will be slow, but probably not as slow as swapping back and forwards with main memory? i.e. if I need the full 128GB I can just swap out stuff with DRAM, but that's really, really, really, really bad performance ;). So it'd be 8x slower than on a die, but 8x isn't really really bad. Anyway, I assumed it wasn't supported, just wanted to check if I'd missed something</p> <p>Peter: but if you already have the data in memory on the other GCD, would it not make more sense to do the compute there in-place, rather than waiting for the kernel to finish on GCD 1 and then transfer the data to GCD 2? It is supported in the sense that it will work with managed memory. The kernel on GCD 1 can load data automatically from GCD 2 with decent bandwidth, typically 150 GB/s (see this paper).</p> <p>George: some of the above are true if you use both GCDs, in your case is like you use only one.</p> </li> </ol>"},{"location":"Profiling-20230413/02_Intro_rocprof/","title":"Introduction to ROC-Profiler (rocprof)","text":"<ul> <li> <p>Slides</p> </li> <li> <p>Recording in <code>/appl/local/training/profiling-20230413/recordings/02_Intro_rocprof.mp4</code></p> </li> </ul>"},{"location":"Profiling-20230413/02_Intro_rocprof/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Can the PyTorch profiler be used without any specific things to take into account,      see link?  </p> <p>Answer: </p> <p>That is correct. Let us know if you come across any problems.</p> </li> <li> <p>Could you give a rough estimate on the overhead in terms of percentage?</p> <p>Answer</p> <ul> <li>Generally very low, but can be high in unusual cases.</li> <li>Hard to say exactly what the overhead is, depends usually on the ammount of data being collected. A code with a lot of smaller chunks of GPU activity are usually more pronoe to show more overhead.</li> </ul> </li> </ol>"},{"location":"Profiling-20230413/03_Intro_OmniTrace/","title":"Introduction to OmniTrace","text":"<ul> <li> <p>Slides</p> </li> <li> <p>Recording in <code>/appl/local/training/profiling-20230413/recordings/03_Intro_OmniTrace.mp4</code></p> </li> </ul>"},{"location":"Profiling-20230413/03_Intro_OmniTrace/#remarks","title":"Remarks","text":"<ul> <li>Perfetto, the \"program\" used to visualise the output of omnitrace, is not a regular application but      a browser application. Some browsers nowadays offer the option to install it on your     system in a way that makes it look and behave more like a regular application (Chrome, Edge among others).</li> </ul>"},{"location":"Profiling-20230413/03_Intro_OmniTrace/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Since there is support for OpenCL, does it support also SYCL? Or it will in the future?</p> <p>Answer</p> <ul> <li>There currently no plans to support the SYCL programming models in the AMD tools. For SYCL you'd have to rely on the HIP/HSA activity it generates.</li> <li>Peter: I have tested HipSYCL code with rocprof, and you can see the kernels launching.</li> <li>OpenSYCL uses HIP for AMD GPUs, so it should be able to track.</li> </ul> </li> <li> <p>On LUMI ROCm is only available on LUMI-G, correct? What about onmitrace/perf? Is this available on LUMI-C?</p> <p>Answer</p> <ul> <li>Omnitrace could eventually be used to sample CPU code - omniperf is useless in no-GPU systems.      These tools are not generally available but can be easily installed as indicated in the presentations.</li> <li>The AMD \u03bcProf tool is used for the AMD CPUs. </li> <li>The ROCm modules are available on LUMI-C and the login nodes also, but there was a problem with versions      before the maintenance. If these tools connect to GPU-specific device drivers though they will fail on non-GPU nodes.</li> </ul> </li> <li> <p>What is a reasonable maximum number of mpi processes for omnitrace/perf to deal with?</p> <p>Answer</p> <ul> <li>Omniperf needs application replaying to collect multiple counters so the application would have to be replayed equally in all ranks. Omnitrace as MPI trace features and can use wil multiple ranks. In general, you'd be interested in profiling at the scale that is relevant for you and then maybe focus on more problematic/representative ranks, i.e. activate profile on only a given rank or set of ranks while using multiple ranks.</li> <li>A related question is how many MPI ranks to use per GPU - this depends but usually a rank por GCD is the choice for many apps. You can use more and the runtime/driver is ready for it without any requires wrapping. My recommendation however is to use ROCm 5.4+ if the intent is to overpopulate the GCDs with ranks.</li> <li>Omniperf requires 1 MPI process only. Omnitrace, can be large, not sure what limit except how to analyze the data.</li> </ul> </li> <li> <p>Can you track memory usage with these tools? Thanks, will it give you maximum memory usage and where the memory is allocated in the code? Thanks</p> <p>Answer</p> <ul> <li>Yes, omnitrace samples memory usage. </li> </ul> </li> </ol>"},{"location":"Profiling-20230413/04_Intro_OmniPerf/","title":"Introduction to Omniperf","text":"<ul> <li> <p>Slides</p> </li> <li> <p>Recording in <code>/appl/local/training/profiling-20230413/recordings/04_Intro_OmniPerf.mp4</code></p> </li> </ul>"},{"location":"Profiling-20230413/04_Intro_OmniPerf/#remarks","title":"Remarks","text":"<p>Warning</p> <p>For security reasons it is best to run <code>omniperf analyze</code> on a single user machine that  is protected by a firewall (which is why we do not want to install it visibly on LUMI).  It opens an unprotected port to a webserver so everybody with access to LUMI can easily  guess the port number and get access to some of your data that way.</p>"},{"location":"Profiling-20230413/04_Intro_OmniPerf/#qa","title":"Q&amp;A","text":"<ol> <li> <p>Not related to omniperf. On <code>tranining/exercises/HPE/openacc-mpi-demos</code> after doing <code>sbatch job.slurm</code>.     <pre><code>srun: error: CPU binding outside of job step allocation, allocated CPUs are: 0x01FFFFFFFFFFFFFE01FFFFFFFFFFFFFE.\nsrun: error: Task launch for StepId=3372350.2 failed on node nid007281: Unable to satisfy cpu bind request\nsrun: error: Application launch failed: Unable to satisfy cpu bind request\n</code></pre></p> <p>Answer</p> <ul> <li>let me fix it, I will report here when it is done (for the record, this is due to the today's change in Slurm)... done, please check.<ul> <li>what change in slurm happened today?</li> <li>LUMI admins somehow reverted a change in Slurm that came in with the update where SLURM no longer propagates cpus-per-task if set in an SBATCH job comment into the srun. The old behaviour was restored but we tested the scripts yesterday. There was a user email this morning.</li> </ul> </li> </ul> </li> <li> <p>Slide 43, the kernels performance are good or not? There is a threshold in terms of distance from boundaries?</p> <p>Answer</p> <p>Will be in the recording. The performance is not very good (and take into account the scales are logarithmic so the dots are very far from the boundary).</p> </li> </ol>"},{"location":"Profiling-20230413/05_Exercises/","title":"Exercises","text":"<ul> <li> <p>Files for the exercises are available in      <code>/appl/local/training/profiling-20230413/files/exercises-profiling-20230423.tar.gz</code></p> </li> <li> <p>Exercises from HPE are available in     <code>/appl/local/training/profiling-20230413/files/05_Exercises_HPE.pdf</code></p> </li> <li> <p>AMD exercidses are available as an online text     (local web copy(PDF))     or as <code>/appl/local/training/profiling-20230413/files/05_LUMI-G_Pre-Hackathon-AMD.pdf</code></p> </li> <li> <p>Extra software that was made available by AMD is available in     <code>/appl/local/training/profiling-20230413/files/software-profiling-20230423.tar.gz</code>.     As the configuration of LUMI is continuously evolving, this software may not work anymore.</p> </li> </ul>"},{"location":"Profiling-20230413/05_Exercises/#qa","title":"Q&amp;A","text":"<p>Info</p> <p>AMD Exercises</p> <p>You can find the instructions in this HackMD document</p> <p>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000502/exercises/HPE/lumi_g.sh</code> Note however that this script is for the reservation made for the course and needs to be adapted afterwards.</p> <p>Info</p> <p>HPE Exercises</p> <ul> <li>Exercise notes and files including pdf and Readme with instructions on LUMI are in the <code>exercises/HPE</code>     subdirectory after untarring the files for the exercises.</li> <li>General examples<ul> <li>Directories: openacc-mpi-demos, BabelStream \u2013   Try different parallel offload programming models (OpenACC, OpenMP, HIP) and examples</li> </ul> </li> <li> <p>Tests based on the HIMENO benchmark</p> <ul> <li>Directory: cray_acc_debug</li> <li>Directory: compiler_listings</li> </ul> </li> <li> <p>In some exercises you have source additional files to load the right modules necessary, check the README file.</p> </li> <li> <p>Follow the Readme.md files in each subfolder</p> </li> </ul> <ol> <li> <p>I am stuck on the first AMD one.</p> <ul> <li>I can compile the nbody-orig, and it runs without srun. With srun, it dies with <code>\"hipErrorNoBinaryForGpu: Unable to find code object for all current devices!\"</code></li> <li>What does the <code>-DSHMOO</code> flag mean for the hip compiler?</li> <li>If I run <code>rocprof --stats nbody-orig 65536</code> (no srun), it dies with <code>Exception: Could not run command: \"rocminfo\"</code></li> </ul> <p>Answer</p> <ul> <li> <p>Please add <code>--offload-arch=gfx90a</code> in the compilation. </p> <pre><code>hipcc --offload-arch=gfx90a -I../ -DSHMOO nbody-orig.cpp -o nbody-orig\n</code></pre> </li> <li> <p><code>-D</code> is the compiler flag for a C language family compiler to define a symbol for the preprocessor.</p> </li> </ul> </li> <li> <p>I did not get if Omnitrace is available from a module on LUMI or not, sorry! Should I install it?</p> <p>Answer</p> <p>No official module currently that fits nicely in the software stack, but for the exercises you can use</p> <pre><code>module use /project/project_465000502/software/omnitrace192/share/modulefiles/\nmodule load omnitrace/1.9.2\n</code></pre> </li> <li> <p>How can i get access to omniperf on LUMI?</p> <p>Answer</p> <p><pre><code>module use /project/project_465000502/software/omnitrace192/share/modulefiles/\nmodule load omnitrace/1.9.2\n</code></pre> <pre><code>module load cray-python\nmodule use /project/project_465000502/software/omniperf108/modules\nmodule load omniperf\nexport ROOFLINE_BIN=/project/project_465000502/software/omniperf108/bin/utils/rooflines/roofline-sle15sp3-mi200-rocm5\n</code></pre></p> <p>No plans to have it officially available due to the security issues mentioned earlier in this document.</p> </li> <li> <p>I'm having a problem with perftools and OpenACC code</p> <pre><code>Instrumented code exits with \"pat[WARNING][0]: abort process 72108 because of signal 6 ...\"\n</code></pre> <p>This happens both with \"perftools-lite-gpu\" as well as with \"perftools\" + \"pat_build\". Uninstrumented code works fine.</p> <ul> <li>Can you try the latest perftools modules. You will have to unload them (including perftools-base) and reload the newer ones </li> </ul> <p>Same with perftools-base/23.03.0</p> <ul> <li>Could you share the code? </li> </ul> <p>Simple heat-equation toy code: https://github.com/cschpc/heat-equation I was using the \"3d/openacc/fortran\" version</p> <ul> <li> <p>I've tried with the following steps:</p> <pre><code>git clone https://github.com/cschpc/heat-equation\ncd heat-equation/3d/openacc/fortran\nmodule load PrgEnv-cray\nmodule swap cce cce/15.0.1 # better use always the newest compiler\nmodule load craype-accel-amd-gfx90a rocm\nmodule load perftools-lite-gpu\nmake COMP=cray\nsrun -n 1 --gres=gpu:8 ./heat_openacc\n</code></pre> <p>And got the error... </p> </li> <li> <p>I will file a ticket for that...</p> </li> <li> <p>(Harvey) Started to look at this, need to be sure the Fortran is valid first (checked: looks fine, the USEs have no circular chain). I'm sure I will run out of time so please put in the ticket.</p> </li> </ul> </li> <li> <p>Can I use the cray compiler with rocprof?</p> <ul> <li>I tried with an example and it works, I assume it could depend on what you want to do.</li> </ul> <p>I would like to trace my application; I tried in the past but I did not manage to produce a .csv file for PERFETTO. I am trying again, </p> <p>I used:</p> <pre><code>module load craype-accel-amd-gfx90a\nCC -x hip -o vcopy vcopy.cpp -L/opt/rocm/lib/ -lamdhip64\nsrun -n 1 rocprof --hip-trace ./vcopy 1048576 256\n</code></pre> <p>I get some errors I can not understand, regarding a HSA table already existing. I added -t ${PWD} to use the current directory, I see the temporary directories created but I get the same error and the directories contain only some .txt files</p> <p><pre><code>Traceback (most recent call last):\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/tblextr.py\", line 833, in &lt;module&gt;\n    hsa_trace_found = fill_api_db('HSA', db, indir, 'hsa', HSA_PID, COPY_PID, kern_dep_list, {}, 0)\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/tblextr.py\", line 406, in fill_api_db\n    table_handle = db.add_table(table_name, api_table_descr)\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/sqlitedb.py\", line 48, in add_table\n    cursor.execute(stm)\nsqlite3.OperationalError: table HSA already exists \n    Profiling data corrupted: ' /users/bellenta/work_dir/rocm/rpl_data_230413_165341_47398/input_results_230413_165341/results.txt \n</code></pre> I deleted a results.db present in the directory, and now I see a results.csv file together with others (however still errors in the logfile).. maybe there is a flag to overwrite</p> <ul> <li>This seems like rocprof get killes, can you provide the used command?</li> </ul> <p><code>srun -N ${SLURM_NNODES} -n 4 rocprof -t ${PWD} --hip-trace --hsa-trace ./pw.x -i atom.in &gt; atom.out.${SLURM_JOBID} 2&gt;&amp;</code></p> <ul> <li>Do you have the slides, you need to use a wrapper for multiple processes, could you try with 1 process?</li> </ul> <p>Before I was using the wrapper, and it wasn't working as well but I'll try again. However, now without the wrapper I see a different folder for each mpi rank and it reports an error regarding profiling data corruption, maybe something in the code... </p> <ul> <li>Yes it is because is more than 1 process, if you try 1 process, it works, right? </li> </ul> <p>yes! by launching with one process only, so no MPI distribution</p> <ul> <li> <p>It needs the wrapper, I believe.</p> <pre><code>WORK_DIR=${PWD}\nif [[ \"$SLURM_PROCID\" == 0 ]]; then\n    rocprof -t ${WORK_DIR} --hsa-trace --hip-trace \\\n            ./pw.x -i atom.in\nelse\n            ./pw.x -i atom.in\nfi\n</code></pre> </li> <li> <p>This will isntrument only process 0, it depends on what you want to do.</p> </li> </ul> <p>This worked, thank you very much! I want to see data movements which should be the same for each MPI rank. Is it feasible to see all the GPUs together with rocprof?</p> <ul> <li>Omnitrace would be better </li> </ul> </li> <li> <p>Trying out some code of my own I get this error when running \"MPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked\", is this a compile time issue?</p> <p>Answer</p> <ul> <li> <p>Are you using hipcc? add this:</p> <pre><code>module load craype-accel-amd-gfx90a\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\n-I${MPICH_DIR}/include\n-L${MPICH_DIR}/lib -lmpi ${PE_MPICH_GTL_DIR_amd_gfx90a} ${PE_MPICH_GTL_LIBS_amd_gfx90a}\n</code></pre> </li> </ul> </li> <li> <p>Perftools information for HIP code is not very useful</p> <p>I was playing with simple C++ heat-equation toy code https://github.com/cschpc/heat-equation (3d/hip version), which launches kernels asynchronously. Pat_report shows all the time being spent in hipDeviceSynchronize, instead of the actual kernels: <pre><code>||  56.9% |  7.172922 |   -- |    -- |    500.0 | hipDeviceSynchronize\n...\n||   0.0% |  0.001363 |   -- |    -- |    500.0 | hipKernel.evolve_interior_kernel\n||   0.0% |  0.001353 |   -- |    -- |    500.0 | hipKernel.evolve_z_edges_kernel\n||   0.0% |  0.001325 |   -- |    -- |    500.0 | hipKernel.evolve_x_edges_kernel\n||   0.0% |  0.001306 |   -- |    -- |    500.0 | hipKernel.evolve_y_edges_kernel\n</code></pre></p> <p>Is there way to get the time actually spent in kernels?</p> <ul> <li>Is this tracing? (<code>-w</code> flag for pat_build) You can also decide to mask a function (<code>-T</code> flag). Check man pat_build for more info.</li> <li>You can collect timeseries data (PAT_RT_SUMMARY=0) and view a timeline in apprentice2 and this can show kernels. </li> </ul> <p>Thanks, with tracing and timeseries apprentice2 does not show Time Line but gives \"Data server terminated\" error</p> </li> <li> <p>Omnitrace-instrument seems to take ages to launch for the Jacobi example. Waitng about 10 mins now. Is it normal?</p> <ul> <li>I assume dynamic instrumentation? yes</li> <li>Do binary rewriting, I think the storage is not performing well</li> </ul> <p>Thanks. Is there somewhere I can read about what this dynamic instrumetation means vs (I guess) static? I am a newbie :-) </p> <ul> <li>In the slides there is a command with <code>--simulate</code> that show sall the libraries that access the dynamic instrumentation and they are a lot, so the binary rewriting makes profiling accessing onlyt he required libraries which are minimal.</li> </ul> </li> <li> <p>I managed to get a roofline plot using the saxpy example, meaning that i can see the kernel \"points\" on the plot. However, i can't do the same with the <code>vcopy</code> example. I mean, it generates a report, so i guess that it works, but it does not show any point on the plot. Can you think of a reason about it? EDIT: because it doesn't have FP operation i guess... </p> <ul> <li>Yes, vcopy has 0 FLOPs, check more the other things than roofline for vcopy</li> </ul> <p>I changed it to use dgemm</p> </li> </ol>"},{"location":"Profiling-20230413/hedgedoc_notes/","title":"Notes from the HedgeDoc document","text":""},{"location":"Profiling-20230413/hedgedoc_notes/#questions-regarding-course-organisation-or-lumi-in-general","title":"Questions regarding course organisation or LUMI in general","text":"<ol> <li> <p>Can I ask for incresing the home directory capacity?</p> <p>Answer: No. The home directory cannot be extended, not in capacity and not in number of files as it is also the only directory that is not billed. The home directory is only for stricly personal files and typically the type of stuff that Linux software tends to put in home directories such as caches. The project directory is the directory to install software, work on code, etc., and the scratch and flash directory are for temporary data. You can always create a subdirectory for yourself in your project directory and take away the group read rights if you need more personal space.</p> </li> <li> <p><code>/project/project_465000502/slides</code> is empty now, right? Thanks.</p> <p>Answer Yes. HPE tends to upload the slides only at the end of the presentation.            PDF file is now copied.</p> </li> <li> <p>How one can see <code>/project/project_465000502/</code> on LUMI?     When I do <code>ls</code> in the terminal, I do not see this folder.</p> <p>Answer Did you accept the project invite you got earlier this week? And if you have a Finnish user account you will now have a second userid and that is the one you have to use.</p> <p>Did you try to <code>cd</code> into <code>/project/project_465000502</code>? That directory is not a subdirectory of your home directory!</p> <pre><code>cd /project/project_465000502\n</code></pre> </li> </ol>"},{"location":"Profiling-20230413/hedgedoc_notes/#hpe-cray-pe-tools","title":"HPE Cray PE tools","text":"<ol> <li> <p>Can the tools be used for profiling GPU code which is not directive-based, but written in CUDA/HIP?</p> <p>Answer: Yes, we provide examples in perftools/perftools-for-hip (and clearly CUDA is supported too) and perftools-lite-gpu. Perftools-lite can give output like this for HIP code: <pre><code>Table 2:  Profile by Function Group and Function\n\n  Time% |     Time | Imb. |  Imb. | Team |    Calls | Group\n        |          | Time | Time% | Size |          |  Function=[MAX10]\n        |          |      |       |      |          |   Thread=HIDE\n        |          |      |       |      |          |    PE=HIDE\n\n 100.0% | 0.593195 |   -- |    -- |   -- | 14,960.0 | Total\n|---------------------------------------------------------------------------\n|  57.5% | 0.341232 |   -- |    -- |   -- |     18.0 | HIP\n||--------------------------------------------------------------------------\n||  39.5% | 0.234131 |   -- |    -- |    1 |      3.0 | hipMemcpy\n||  10.2% | 0.060392 |   -- |    -- |    1 |      2.0 | hipMalloc\n||   7.2% | 0.042665 |   -- |    -- |    1 |      1.0 | hipKernel.saxpy_kernel\n||==========================================================================\n</code></pre></p> </li> <li> <p>Completely unrelated to this course, but, is it possible to use all 128GB of GPU memory on the chip from a single GCD? i.e. have processes running on one GCD access memory on the other GCD.</p> <p>Answer Not sure if this is allowed. We never investigated since the performance will be really, really bad. The inter-die bandwidth is low compared to the memory bandwidth. BAsically 200 GB/s read and write (theoretical peak) while the theoretical memory bandwidth of a single die is 1.6 TB/s. </p> <p>Follow up Yes, I appreciate it will be slow, but probably not as slow as swapping back and forwards with main memory? i.e. if I need the full 128GB I can just swap out stuff with DRAM, but that's really, really, really, really bad performance ;). So it'd be 8x slower than on a die, but 8x isn't really really bad. Anyway, I assumed it wasn't supported, just wanted to check if I'd missed something</p> <p>Peter: but if you already have the data in memory on the other GCD, would it not make more sense to do the compute there in-place, rather than waiting for the kernel to finish on GCD 1 and then transfer the data to GCD 2? It is supported in the sense that it will work with managed memory. The kernel on GCD 1 can load data automatically from GCD 2 with decent bandwidth, typically 150 GB/s (see this paper).</p> <p>George: some of the above are true if you use both GCDs, in your case is like you use only one.</p> </li> </ol>"},{"location":"Profiling-20230413/hedgedoc_notes/#amd-rocm-profiling-tools","title":"AMD ROCM profiling tools","text":""},{"location":"Profiling-20230413/hedgedoc_notes/#rocprof","title":"ROCProf","text":"<ol> <li> <p>Can the PyTorch profiler be used without any specific things to take into account,      see link?  </p> <p>Answer: </p> <p>That is correct. Let us know if you come across any problems.</p> </li> <li> <p>Could you give a rough estimate on the overhead in terms of percentage?</p> <p>Answer</p> <ul> <li>Generally very low, but can be high in unusual cases.</li> <li>Hard to say exactly what the overhead is, depends usually on the ammount of data being collected. A code with a lot of smaller chunks of GPU activity are usually more pronoe to show more overhead.</li> </ul> </li> </ol>"},{"location":"Profiling-20230413/hedgedoc_notes/#omnitrace","title":"Omnitrace","text":"<ol> <li> <p>Since there is support for OpenCL, does it support also SYCL? Or it will in the future?</p> <p>Answer</p> <ul> <li>There currently no plans to support the SYCL programming models in the AMD tools. For SYCL you'd have to rely on the HIP/HSA activity it generates.</li> <li>Peter: I have tested HipSYCL code with rocprof, and you can see the kernels launching.</li> <li>OpenSYCL uses HIP for AMD GPUs, so it should be able to track.</li> </ul> </li> <li> <p>On LUMI ROCm is only available on LUMI-G, correct? What about onmitrace/perf? Is this available on LUMI-C?</p> <p>Answer</p> <ul> <li>Omnitrace could eventually be used to sample CPU code - omniperf is useless in no-GPU systems.      These tools are not generally available but can be easily installed as indicated in the presentations.</li> <li>The AMD \u03bcProf tool is used for the AMD CPUs. </li> <li>The ROCm modules are available on LUMI-C and the login nodes also, but there was a problem with versions      before the maintenance. If these tools connect to GPU-specific device drivers though they will fail on non-GPU nodes.</li> </ul> </li> <li> <p>What is a reasonable maximum number of mpi processes for omnitrace/perf to deal with?</p> <p>Answer</p> <ul> <li>Omniperf needs application replaying to collect multiple counters so the application would have to be replayed equally in all ranks. Omnitrace as MPI trace features and can use wil multiple ranks. In general, you'd be interested in profiling at the scale that is relevant for you and then maybe focus on more problematic/representative ranks, i.e. activate profile on only a given rank or set of ranks while using multiple ranks.</li> <li>A related question is how many MPI ranks to use per GPU - this depends but usually a rank por GCD is the choice for many apps. You can use more and the runtime/driver is ready for it without any requires wrapping. My recommendation however is to use ROCm 5.4+ if the intent is to overpopulate the GCDs with ranks.</li> <li>Omniperf requires 1 MPI process only. Omnitrace, can be large, not sure what limit except how to analyze the data.</li> </ul> </li> <li> <p>Can you track memory usage with these tools? Thanks, will it give you maximum memory usage and where the memory is allocated in the code? Thanks</p> <p>Answer</p> <ul> <li>Yes, omnitrace samples memory usage. </li> </ul> </li> </ol>"},{"location":"Profiling-20230413/hedgedoc_notes/#omniperf","title":"Omniperf","text":"<ol> <li> <p>Not related to omniperf. On <code>tranining/exercises/HPE/openacc-mpi-demos</code> after doing <code>sbatch job.slurm</code>.     <pre><code>srun: error: CPU binding outside of job step allocation, allocated CPUs are: 0x01FFFFFFFFFFFFFE01FFFFFFFFFFFFFE.\nsrun: error: Task launch for StepId=3372350.2 failed on node nid007281: Unable to satisfy cpu bind request\nsrun: error: Application launch failed: Unable to satisfy cpu bind request\n</code></pre></p> <p>Answer</p> <ul> <li>let me fix it, I will report here when it is done (for the record, this is due to the today's change in Slurm)... done, please check.<ul> <li>what change in slurm happened today?</li> <li>LUMI admins somehow reverted a change in Slurm that came in with the update where SLURM no longer propagates cpus-per-task if set in an SBATCH job comment into the srun. The old behaviour was restored but we tested the scripts yesterday. There was a user email this morning.</li> </ul> </li> </ul> </li> <li> <p>Slide 43, the kernels performance are good or not? There is a threshold in terms of distance from boundaries?</p> <p>Answer</p> <p>Will be in the recording. The performance is not very good (and take into account the scales are logarithmic so the dots are very far from the boundary).</p> </li> </ol> <p>Warning</p> <p>For security reasons it is best to run <code>omniperf analyze</code> on a single user machine that  is protected by a firewall (which is why we do not want to install it visibly on LUMI).  It opens an unprotected port to a webserver so everybody with access to LUMI can easily  guess the port number and get access to some of your data that way.</p>"},{"location":"Profiling-20230413/hedgedoc_notes/#exercises","title":"Exercises","text":"<p>Info</p> <p>AMD Exercises</p> <p>You can find the instructions in this HackMD document</p> <p>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000502/exercises/HPE/lumi_g.sh</code> Note however that this script is for the reservation made for the course and needs to be adapted afterwards.</p> <p>Info</p> <p>HPE Exercises -   Exercise notes and files including pdf and Readme with instructions on LUMI at <code>/project/project_465000502/exercises/HPE/</code> -   General examples     -   Directories: openacc-mpi-demos, BabelStream     \u2013   Try different parallel offload programming models (OpenACC, OpenMP, HIP) and examples -   Tests based on the HIMENO benchmark     -   Directory: cray_acc_debug     -   Directory: compiler_listings</p> <ul> <li>Copy the files to your home or project folder before working on the exercises.</li> <li> <p>In some exercises you have source additional files to load the right modules necessary, check the README file.</p> </li> <li> <p>Follow the Readme.md files in each subfolder</p> </li> <li> <p>To run slurm jobs, set the necessary variables for this course by <code>source /project/project_465000502/exercises/HPE/lumi_g.sh</code>.     Note however that this script is for the reservation made for the course and needs to be adapted afterwards.</p> </li> </ul> <ol> <li> <p>I am stuck on the first AMD one.</p> <ul> <li>I can compile the nbody-orig, and it runs without srun. With srun, it dies with <code>\"hipErrorNoBinaryForGpu: Unable to find code object for all current devices!\"</code></li> <li>What does the <code>-DSHMOO</code> flag mean for the hip compiler?</li> <li>If I run <code>rocprof --stats nbody-orig 65536</code> (no srun), it dies with <code>Exception: Could not run command: \"rocminfo\"</code></li> </ul> <p>Answer</p> <ul> <li> <p>Please add <code>--offload-arch=gfx90a</code> in the compilation. </p> <pre><code>hipcc --offload-arch=gfx90a -I../ -DSHMOO nbody-orig.cpp -o nbody-orig\n</code></pre> </li> <li> <p><code>-D</code> is the compiler flag for a C language family compiler to define a symbol for the preprocessor.</p> </li> </ul> </li> <li> <p>I did not get if Omnitrace is available from a module on LUMI or not, sorry! Should I install it?</p> <p>Answer</p> <p>No official module currently that fits nicely in the software stack, but for the exercises you can use</p> <pre><code>module use /project/project_465000502/software/omnitrace192/share/modulefiles/\nmodule load omnitrace/1.9.2\n</code></pre> </li> <li> <p>How can i get access to omniperf on LUMI?</p> <p>Answer</p> <p><pre><code>module use /project/project_465000502/software/omnitrace192/share/modulefiles/\nmodule load omnitrace/1.9.2\n</code></pre> <pre><code>module load cray-python\nmodule use /project/project_465000502/software/omniperf108/modules\nmodule load omniperf\nexport ROOFLINE_BIN=/project/project_465000502/software/omniperf108/bin/utils/rooflines/roofline-sle15sp3-mi200-rocm5\n</code></pre></p> <p>No plans to have it officially available due to the security issues mentioned earlier in this document.</p> </li> <li> <p>I'm having a problem with perftools and OpenACC code</p> <pre><code>Instrumented code exits with \"pat[WARNING][0]: abort process 72108 because of signal 6 ...\"\n</code></pre> <p>This happens both with \"perftools-lite-gpu\" as well as with \"perftools\" + \"pat_build\". Uninstrumented code works fine.</p> <ul> <li>Can you try the latest perftools modules. You will have to unload them (including perftools-base) and reload the newer ones </li> </ul> <p>Same with perftools-base/23.03.0</p> <ul> <li>Could you share the code? </li> </ul> <p>Simple heat-equation toy code: https://github.com/cschpc/heat-equation I was using the \"3d/openacc/fortran\" version</p> <ul> <li> <p>I've tried with the following steps:</p> <pre><code>git clone https://github.com/cschpc/heat-equation\ncd heat-equation/3d/openacc/fortran\nmodule load PrgEnv-cray\nmodule swap cce cce/15.0.1 # better use always the newest compiler\nmodule load craype-accel-amd-gfx90a rocm\nmodule load perftools-lite-gpu\nmake COMP=cray\nsrun -n 1 --gres=gpu:8 ./heat_openacc\n</code></pre> <p>And got the error... </p> </li> <li> <p>I will file a ticket for that...</p> </li> <li> <p>(Harvey) Started to look at this, need to be sure the Fortran is valid first (checked: looks fine, the USEs have no circular chain). I'm sure I will run out of time so please put in the ticket.</p> </li> </ul> </li> <li> <p>Can I use the cray compiler with rocprof?</p> <ul> <li>I tried with an example and it works, I assume it could depend on what you want to do.</li> </ul> <p>I would like to trace my application; I tried in the past but I did not manage to produce a .csv file for PERFETTO. I am trying again, </p> <p>I used:</p> <pre><code>module load craype-accel-amd-gfx90a\nCC -x hip -o vcopy vcopy.cpp -L/opt/rocm/lib/ -lamdhip64\nsrun -n 1 rocprof --hip-trace ./vcopy 1048576 256\n</code></pre> <p>I get some errors I can not understand, regarding a HSA table already existing. I added -t ${PWD} to use the current directory, I see the temporary directories created but I get the same error and the directories contain only some .txt files</p> <p><pre><code>Traceback (most recent call last):\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/tblextr.py\", line 833, in &lt;module&gt;\n    hsa_trace_found = fill_api_db('HSA', db, indir, 'hsa', HSA_PID, COPY_PID, kern_dep_list, {}, 0)\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/tblextr.py\", line 406, in fill_api_db\n    table_handle = db.add_table(table_name, api_table_descr)\n    File \"/pfs/lustrep3/appl/lumi/SW/LUMI-22.08/G/EB/rocm/5.3.3/libexec/rocprofiler/sqlitedb.py\", line 48, in add_table\n    cursor.execute(stm)\nsqlite3.OperationalError: table HSA already exists \n    Profiling data corrupted: ' /users/bellenta/work_dir/rocm/rpl_data_230413_165341_47398/input_results_230413_165341/results.txt \n</code></pre> I deleted a results.db present in the directory, and now I see a results.csv file together with others (however still errors in the logfile).. maybe there is a flag to overwrite</p> <ul> <li>This seems like rocprof get killes, can you provide the used command?</li> </ul> <p><code>srun -N ${SLURM_NNODES} -n 4 rocprof -t ${PWD} --hip-trace --hsa-trace ./pw.x -i atom.in &gt; atom.out.${SLURM_JOBID} 2&gt;&amp;</code></p> <ul> <li>Do you have the slides, you need to use a wrapper for multiple processes, could you try with 1 process?</li> </ul> <p>Before I was using the wrapper, and it wasn't working as well but I'll try again. However, now without the wrapper I see a different folder for each mpi rank and it reports an error regarding profiling data corruption, maybe something in the code... </p> <ul> <li>Yes it is because is more than 1 process, if you try 1 process, it works, right? </li> </ul> <p>yes! by launching with one process only, so no MPI distribution</p> <ul> <li> <p>It needs the wrapper, I believe.</p> <pre><code>WORK_DIR=${PWD}\nif [[ \"$SLURM_PROCID\" == 0 ]]; then\n    rocprof -t ${WORK_DIR} --hsa-trace --hip-trace \\\n            ./pw.x -i atom.in\nelse\n            ./pw.x -i atom.in\nfi\n</code></pre> </li> <li> <p>This will isntrument only process 0, it depends on what you want to do.</p> </li> </ul> <p>This worked, thank you very much! I want to see data movements which should be the same for each MPI rank. Is it feasible to see all the GPUs together with rocprof?</p> <ul> <li>Omnitrace would be better </li> </ul> </li> <li> <p>Trying out some code of my own I get this error when running \"MPIDI_CRAY_init: GPU_SUPPORT_ENABLED is requested, but GTL library is not linked\", is this a compile time issue?</p> <p>Answer</p> <ul> <li> <p>Are you using hipcc? add this:</p> <pre><code>module load craype-accel-amd-gfx90a\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\n-I${MPICH_DIR}/include\n-L${MPICH_DIR}/lib -lmpi ${PE_MPICH_GTL_DIR_amd_gfx90a} ${PE_MPICH_GTL_LIBS_amd_gfx90a}\n</code></pre> </li> </ul> </li> <li> <p>Perftools information for HIP code is not very useful</p> <p>I was playing with simple C++ heat-equation toy code https://github.com/cschpc/heat-equation (3d/hip version), which launches kernels asynchronously. Pat_report shows all the time being spent in hipDeviceSynchronize, instead of the actual kernels: <pre><code>||  56.9% |  7.172922 |   -- |    -- |    500.0 | hipDeviceSynchronize\n...\n||   0.0% |  0.001363 |   -- |    -- |    500.0 | hipKernel.evolve_interior_kernel\n||   0.0% |  0.001353 |   -- |    -- |    500.0 | hipKernel.evolve_z_edges_kernel\n||   0.0% |  0.001325 |   -- |    -- |    500.0 | hipKernel.evolve_x_edges_kernel\n||   0.0% |  0.001306 |   -- |    -- |    500.0 | hipKernel.evolve_y_edges_kernel\n</code></pre></p> <p>Is there way to get the time actually spent in kernels?</p> <ul> <li>Is this tracing? (<code>-w</code> flag for pat_build) You can also decide to mask a function (<code>-T</code> flag). Check man pat_build for more info.</li> <li>You can collect timeseries data (PAT_RT_SUMMARY=0) and view a timeline in apprentice2 and this can show kernels. </li> </ul> <p>Thanks, with tracing and timeseries apprentice2 does not show Time Line but gives \"Data server terminated\" error</p> </li> <li> <p>Omnitrace-instrument seems to take ages to launch for the Jacobi example. Waitng about 10 mins now. Is it normal?</p> <ul> <li>I assume dynamic instrumentation? yes</li> <li>Do binary rewriting, I think the storage is not performing well</li> </ul> <p>Thanks. Is there somewhere I can read about what this dynamic instrumetation means vs (I guess) static? I am a newbie :-) </p> <ul> <li>In the slides there is a command with <code>--simulate</code> that show sall the libraries that access the dynamic instrumentation and they are a lot, so the binary rewriting makes profiling accessing onlyt he required libraries which are minimal.</li> </ul> </li> <li> <p>I managed to get a roofline plot using the saxpy example, meaning that i can see the kernel \"points\" on the plot. However, i can't do the same with the <code>vcopy</code> example. I mean, it generates a report, so i guess that it works, but it does not show any point on the plot. Can you think of a reason about it? EDIT: because it doesn't have FP operation i guess... </p> <ul> <li>Yes, vcopy has 0 FLOPs, check more the other things than roofline for vcopy</li> </ul> <p>I changed it to use dgemm</p> </li> </ol>"},{"location":"Profiling-20230413/schedule/","title":"Course schedule","text":"10:15\u00a0\u00a0 Welcome and introduction Presenters: Emmanuel Ory (LUST), J\u00f8rn Dietze (LUST), Harvey Richardson (HPE)( Recording: <code>/project/project_465000502/recordings/00_Introduction.mp4</code> on LUMI only. 10:30 Preparing an Application for Hybrid Supercomputing Presenter: John Levesque (HPE) 12:00 lunch break (60 minutes) 13:00 Introduction to ROC-prof profiler Presenter: George Markomanolis (AMD) 13:30 Introduction to OmniTrace Presenter: George Markomanolis (AMD) 14:10 5-minute break 14:15 Introduction to Omniperf and Hierarchical Roofline on AMD InstinctTM MI200 GPUs Presenter: George Markomanolis (AMD) 14:55 break 15:05 Hands-on with examples or own code 16:30 Close"},{"location":"User-Coffee-Breaks/","title":"LUMI User Coffee Break Talks","text":"<p>In reverse chronological order:</p> <ul> <li> <p>Cotainr on LUMI (September 27, 2023)</p> </li> <li> <p>Spack on LUMI (August 30, 2023)</p> </li> <li> <p>Current state of running AI workloads on LUMI (June 28, 2023)</p> </li> </ul>"},{"location":"User-Coffee-Breaks/20230628-user-coffee-break-AI/","title":"Current state of running AI workloads on LUMI (June 28, 2023)","text":"<p>Presenters: Christian Schou Oxvig and Ren\u00e9 L\u00f8we Jacobsen (LUST &amp; DeiC)</p> <ul> <li>Slides (PDF)</li> </ul>"},{"location":"User-Coffee-Breaks/20230628-user-coffee-break-AI/#qa","title":"Q&amp;A","text":"<p>Full archive of all LUMI Coffee Break questions. This page only shows the  AI-related questions.</p> <ol> <li> <p>Q: On this page https://github.com/Lumi-supercomputer/ml-examples/tree/main/tensorflow/hvd, options for installing Horovod are described.      The first one uses cray-python and tensorflow-rocm from pip. But it does not explain what module is necessary to load for Horovod to function, despite that the environment is without a running mpirun executable (GPU-aware), required by Horovod. If OpenMPI is loaded first, the horovod package will not compile with NCCL support. Knowing what other packages than cray-python (and OpenMPI?) are necessary when installing horovod with pip and not a docker, would be helpful.</p> <p>Answer:</p> <ul> <li> <p>Please, notice that that\u2019s not lumi\u2019s official documentation.</p> </li> <li> <p>The idea there is to install horovod within the container. That\u2019s why it doesn\u2019t need any system modules loaded.      The image already has a horovod installation, but somehow it doesn\u2019t work for us. We are only replacing it.</p> <p>OpenMPI is used only as a launcher while all the communication is done via rccl.</p> <p>Nevertherless, since you are having issues with those instructions, we will have a look to see if anything needs to be changed. We should probably update it to the latest image.</p> </li> </ul> </li> <li> <p>Q: On the same page, this script      loads many modueles and sets environment variables. But they are not explained, which makes it difficult to experiment with new dockers. Likewise, it is not explained why some areas are mapped into the Singularity image (e.g., app). Where is this information available?</p> <p>Answer:  Maybe the sections Accessing the Slingshot interconnect and OpenMPI of the README.md have the information that you need.</p> </li> <li> <p>Q: How can the package Accelerate from Huggingface be loaded, working with Pytorch2 and AMD infrastructure?</p> <p>Answer: (Christian) One option is to use cotainr to build a Singularity/Apptainer container from a conda/pip environment. On LUMI you can module load LUMI, module load cotainr to get access to cotainr. You may use this (somewhat outdated) PyTorch+ROCm example as a starting point. Modify the conda environment YAML file to your needs, i.e. include the torch 2.0 and accelerate pip packages. You probably want to use a ROCm 5.3 based version for best compatibility with LUMI, i.e. use --extra-index-url https://download.pytorch.org/whl/rocm5.3. If you try this and it doesn\u2019t work, please submit a ticket to the LUMI user support team via https://lumi-supercomputer.eu/user-support/need-help/.</p> </li> <li> <p>Q: I notice that aws-ofi-rccl automatically replaces Lmod \u201cPrgEnv-cray/8.3.3\u201d with \u201ccpeGNU/22.08\u201d when I load it.      Could you explain this behavior, and if the GNU environment is necessary to use (also it terms of python version) when using Singuarlity dockers?</p> <p>Answer: This is because the module has been built with EasyBuild using the <code>cpeGNU/22.08</code> toolchain and that module may be needed for the AWS plugin to find the runtime libraries. You'd have to compile the plugin during the construction of the container with a C compiler in the container to avoid that.</p> </li> </ol>"},{"location":"User-Coffee-Breaks/20230830-user-coffee-break-Spack/","title":"Spack on LUMI (August 30, 2023)","text":"<p>Presenters: Peter Larsson (LUST &amp; KTH PDC)</p>"},{"location":"User-Coffee-Breaks/20230830-user-coffee-break-Spack/#qa","title":"Q&amp;A","text":"<p>Full archive of all LUMI Coffee Break questions. This page only shows the  Spack-related questions.</p> <ol> <li> <p>Q: I do not know all the limitations but if you create many spack instances in a project you can hit the quota regarding number of files, right?</p> <p>Answer: Yes, it is true. For this reason we provide \u201ccentral\u201d spack installation with most common software pieces already available (so called upstream spack instance). If you use spack module then you wouldn\u2019t need to install everything in your own directory.</p> </li> </ol>"},{"location":"User-Coffee-Breaks/20230927-user-coffee-break-cotainr/","title":"Cotainr on LUMI (September 27, 2023)","text":"<p>Presenters: Christian Schou Oxvig (LUST &amp; DeiC)</p> <p>Materials:</p> <ul> <li> <p>Cotainr: tool to build Singularity/Apptainer containers for certain use cases especially conda and pip.      Tool website</p> </li> <li> <p><code>cotainr</code> in the LUMI docs</p> </li> <li> <p>Slides (PDF)</p> </li> </ul>"},{"location":"User-Coffee-Breaks/20230927-user-coffee-break-cotainr/#qa","title":"Q&amp;A","text":"<p>Full archive of all LUMI Coffee Break questions. This page only shows the  cotainr-related questions.</p> <ol> <li> <p>Q: Is it recommended/possible to use multiprecision in my tensorflow models during training?</p> <p>Answer: That's a question to ask to a Tensorflow specialist. It requires domain knowledge to answer. We are a small team and can impossibly have expertise in all applications and how they behave on LUMI.</p> <p>However, the AMD GPUs are relatively strong in FP32 and very strong in FP64 but not so strong in lower precision formats so it may not pay off as much as you would expect from some other GPUs.</p> <p>Comment on the answer: it is also a question on GPU type, with NVIDIA, the command: <code>tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")</code> works transparently (and I am not specialist neither)</p> </li> <li> <p>Q: For containr, where is the image stored (on which quota does it go)?</p> <p>Answer: That depends on where you install it. We recommend that the image is stored in your project folder. The image will only be a single file.</p> </li> <li> <p>Q: For my conda installation on LUMI, I followed the instructions provided on the LUMI container wrapper doc page, unlike containr build mentioned today. Seems like it did build on the file system. So should I do it again differently?     The commands I used were:     <pre><code>$ module load LUMI\n$ module load lumi-container-wrapper\n$ mkdir MyEnv\n$ conda-containerize new --prefix MyEnv env.yaml\n$ which python\n{my project path}/MyEnv/bin/python\n</code></pre></p> <p>Answer: It does put some things on the file system like wrapper scripts but the main installation is done in a SquashFS file that will be among those files. But the container wrapper does, e.g., create wrapper scripts for everything in the bin directory in the container so that you don't need to use singularity commands to start something in the container.</p> <p>Comment: You can use cotainr as an alternative to the LUMI container wrapper. Please take a look at the LUMI docs page Installing Python Packages for more details about the differences.</p> </li> <li> <p>Q: Does the <code>--system</code> option installs ROCM GPU optimized BLAS/LAPACK releases when selecting lumi-g ? </p> <p>Answer: The system flag defines a base image for your container. For LUMI-G it will include the full ROCm stack. You can use <code>--base-image</code>, if you want to specify your own base image. </p> </li> <li> <p>Q: Is there a command similar to <code>--post-install</code> for cotainr that is present in the lumi-container-wrapper? </p> <ul> <li>The <code>--post-install</code> command allows commands to be executed inside the container after creating the squashfs file.</li> <li><code>--post-install</code> is not available in containr and for best practice you should re-build the container with the python file. </li> </ul> </li> <li> <p>Q: Being new to containers in general, is it possible to have my \"core\" image built with containr, and when running it, pip install new packages to use in the container for one certain project? Thank you.</p> <p>Answer Containers are read-only once created so <code>pip install</code> would do an installation outside the container in the default Python installation directories.</p> </li> <li> <p>Q: I use conda env for the ML part of my code but I have also Cray compilers and tools to use with this. What are your suggestions for such mixed requirements ? </p> <p>Answer I don't think there is a generic answer to that. The problem is that if you start to mix software compiled with different compilers, you can have conflicts between run-time libraries of compilers. Ideally you'd use the same compilers as those ML parts were built with, but that's something that you don't always know... Unfortunately compiling our own PyTorch and Tensorflow to ensure compatibility is outside what LUST can do given the size of the team, and is something that AMD advised us not to do as it is very difficult to get it right.</p> </li> <li> <p>Q: As an addition to the question about post-install: Singularity has the option to make a \"sandbox\" image, so that you are able to install linux packages in the shell after creation. Wouldn't this be an easy addition, that doesn't make it too complicated for the basic user? A <code>--sandbox</code> option.</p> <p>Answer Cotainr actually exploits sandbox to build the container. But it is not a good practice to build containers and then extend them afterwards as you may loose reproducibility as you don't have a definition file anymore that covers the whole container.</p> </li> <li> <p>Q: Does cotainr works also with pipenv?</p> <p>Answer Currently only Conda is supported, but the documentation does show a way to add pip packages to the environment.</p> </li> <li> <p>Q: I am running an R code on LUMI-C using the small partition. How can I efficiently allocate a whole node in order to cut billing units?. Are there any specific commands to adjust the minimum number of GB per core to be allocated?</p> <p>Answer It is possible to allocate a full node in the small partition by using the <code>#SBATCH --exclusive</code> flag in SLURM, but you might as well run in the standard partition as well, which allocated a full node by default. Same with memory: there are flags to specify the amount of memory per core, per rank, per GPU etc in SLURM (please see the sbatch man page).</p> </li> <li> <p>Q: Is it easy to add something like \"module load\" in the cotainr build script, to start with a known group of packages?</p> <p>Answer That doesn't make much sense in the spirit of containers as containers try to offer a self-contained environment. The primary use of modules is to support multiple versions of one package which is not of use in containers.</p> <p>Packages also are not taken from the system, but currently from the Conda repositories and for containers in general from different software repositories.</p> </li> <li> <p>Q: Does the LUMI container image include Cray compiler ? And if yes could, this container by use on our PC ?</p> <p>Answer The Cray compiler is NOT public domain but licensed software so you cannot use it outside of LUMI or other systems that have a license for it. There actually exists a containerised version of the PE but it is given only to users who have signed heavy legal documents in a specific project.</p> <p>So the Cray compiler is also not contained in the base images of cotainr and never will unless HPE would open source the PE which they will not do anytime soon as it is one of the selling points for their systems.</p> </li> <li> <p>Q: With a singularity container built with cotainer based on a conda env, is it possible to add packages to the environment after the container is built?</p> <p>Answer Please see the answers above.</p> </li> <li> <p>Q: So is there container with gnu/llvm +rocm for building fortran code for LUMI in our PC ?</p> <p>Answer Why not simply install the gnu compilers or ROCm + LLVM (the AMD compilers are LLVM-based) on your PC? ROCm in a container would still need an AMD GPU and driver installed in the PC if you want to test the software also and not only compile. In fact, not even all compiles would work as software installation scripts sometimes need the GPU to be present as they try to automatically check the type etc.</p> <p>Comment The point was to have a good starting point, that User Support have already tested .</p> <p>Reply Testing is not absolute anyway as a container still depends on the underlying hardware, OS kernel and drivers. It is a misconception that containers are fully portable. And having the software in a container can make development harder as you will always be mixing things in the container with things outside it.</p> <p>Moreover, we don't have the resources to test such things thoroughly. It is already not possible to thoroughly test everything that runs on the system, let alone that we can test if things would also work on other systems.</p> </li> <li> <p>Q: Has cotainr images access to all lustre filesystems?</p> <p>Answer Yes, but you need to do the binding as explained in our singularity documentation.</p> </li> </ol>"},{"location":"User-Updates/","title":"User updates","text":"<ul> <li>Update after the August 2023 maintenance</li> </ul>"},{"location":"User-Updates/Update-202308/","title":"Changes after the update of August 2023","text":"<p>The main purpose of the August 2023 update of LUMI was to add in additional GPU hardware that will become gradually available to users (as extensions of the current partitions).</p> <p>However, a few changes were made to the scheduler, one of which has a large impact on GPU jobs, and we also want to put more emphasis on proper and efficient use of the system as queue times have become rather long lately.</p> <ul> <li>Changes to the low-noise mode on LUMI-G. These changes have      implications for job scripts so read carefully.</li> <li>Policy change on dev-g and eap</li> <li>Responsible use of LUMI-C and LUMI-G</li> </ul>"},{"location":"User-Updates/Update-202308/lumig-devg/","title":"The dev-g and eap partitions","text":""},{"location":"User-Updates/Update-202308/lumig-devg/#policy-change-of-dev-g","title":"Policy change of dev-g","text":"<p>The dev-g partition was always meant for the development of GPU software, and in particular, to get a quick turnaround time if you need to run software under the control of a debugger or for short profiling runs. We have observed that the queue has been abused for production or near-production runs instead to bypass longer waiting times on the regular queue.  This complicates the work of developers. Also, a maximum of 16 nodes per job has not always been enough for some debugging runs.</p> <p>Therefore the following policy changes will be implemented:</p> <ul> <li>The maximum size for a job increases from 16 to 32 nodes.</li> <li>The maximum runtime (walltime) for a job is decreased from 6 to 3 hours.</li> <li>The maximum number of jobs is unmodified. Users can have only one running job in this     partition.</li> </ul> <p>User action: Some job scripts may require changes and you may have to move to a different partition if you were not using dev-g in the intended way.</p>"},{"location":"User-Updates/Update-202308/lumig-devg/#the-eap-partition","title":"The eap partition","text":"<p>The EAP (Early Access Platform) partition was a leftover of the early days of LUMI when a GPU development system with MI100 nodes was attached to the system. As a transition measure a new eap partition was created on LUMI-G with the full MI250X hardware, and just as the original eap partition, it allowed development of GPU software without GPU billing units. However, we've recently seen abuse of this partition for regular runs, and developers have now had ample time to request development projects at EuroHPC or, for groups in LUMI consortium countries, their local resource allocators.</p> <p>The eap partition was removed during the update and will not return. All users who want to experiment on the GPU nodes now need projects with GPU billing units.</p> <p>User action: Request GPU billing units from your resource allocator. Depending on your use profile,  use dev-g, small-g or standard-g instead.</p>"},{"location":"User-Updates/Update-202308/lumig-lownoise/","title":"The low-noise mode on LUMI-G","text":""},{"location":"User-Updates/Update-202308/lumig-lownoise/#configuration-changes","title":"Configuration changes","text":"<p>The configuration of LUMI-G has been made more symmetrical.</p> <p>Previously, a low-noise mode was enabled reserving one core (core 0) for the operating system and drivers. This was needed because benchmarking before the pilot phase showed that the jitter caused by OS processes in the background stealing time from some cores that were in use by applications, had a very negative impact on scalability.</p> <p>This created an asymmetry as one CCD (chiplet) of the CPU had 7 cores available while all others had 8 cores available. And this in turn almost forced users to do a fully manual CPU binding in standard-g, and gave very bad core allocations in small-g. Some changes have been made to the scheduler config to improve this situation.</p> <p>What has changed:</p> <ul> <li> <p>The first core of each CCD is now reserved. As a result, only 56 cores are available to     Slurm on each LUMI-G node. The reserved cores are 0, 8, 16, 24, 32, 40, 48 and 56.</p> </li> <li> <p>The thread distribution and binding behaviour of <code>--cpus-per-task</code> has been improved.      Even with the old distribution rules, <code>--cpus-per-task=7</code> would now give a nice      distribution on the standard-g partition with effectively each task on its own CCD,      which in turn makes proper GPU mapping possible. However, in some cases, even with     a lower value of <code>--cpus-per-task</code> you will still have nice mapping with tasks     not spanning multiple CCDs (and if there are 8 tasks or less, each task on a separate     CCD). You should experiment with this though as it is not true in all cases and as on     small-g it is only the case if you happen to have a node that is empty.</p> </li> </ul> <p>What has not changed:</p> <ul> <li> <p>Proper binding is only possible on job-exclusive nodes, but that is the very nature     of binding as it requires full control of all resources.</p> </li> <li> <p>For those users who also work on Frontier: The configuration of the GPU nodes is now      more similar but still not the same. E.g., the Slurm socket is still defined as the physical     socket and not an L3 cache domain as on Frontier, because modifying this would have had      implications for LUMI-C also. So don't expect that you can simply use the same strategy for     resource requests for all cases on LUMI and Frontier.</p> </li> <li> <p><code>--gpu-bind=closest</code> still does not work as expected. On standard-g, it will not      give you the proper GPUs (apart from other problems with Slurm doing the binding).     On small-g, it will not enforce an allocation with the proper CPU cores for the GPUs     in your allocation.</p> </li> <li> <p>The Slurm GPU binding is still incompatible with shared memory communication between      GPUs in different tasks, as is used by, e.g., GPU-aware Cray MPICH intra-node communication.     So the trick of avoiding Slurm doing the binding and do a manual binding instead via the     <code>select_gpu</code> script used in the LUMI documentation, is still needed.</p> </li> </ul> <p>User impact:</p> <ul> <li> <p>Any job script that in one way or another asks for more than 56 cores on a node of LUMI-G will     fail.</p> </li> <li> <p>Any job script that uses <code>--cpu-bind=map_cpu:</code> and that has one of the now unavailable cores in the      map will fail. </p> <p>The \"MPI-based job\" in the GPU examples in the LUMI documentation before the August 2023 update does no longer work. Also, the <code>--cpu-bind=map_cpu:</code> line that was shown on the \"Distribution and binding\" page does no longer work after the update. The documentation has been corrected.</p> </li> <li> <p>Any job script that uses <code>--cpu-bind=mask_gpu:</code> and that includes a now unavailable core in the mask     will fail. </p> <p>The  \"Hybrid MPI+OpenMP job\" example in \"GPU examples already took this into account and is still correct. The example mask on the  \"Distribution and binding\" page is wrong and all occurrences of <code>ff</code> need to be modified to <code>fe</code>. The documentation has been corrected. </p> </li> </ul> <p>All training materials in the \"LUMI training materials\" archive web site reflect the state of LUMI at the time that the course was given. These materials are not updated after the course, so some job scripts for LUMI-G contained in those courses will be incorrect. As courses are lectured again, a new version of the course materials will be made available on this site and LUMI (as some materials cannot be published on the web).</p> <p>In particular,</p> <ul> <li> <p>The latest materials for the 4-day comprehensive LUMI training     are currently those of the May 30 - June 2 course in Tallinn, but a new version will become available some days after the training in      Warsaw, October 3-6.</p> </li> <li> <p>The latest materials of the 1-day introductory LUMI training     are currently those of the course in early May 2023. A new edition has not yet been planned but is expected in the fall of 2023.</p> </li> </ul>"},{"location":"User-Updates/Update-202308/lumig-lownoise/#mpi-based-job-example","title":"MPI-based job example","text":"<p>The example from the \"MPI-based job\" section on the \"GPU examples\" documentation page needs only an almost trivial modification on line 23:</p> <pre><code>#!/bin/bash -l\n#SBATCH --job-name=examplejob   # Job name\n#SBATCH --output=examplejob.o%j # Name of stdout output file\n#SBATCH --error=examplejob.e%j  # Name of stderr error file\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=2               # Total number of nodes \n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node, 16 total (2x8)\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=1-12:00:00       # Run time (d-hh:mm:ss)\n#SBATCH --mail-type=all         # Send email at begin and end of job\n#SBATCH --account=project_&lt;id&gt;  # Project for billing\n#SBATCH --mail-user=username@domain.com\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\n\nchmod +x ./select_gpu\n\nCPU_BIND=\"map_cpu:49,57,17,25,1,9,33,41\"\n\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu &lt;executable&gt; &lt;args&gt;\nrm -rf ./select_gpu\n</code></pre> Download runnable example <p>Example: example-mpi.sh</p> <p>Run with:</p> <pre><code>sbatch -A project_46YXXXXXX example-mpi.sh\n</code></pre> <p>Future updates of LUMI may invalidate this script.</p>"},{"location":"User-Updates/Update-202308/lumig-lownoise/#hybrid-mpiopenmp-job","title":"Hybrid MPI+OpenMP job","text":"<p>The mask in the example from the \"Hybrid MPI+OpenMP job\" section on the \"GPU examples\" documentation page is still correct:</p> <pre><code>#!/bin/bash -l\n#SBATCH --job-name=examplejob   # Job name\n#SBATCH --output=examplejob.o%j # Name of stdout output file\n#SBATCH --error=examplejob.e%j  # Name of stderr error file\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=2               # Total number of nodes \n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node, 16 total (2x8)\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=1-12:00:00       # Run time (d-hh:mm:ss)\n#SBATCH --mail-type=all         # Send email at begin and end of job\n#SBATCH --account=project_&lt;id&gt;  # Project for billing\n#SBATCH --mail-user=username@domain.com\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\n\nchmod +x ./select_gpu\n\nCPU_BIND=\"mask_cpu:7e000000000000,7e00000000000000\"\nCPU_BIND=\"${CPU_BIND},7e0000,7e000000\"\nCPU_BIND=\"${CPU_BIND},7e,7e00\"\nCPU_BIND=\"${CPU_BIND},7e00000000,7e0000000000\"\n\nexport OMP_NUM_THREADS=6\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu &lt;executable&gt; &lt;args&gt;\nrm -rf ./select_gpu\n</code></pre> <p>The mask here is built up of <code>7e</code> blocks which use cores 1 till 6 of each CCD, but do not use the reserved core 0 nor the available core 7. In general, any mask element with a 1, 3, 5, 7, 9, B, D or F in position 1, 3, 5, 7, 9, 11, 13 or 15  (counting from the right and starting with 1) is wrong as it would have a 1-bit on the position of core 0 of one of the CCDs. Or in other words, the odd positions (counting from the right and starting from 1) of each mask element should be an even hexadecimal number (including 0).</p> Download runnable example <p>Example: example-hybrid.sh</p> <p>Run with:</p> <pre><code>sbatch -A project_46YXXXXXX example-hybrid.sh\n</code></pre> <p>Future updates of LUMI may invalidate this script.</p>"},{"location":"User-Updates/Update-202308/lumig-lownoise/#comprehensive-training-advanced-placement-lecture","title":"Comprehensive training \"Advanced Placement\" lecture","text":"<p>Many of the slides of the GPU-related slides of the  \"Advanced Placement\" lecture of the comprehensive LUMI course of May-June 2023  need changes.</p> <p>Note that numbers refer to the page numbers on the slides themselves. Some slides are left out of the bundle so your PDF reader may show a second numbering.</p> <ul> <li> <p>The example on slide 61 which did not work (as explained on slide 62 and 63) will now actually work</p> <pre><code>#!/bin/bash\n#SBATCH -p &lt;partition&gt;\n#SBATCH -A &lt;your_project&gt;\n#SBATCH --time=00:02:00\n#SBATCH --nodes=2\n#SBATCH --gres=gpu:8 \n#SBATCH --exclusive\n#SBATCH --ntasks-per-node=8 \n#SBATCH --cpus-per-task=7 \n#SBATCH --hint=nomultithread\n\nexport OMP_PLACES=cores\nexport OMP_PROC_BIND=close\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\n\nsrun ./xthi | sort -n -k 4 -k 6\n</code></pre> <p>The mask shown on slide 63 is still correct though and that approach also works.</p> <p>The Python script on slide 64 to generate masks is also correct  as is the job script on slide 65 that uses that mask:</p> <pre><code>#!/bin/bash\n#SBATCH -p &lt;partition&gt; \n#SBATCH -A &lt;your_project&gt; \n#SBATCH --time=00:02:00 \n#SBATCH --nodes=1\n#SBATCH --gres=gpu:8 \n#SBATCH --exclusive\n#SBATCH --ntasks-per-node=8 \n#SBATCH --hint=nomultithread\n\nexport OMP_PLACES=cores\nexport OMP_PROC_BIND=close\nexport OMP_NUM_THREADS=7\n\nASRUN=\"srun --cpu-bind=mask_cpu:0xfe,0xfe00,0xfe0000,0xfe000000,0xfe00000000,0xfe0000000000,0xfe000000000000,0xfe00000000000000\"\n\n${ASRUN} ./xthi | sort -n -k 4 -k 6\n</code></pre> <p>(but the <code>--cpus-per-task</code> line on that slide is wrong and was wrong before as that should not be used together with manual binding based on maps or masks, so we also cannot rely on <code>SLURM_CPUS_PER_TASK</code>.)</p> </li> <li> <p>The script on slide 72:</p> <pre><code>#!/bin/bash\n#SBATCH -p &lt;partition&gt;\n#SBATCH -A &lt;your_project&gt;\n#SBATCH --time=00:02:00\n#SBATCH --nodes=2\n#SBATCH --gres=gpu:8\n#SBATCH --exclusive\n#SBATCH --ntasks-per-node=8 \n#SBATCH --hint=nomultithread\n\nexport OMP_PLACES=cores\nexport OMP_PROC_BIND=close\nexport OMP_NUM_THREADS=7\n\nASRUN=\"srun --cpu-bind=mask_cpu:0xfe,0xfe00,0xfe0000,0xfe000000,0xfe00000000,0xfe0000000000,0xfe000000000000,0xfe00000000000000\"\n\n${ASRUN} ./select_gpu.sh &lt;my_app&gt;\n</code></pre> <p>with <code>select_gpu.sh</code>: </p> <pre><code>#!/bin/bash\n\nexport ROCR_VISIBLE_DEVICES=$SLURM_LOCALID\n\nexec $*\n</code></pre> <p>(and with the <code>--cpus-per-task</code> line removed)</p> <p>will still give a correct CPU binding and the GPU binding is still too naive. It is corrected by the <code>select_gpu.sh</code> script on slide 74 which does not require any modifications either:</p> <pre><code>#!/bin/bash\nGPUSID=\"4 5 2 3 6 7 0 1\"\nGPUSID=(${GPUSID})\nif [ ${#GPUSID[@]} -gt 0 -a -n \"${SLURM_NTASKS_PER_NODE}\" ]; then\nif [ ${#GPUSID[@]} -gt $SLURM_NTASKS_PER_NODE ]; then\nexport ROCR_VISIBLE_DEVICES=${GPUSID[$(($SLURM_LOCALID))]}\nelse\nexport ROCR_VISIBLE_DEVICES=${GPUSID[$(($SLURM_LOCALID / ($SLURM_NTASKS_PER_NODE / ${#GPUSID[@]})))]}\nfi fi\nexec $*\n</code></pre> <p>(Note that this script however assumes that the number of tasks per node is a multiple of the number of GPUs in the  list.)</p> </li> </ul> Download runnable example based on the script of slide 72-74 <p>Example: example-cray.sh</p> <p>Run with:</p> <pre><code>sbatch -A project_46YXXXXXX example-cray.sh\n</code></pre> <p>Future updates of LUMI may invalidate this script.</p>"},{"location":"User-Updates/Update-202308/lumig-lownoise/#some-other-examples","title":"Some other examples","text":""},{"location":"User-Updates/Update-202308/lumig-lownoise/#mask-for-1-gpu-per-task-7-cores-per-task","title":"Mask for 1 GPU per task, 7 cores per task:","text":"<pre><code>#!/bin/bash -l\n#SBATCH --job-name=examplejob   # Job name\n#SBATCH --output=examplejob.o%j # Name of stdout output file\n#SBATCH --error=examplejob.e%j  # Name of stderr error file\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=2               # Total number of nodes \n#SBATCH --ntasks-per-node=8     # 8 MPI ranks per node, 16 total (2x8)\n#SBATCH --gpus-per-node=8       # Allocate one gpu per MPI rank\n#SBATCH --time=1-12:00:00       # Run time (d-hh:mm:ss)\n#SBATCH --mail-type=all         # Send email at begin and end of job\n#SBATCH --account=project_&lt;id&gt;  # Project for billing\n#SBATCH --mail-user=username@domain.com\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\nexport ROCR_VISIBLE_DEVICES=\\$SLURM_LOCALID\nexec \\$*\nEOF\nchmod +x ./select_gpu\n\nCPU_BIND=\"mask_cpu\"\nCPU_BIND=\"${CPU_BIND}:00fe000000000000,fe00000000000000\" # CCD 6. 7\nCPU_BIND=\"${CPU_BIND},0000000000fe0000,00000000fe000000\" # CCD 2, 3\nCPU_BIND=\"${CPU_BIND},00000000000000fe,000000000000fe00\" # CCD 0, 1\nCPU_BIND=\"${CPU_BIND},000000fe00000000,0000fe0000000000\" # CCD 4, 5\n\nexport OMP_NUM_THREADS=7\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu &lt;executable&gt; &lt;args&gt;\nrm -rf ./select_gpu\n</code></pre> <p>This mask makes the first hardware thread on all 7 non-reserved cores of all CCDs available, one CCD per task.  For hybrid OpenMP applications, use can then be restricted again by setting <code>OMP_NUM_THREADS</code> to a lower value.</p> Download runnable example <p>Example: example-1gpt-7cpt.sh</p> <p>Run with:</p> <pre><code>sbatch -A project_46YXXXXXX example-1gpt-7cpt.sh\n</code></pre> <p>Future updates of LUMI may invalidate this script.</p>"},{"location":"User-Updates/Update-202308/lumig-lownoise/#mask-for-2-tasks-per-gpu-3-cores-per-task","title":"Mask for 2 tasks per GPU, 3 cores per task","text":"<pre><code>#!/bin/bash -l\n#SBATCH --job-name=examplejob   # Job name\n#SBATCH --output=examplejob.o%j # Name of stdout output file\n#SBATCH --error=examplejob.e%j  # Name of stderr error file\n#SBATCH --partition=standard-g  # Partition (queue) name\n#SBATCH --nodes=2               # Total number of nodes \n#SBATCH --ntasks-per-node=16    # 16 MPI ranks per node, 32 total (2x16)\n#SBATCH --gpus-per-node=8       # Allocate all eight GPUS in a node\n#SBATCH --time=1-12:00:00       # Run time (d-hh:mm:ss)\n#SBATCH --mail-type=all         # Send email at begin and end of job\n#SBATCH --account=project_&lt;id&gt;  # Project for billing\n#SBATCH --mail-user=username@domain.com\n\ncat &lt;&lt; EOF &gt; select_gpu\n#!/bin/bash\nexport ROCR_VISIBLE_DEVICES=\\$((SLURM_LOCALID/2))\nexec \\$*\nEOF\nchmod +x ./select_gpu\n\nCPU_BIND=\"mask_cpu\"  #7766554433221100,7766554433221100\nCPU_BIND=\"${CPU_BIND}:000E000000000000,00E0000000000000\" # CCD 6\nCPU_BIND=\"${CPU_BIND},0E00000000000000,E000000000000000\" # CCD 7\nCPU_BIND=\"${CPU_BIND},00000000000E0000,0000000000E00000\" # CCD 2\nCPU_BIND=\"${CPU_BIND},000000000E000000,00000000E0000000\" # CCD 3\nCPU_BIND=\"${CPU_BIND},000000000000000E,00000000000000E0\" # CCD 0\nCPU_BIND=\"${CPU_BIND},0000000000000E00,000000000000E000\" # CCD 1\nCPU_BIND=\"${CPU_BIND},0000000E00000000,000000E000000000\" # CCD 4\nCPU_BIND=\"${CPU_BIND},00000E0000000000,0000E00000000000\" # CCD 5\n#                     7766554433221100,7766554433221100\n\nexport OMP_NUM_THREADS=3\nexport MPICH_GPU_SUPPORT_ENABLED=1\n\nsrun --cpu-bind=${CPU_BIND} ./select_gpu &lt;executable&gt; &lt;args&gt;\nrm -rf ./select_gpu\n</code></pre> <p>This mask will use the first hardware thread of each core of core groups 1-3 and 5-7 of each CCD to place tasks (so hardware thread 1-3 in the Linux numbering for task 1, 5-7 for task 2, 9-11 for task 3, ...).</p> Download runnable example <p>Example: example-2tpg-3cpt.sh</p> <p>Run with:</p> <pre><code>sbatch -A project_46YXXXXXX example-2tpg-3cpt.sh\n</code></pre> <p>Future updates of LUMI may invalidate this script.</p>"},{"location":"User-Updates/Update-202308/responsible-use/","title":"Responsible use of LUMI-C and LUMI-G","text":"<p>Responsible use of LUMI can help to reduce waiting times for everybody and helps the priority system to function as designed.</p>"},{"location":"User-Updates/Update-202308/responsible-use/#use-small-or-small-g-for-small-jobs","title":"Use small or small-g for small jobs","text":"<p>The small and small-g partition support jobs that need up to four nodes. Though these partitions are allocatable by resources rather than allocatable by node, it is possible by adding some options to <code>sbatch</code> to use them in the same way as the standard and standard-g partitions.</p> <p>You can get the same environment on the small and standard partitions by:</p> <ul> <li>Adding the option <code>--exclusive</code> to the <code>sbatch</code> flags (as a command line argument or     in an <code>#SBATCH</code> line), and</li> <li>Requesting memory, e.g., using <code>--mem</code>. For migrating from standard to small on LUMI-C, a good     choice is <code>--mem=224g</code> and for migrating from standard-g to small-g, a good option is     <code>--mem=480g</code>. This is needed because <code>--exclusive</code> does not yet give you access to memory in      the same way as the standard and standard-g partition do, but instead still impose the regular     restrictions of small and small-g.</li> </ul> <p>These options should only be used if you indeed need job exclusive nodes and you will also be billed for the full node if you use these options as described here.</p> <p>Job scripts using the above two options can still also run on standard and standard-g without  negative consequences if you adapt the partition.</p> <p>Lines for LUMI-C</p> <pre><code>#SBATCH --partition=small\n#SBATCH --exclusive\n#SBATCH --mem=224g\n</code></pre> <p>Lines for LUMI-G</p> <pre><code>#SBATCH --partition=small-g\n#SBATCH --exclusive\n#SBATCH --mem=480g\n</code></pre> <p>User action: We encourage users to consider using small instead of standard and small-g instead of standard-g for jobs that require 4 nodes or less, in particular if those jobs run for longer than one hour. Shorter low-nodecount jobs can run as backfill and do not so much affect queueing times for users with big jobs who can only use standard or standard-g.</p>"},{"location":"User-Updates/Update-202308/responsible-use/#dont-use-standard-g-if-you-cannot-use-all-gpus","title":"Don't use standard-g if you cannot use all GPUs","text":"<p>A common error on LUMI-G is that users use a GPU node in the standard-g partition but cannot or do not use all GPUs. Standard-g is only allocatable per node. So if you have a job running on a node in standard-g, nor you nor any other user can use the remaining resources on that node (and you are in fact billed for the full node).</p> <p>Common errors include:</p> <ul> <li> <p>Running on a GPU node but forgetting to request GPUs. In some cases, you will see a warning or even     an error message from your application in your output,      but in other cases the software will just run fine without a warning, as     the same binary may support both GPU and non-GPU use.</p> </li> <li> <p>Running software that is not built for a GPU. Software will not use a GPU in some magical way     just because there is a GPU in the system but needs to be written and built for using a GPU.     Most Python and R packages do not support GPU computing. And packages written for an NVIDIA GPU     cannot run on an AMD GPU, just as software compiled for an x86 processor cannot run on an ARM     processor.</p> <p>If you use a package which is not written for GPU use, you will not get any warning as software  does not give warnings if there is more hardware in the system than it needs or if it doesn't  know a piece of hardware and doesn't need it.</p> </li> <li> <p>Know your software. Not all software can use more than one GPU, let alone that it could use more     than one GPU efficiently for the problem that you are trying to solve. And for all practical      purposes one GPU is one GCD or half of an MI250X package.</p> <p>Again, in many cases you won't get a warning as computers warn or produce error messages if they try to use something which is not available but don't produce warnings if some piece of software does not use all the hardware in the node (and that is a good thing as most shell commands would then also have to produce that warning).</p> </li> </ul>"},{"location":"User-Updates/Update-202308/responsible-use/#proper-test-jobs-are-not-only-short-in-duration-but-also-small-in-size","title":"Proper test jobs are not only short in duration but also small in size","text":"<p>Try to avoid running short test jobs that need a lot of nodes. </p> <p>A supercomputer is never run in pre-emptive mode. Jobs run until they are finished and are not interrupted for other jobs.</p> <p>Now assume you submit a 512-node job on LUMI-C, half the size of the standard partition, and assume that all other jobs in the system would be running for the maximum allowed walltime of 2 days. The scheduler will need to gather nodes as they become available for the 512-node job, so if all jobs would run for 2 days and you need  half of the total number of nodes, then on average this could take one full day, with the first resources in  the pool becoming available almost immediately but the last few of the requested nodes only when the job starts. On average nodes would have been kept idle for half a day, so you really loose the equivalent of 256 node-days of  capacity.</p> <p>You can see that this process makes a lot of resources unavailable for other jobs for a long time and leads to inefficient use of the supercomputer. Luckily LUMI also supports backfill, i.e., small and short jobs can still start if the scheduler knows these jobs will finish before it expects to be able to collect the nodes for the 512-node job, even if they have a much lower priority than the big job. </p> <p>However, usually there are not enough suitable jobs for backfill, so very large jobs will usually lead to lots of nodes being idle for some time and hence inefficient use of resources. LUMI is built for research into jobs for the exascale area, so we do want to keep it possible to run large jobs. But users who do this should realise the consequences for the operation of the system and be responsible:  Test on smaller configurations on a smaller number of nodes, then when you scale up for the large number of nodes go immediately for a long run and instead ensure that your job is cancelled properly if something goes wrong. 15-minute 512-node test jobs are a very bad idea. That job is worth just over 5 node days of production but can cost a large multiple of that in idle time as the scheduler gathers resources.</p>"},{"location":"User-Updates/Update-202308/responsible-use/#dont-use-large-jobs-just-for-the-fun-of-it","title":"Don't use large jobs just for the fun of it","text":"<p>Sometimes you have the choice between using more nodes and getting a shorter runtime, or fewer nodes with a larger runtime. In general using fewer nodes will always be more efficient as parallel efficiency for a given problem size usually decreases with increasing node counts. So you'll likely get more from your allocation by using smaller jobs.</p> <p>Also, the more nodes a job requires, the longer it may take to get scheduled, even just because it may take a while to gather  the required number of nodes. Showing how well your code can scale may certainly be a worthwhile addition to your paper, but it does not mean that all runs have to be done at those extreme node counts.</p> <p>And as already discussed, very large jobs also have a negative impact on the efficiency of the resource use of the scheduler, and hence on the waiting times for everybody.</p> <p>If you need a big run requiring on the order of 80 nodes or more, do so responsibly and ensure that it can run for a while so that  resources haven't been kept idle by the scheduler for basically nothing.</p>"},{"location":"User-Updates/Update-202308/responsible-use/#use-a-reasonable-estimate-for-the-walltime","title":"Use a reasonable estimate for the walltime","text":"<p>Of course it is OK to use a good safety margin when estimating the walltime a job will need, but just taking the  maximum allowed for a partition only to be as safe as possible is very asocial behaviour. It makes it impossible for a  scheduler to properly use backfill to use resources that are idle while nodes are being collected for a big job. Not only are jobs that request the maximum allowed walltime not suitable as backfill (and hence cannot  run earlier than can be expected based on their priority), but overestimating the  walltime needed for a job will also needlessly delay that big job simply because the scheduler thinks the nodes will only be available at a later time than they actually are and hence will wrongly assume that it is still safe to start short lower priority jobs as backfill.</p> <p>The maximum walltime on LUMI is high compared to many other large clusters in Europe that have a 24-hour limit for larger jobs. Don't abuse it.</p>"},{"location":"User-Updates/Update-202308/responsible-use/#core-and-memory-use-on-small-g-and-dev-g","title":"Core and memory use on small-g and dev-g","text":"<p>The changes made to the configuration of LUMI are not yet reflected in the billing policy. However,  to enable everybody to maximally exploit the nodes of LUMI-G, one should</p> <ul> <li>request at most 60 GB of CPU memory for every GPU requested as then all 8 GPUs can be used     by jobs with a fair amount of system memory for everybody, and</li> <li>not request more than 7 cores for each GPU requested. </li> </ul> <p>If all users do this, the GPUs in a node can be used maximally.</p>"}]}