# Comprehensive General LUMI Training, May 30 - June 2, 2023

## Course organisation

-   Location: TalTech IT Kolled≈æ, Raja 4c, Tallinn, Estonia, room ICO-221

    [Public transportation in Tallinn](https://visittallinn.ee/eng/visitor/plan/transport/public-transport)

-   [Original schedule (PDF)](https://462000265.lumidata.eu/4day-20230530/files/2023-05_General-LUMI-Training-Agenda.pdf)

    [Dynamic schedule (adapted as the course progresses)](schedule.md)

     *The dynamic schedule also contains links to pages with information about the course materials, but 
     those links are also available below on this page.*

-   [HedgeDoc for questions](https://md.sigma2.no/lumi-general-course?both)

-   There are two Slurm reservations for the course:

    -   CPU nodes: `training_cpu`
    -   GPU nodes: `training-gpu`


## Course materials

Course materials include the Q&A of each session, slides when available and notes when available.

Due to copyright issues some of the materials are only available to current LUMI users and have to be
downloaded from LUMI.

| Presentation | slides | notes | recording |
|:-------------|:-------|:------|:----------|
| [Introduction](extra_1_00_Introduction.md) | / | / | [web](extra_1_00_Introduction.md) |
| [HPE Cray EX Architecture](extra_1_01_HPE_Cray_EX_Architecture.md) | [lumi](extra_1_01_HPE_Cray_EX_Architecture.md) | / | [lumi](extra_1_01_HPE_Cray_EX_Architecture.md) |
| [Programming Environment and Modules](extra_1_02_Programming_Environment_and_Modules.md) | [lumi](extra_1_02_Programming_Environment_and_Modules.md) | / | [lumi](extra_1_02_Programming_Environment_and_Modules.md) |
| [Running Applications](extra_1_03_Running_Applications.md) | [lumi](extra_1_03_Running_Applications.md) | / | [lumi](extra_1_03_Running_Applications.md) |
| [Exercises #1](extra_1_04_Exercises_1.md) | / | / | / |
| [Compilers and Parallel Programming Models](extra_1_05_Compilers_and_Parallel_Programming_Models.md) | [lumi](extra_1_05_Compilers_and_Parallel_Programming_Models.md) | / | [lumi](extra_1_05_Compilers_and_Parallel_Programming_Models.md) |
| [Exercises #2](extra_1_06_Exercises_2.md) | / | / | / |
| [Cray Scientific Libraries](extra_1_07_Cray_Scientific_Libraries.md) | [lumi](extra_1_07_Cray_Scientific_Libraries.md) | / | [lumi](extra_1_07_Cray_Scientific_Libraries.md) |
| [Exercises #3](extra_1_08_Exercises_3.md) | / | / | / |
| [CCE Offloading Models](extra_1_09_Offload_CCE.md) | [lumi](extra_1_09_Offload_CCE.md) | / | [lumi](extra_1_09_Offload_CCE.md) |
| [Debugging at Scale](extra_2_01_Debugging_at_Scale.md) | [lumi](extra_2_01_Debugging_at_Scale.md) | / |  [lumi](extra_2_01_Debugging_at_Scale.md) |
| [Exercises #4](extra_2_02_Exercises_4.md) | / | / | / |
| [Advanced Placement](extra_2_03_Advanced_Application_Placement.md) | [lumi](extra_2_03_Advanced_Application_Placement.md) | / | [lumi](extra_2_03_Advanced_Application_Placement.md) |
| [Exercises #5](extra_2_04_Exercises_5.md) | / | / | / |
| [LUMI Software Stacks](extra_2_05_LUMI_Software_Stacks.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-2_05_software_stacks.pdf) | [web](notes_2_05_LUMI_Software_Stacks.md) |  [web](extra_2_05_LUMI_Software_Stacks.md) |
| [Introduction to HIP Programming](extra_2_06_Introduction_to_AMD_ROCm_Ecosystem.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-2_06_Introduction_to_AMD_ROCm_Ecosystem.pdf) | / | [web](extra_2_06_Introduction_to_AMD_ROCm_Ecosystem.md) |
| [Exercises #6](extra_2_07_Exercises_6.md) | / | / | / |
| [Introduction to Perftools](extra_3_01_Introduction_to_Perftools.md) | [lumi](extra_3_01_Introduction_to_Perftools.md) | / |  [lumi](extra_3_01_Introduction_to_Perftools.md) |
| [Exercises #7](extra_3_02_Exercises_7.md) | / | / | / |
| [Advanced Performance Analysis](extra_3_03_Advanced_Performance_Analysis.md) | [lumi](extra_3_03_Advanced_Performance_Analysis.md) | / |  [lumi](extra_3_03_Advanced_Performance_Analysis.md) |
| [Exercises #8](extra_3_04_Exercises_8.md) | / | / | / |
| [MPI Topics on the HPE Cray EX Supercomputer](extra_3_05_Cray_MPI_on_Slingshot.md) | [lumi](extra_3_05_Cray_MPI_on_Slingshot.md) | / | [lumi](extra_3_05_Cray_MPI_on_Slingshot.md) |
| [Exercises #9](extra_3_06_Exercises_9.md) | / | / | / |
| [AMD Debugger: ROCgdb](extra_3_07_AMD_ROCgdb_Debugger.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-3_07_AMD_ROCgdb_Debugger.pdf) | / | [web](extra_3_07_AMD_ROCgdb_Debugger.md) |
| [Exercises #10](extra_3_08_Exercises_10.md) | / | / | / |
| [Introduction to ROC-Profiler (rocprof)](extra_3_09_Introduction_to_Rocprof_Profiling_Tool.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-3_09_Introduction_to_Rocprof_Profiling_Tool.pdf) | / | [web](extra_3_09_Introduction_to_Rocprof_Profiling_Tool.md) |
| [Exercises #11](extra_3_10_Exercises_11.md) | / | / | / |
| [Performance Optimization: Improving single-core Efficiency](extra_4_01_Performance_Optimization_Improving_Single_Core.md) | [lumi](extra_4_01_Performance_Optimization_Improving_Single_Core.md) | / | [lumi](extra_4_01_Performance_Optimization_Improving_Single_Core.md) |
| [Python and Frameworks](extra_4_02_Introduction_to_Python_on_Cray_EX.md) | [lumi](extra_4_02_Introduction_to_Python_on_Cray_EX.md) | / |[lumi](extra_4_02_Introduction_to_Python_on_Cray_EX.md) |
| [Exercises #12](extra_4_03_Exercises_12.md) | / | / | / |
| [Optimizing Large Scale I/O](extra_4_04_IO_Optimization_Parallel_IO.md) | [lumi](extra_4_04_IO_Optimization_Parallel_IO.md) | / | [lumi](extra_4_04_IO_Optimization_Parallel_IO.md) |
| [Exercises #13](extra_4_05_Exercises_13.md) | / | / | / |
| [Introduction to OmniTrace](extra_4_06_AMD_Ominitrace.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-4_06_AMD_Omnitrace.pdf) (until p. 61) | / |  [web](extra_4_06_AMD_Ominitrace.md) |
| [Exercises #14](extra_4_07_Exercises_14.md) | / | / | / |
| [Introduction to Omniperf](extra_4_08_AMD_Ominiperf.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-4_06_AMD_Omnitrace.pdf) (from p. 62) | / |  [web](extra_4_08_AMD_Ominiperf.md) |
| [Exercises #15](extra_4_09_Exercises_15.md) | / | / | / |
| [Tools in Action - An Example with Pytorch](extra_4_10_Best_Practices_GPU_Optimization.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-4_10_Best_Practices_GPU_Optimization.pdf) | / | [web](extra_4_10_Best_Practices_GPU_Optimization.md) |
| [LUMI User Support](extra_4_11_LUMI_Support_and_Documentation.md) | [web](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-4_11_LUMI_Support_and_Documentation.pdf) | / | [web](extra_4_11_LUMI_Support_and_Documentation.md) |


## Making the exercises after the course

### HPE

The exercise material remains available in the course archive on LUMI:

-   The PDF notes in `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.pdf`

-   The other files for the exercises in either a
    bzip2-compressed tar file `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2` or
    an uncompressed tar file `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar`.

To reconstruct the exercise material in your own home, project or scratch directory, all you need to do is run:

```
tar -xf /appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_HPE.tar.bz2
```

in the directory where you want to work on the exercises. This will create the `exercises/HPE` subdirectory
from the training project. 

However, instead of running the `lumi_c.sh` or `liumi_g.sh` scripts that only work for the course as 
they set the course project as the active project for Slurm and also set a reservation, use the
`lumi_c_after.sh` and `lumi_g_after.sh` scripts instead, but first edit them to use one of your
projects.


### AMD 

There are [online notes about the AMD exercises](https://hackmd.io/@gmarkoma/lumi_training_ee).
A [PDF print-out with less navigation features is also available](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.pdf)
and is particularly usefull should the online notes become unavailable.

The other files for the exercises are available in 
either a bzip2-compressed tar file `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD_.tar.bz2` or
an uncompressed tar file `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar` and can also be downloaded. 
( [bzip2-compressed tar download](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2) or 
[uncompressed tar download](https://462000265.lumidata.eu/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar))

To reconstruct the exercise material in your own home, project or scratch directory, all you need to do is run:

```
tar -xf /appl/local/training/4day-20230530/files/LUMI-4day-20230530-Exercises_AMD.tar.bz2
```

in the directory where you want to work on the exercises. This will create the `exercises/AMD` subdirectory
from the training project. You can do so in the same directory where you installed the HPE exercises.

The software that was installed in the training project is also available as a bzip2-compressed tar archive
on LUMI as `/appl/local/training/4day-20230530/files/LUMI-4day-20230530-Software_AMD.tar.bz2`. You can install it in the
same directory where you installed the files but beware when interpreting instructions as the path to the
software installation is different now.

!!! Warning
    The software and exercises were tested thoroughly at the time of the course. LUMI however is in
    continuous evolution and changes to the system may break exercises and software


## Links to documentation

[The links to all documentation mentioned during the talks is on a separate page](documentation.md).


## External material for exercises

Some of the exercises used in the course are based on exercises or other material available in various GitHub repositories:

-   [OSU benchmark](https://mvapich.cse.ohio-state.edu/download/mvapich/osu-micro-benchmarks-5.9.tar.gz)
-   [Fortran OpenACC examples](https://github.com/RonRahaman/openacc-mpi-demos)
-   [Fortran OpenMP examples](https://github.com/ye-luo/openmp-target)
-   [Collections of examples in BabelStream](https://github.com/UoB-HPC/BabelStream)
-   [hello_jobstep example](https://code.ornl.gov/olcf/hello_jobstep)
-   [Run OpenMP example in the HPE Suport Center](https://support.hpe.com/hpesc/public/docDisplay?docId=a00114008en_us&docLocale=en_US&page=Run_an_OpenMP_Application.html)
-   [ROCm HIP examples](https://github.com/ROCm-Developer-Tools/HIP-Examples)

