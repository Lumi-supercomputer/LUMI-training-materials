# Loading training data from Lustre and LUMI-O

*Presenter:* Harvey Richardson (HPE)


## Extra materials

-   [Presentation slides](https://462000265.lumidata.eu/ai-20240529/files/LUMI-ai-20240529-11-Training_Data_on_LUMI.pdf)

-   Links from the "More Information" slide:

    -   [LUMI-O in the LUMI documenatation](https://docs.lumi-supercomputer.eu/storage/lumio/)

    -   [Generic Tutorial on reading large datasets](https://www.kaggle.com/code/rohanrao/tutorial-on-reading-large-datasets)

    -   [Best Practice for Data Formats in Deep Learning (SURF)](https://servicedesk.surf.nl/wiki/display/WIKI/Best+Practice+for+Data+Formats+in+Deep+Learning)

    -   [Ray data loading](https://docs.ray.io/en/latest/train/user-guides/data-loading-preprocessing.html)

    -   [Pytorch Tutorial on pre-defined datasets/dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)

    -   Example of keeping training data in memory: 
        [“Scaling Out Deep Learning Convergence Training on LUMI”, Diana Moise & Samuel Antao](https://linklings.s3.amazonaws.com/organizations/pasc/pasc23/submissions/stype119/jvCyu-msa152s2.pdf)


## Q&A

/
