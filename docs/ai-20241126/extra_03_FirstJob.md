# Your first training job on LUMI

*Presenters:* Mats Sj√∂berg (CSC) and Lukas Prediger (CSC)

Content:

-   Using LUMI via the command line
-   Submitting and running AI training jobs using the batch system


<!--
<video src="https://462000265.lumidata.eu/ai-20241126/recordings/03_FirstJob.mp4" controls="controls"></video>
-->


## Extra materials

-   [Presentation slides](https://462000265.lumidata.eu/ai-20241126/files/LUMI-ai-20241126-03-First_AI_job.pdf)

-   [Hands-on exercises](E03_FirstJob.md)

-   [More extensive training materials on Slurm from the recent introductory "Supercomputing with LUMI" course from May 2024](https://lumi-supercomputer.github.io/LUMI-training-materials/2day-20240502/)

    -   A more detailed introduction to Slurm but without AI-specific examples is given in the 
        ["Slurm on LUMI" presentation](https://lumi-supercomputer.github.io/LUMI-training-materials/2day-20240502/extra_06_Slurm/).
        It also discusses the `sacct` command that can be used to get at least some resource use info
        from jobs.

    -   The presentation ["Process and Thread Distribution and Binding"](https://lumi-supercomputer.github.io/LUMI-training-materials/2day-20240502/extra_07_Binding/)
        is more oriented towards traditional HPC codes, but the discussion on a proper mapping
        of GPU dies onto CPU chiplets is also relevant for AI applications. But that is a discussion
        for the second day of this course/workshop.


## Q&A

/
