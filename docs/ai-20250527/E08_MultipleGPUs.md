# Hands-on: Converting the PyTorch single GPU AI training job to use all GPUs in a single node via DDP

<!--
[Exercises on the course GitHub](https://github.com/Lumi-supercomputer/Getting_Started_with_AI_workshop/tree/ai-20250527/08_Scaling_to_multiple_GPUs).
-->
<!--
[Exercises on the course GitHub](https://github.com/Lumi-supercomputer/Getting_Started_with_AI_workshop/tree/main/08_Scaling_to_multiple_GPUs).
-->

<!--
A video recording of the discussion of the solution will follow.
-->

<!--
<video src="https://462000265.lumidata.eu/ai-20250527/recordings/E08_MultipleGPUs.mp4" controls="controls"></video>
-->

## Q&A

/

